World J Surg (2017) 41:1935–1942 
DOI 10.1007/s00268-017-3974-y 






Published online: 7 March 2017 
(cid:2) Socie´te´ Internationale de Chirurgie 2017 
Abstract 
Background Availability of surgical site infection (SSI) surveillance rates challenges clinicians, healthcare admin- 
istrators and leaders and the public. The purpose of this report is to demonstrate the consequences patient self- 
assessment strategies have on SSI reporting rates. 
Methods We performed SSI surveillance among patients undergoing general surgery procedures, including tele- 
phone follow-up 30 days after surgery. Additionally we undertook a separate validation study in which we compared 
patient self-assessments of SSI with surgeon assessment. Finally, we performed a meta-analysis of similar validation 
studies of patient self-assessment strategies. 
Results There were 22/266 in-hospital SSIs diagnosed (8.3%), and additional 16 cases were detected through the 
30-day follow-up. In total, the SSI rate was 16.8% (95% CI 10.1–18.5). In the validation survey, we found patient 
telephone surveillance to have a sensitivity of 66% (95% CI 40–93%) and a speciﬁcity of 90% (95% CI 86–94%). 
The meta-analysis included ﬁve additional studies. The overall sensitivity was 83.3% (95% CI 79–88%), and the 
overall speciﬁcity was 97.4% (95% CI 97–98%). Simulation of the meta-analysis results divulged that when the true 
infection rate is 1%, reported rates would be 4%; a true rate of 50%, the reported rates would be 43%. 
Conclusion Patient self-assessment strategies in order to fulﬁll 30-day SSI surveillance misestimate SSI rates and 
lead to an erroneous overall appreciation of inter-institutional variation. Self-assessment strategies overestimate SSIs 
rate of institutions with high-quality performance and underestimate rates of poor performance. We propose such 
strategies be abandoned. Alternative strategies of patient follow-up strategies should be evaluated in order to provide 
valid and reliable information regarding institutional performance in preventing patient harm. 
Vered Richter and Matan J. Cohen have contributed equally to this 
work. 



1 Center for Clinical Quality and Safety, Hadassah-Hebrew 
University Medical Center, POB 12000, 91120 Jerusalem, 
Israel 

Diseases, Hadassah-Hebrew University Medical Center, 
Jerusalem, Israel 

Surgery Department, Hadassah-Hebrew University Medical 
Center, Jerusalem, Israel 
Surgical site infections (SSIs) are the most common 
nosocomial infection in surgical wards and the second 
most common within hospitals [1]. The consequences of 
SSIs include longer hospitalizations, readmissions post- 
discharge, further testing, extended antibiotic treatment, 
prolonged suffering for the patient, additional work loss 
days and increased mortality [2]. SSIs are estimated to be 
the cause of death in 38–75% of post-operative mortality 
cases and are associated with very high economic costs 
[1–4]. 




There are many factors that pre-determine the potential 
for developing an SSI; some are patient-related while 
others are related to the surgical procedure and its environs. 
However, it is well accepted that many infections can be 
prevented by implementation of well-known, evidence- 
based bundles [5, 6]. SSIs incidence serves as a quality 
measure in evaluating hospital performance [7]. 
When creating such measures for the purpose of com- 
parison between medical institutions, a uniform deﬁnition 
of SSIs is needed and confounding factors such as the 
preoperative risk of infection must be controlled. The 
CDC’s criteria deﬁne a SSI as an infection that appears in 
the incision within one month after the operation or within 
one year if an implant was left in place [8]. Additionally, a 
signiﬁcant proportion of SSI becomes evident after patient 
discharge. Therefore, in order to assess 30-day incidence of 
SSIs, patient follow-up is necessary after discharge [9, 10]. 
Variation in the methods employed to ascertain the exis- 
tence of infection after discharge could account for varia- 
tion in SSI incidence rates and provide disservice to quality 
initiatives that aim to decrease outcome variation and drive 
through competition between healthcare 
improvement 
service providers. 
Patient follow-up strategies include clinic follow-up and 
surgeon/physician diagnoses of SSIs. Another option 
would be to follow-up hospital readmission and referrals to 
emergency rooms, assuming the at 
least deep-wound 
infections would necessitate medical attention to those 
ends. These two strategies for follow-up are prone to 
selection bias and are dependent on varying diagnostic 
practices of doctors. Independent committees of healthcare 
professionals have also been proposed, though they asso- 
ciated with greater institutional resource consumption and 
can lead to tensions with the surgical staff under scrutiny 
[11, 12]. 
Patient self-assessment strategies and either patient 
sampling or complete follow-up have also been proposed. 
Using standard questions, patient responses could be con- 
sistent in their level of accuracy and relative to other 
strategies; these might consume less institutional resources 
to meet the ends of surveillance. Previous studies have 
tested the patient’s ability to detect the presence or absence 
of SSI. They are limited in number and used various 
methods of self-evaluation. In these studies, the speciﬁcity 
was 92–99% while the sensitivity was 52–90% [9, 13–16]. 
This report resulted from a survey to measure and 
implement continuous surveillance of SSI rates. To that 
end, we instituted post-discharge surveillance via telephone 
calls to discharged patients. We tested the reliability of the 
patients’ self-assessment survey by performing a validation 
survey and additionally performed a meta-analysis 
including our results and previous surveys of patient self- 
assessment. 


We conducted two complementing studies: a prospective 
observational surgical site infection surveillance survey 
and a validation study to assess the reliability of telephone 
follow-up for the diagnosis of post-discharge surgical site 
infections. 
We used the SSI diagnosis criteria as deﬁned by the US 
Centers for Disease Control. SSIs were divided into three 
categories: superﬁcial infection, deep infection or infection 
of an organ or cavity that were related to the surgery [8]. 
Surgery was classiﬁed as clean, clean-contaminated, con- 
taminated or dirty [6, 17]. 

The study population was comprised of all patients who 
underwent an elective surgery in the general surgery wards 
of the Hadassah Ein-Kerem University Hospital between 
the months of August and November 2007. Patients who 
underwent anal surgery or collaborative surgery (for 
example, involving urologist or gynecologist) were exclu- 
ded. In the event that a single patient underwent more than 
one surgery during the above period of time, only the ﬁrst 
operation was included in the study. The survey included 
in-hospital and post-discharge surveillance. 
During hospitalization, a registered nurse ﬁlled out daily 
a standardized form pertaining to each patient, using data 
from the patient’s written and computerized records. Dur- 
ing daily morning rounds, the house surgeons ﬁlled out a 
surveillance table and documented the wound characteris- 
tics. In the event that an infection was detected, it was 
recorded as superﬁcial, deep or surgical organ/cavity 
infection. 
A surveyor conducted a telephone survey 30 days post- 
discharge, using a standardized surveillance form. The 
patient was asked if there were any problems pertaining 
to the surgical incision. In the event that he responded in 
the afﬁrmative, he was questioned regarding redness, 
serous exudate, purulent exudate, spontaneous or physi- 
the wound edges, culture 
cian assisted separation of 
obtainment, antibiotic treatment and hospital 
referral/ 
readmission. An SSI was deﬁned by the CDC criteria, 
based on the information gathered. Patients, who were 
diagnosed with SSI prior to discharge, were not ques- 
tioned by phone. 
Additional data recorded included age, sex, pre-surgery 
blood glucose (below/above 150mb/dL), American Society 
of Anesthesiologists (ASA) score, surgery type (elective/ 
urgent), length of surgery, pre-surgery antibiotics. We also 
determined the National Healthcare Surveillance Network 
(NHSN) risk index for each patient [1]. 








Female gender 
Cr [ 150 lmol/L 
Glucose [150 mg/dl 


2 
3 











115 (43.2%) 
37 (13.9%) 




We conducted a separate study to determine the reliability 
of the telephone survey. In this study, we compared the 
telephone survey results with the report from examination 
by a surgeon the following day. 
The study included patients who underwent surgery in 
the general surgery department at Hadassah Ein-Kerem 
between the months of November 2007 and March 2008, 
excluding anal and collaborative surgery, and who were 
scheduled for follow-up in the surgical clinic. Data on 
patients, who visited the clinic more than once during the 
study period, were collected only from their ﬁrst visit, and 
all other visits were excluded. Patients whose clinic visit 
was more than a day after the telephone survey were 
excluded from the study. Patients who were informed by a 
medical authority that they had a SSI prior to their clinic 
visit were excluded from the study. 
The telephone survey, which utilized an identical form 
to the one in the Surgical site infection surveillance survey, 
was conducted on the evening prior to the scheduled clinic 
follow-up by a single surveyor. 
On the next day, the patient was examined in the out- 
patient clinic by a surgeon who determined whether or not 
they had an SSI. The surgeon ﬁlled out the surgical wound 
assessment form and indicated whether there was an 
infection and if so, its type. The form used was identical to 
the one used during in-hospital surveillance. The surgeon 
was unaware of the results of the telephone survey con- 
ducted the day before. In event that patients visited the 
clinic and did not have a form ﬁlled out by the surgeon, the 
written documentation on the visit was inspected to 
abstract relevant data. The telephone survey results were 
compared with the surgeon reports, using the results of the 
surgeon’s examination as the gold standard. 


The proportion of patients who contracted at least one SSI 
was calculated with a 95% conﬁdence interval. 

McNemar’s test was used to test whether there was a sig- 
niﬁcant difference in the distribution between the telephone 
survey and the surgeon’s diagnosis. Estimates of sensitivity 
and speciﬁcity were generated with the surgical diagnosis 
serving as the gold standard repetition. We also collected 
additional studies in the literature that assessed patients’ 
self-diagnosis of surgical site infections. A meta-analysis 
was conducted to summarize these measures. The pooled 
sensitivity and speciﬁcity measures were weighted by study 
size, and we tested for heterogeneity (I2) of the measures 
within the relevant studies. 
Finally, we evaluated the effects of self-assessment of 
the reported SSI rates by inferring the diagnostic charac- 
teristics of patients’ self-assessment from our study and 
from the meta-analysis. 
The study was performed with approval from the insti- 
tutional ethical board for performance of quality surveys. 


The survey included 266 patients who underwent surgical 
procedures. Seventeen patients have been excluded from 
the survey: 13 because of an excluded surgery type (anal 
and collaborative) and four due to readmissions. During the 
study period, one patient died a month after small bowel 
resection, due to disseminated metastatic disease. 

Patient characteristics are presented in Table 1. The 
most prevalent 
surgery was bowel/stomach/ 
esophagus (26.7%) followed by inguinal hernia repair 
(23.7%). Most operations were elective (72.9%) and non- 
laparoscopic (80.1%). The average surgery duration was 
1.6 h (SD = 1.2). Prophylactic antibiotics were provided 
to 134 (50%) of the patients within an hour prior to the 
surgery. 
During hospital stay, 22 of the 266 patients (8.3%) 
developed an SSI while the remaining 244 (91.7%) 
underwent the telephone survey a month post-surgery. 
Of the 244 telephone surveys conducted, 204 surveys 





SSI detected during hospital stay 
n = 22 
N (%) 
Additional SSI detected after discharge 
n = 16 
N (%) 


Organ/space SSI 
Unknown 


3 (13.6%) 
1 (4.5%) 


2 (12.5%) 
0 
Total 
n = 38 
N (%) 


5 (13.1%) 
1 (2.6%) 



Not infected 
N (%) 

Not infected N (%) 
Infected N (%) 




Infected 
N (%) 
















Telephone interview to all 
patients by research 
nurse 10, 20, 30 days 
post-surgery 
Research nurse; all patients identifying 
problems and 10% of those who did 
not were visited by a trained research 
nurse 


Assessed weekly by experienced 
infection control nurses (ICNs) 























Whitby et al. 
[14]—non- 
educated 
patients 
Whitby et al. 
[14]— 
educated 
patients 










Questionnaire (?Mailed 
surgeon Questionnaire) 
records with codes indicative of SSIs, 
which were then conﬁrmed by record 
review by ICPs 
Seaman and 
Lammers 
[15] 


















Current 
report 




















* p = 0.012; ** p \ 0.001 for heterogeneity 
a Sensitivities and speciﬁcities are presented as reported. In events of arithmetic discrepancies, please refer to the original publications 
(84%) yielded data and 40 surveys (16%) were unfruit- 
ful; 21 (8.6%) due to lack of coordination between the 
members of the research project and 19 (7.8%) due to 
in completing the survey (the 
technical difﬁculties 
patient was unavailable or had no common language 
In the telephone survey, 16/204 
with the surveyor). 








Sensitivity = 0.67 
True positive responses 
1-speciﬁcity = 0.1 
False positive responses 
Sensitivity = 0.83 
True positive responses 
1-speciﬁcity = 0.03 
False positive responses 















































































patients (7.8%) reported positively to questions con- 
ﬁrming they had SSIs. 
There were no differences in patient characteristics of 
age, sex, creatinine level, glucose level and ASA index 
between those who participated in the telephone survey and 
those who did not. A higher percentage of patients who 
underwent telephone survey, 116 (56.8%), received pro- 
phylactic antibiotics on time (within an hour prior to sur- 
gery) compared to those who did not participate in the 
survey, 11 (27.5%); p = 0.005. 
In total, 16.8% (38/226) of the patients experienced a 
SSI (95% CI 10.1 to 18.5). SSI depth distribution is pre- 
sented in Table 2. The 40 patients with missing data on the 
telephone survey provide a range of error for the overall 
rate of SSI in our population: between 29% (if all 40 had 
SSIs) and 10% (if none of the 40 had SSIs). 
Of the 16 patients with SSI detected through the tele- 
phone survey, ﬁve (31%) were re-hospitalized within less 
than a month; three (19%) due to an SSI (two superﬁcial 
infections and one in an organ). One patient (6%) was 
hospitalized due to fever of unknown origin and another 
patient (6%) due to erythema, swelling and induration at 
the incision site, not thought to be an infection. 
During the telephone survey, there were no reports of 
admissions to other hospitals in Israel. Two patients (12%) 
came to the emergency room and were treated with 
antibiotics, due to suspected SSI. One patient (6%) went to 
an emergency department of a hospital in France and was 
treated there with antibiotics, due to a deep wound 
infection. 

The survey included 329 telephone contacts among post- 
the 
surgery patients, up-to one month after surgery at 
general surgery department. Of these, 263 fulﬁlled all cri- 
teria and were included in the study; 33 patients who 
participated in the telephone survey failed to appear for 
clinic follow-up the next day, 24 patients appeared in the 
survey more than once and only their ﬁrst visit to the clinic 
was included, seven patients visited the clinic but had no 
surgical incision assessment form on ﬁle and no report on 
the surgical incision was found in the medical record or 
was available and two patients were hospitalized due to SSI 
and were not included in the survey analysis. 


Among the completed telephone reports, 198 (75.3%) 
were compared to the surgical incision assessment form 
and 65 (24.7%) were compared to the surgeon’s report in 
the patient’s medical record. 
A comparison of the telephone survey and the surgeon’s 
exam is presented in Table 3. Of the 251 patients who were 
not diagnosed with an SSI, 226 patients answered that there 
was no SSI. This translates to a speciﬁcity of 90% (95% CI 
86–94%) for patient self-assessment on a telephone survey. 
Of the 12 patients classiﬁed by the surgeon as having a SSI, 
eight answered on the survey that they had an SSI, with a 
sensitivity of 66.7% (95% CI 40–93%). We also calculated 
the positive likelihood ratio (95% CI) to be 6.7 (3.9–11.5) 
and the negative likelihood ratio (95% CI) to be 0.37 



Reilly, Whitby, Sands and Seaman all found sensitivity 
measures similar to the one found in the present study 
[9, 13–15]. The sensitivity found in Mitchell’s study is 
higher than the one found by us [16]. In this study, a 
number of SSIs identiﬁed by patients but not by the sur- 
geon were reevaluated and classiﬁed as SSIs. Seaman 
found speciﬁcity similar to ours, but all the other studies 
found higher speciﬁcities [15]. 
We performed a meta-analysis of these studies and ours. 
The results are presented in Table 4. The overall sensitivity 
is 83.3% (95% CI 79–88%), and the overall speciﬁcity is 
97.4% (95% CI 97–98%). There is much variability 
between the studies with statistically signiﬁcant hetero- 
(p = 0.012, 
and 
sensitivity 
for 
geneity 
p \ 0.001, respectively). 

In Table 5, we provide the results of simulating the effects 
of self-assessment inaccuracies on reported post-discharge 
SSI rates. The higher the true rate, the greater the ratio of true 
positive events versus false positive events. For examples, 
when the true infection rate is 1%, reported rates would be 
anywhere between 4 and 11% (range between our local results 
and meta-analysis); when the true rate is 50%, reported rates 
would range between 39 and 43%. Both the results of our 
validation survey of patient self-assessment and the results of 
the meta-analysis demonstrate that when the true post-dis- 
charge SSI rate is lower than 15%, the self-assessment inac- 
curacies lead to overestimation of the true SSI rate (the ratio of 
true rate vs. reported rate is below 1.0). Figure 1 demonstrates 
the error of SSI rate estimation using patient self-assessment 
using our institutional ﬁndings of the pooled results from the 
meta-analysis. In either case, rate estimation error reduced the 
variation between reported rates. 

In this report, we present a survey measuring our institu- 
tions 30-day post-surgical SSI rate, using telephone follow- 
up. The in-hospital SSI rate was 8.3%, and the telephone 
survey measured a 7.8% SSI rate among patients who were 
followed through the telephone survey. In order to evaluate 
the reliability of the telephone follow-up, we conducted a 
study comparing patient telephone responses to surgeon 
clinic assessment. In this study, we found that patient 
response had a sensitivity of 67% and a speciﬁcity of 90% 
(LR? 6.7, LR- 0.37). Additionally we performed a sys- 
tematic review of studies assessing patient self-report of 
SSIs. The overall sensitivity was 83% and the overall 
speciﬁcity 97%. However, signiﬁcant heterogeneity was 
found between the studies. 
There is an inherent paradox regarding the use of self- 
reported schemes for diagnosis of SSIs, assuming that 
surgeon clinical assessment is the gold standard. Given any 
(0.17–0.82). The probability of agreement was statistically 
signiﬁcant (p value \0.001), and the kappa (95% CI) was 
calculated to be 0.31 (0.13–0.49). We repeated the analyses 
with stratiﬁcation for the source of information (surgical 
incision assessment form vs. surgeon’s report in medical 
record), and this yielded similar results. 

We found ﬁve studies that examined the reliability of post- 
discharge surveillance and published their data so that 
speciﬁcity and sensitivity could be calculated and com- 
pared to the ﬁndings in our study. Table 4 summarizes the 
ﬁndings. Of the ﬁve studies reviewed, three were con- 
ducted by a mailed questionnaire and two by a phone 
interview with the patient. Reilly’s phone study was con- 
ducted by one nurse [13], while Seaman and Lammers [15] 
conducted their survey using a number of surveyors. In all 
of the studies, except Mitchell’s, the gold standard included 
a physical exam by a medical professional but not a 
physician [16]. None of the studies state the number of 
days that elapsed from the home survey to the gold stan- 
dard exam. Sands, Whitby and Mitchell used a wide patient 
population from a number of 
surgical departments 
[9, 14, 16]. Seaman and Lammers [15] only included 
patients with lacerations treated at A&E. Reilly et al.’s [13] 
study population comprised of patients who underwent 
orthopedic surgeries. 

Fig. 1 SSI rate estimation error. The dotted line presents an ideal 
surveillance tool reporting the exact SSI rate. The solid line presents 
the rate reported of a surveillance tool with a sensitivity of 83% and 
a speciﬁcity of 97%, corresponding to the results of the meta- 
analysis. The dashed line presents the rate reported of a surveillance 
tool with a sensitivity of 67% and a 90% of 
speciﬁcity, 
corresponding to the results of our institutional study 


set of self-assessment test characteristics, the lower the true 
SSI rate, the greater the false positive rate of self-assess- 
ment, compared to true positives. Extrapolating our ﬁnd- 
ings, assuming that among patients discharged from our 
institution there would indeed have occurred another 22 
SSI cases, 37 patients in the telephone follow-up would 
have reported SSI, of which 15 would have been true 
positives and 22 would have been false positives. Using the 
meta-analysis data, the respective numbers would have 
been 25 SSI reports in total, 18 true positives and 7 false 
positives. Table 5 demonstrates the expected true positive 
and false positive count given increasing true SSI rates for 
cohorts of 1000 hypothetical post-surgical patients. 
The rate of infection differs across hospitals, surgeons, 
patients and types of surgery. The American National 
Nosocomial Infection Survey (NNIS) held during the years 
1992–2004 found SSI rates to range from 0.67% to 4.97% in 
general surgery operations, depending on the type of surgery 
and on the NNIS Risk Index [1]. In a review conducted by 
Holtz covering the years 1967–1990, SSI rates differed 
dramatically between studies, ranging from 22.3% in a 
report on appendectomies to 2.5% in a study that included all 
types of surgery. Research that included only general sur- 
gery cases identiﬁed an SSI rate of 13.5% [18]. Weiss’ study 
conducted in Minnesota in the years 1993–1998 showed a 
3.2% infection rate in general surgery operations [19]. In 
contrast, the SSI rate for general surgery operations, reported 
by London hospitals in 2004, ranged from 12.6–19.3%. 
Weinwurm’s study, conducted in 2002–2004 in Canada, 
exclusively on bowel surgeries, showed a SSI rate of 23% 
[20]. The rate of SSIs reported in Thailand for general sur- 
gery, vascular, orthopedics and obstetrics-gynecology 
operations in the years 2003–2004 was 1.4% [21]. In Bolivia, 
in 1999 the SSI rate in general surgery, orthopedics and 
obstetrics-gynecology operations was 12% [22]. Follow-up 
surveillance only adds to this array of results. Interestingly, it 
will generally lead to an underestimation of the true vari- 
ability. The inaccuracies will necessarily overestimate the 
rate of institutions with low rate and underestimate the 
results of institutions with high rates. 
In contrast, assuming post-discharge diagnosis was 
accurate, not counting these events would lead to an 
underestimation of the true SSI rates [3]. Not all hospitals 
routinely monitor the incidence in SSIs for a full month; 
this includes our institution, where a month of surveillance 
is not standard practice. 
Reilly studied the effect of post-discharge surveillance 
on SSI rates and found that the group that had post-dis- 
charge follow-up had a signiﬁcantly higher SSI rate when 
compared to the group with no post-discharge surveillance 
[23]. In a review by Holtz, 68% of SSIs following general 
surgery operations were detected after discharge from the 
ward. In other types of surgery, the rate of SSIs detected 
post-discharge ranges between 13 and 71% in different 
studies [18]. In Weinwurm’s study, the SSI rate during 
hospitalization was 15% and the post-discharge SSI rate 
was 8% [20]. Another study, conducted in Thailand, found 
that 27.6% of SSIs were detected post-discharge [21]. 
Therein lies the paradox, no follow-up means that there 
is underestimation of institutions’ SSI rates. Inaccurate 
follow-up leads to ﬂawed estimations which decreased the 
observed variability between institutions. 


Reporting quality measures, among them SSI rates, is 
becoming standard. Like other quality improvement initia- 
tives, it is intended to aid healthcare providers to direct 
attention to preventable harm to patients and thus improve 
like other quality 
outcomes and service. However, 
improvement initiatives, controversy and practical difﬁcul- 
ties exist. In this report, we focus on two elements of SSI 
surveillance—post-discharge 
complete 
30-day SSI ascertainment and the use of patient self-report to 
diagnose post-discharge SSIs. Though 30-day post-dis- 
charge follow-up is necessary to estimate the TRUE SSI 
rates, this is not the aim of SSI surveillance. We demonstrate 
in this report how patient follow-up using self-report pro- 
vides a disservice to the quality improvement cause. Even if 
standardization of patient self-report is achieved, institutions 
with better performance will have overestimation of their 
rates. As we commented with regard to CLABSI surveil- 
lance [24], methodology can lead to improvement disin- 
centives, especially when inter-institution comparisons and 
public reporting are competitive considerations. A system- 
atic review of various post-discharge telephone follow-up 
interventions, not limited to infection surveillance, con- 
cluded with similar ﬁndings [25]. 
Promotion of post-discharge surveillance of deep wound 
infections alone is a reasonable approach and likely less 
prone to diagnostic uncertainty and interpretation, and their 
occurrence is expected to be a notable event. We believe 
that our results support this course of action. However, 
appropriate investigations should examine potential pitfalls 
is such surveillance and assess their validity and reliability 
for quality surveillance, follow-up and comparisons. As 
mentioned above, professional 
independent committees 
could be charged with surveillance, though appropriate 
organizational action should facilitate their acceptance 
among surgical staff and plan to prevent disruptive 
behavior within the institutions [12]. 

1. National Nosocomial Infections Surveillance (NNIS) System 
Report (2004). Data summary from January 1992 through June 
2004, issued October 2004. Am J Infect Control 32(8):470–485 
2. Perencevich EN, Sands KE, Cosgrove SE, Guadagnoli E, Meara 
E, Platt R (2003) Health and economic impact of surgical site 



infections diagnosed after hospital discharge. Emerg Infect Dis 
9(2):196–203 
3. Gastmeier P (2006) Postdischarge surveillance for surgical site 
infection: the continuing challenge. Infect Control Hosp Epi- 
demiol 27(12):1287–1290 
4. Haley RW, Culver DH, White JW, Morgan WM, Emori TG, 
Munn VP et al (1985) The efﬁcacy of infection surveillance and 
infections in US 
control programs in preventing nosocomial 
hospitals. Am J Epidemiol 121(2):182–205 
5. Anderson DJ, Kaye KS, Classen D, Arias KM, Podgorny K, 
Burstin H et al (2008) Strategies to prevent surgical site infec- 
tions in acute care hospitals. Infect Control Hosp Epidemiol 
29(Suppl 1):S51–S61 
6. Anderson DJ, Podgorny K, Berrios-Torres SI, Bratzler DW, 
Dellinger EP, Greene L et al (2014) Strategies to prevent surgical 
site infections in acute care hospitals: 2014 update. Infect Control 
Hosp Epidemiol 35(6):605–627 


8. Horan TC, Gaynes RP, Martone WJ, Jarvis WR, Emori TG 
(1992) CDC deﬁnitions of nosocomial surgical site infections, 
1992: a modiﬁcation of CDC deﬁnitions of surgical wound 
infections. Infect Control Hosp Epidemiol 13(10):606–608 
9. Sands K, Vineyard G, Platt R (1996) Surgical site infections 
occurring after hospital discharge. J Infect Dis 173(4):963–970 
10. Consensus paper on the surveillance of surgical wound infections 
(1992) The Society for Hospital Epidemiology of America; The 
Association for Practitioners in Infection Control; The Centers for 
Disease Control; The Surgical Infection Society. Infect Control 
Hosp Epidemiol 13(10):599–605 
11. Mertz D, Whitlock R, Kokoszka AY, Smith SW, Carignan A, 
Rehan M et al (2016) Routine surveillance versus independent 
assessment by an outcome adjudication committee in assessing 
patients for sternal surgical site infections after cardiac surgery. 
Infect Control Hosp Epidemiol 37(5):600–602 
12. Talbot TR, Bratzler DW, Carrico RM, Diekema DJ, Hayden MK, 
Huang SS et al (2013) Public reporting of health care-associated 
surveillance data: recommendations from the healthcare infection 
control practices advisory committee. Ann Intern Med 159(9):631– 
635 
13. Reilly J, Noone A, Clift A, Cochrane L, Johnston L, Rowley DI 
et al (2005) A study of telephone screening and direct observation 
of surgical wound infections after discharge from hospital. J Bone 
Joint Surg Br 87(7):997–999 
14. Whitby M, McLaws ML, Doidge S, Collopy B (2007) Post-dis- 
charge surgical site surveillance: does patient education improve 
reliability of diagnosis? J Hosp Infect 66(3):237–242 


16. Mitchell DH, Swift G, Gilbert GL (1999) Surgical wound 
infection surveillance: the importance of infections that develop 
after hospital discharge. Aust N Z J Surg 69(2):117–120 
17. Woods RK, Dellinger EP (1998) Current guidelines for antibiotic 
prophylaxis of surgical wounds. Am Fam Phys 57(11):2731–2740 
18. Holtz TH, Wenzel RP (1992) Postdischarge surveillance for 
nosocomial wound infection: a brief review and commentary. Am 
J Infect Control 20(4):206–213 
19. Weiss CA 3rd, Statz CL, Dahms RA, Remucal MJ, Dunn DL, 
Beilman GJ (1999) Six years of surgical wound infection 
surveillance at a tertiary care center: review of the microbiologic 
and epidemiological aspects of 20,007 wounds. Arch Surg 
134(10):1041–1048 
20. Weinwurm D (2005) Surveillance of selected bowel surgeries for 
surgical site infection (SSI) rates in-hospital plus post-discharge. 
Am J Infect Control 33(5):e169 
21. Kasatpibal N, Jamulitrat S, Chongsuvivatwong V (2005) Stan- 
dardized incidence rates of surgical site infection: a multicenter 
study in Thailand. Am J Infect Control 33(10):587–594 
22. Soleto L, Pirard M, Boelaert M, Peredo R, Vargas R, Gianella A 
et al (2003) Incidence of surgical-site infections and the validity 
of the National Nosocomial Infections Surveillance System risk 
index in a general surgical ward in Santa Cruz, Bolivia. Infect 
Control Hosp Epidemiol 24(1):26–30 
23. Reilly J, Allardice G, Bruce J, Hill R, McCoubrey J (2006) 
Procedure-speciﬁc surgical site infection rates and postdischarge 
surveillance in Scotland. 
Infect Control Hosp Epidemiol 
27(12):1318–1323 
24. Cohen MJ, Benenson S (2011) Surveillance quality in reporting 
nosocomial bloodstream infection rates. JAMA 305(8):779–80; 
author reply 80 
25. Mistiaen P, Poot E (2006) Telephone follow-up, initiated by a 
hospital-based health professional, for postdischarge problems in 
patients discharged from hospital to home. Cochrane Database 
Syst Rev (4):CD004510 

