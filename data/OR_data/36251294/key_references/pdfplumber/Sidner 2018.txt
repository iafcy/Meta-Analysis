17
Creating New Technologies for Companionable Agents
to Support Isolated Older Adults
CANDACEL.SIDNER,WorcesterPolytechnicInstitute
TIMOTHYBICKMORE,NortheasternUniversity
BAHADORNOORAIEandCHARLESRICH,WorcesterPolytechnicInstitute
LAZLORING,NortheasternUniversity
MAHNISHAYGANFAR,WorcesterPolytechnicInstitute
LAURAVARDOULAKIS,NortheasternUniversity
Thisarticlereportsonthedevelopmentofcapabilitiesfor(on-screen)virtualagentsandrobotstosupport
isolatedolderadultsintheirhomes.Areal-timearchitecturewasdevelopedtouseavirtualagentorarobot
interchangeablytointeractviadialogandgesturewithahumanuser.Userscouldinteractwitheitheragent
on12differentactivities,someofwhichincludedon-screengames,andformstocomplete.Thearticlereports
onapre-studythatguidedthechoiceofinteractionactivities.Amonth-longstudywith44adultsbetween
theagesof55and91assesseddifferencesintheuseoftherobotandvirtualagent.
CCSConcepts:•Human-centeredcomputing→Usermodels;Userstudies;Fieldstudies;•Comput-
ingmethodologies→Cognitiverobotics;Intelligentagents;
Additional Key Words and Phrases: Content Indicators: I.2.m, I.2.9, H.1.2, H.5.2 keywords: virtual agents,
virtual agent companions, social isolation, older adults, robot compantions, situated dialog systems, real-
timedialogsystems,human-robotinteraction,engagement,human-agentinteractionstudies,human-robot
interactionstudies
ACMReferenceformat:
CandaceL.Sidner,TimothyBickmore,BahadorNooraie,CharlesRich,LazloRing,MahniShayganfar,and
LauraVardoulakis.2018.CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlder
Adults.ACMTrans.Interact.Intell.Syst.8,3,Article17(July2018),27pages.
https://doi.org/10.1145/3213050
1 INTRODUCTION
Socialisolationisabroadlytroublingtrendinmodernsociety.Manystudieshavedemonstrated
thenegativeeffectofthelackofsocialsupportonhealthandwell-beingintheelderly;onestudy
foundthatsocialisolationleadstonumeroushealtheffectsintheelderly[31],whileanotherfound
ThismaterialisbasedonworksupportedbytheNationalScienceFoundationunderGrantNumbersIIS-0811942andIIS-
1012083.Anyopinions,findings,andconclusionsorrecommendationsexpressedinthismaterialarethoseoftheauthors
anddonotnecessarilyreflecttheviewsoftheNationalScienceFoundation.
Authors’addresses:C.L.Sidner,B.Nooraie,C.Rich,andM.Shayganfar,WorcesterPolytechnicInstitute,100Institute
Rd,Worcester,MA01609;emails:sidner@wpi.edu,{bahador.nooraei,m.shayganfar}@gmail.com;T.Bickmore,L.Ring,and
L.Vardoulakis,NortheasternUniversity,177HuntingdonAve.,Boston,MA02115;emails:{bickmore,lring}@ccs.neu.edu,
lauravar@google.com.
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfee
providedthatcopiesarenotmadeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeand
thefullcitationonthefirstpage.CopyrightsforcomponentsofthisworkownedbyothersthanACMmustbehonored.
Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requires
priorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.
©2018ACM2160-6455/2018/07-ART17$15.00
https://doi.org/10.1145/3213050
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:2 C.L.Sidneretal.
thatmortalityissignificantlyhigherforelderswhoaresociallyisolated[51].Companionshipand
socialsupportarealsoknowntobesignificantpositivefactorsindiseaserecoveryandmortality,
especiallyforolderadults[36,58].
Forpurposesofthisarticle,socialisolationisdefinedasthecircumstancesoflivingalone,having
asmallsocialnetworkoffriendsandfamily,fewsocialencounters,andfeelingsofloneliness.Social
supportisdefinedasmechanismsthatprovideassistancetothosewholiveinsocialisolationto
reducetheiractualisolation,toreducetheirsenseofloneliness,ortoreduceboth.
What types of technology could support isolated older adults? Email, video calls, and texting
arealreadyavailable,butsocialisolationcontinuesasatroublingtrend.Humancompanionsare
expensive,orwhenvoluntary,arenotavailableinthenumbersneeded.Intelligentvirtualagents
havebeendevelopedformanysettings,includinghomerealestate,exercisepromotion,touring
culturalsites,andchildren’seducation.Anintelligentvirtualagentservingasasocialcompanion
toanolderadult(ratherthan,say,someonewhomakesamealortakesaseniorshopping)offers
anothertechnologicalpossibility.Toexplorehowadultsserveassocialcompanions,observations
ofadultswhohadvolunteeredtobesocialcompanionstoolderadultswereconductedthrougha
non-profitorganizationinBoston[54].Resultsfromthoseobservationsindicatedthatvolunteers
sawtheirseniorsasfriendswhomtheyvisited1–2hoursperweek.Theiractivitiesincludedco-
TVwatching,smalltalk,seniorstorytelling,sports,healthofthesenior,reportsonthesenior’s
family,andseniorfutureplans.Tocreateavirtualagentthatcouldserveasafriendlycompanion,
theresearchteamwhoundertooktheworkreportedhereconsideredwaysinwhichanagentcould
perform companionable activities with a senior, although it was clear to the team that a virtual
agentcouldnotbecountedasafriendinthehumansense.Atthesametime,technologycanbe
usedtohelpseniorsconnecttootherpeople.Sotheteamalsowantedtousethesamevirtualagent
toassistseniorsinkeepingandmakingconnectionswithothers.
Thefocusoftheresearchreportedherehasthepotentialforreducingisolationinolderadults.
When this research began, several questions guided the research team’s efforts: What types of
activitieswouldinterestolderadultswhenpresentedonacomputerscreen,andwhichactivities
mightreduceisolation?Whichtechnologycouldbeusedordevelopedtoexploretheuseofboth
on-screenvirtualagentsandrobots?Howmightthattechnologyprovideafamiliarparadigmfor
interactionthatwaseasytouse,presentedtheagentsassociableaspossible,andcouldoperate
reliablyforanextendedperiodoftime?
The project undertaken by the team is called the AlwaysOn project and was begun in 2011.
Itproducedagentsthatarecognitivelycapable,meaningtheyhavelimitedwaystoreasonwith
their human partners and their environment, and they can perform tasks behind the scenes to
simplifysomeaspectsofusingcomputersthatarefrustratinglycomplextomanycomputerusers.
The agents are “AlwaysOn agents,” meaning that they are available to their human partner at
anytimethehumanuserispresentbymeansofvarioussensingmechanismsthatarebuiltinto
theagent.Theagentsusedialogasameansofcommunicatingwiththeirhumanpartners,again
to do away with much of the complexity of current computer (and cell phone) interactions. All
thesetechnologiesarebroughttogetherinonesystemforthepurposeofcontinuouslysupport-
ingisolatedolderadults.AlwaysOnagentsofferthepotentialtocounteractisolationdirectlyby
providinginteractionsthatapproximatecompanionshipandasintermediariesbyputtingisolated
peopleincontactwithotherpeople,bothelectronicallyandphysically.Thisarticlereportsonboth
theuserstudiesandthetechnologybuilttouseAlwaysOnagents,bothvirtualandrobotic.
2 RELATEDEFFORTS
TheresearchreportedheregrowsfromworkbyBickmoreandcolleaguesondevelopingvirtual
agent-basedhealthcoachingapplicationsforolderadults,primarilyinexercisepromotion[4–6].
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:3
Inthesesystems,on-screenagentsweredeployedtoolderadulthomesforamonthorlonger,and
theresearchersfoundthatolderadultuserscouldsuccessfullyusetheapplicationsandloggedin
regularly,resultinginsignificantincreasesinphysicalactivity.Thefocusofthecurrentworkis
ontargetingsocialisolationbyprovidingarangeofactivitiestoinvolvetheolderadultandinthe
technologyinfrastructureandmorphologyofthesocialagentinteractingwiththeuser.
Anumberofstudiesaboutthedesignofvirtualagentsforusewitheldershavebeenundertaken
[27,53,60].ManyoftheseeffortsoccurredwellaftertheAlwaysOnprojecthadbegun.Thesestud-
ieshaveconsideredtypesoftasks,whetherahuman-lookingagentisvalued,andconstraintson
whatagentsmightdo,includingforelderswithcognitiveimpairment.Amongthetasksconsid-
ered were ones to keep track of medications, play games, such as chess, and provide reminders
of appointments. These efforts were design studies only and do not report on attempts to build
systemsbasedonthesestudies.Onesystem[34]wasdesignedtointeractwitholderadultstodo
suchtasksasnewspaperreadingandgeneralchit-chat.However,noevaluationofthissystemwith
actualuserswasundertaken,norwasthesystemusedinanysignificantwaywitholderusers.In
contrast,afocusoftheAlwaysOneffortwastodevelopasystemthatcouldbetestedandcould
be used for more than a few days. A European Union project, Miraculous Life [29], posited the
development of virtual agents to exist in the homes of elders to provide emotional support and
connecttheelderwithcaregiversandfamilyonadailybasis.Onereportfromtheprojectoutlines
design considerations for such an agent [15]. The German–Greek project Care explored the use
ofdigitaldisplayframesforrecommendersystemstoprovideolderadultswithwellnessadvicein
theirhomes[48].Theyinvestigatedactivitiesthatwouldsupportwellnessforthisgroup,builtthe
technology,anddidprototypetestingwithtwoolderadultswholivedtogether.
TheEuropeanUnionVERVEprojecthasalsoconsideredsocialisolation,especiallyforpersons
withAlzheimer’s,Parkinson’sdisease,andphobiatypeanxieties,aswellasolderadultswhofear
falling.Theirthrusthasbeentoproducevirtualworldsandvirtualenvironmentsinseriousgames
with virtual agents to assist their target population. A challenging aspect of this research effort
istocreateveryrealisticcharactersinvirtualenvironments.TheVERVEteamevaluatedtheuse
of serious games in patients with Alzheimer’s and related diseases [38]. In contrast, the efforts
reportedinthecurrentarticlearemoremodest,becausethisworkdoesnotconsiderthechallenges
ofagingadultswithseriousillnessorphobias,anditdoesnotundertaketocreatetherichtypes
ofworldsrequiredinVRorseriousgames.
Alltheeffortscitedaboveledourteamtoconsideranagentwhowasabletocommunicatewitha
healthyolderuser,maintaintheprivacyofthatuser,andfocusoncomputationalcapabilitiesthat
would support realistic communication and permit long-term evaluation of the resulting agent
systemwithusers.
Robotictechnologyhasmadesubstantialinroadsinlongitudinalcareforolderadults.TheParo
seal-like robot has been used extensively in nursing homes to calm older adult patients [56], to
providepleasantpetlikeinteractions,andtoincreaseinteractionsamongtheolderadults[46].Re-
searchershaveusedzoomorphicrobots[24]withathree-personsampleofeldersintheirhomefor
exercisecoachingforaperiodof10days;onesubjectusedtherobotfaithfullybuttheothersdid
not.SeveralEuropeanUnionprojectsarefocusedonrobotsforeldercare,especiallymobilerobots
tohelpthosewithmildcognitiveimpairmentorphysicalimpairments[20,30].TheKompaimobile
robot,whichstartedtobedevelopedcommerciallyin2010,hadanarchitecturethatincludedpro-
vidinggames,weathertalk,healthchecks,ashoppinglist,andanagendaforelderlyusers[14].
Testing of Kompai with speech input concluded that both vocabulary and syntax needed to be
greatlyincreasedwhilethetestingofthecomputerscreeniconsyieldedmixedresults;nolong-
termstudiesoftherobotwitheldersisavailable[13].AcomparisonstudyofKompaiwithanother
mobilerobot(operatedinWizardofOzmode)withelders[19]indicatedthatusersexpectations
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:4 C.L.Sidneretal.
fortherobotsexceededtheircapabilities,thatcompanionshipacceptancedependedonknowing
whentoreactandsmartdialogmanagement,whileprivacyandtechnologyacceptancedepended
ontransparencyofthetechnology,socialsituationawarenessoftherobot,andhelpfulresponses.
Other efforts for robots and the elderly include teleoperated robots to help with everyday tasks
[28].TheAlwaysOnprojectlearnedfromtheseeffortsregardingthechallengesofspeechandthe
needforgooddialogandthatprivacymatterswouldneedtobeconsideredindevelopingasystem.
TheAlwaysOnprojectalsochosetoincludewalkingpromotionasanactivityforusers.
Arecentstudy[12]reportsontheattitudesanduseofthesamezoomorphicrobotasinKlamer
et al. [24] but greatly enhanced to broadcast news, messages, music, texts, alerts, and radio and
with a built-in webcam to enable users to communicate with family at home or to watch their
homes when absent. This robot was placed in 70 homes with a total of 102 adults (a mixture of
single adults, families with young children, and families with teenagers) for 5 months. The re-
searchersconsideredusageduringfivephases:pre-adoption,adoption,adaptation,incorporation,
andidentification,whichtheteamdevisedbasedonotherresearch.Ofthetotalparticipants,55
usedtherobotthroughallthephasesofusage,while21stoppedattheincorporationphaseofuse.
Foradaptionthroughidentificationphases,theresearchersfoundthatusagetendedtodropexcept
foragroupofdedicatedparticipantsinthestudy.Participantswereaskedaboutalargenumber
ofattitudinalandsocialbeliefsincludingusefulness,enjoyment,adaptivity,trust,andintelligence
(whichdroppedoverthefivephases),whilesociability,attitudetowardsrobots,andcompanion-
ship rose. The AlwaysOn project is another effort to understand the value of robots and virtual
agentsinextendedhomeuse,albeitwithadifferentpopulationthanthezoomorphicrobotproject.
StudieshavecomparedGUIinterfaces,robots,andon-screenagents.TheauthorsofFasolaand
Mataric [10] created a social robot, that is, a humanoid robot with speech ability and that per-
formed social behaviors, including praise for effort and humor/commentary for exercise coach-
ingwitholderadults.Intheirevaluationsusingeitherthephysicalrobotoravirtual(on-screen)
version of the robot, subjects rated the physical robot more highly on measures of enjoyability,
socialpresence,usefulness,andsocialattraction.TheauthorsofKiddandBreazeal[22]concluded
that robots were favored over onscreen characters, while the authors of Wainer et al. [57] con-
cludedthatuserspreferredaphysicallypresentrobot(theirrobothadahead,butnofaceorother
humanoid features besides movement) to the same one presented on over a video link versus a
simulation. However, the authors of Wrobel et al. [59] found that for elders performing a game
task,thepreferencewasforastandardcomputerscreenfollowedbyarobotand,last,byanon-
screenagent.Thatworkalsopointedoutthattheeldersindicatedthattheywerefocusedontask
performance,andsohavingfewernewdeviceswerebetterforgettingworkdone.Hasagawaand
colleagues[16]found,whencomparingaphysicalrobotwithhumanoidfeatures,ananimatedon-
screenagentcharacterofthesamerobot,andaGPSsystemforthetaskofgettingdirections,that
users dispreferred the GPS system over the robot and screen agent. However, users performed
more gestures with the on-screen agent than with the robot. These various efforts encouraged
ourteamtoincludearobotasanAlwaysOnagentbuttootherwiseholdfixedhowbothagents
interactedwithusers.
3 INITIALUSERSTUDIESWITHELDERS
Tobetterunderstandwhatuserswantedtodowithanagent,theeffectofbeingalwayson,andto
evaluatesomecandidateactivities,severaloftheauthorsconductedaseriesofpreliminarystudies.
ThesestudiesincludedaWizardofOz(WOZ)studyinwhichseveralusersinteractedwithavirtual
agentcontrolledremotelybyanexperimenterandanearlyprototypeofafullyautonomousvirtual
agent.Bothstudiesinvolvedhavingtheagentinthehomesofolderadultsforaweek.
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:5
The purpose of the WOZ study [54] was to determine the range of topics that isolated older
adultswouldwanttodiscusswithavirtualagentintheirhome.Participantswere12olderadults
(10 women, 2 men) who lived alone, ages 56–73, generally well educated (all but 1 had some
college).Theyscoredanaverageof38.6(SD8)ofapossible80ontheUCLAlonelinessinstrument
[45],indicatingoveralllowlevelsofloneliness.Morethanhalfoftheparticipantswantedtotalk
abouttheweather,family,andpersonalstories(tellingstoriestotheagent).Additionally,halfof
alltheconversationsinvolveddiscussingtheparticipant’sfutureplansandactivities.
Thepurposeofthesecondstudywastodeterminetheeffectivenessofproactiveconversation
initiationbyavirtualagent.Thisstudyinvolvedafullyautonomousvirtualagent[39]thatcould
talktoeldersaboutalimitedrangeoftopics,includingchatabouttheweatherandexerciseand
humorousanecdotestoldbytheagent.Thissystemusedamotionsensortodetecttheuser’spres-
enceandinitiateconversationswhentheelderwalkedneartheagent.Twelve(1male,11female)
olderadults,ages56–75,wholivedalone,participatedintheweek-longstudyandwererandom-
izedeithertothesensor-drivenproactivesystemoranequivalentsystemthatdidnotproactively
initiateconversations.Participantsconducted15.9(SD8.1)interactionsperweekonaverage,last-
inganaverageof140(SD26)secondseach.Participantsintheproactiveconditionreportedfeeling
significantlylesslonely,t(154)=−3,p<.05,andmoresatisfiedt(154)=−4.04,p<.05,compared
toparticipantsinthenon-proactivecondition.
4 DESIGNINGFORTHEUSEREXPERIENCE
The outcomes of the previously discussed studies influenced the design of the user experience
with the agents of the AlwaysOn system in terms of types of activities provided to the planned
populationofolderadultsandintermsoftheparadigmofconversationalinteraction,especially
dialog.Thetypeofagent,whichisdiscussedbelow,wasonetheresearchteamwishedtostudy
foritseffectsonuserbehaviorandsatisfaction.
ThemaininteractionparadigmintheAlwaysOnsystemisconversationand,inparticular,di-
alog. The agent makes its contributions to the dialog using speech and gestures, and the user
chooseshis/hercontributionfromamenuofutterancesprovidedonthetouchscreen.Dialogis
thustheprincipalwayofinteracting.Dialogsoccurredaroundvariousactivities,anduserscould
undertakeeachactivityforanextendedperiodoftimeifdesired,fromafewminutestoone-half
hour.Someoftheactivitiesinvolveadditionalon-screengraphics,suchasthecardgameshown
in Figure 1, where the user directly manipulated the cards on-screen. However, the team other-
wiseeschewedothertraditionalGUImethodsusingicons,pull-downlists,clickingonapps,and
thelike,infavorofusingspeechoutputandmenuinputdialoginteraction,asillustratedinthat
figure.Thischoiceprovidedaninterfacewithrelativelyfewon-screendemandstointeractwith
theagentandtoperformactivities.
Theagentspeakingandtheuserrespondingviatextofferedaninteractionthatwasnotquite
anormalface-to-faceconversationbutoneveryclosetoit.Theexceptionstothisconversational
style were direct manipulation, which was needed for playing cards or tic-tac-toe and a virtual
keyboardtoallowtypinginnewpropernamesofpeopleandplaces.Theresearchteam’smotiva-
tionforthisdesignchoicewastoprovideasingleinteractionmethodthatwouldseemfamiliarto
usersandwouldrequiretheleastadditionalmechanisms.Theteamchosenottoengageinspeech
understandingbytheagents,because(1)voicemodelsforolderadultsarestillnotwidelyavailable
inspeechrecognition;(2)Bickmoreandcolleagues[6]hadusedthesametypeofinterfacewith
132geriatricpatientsfortwomonthsforexecisecoaching,andnoneoftheparticipantshadany
troubleusingtheinterface;(3)otherresearch(discussedearlier)suggestedspeechwasatechnical
challenge;and(4)progressinspeechunderstandingwasnotafocusoftheproject.
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:6 C.L.Sidneretal.
Fig.1. Theon-screenagentKarenplayscardswiththeuser.
Twoformsofembodimentofasocialagentweredeveloped.Karen,showninFigure1,comes
fromtheworkofBickmoreetal.2005.Karenisahumanlikeagentanimatedfromacartoon-shaded
three-dimensional(3D)model.SheisshowninFigure1playingasocialgameofcardswithauser.
Noticethatuserinputisviaatouch-screenmenuusinganASUStouch-screencomputer.Also,the
speechbubbledoesnotappearintheactualinterface,whichusestext-to-speechgeneration.The
Reetirobot[37],showninFigure2,isadesktoprobotwithaheightofapproximately2feet.The
robothascamerasinitseyes,amoveablemouth,2degreesoffreedominitsneck,and“ears”that
canrotate.TherobotusedtheASUStouchscreenforalltheuserresponsestotherobot,exactly
astheuserdidforthevirtualagent.Inuserinteractions,bothagentswerereferredtoasKaren.
Sensor technology for the agents is identical. Both agents, in addition to speech generation
usingtheIvonaSallivoice,producenoddinggesturesinthedialogasaformofbackchanneling
[61].Theyalsotracktheuser’sfaceusingoff-the-shelffacerecognitionsoftware,eitherthrough
anonboardcameraintheASUScomputer,forthevirtualagent,orthroughtherobot’seye-based
cameras.1Theybothusedaverysimpleinfra-redmotiondetectorforsensingmotionintheroom.
The motion sensor is the small black box, outlined in red, with the white button visible in the
lower-leftcorneroftheASUSinterfacescreeninFigure2.Whenanactivityprovidedinformation
onthecomputerscreen,theagentgenerallyturnedtolookatthescreenafteritscontributionto
thedialog.Fiveoftheactivitiesprovidedsomeon-screeninformationthattheusermanipulated.
ThetypeofroboticagentusedinAlwaysOnresultedfrompracticalconcerns.Whiletheteam
wouldhavepreferredamorehuman-lookingrobot(tomatchandcomparemorereadilywiththe
humanlikeon-screenagent),reliablehuman-lookingrobotsthatcouldoperatefortheplannedtime
frameofonemonthofusewithoutfailurewerenotavailable.Astheteamwasplanningonmaking
1Avideoexampleoftherobotinteractingwithapersononanumberofactivitiesisavailableinavideo[50].
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:7
Fig.2. TherobotReetiinteractswiththeuserandthecalendaractivity.
theAlwaysOnsystemavailableforafullmonthwitholderusers,Reetiwastheonlycommercially
availablerobotthathadbeenusedbyothergroupsreliablyforextendedperiodsoftime.
The project uses both an on-screen agent and a robot to understand what differences might
exist in their use over a long period of time. A number of studies have shown that users trust
robotsmorethanon-screenagents(cf.thestudiesmentionedabove),butmostofthosestudiesdid
notattempttoinvolveusersformorethanasingleinteraction.Anotableexceptionisthework
of Kidd and Breazeal [23] on long-term interactionwith a wait-loss coach robot. However, they
didnotcompareon-screenagentsandrobots,justrobotstocomputerlogging.Theresearchteam
imagined that in long-term use, users might not find one more preferable than the other, even
thoughcertainbehaviors,suchasfacetracking,aremorenoticeablewiththerobot.
Thetwoagentswereprogrammedtoofferandparticipateinanarrayofactivitieswiththeuser.
Differentactivitiescanservedifferentgoals,eitherimprovingtheuser’swell-beingbydoingsome
sociallyengagingactivityorconnectinguserstofriendsandfamilybeyondtheagentinterface.A
reasonablyextensivenumberofactivitieswereneededifusersweretointeractovermanydaysand
weekswithoutgettingboredwiththesystem.Theinitialstudiesundertakenbytheauthorsindi-
catedthatuserswantedmorethingstodowiththeagentwhentheinteractionstookplaceoversev-
eraldays.ThisresultpushedtheAlwaysOnteamtodeviseanumberofdifferenttypesofactivities.
Activitiessuchastalkingabouttheweatherorplayingasocialgameofcardsaremeantas
icebreakerstohelptheusertogettoknowtheagent.Socialgameplaywascreatedbydeveloping
angamearchitectureandsub-systemthatwouldallowtheagenttotalkabouthowthegamewas
going [2]. Three games were developed using this architecture: the card game rummy, classical
checkers,andtic-tac-toe.Eachofthesegamesprovidedadirect-manipulationinterfacetomake
it possible to play the game. Activities to support well-being included getting health tips and
nutritioncoaching,whichalsopresentedchartsabouttheuser’sprogressandformstofillin.
Otheractivitiesweremoreinstrumentalinnature,suchastheagent’saboutself-introduction
dialogs, in which it interactively explained its capabilities to the user. For each user, an initial
enrollment dialog, in which the person’s name, birthdate, and friends and family names were
requested,gavetheagentsomeinitialinformationabouttheuser.Oncetheagentknewaboutthe
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:8 C.L.Sidneretal.
Fig.3. Aconversationwiththeagentaboutexercise.
user’sfamilyandfriends,oneofitsactivitiessupportedthereporteduserdesirefromourinitial
studiestoexplainaboutfamilyandfriends,albeitinaverylimitedfashion.Otherinstrumental
activitiesincludedapersonalcalendaractivity(showninFigure2withtheReetirobot),which
presentedacalendarwitheventsandwasusedtoaddordeleteeventssuchasbirthdaysandplans
withfriends.Theagentmadechangesbasedondialogwiththeuser.Toprovidesomelight-hearted
enjoyment,theagenttoldshorthumorousanecdotestotheuser,anactivitythatusersreported
likinginpreliminarystudies.Alltheseactivitiesmadeforasocialagentwhowasusefulandyet
couldmakelight-heartedconversationwiththeuser.
Several activities directly address the project goal of socially connecting the user with other
people.TheteamimplementedVideobuddy,anactivityinwhichtheagentarrangedvideocalls
fortheuserwithfamilyandfriends.Inthisactivitytheagentundertookallofthecomplexityin
standardvideointerfacesforcontactingthevideopartnerandsettingupthecall.Theusersimply
indicated that he or she wanted to reach a person, and the rest was undertaken by the agent.
The user did not have to click on various icons presented on the left and right of the screen to
determinehowtomakeacall(asisthecasewithSKYPEandHangout),nordidtheuserhaveto
deal with calls that failed in some way. The agent was programmed to indicate to the user that
a call ended prematurely if video was lost. While the agent set up the call, the user was free to
dootheractivities,andtheagentwouldinterrupttheuserwhenthecallwasreadytotake.The
activitytocoachoutdoorexercise,anareawellexploredbyBickmoreetal.inearlierwork[4],
had been shown to result in more social connection by getting the user out of his/her dwelling
andintothecommunity[6].AsampleinteractionofexercisecoachingisshowninFigure3.
Finally,thepersonallifestoryacquisitionactivityaddressedbothaprojectgoalandabenefit
forseniors.Seniorstellstoriesabouttheirlivesinparttomakesenseoftheirfulllifeexperience
[8].Inthelifestoryacquisitionactivity,theusertoldapersonalstory,whichwasaudioandvideo
recordedbytheagentforlatersharingwiththeuser’sfamilyandfriendsovertheInternet;thisac-
tivityofferedmitigationofsocialisolationbyprovidingtheelderwithanewmeansofconnecting
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:9
Fig.4. Asamplebeginningofthedayconversation.
withothers.Lifestoryacquisitionwassupplementedbyaseriesofsuggestionsofpositivetopics,
oneofwhichtheagentcouldsuggesttotheuserincasetheusercouldnothimorherselfdecide
howtoorganizehisorherstorytellingthoughts.
A typical interaction with the agent might start with some greetings (specific to the time of
day)andthensomediscussionoftheweather.Theweatherdiscussioncouldbeasshortastoday’s
weather forecast or extend to the next day, weather in other cities, and weather where friends
or family live. At the user’s choice, weather might be followed by a social game of cards where
theagent’sanduser’shandsinthegameandthewaythegameisplayedoutarecommentedon.
Additionalactivitieswouldfollowbasedonwhattheuserhadlearnedaboutthesetofactivities
availableandhowlongtheuserhadinteractedwiththeagent.Astheuserhadmoresessions,ad-
ditionalactivitieswereintroducedtherebyreducingoverwhelmingtheuserwithalltheactivities
earlyintheuser’sexperiencethewithagent.
Asampleconversationwiththeagentwhenfirstinteractingwithanagentfortheday,butwhen
thetimeofdayispastnoon,isshowninFigure4.
The AlwaysOn system continuously maintained a model of the state of engagement [49] be-
tweentheuserandtheagent.Theagentremainedquiescent,withnogesturesexcepteyeblinks
for the virtual agent and eye movements for the robot agent, until it sensed nearby motion (via
aninfraredmotiondetector)followedbytheappearanceofafaceinitsvisionsystem.Giventhat
information,theagentwouldlookattheuserandofferagreeting.Noresponsereturnedtheagent
tothequiescentstate.Auserresponsetoanagentgreetingmovedtheagenttotheengagedstate.
Engagement was assumed successful as long as the user remained in view of the agent and re-
spondedinthedialog.Thedisengagementstatecouldcomeaboutatthenaturalconclusionofthe
conversation (with goodbyes) or when the user was no longer visible for an unexpected reason
foranextendedperiodoftime,e.g.,toansweraringingdoorbell.BecausetheAlwaysOnagents
could not understand sounds in the environment, they could not know why the user might be
disengaging,buttheyhadsimplestrategiesfordealingwithwhattheyperceivedasunexpected
disengagement.Theywaitedforaperiodoftimeafterasking“areyoustillthere?”Iftheuserdid
notansweranddidnotreturn,thentheagentwoulddisengageandendtheinteraction.Theagent
didnotinitiatedisengagement,althoughitcouldattempttohurrytheconclusionofasessionif
someeventintheuser’scalendarwasabouttostart.
5 ANARCHITECTURETOSUPPORTAGENTSWITHONGOING
ENGAGEMENTANDDIALOG
ThearchitectureoftheAlwaysOnsystemwasdrivenbytheneedforongoingengagementanddia-
logwithitshumanuser.TheresearchteamstartedoutusingthecollaborativedialogsystemDisco
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:10 C.L.Sidneretal.
system for dialog [44], but it became evident that the proper integration of dialog and gestures,
whichsupporteddialogandengagement,requiredmorereal-timecontrol.Anadditionalsoftware
challenge was allowing the activities about which the user and agent had dialogs to be built by
manymembersoftheteamandwithdifferentsoftwaretoolsbuttobeeasytointegrateintothe
AlwaysOn system. Thus modularity and extensibility with respect to activities was a necessity
[33].Thissectiondiscussesbothoftheseconcernswithspecificneedsthatareenumeratedbelow.
5.1 UseCasesforReal-TimeEngagementandDialogInteraction
A detailed set of use cases, a methodology from software engineering, guided the development
oftheAlwaysOnsystemforitsengagementanddialogneeds.Inthisapproach,oneidentifiesat
thebeginningofthedesignprocessacollectionofarchetypalbehaviors(the“usecases”)thatthe
systemshouldsupportandthenevaluatestheimplementedsystemintermsofhowwellitsupports
eachofthesebehaviors.Furthermore,theusecasesshouldbechosentocoverthemostchallenging
aspectsofthesystem’srequiredbehavior.Theninecasespresentedheresupportengagmentand
dialogbetweentheagentandtheuser.AsdefinedbySidneretal.[49],engagementis“theprocess
bywhichtwo(ormore)participantsestablish,maintainandendtheirperceivedconnectionduring
interactions they jointly undertake.” Furthermore, as shown below, engagement involves both
verbalandnonverbalbehavior.
Case(1)WalkingUptotheAgent:Thefirstusecaserelatestoestablishingengagement.Specif-
ically, when the user walks by and triggers the motion detector, the agent should awake from
itsquiescentstateandissueagreeting,suchas“Goodmorning.”Iftheuserthenrespondsbyap-
proachingthecomputer(whichtheagentcannoticewithfacedetectionsoftwareonthewebcam),
thentheagentshouldcontinuestartfacetracking(seenextusecase)andcontinuewithafurther
engagingutterance,suchas“Howdidyousleep?”
Thenextfourusecasesrelatetomaintainingengagement.Relatedworkidentifiedfourtypes
of “connection events” that function to maintain engagement [17, 43]. Each type of connection
eventhasacorrespondingusecase.Ingeneral,theseusecasesinvolvecrucialtimingconstraints
betweentheverbaland/ornonverbalbehaviorsoftheuserandtheagent.
Case(2)FaceTracking:Facetrackingistheagent’sattempttoachievewhatistechnicallycalled
mutual facial gaze [1] with the user. When the agent is face tracking, it should orient its gaze
towardwhereitdetectstheuser’sface.Inadditiontobeingtheagent’sdefaultgazebehaviorfor
maintainingengagement,mutualfacialgazecanhaveotherinteractionfunctions.Forexample,it
istypicaltoestablishmutualfacialgazeattheendofaspeakingturn(seenextusecase).
Case(3)Turn-Taking:Eventhoughaconversationalinteractionentailsmuchmorethanturn-
taking,anembodiedconversationalagentneverthelessdoesneedtomanagespeakingturns,par-
ticularly ina menu-basedsystem. Inlinguistics, anadjacencypair[47] isthetermusedtorefer
totwoutterancesbytwospeakers,withminimaloverlaporgapbetweenthem,suchthatthefirst
utterance provokes the second utterance. A question-answer pair is a classic example of an ad-
jacency pair. Thus, after producing the “first turn” of an adjacency pair, the agent should wait
untiltheuserresponds(oruntilsomespecifiedtimeoutoccurs).Insomeconversationalcircum-
stances,theuser’sresponsecanalsobefollowedbya“thirdturn”inwhichtheagent,forexample,
acknowledgestheuser’sresponse.
Importantly,theconceptofadjacencypairisgeneralizedbeyondthetraditionallinguisticdef-
initiontoincludebothverbalandnonverbalresponses.So,forexample,anodcanbetheanswer
to a question, instead of a spoken “yes,” or the performance of an action can be the nonverbal
responsetoaverbalrequest,suchas,“pleasepassthesalt.”Adjacencypairs,ofcourse,alsooften
overlap with the other nonverbal behaviors, such as face tracking and directed gaze (see Use
Case5).
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:11
Fig.5. Timelinefordirectedgaze.
Case (4) Backchanneling: A backchannel is an interaction event in which a listener directs a
briefverbalornonverbalcommunicationbacktothespeakerduringthespeaker’sutterance.Typ-
icalexamplesofbackchannelsarenodsand/orsaying“uh,huh.”Backchannelsaretypicallyused
to communicate the listener’s comprehension of the speaker’s communication (or lack thereof,
e.g., a quizzical facial expression) and/or desire for the speaker to continue. A conversational
agentshouldbeabletobothgenerateappropriatebackchannelsandinterpretbackchannelsfrom
theuser.
Case (5) Directed Gaze: Finally, Figure 5 shows the time line for the last, and most complex,
engagement maintenance use case, called directed gaze [21]. In this behavior, one person (the
initiator)looksandoptionallypointsatsomeobjectintheimmediateenvironmenttomakeitmore
salient,followingwhichtheotherperson(theresponder)looksatthesameobject.Thisbehavior
isoftensynchronizedwiththeinitiatorreferringtotheobject(s)verbally,asin“nowspreadthe
cream cheese on the cracker” (pointing first to the cream cheese and then to the cracker). By
turninghisgazewheredirected,theresponderintendstobecooperativeandtherebysignalshis
desiretocontinuetheinteraction(maintainengagement).
Inmoredetail(seeFigure5),noticefirstthattheactofpointing(1),ifitispresent,beginsafter
the initiator starts to look (2) at the object. Looking at the object is likely, because it is hard to
accurately point at something without looking to see where it is located. After some delay, the
responder looks at the salient object (4). The initiator usually maintains the pointing (1), if it is
present,atleastuntiltheresponderstartslookingattheobject.However,theinitiatormaystop
lookingattheobject(2)beforetheresponderstartslooking(4),especiallywhenthereispointing.
Thisswitchcanoccurtothattheinitiatorcancheckwhethertheresponderhasdirectedhisgaze
yet. Finally, there may be a period of shared gaze, i.e., a period when both the initiator (3) and
responder(4)arelookingatthesameobject.
Case (6) Walking Away: This use case relates to ending engagement. Hopefully, most of the
timedisengagementbetweentheagentanduserwilloccurastheresultofanexplicitleave-taking
conversational exchange, such as, “Goodbye; see you later.” However, the agent should also be
preparedtodealwiththeusersimplywalkingawayatanytime.
Theremainingthreeusecasesrelatetovariouskindsofinterruptionbehaviorsthatareessential
to dialog behavior. The ability to do more than one thing at a time and smoothly shift between
themisakeyrequirementforanaturalconversationalagent.
Case(7)ScheduledEvent:Onereasonforinterruptinganactivityistoduethe(imminent)oc-
currenceofascheduledexternalevent.Forexample,intheAlwaysOneffort,theagenthelpsthe
user keep a personal calendar of events such as lunch dates, doctor appointments, and so on. If
theuserhasalunchdateatnoon,thentheagentwillinterruptwhatevertheagentanduserare
doingtogether(e.g.,playingcards)10or15minutesbeforenoontoremindtheuserofthelunch
dateandtowrapuporpostponethecurrentactivity.
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:12 C.L.Sidneretal.
Fig.6. TheoverallarchitectureoftheAlwaysOnsystem.
Case (8) Changing Topic: A conversational agent should be able to, either of its own volition
or in response to the user’s behavior, smoothly change the topic of the conversation, and then,
if appropriate, smoothly return to the original interrupted topic. For example, in the AlwaysOn
effort,activitiessuchasplayingcardsareviewedassocial“containers,”withinwhichothertopics
canalsobediscussed.Forexample,attheendoftheuser’sturninacardgame,theagentcould
say,“Bytheway,haveyouthoughtaboutmysuggestionsforhowtogetmoreexercise?”Aftera
shortdiscussionofexercise,theagentcouldreturntothecardgamebysaying,“Ok,soIthinkit’s
yourturnnow.”
Case (9) Barge-In: Barge-in is a common dialog phenomenon similar to backchanneling (Use
Case4),inthatthelistenerstartscommunicatingbeforethespeaker’sturnisfinished.Inthecase
ofbarge-in,however,thelistener’sintentionisforthespeakertostopandletthelistener“take”
the turn. A conversational agent should be able to respond to the user’s barge-in by promptly
ceasingtotalk.Inapurelyspokenlanguagesystem,theusercanbargeinsimplybystartingto
speak. A menu-driven system, such as the one used in the AlwaysOn project, can support user
barge-in by displaying a menu for the user to click on while the agent is still speaking. Should
theuserclickonthemenuitem,theagentshouldstopspeakingitsturnatthattime.Thecaseof
aconversationalagentbarginginontheuserislesscommon.However,Chaoetal.[9]describe
astrategy,calledminimumnecessaryinformation,forarobottostartactingbeforetheuserhas
finishedspeakinginstructions.
Figure 6 shows the overall architecture of the AlwaysOn system in which both hard real-
time (taken to be responses in milliseconds) and long-term time (days or weeks) could both be
supported.The solutionwas an extension, called Disco for Real-Time (DiscoRT)on the left side
of the figure to focus on real-time needs. For the long-term needs, the Session Manager, shown
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:13
ontherightsideofFigure6,organizedwhichactivitieswouldbeundertakenateachsessionwith
the user as an activity plan. Individual activities were authored as plug-ins to the architecture.
Pluginsthusallowedformodularityandextensibilityofactivities.Pluginsweremadeavailableto
the Session Manager to use to determine a plan as a combination of all the activities and of the
resultsofprevioussessions,duringwhichtheusercouldtryanewactivityorupdateaprevious
activitywithnewinformationorevents.Italsousedgeneralrulesonhowtointroducetheuserto
yetmoreactivitiesuntilalltheactivitieswereavailabletotheuser.Whiletheoptionofallowing
userstoindicateactivitiestheyneverwantedtodoagainordoateverysessionwasnotexplored,
theSessionManagerwouldbethelocusofsuchchoices.
In brief, DiscoRT implements an arbitration-based parallel schema architecture that handles
suchhardreal-timephenomenaasbarge-in(theagentimmediatelystopsspeakinginthemiddle
ofanutterancewhentheusertouchesamenuitemonthescreen)andtime-outs(theagentrepeats
anutterancewhentheuserdidnotrespondaftersometime).DiscoRTalsocoordinatestheinputs
from the agent’s sensors and helps manage Disco’s dialog focus. Hard real time was a critical
featureoftheAlwaysOnsystemnotonlyforbarge-inandtime-outsbutalsotokeeptheagents
trackingtheuser(viaeyegaze)astheusermovedabout,tomaintainengagement,toparticipatein
dialog,andtorespondquicklyingameplaying,calendaruse,andotherinteractionsthatrequired
directmanipulationofthescreen.
ThedesignofDiscoRTalsoaimedtosupportvirtualagentsandrobotsthat,unlikeintheAl-
waysOn system, can use their hands and arms to point at and manipulate objects in their en-
vironment. DiscoRT is designed to support fully spoken interaction, as well as the menu-based
interactionmodeoftheAlwaysOneffort.
TheSemanticNetworkinFigure6storesinformationgleanedfromtheuserabouthis/herin-
terestsandactivities,aswellasbasicmodelsofsucheventsastimeforuseincalendaringandthe
like.TheAlwaysOnsystemisimplementedinacombinationofJavaand.NETonWindows.
Figure7showsthedetailed,abstractmachinearchitectureoftheDiscoRTsystemthatwasde-
signed,implemented,andusedfortheAlwaysOnagentstosupporttheusecasesaboveinaprin-
cipled and general way. A discussion of the details of the architecture will provide the basis for
accountingforhowthenineusecaseshavebeenimplemented.Fourkeyfeaturesofthisarchitec-
tureareasfollows:
(1) MultipleThreads:Supportingthecontinuousmutualsignalingmodelofinteractionobvi-
ouslyrequiresahighlyparallelarchitecturewithmultiplethreads.Eachinputandoutput
modalityandtheinternaldecision-makingprocessesneedstofunctionindependentlywith-
outblockingoneother.
(2) Resource Arbitration: The agent’s face, voice, hands, and gaze are resources that can be
usedfordifferent(andsometimescompeting)purposesinaninteraction.Forexample,the
agent’sgazecanbeusedtoachievemutualfacialgaze(UseCase2)oritcanbeuseddirect
theuser’sgazetoasalientobjectintheenvironment(UseCase5).Similarlytoacomputer
operatingsystem,oneofthekeyfunctionsofDiscoRTistoarbitratebetweencompeting
demandsforagivenresource.
(3) Real-TimeControl:Timingiscriticalinalloftheusecases.However,thereismoremargin
for error in some use cases than in others. For example, an inappropriate delay of even
afractionofasecondintheagent’sresponsetoauser-initiateddirectedgazeorbarge-in
wouldbenoticeableanddegradethebelievabilityoftheagent.Ontheotherhand,changing
topicsorremindingtheuserofanupcomingscheduledeventcanbedelayedasecondor
two without harmful effects. These different timing needs are dubbed “hard” and “soft”
real-time,respectively,andhandledseparatelyinthearchitecture.
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:14 C.L.Sidneretal.
Fig.7. ThedetailedarchitectureofDiscoRT.
(4) DialogueManagement:AuniquefeatureofDiscoRTarchitectureisitsintegrationwiththe
Disco dialogue manager, shown in Figure 7 on the far right. Among other things, Disco
providesafocusstackforhelpingtomanageinterruptions.
Theleftofthefigurenotesperceptors,whichisthesystem’sabstractionforsensingcapabil-
ities,suchasfacedetection,motiondetection,menuinput,speechrecognition,emotionrecogni-
tion,andsoon.Someperceptorssimplyabstracttheoutputofasinglehardwaresensor,suchas
the infrared motion detector in the AlwaysOn project. However, perceptors can also fuse infor-
mationfrommultipleinputmodes,suchasanemotionrecognitionperceptorthatcombinesfacial
expressioninformationfromacamerawithtoneofvoiceinformationfromamicrophone.Boththe
schemasandtherealizersusetheoutputoftheperceptors;forexample,theschemathatestablishes
engagementusesfacedetectionandmotionperception.Notethatthereisnoemotionrecognition
usedbyAlwaysOnagents,butthearchitectureisgeneralenoughtoincludesuchbehavior.
SchemasarethecoreoftheDiscoRTarchitecture.FortheAlwaysOnagents,thereisaschema
corresponding to each social activity that the agent can do with the user, such as talking about
the weather, playing cards, and so on. These schemas are created and destroyed as the system
runs.Afewotherschemas,suchastheschemathatmanagesengagementandtheoneforgoals,
arealwaysrunning.Thefundamentalfunctionofaschemaistocontinuallyproposebehaviors.
Each schema runs on its own thread with a loop cycle rate depending on its needs. To decide
whatbehaviortoproposeatagivenmoment,aschemacanconsultitsownstatevariablesandthe
system’sperceptors,aswellasexternalsourcesofinformation.Forexample,theweatherschema
downloadsup-to-dateweatherinformationfromtheInternet.Schemasmakebehaviorproposals,
whichareprogramstobeexecuted.Forexample,thedirectedgazebehavior(seeFigure5)requires
three resources (voice, hand, and gaze) and includes a complex realizer program to synchronize
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:15
thecontroloftheresourceswithinputfromtheperceptors.TherearenorestrictionsinDiscoRT
ontheinternalimplementationofaschema,andtheAlwaysOnschemasvaryfromstatemachines
implementedinJavatoprogramswritteninthespecializedlanguageforDiscoprogramming.
Theresourcearbitrationthread/looprunsapproximatelyoncepersecondandgathersupthe
collectionofbehaviorproposalsfromalloftherunningschemas.Proposalswithnon-overlapping
resourcerequirementsaredirectlyscheduled,i.e.,aninstanceofthespecifiedrealizeriscreatedand
startedrunning(unlessitisalreadyrunning).Resourceconflictsbetweenproposalsareresolved
usingasimplesystemofper-schemaprioritieswithsomefuzzylogicrules[11]tomakethesystem
morestable,i.e.,topreventswitchingbehaviorstooquicklybetweencloselycompetingschemas.
Thebehaviorproposalsthatarechosenarethenscheduled.
Since DiscoRT is designed to support conversational agents, it includes specialized machin-
eryfordialoguemanagement.ItusestheDiscodialoguemanager,anopen-sourcesuccessorto
Collagen[40,41].Discohastwokeydatastructures:aplantreeandafocusstack.Eachofthese
hasapointofintegrationwithDiscoRT,asshowninFigure7.
Theplantree,whichistypicallyprovidedfromanothercomponentoutsideofDiscoRT(inthe
caseofAlwaysOntheplantreeistheactivityplanproducedbytheSessionManagerinFigure6)
representstheagent’sgoalsforitsinteractionwithuserasahierarchicaltasknetwork[42].This
formalismincludesoptionalandrepeatedgoalsandpartialorderingconstraintsbetweensubgoals.
Thusthetypicalinteractionexample,startingwithgreetings,andsoon,describedinSection3,is
formalizedasaplantree.Theplantreecanbeupdatedwhilethesystemisrunning.
DiscoRTincludesapredefinedschema,calledthegoalsschemainFigure7,whichisalwaysrun-
ningandautomaticallystartstheschema(s)correspondingtothecurrentlylivegoal(s)intheplan
tree.Thus,forexample,whenthe“discusstheweather”goalbecomeslive,thegoalsschemastarts
theweatherschema.Whentheschemaexits,thecorrespondinggoalintheplantreeisautomati-
callymarkedasdone.Thefocusstackisstackofgoals,whichcapturesthefamiliarphenomenon
ofpushingandpoppingtopicsinhumanconversation.Forexample,theagentcaninterruptthe
user’sactivitytoinformhimorherofascheduledmeeting,butiftheuserwantstocontinuethe
currentactivity,thenthefocusstackmakesthereturntotheactivitypossible.
InDiscoRT,interactionthatfacilitateschanginggoalsisachievedbymakingthefocusstacka
resourcethatrepresentscontrol of thecurrenttopicof conversation. Schemasthatinvolve con-
versation,suchasthecardsschema,theexerciseschema,andthecalendarschemaintheexample
above,requirethefocusstackintheirbehaviorproposals.Whentheresourcearbitratorstartsa
newbehaviorrealizerthatrequiresthefocusstack,itpushesthegoalassociatedwiththepropos-
ingschemaontothestack(unlessitisalreadythere).Whenthebehaviorrealizerfinishes,thegoal
isautomaticallypoppedoffthestack,asisdiscussedforUseCase(7).Thisintegrationbetweenthe
dialoguemodelandtheschemaarchitectureinDiscoRTispowerfulandflexible.Forexample,it
ispossibleandsometimesusefulforaschematoproposeaspeechbehaviorwithoutrequiringthe
focusstack.Ifyoupokearobot,thenitmightrespondbysaying“Ouch!”withoutchangingthe
conversationalfocus.DiscoRTalsowasprovidedwithhooksforautomaticallyproducinggeneric
transitionlanguagewhenthestackispushedandpopped,suchas“excusetheinterruption,but...”
or“now,returningto...”
The behavior realizers (bottom of Figure 7) realize the gestures and verbal responses of the
agent.Realizersimplementthehardreal-timeeventsynchronizationinthesystem;hardreal-time
events are those the require nearly spontaneous responses to user input, such as barge-in,
time-out, and responding to user-initiated directed gaze. A behavior realizer in DiscoRT is very
similar (hence the name) to a BML realizer [55]. However, for the reasons discussed in detail
in Holroyd and Rich [18], this architecture uses an event-driven Petri net rather than a fixed
scheduleasinmostBMLrealizers.
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:16 C.L.Sidneretal.
Further,inDiscoRTtherecanbemultiplerealizersindependentlycontrollingnon-overlapping
resourcesets(thinkofarobot“rubbingitstummyandpattingitshead”atthesametime).Each
behaviorrealizerhasaseparatethreadthatrunsbydefaultat10Hz.Realizersoftengetinformation
fromperceptors.TheDiscoRTonessupportalloftheessentialtimingrelationshipsofBML(syn-
chronize, before, after, and fixed delay). The complete BML specification was not implemented,
becausemuchofitconcernedspecificgesturalactions;DiscoRTusesamoregeneralframework.
Also,therealizerprogrammingAPIforDiscoRTusesJavaratherthanXML.
5.2 ImplementationofUseCases
Withthedetailsofthearchitectureinmind,theusecasesasappliedtotheAlwaysOnarchitecture
andagentscanbediscussedinmoredetail.
Case(1)WalkingUptotheAgent:Theengagementschema(implementedasastatemachine)
continuallypollsthemotionperceptor(whichabstracttheinfra-reddmotiondetectorhardware).
When motion is detected, the schema proposes a speech behavior (e.g., “Good morning” before
noonand“How’syourdaygoing?”betweennoonand6p.m.)andentersastateinwhichitstarts
pollingthefaceperceptor(whichabstractstheoutputoffacedetectionsoftwareoperatingonthe
webcamoutput).Whenafaceisdetected,theschemaproposesanotherspeechbehaviorandenters
theengagedstate;otherwise,afteratimeout,theschemareturnstothemotionperceptorpolling
state.
Case (2) Face Tracking: A behavior realizer that requires the gaze resource and uses the face
detection perceptor implements face tracking. The realizer simply runs a loop that updates the
agent’sgazetowhereitcurrentlyseestheuser’sface.Thefacetrackingbehaviorthatcausesthe
realizertobestartedisproposedbytheengagementschemawhenitenterstheengagedstate(see
Case6forstoppingtherealizer).
Case(3)Turn-Taking:Turn-takingisimplementedbyanabstractstatemachinethatisreusedin
alloftheschemasthatincludeconversationalbehavior,suchasweather,cards,andcalendar.The
agent’sutterancesareproducedbyproposingspeechbehaviors.Inmenu-basedsystems,thestate
machine waits for the user’s response by waiting for an event from the menu perceptor (which
abstractsthemenuGUI).
Case (4) Backchanneling: Backchanneling is a hard real-time phenomenon, so it must be im-
plemented by a behavior realizer that receives events from a perceptor that detects appropriate
momentsatwhichtoproducebackchannels,suchastheendofphrasesorsentencesintheuser’s
speech.Theschemathatproposesthebackchannelingbehaviorisresponsiblefordecidingwhat
formofbackchannelshouldbeused(e.g.,positiveornegative)andforre-proposinganewbehavior
whentheformofbackchannelshouldbechanged.
Case (5) Directed Gaze: As discussed previously, the time line for directed gaze (Figure 5) is
implementedasabehaviorrealizer.Anyschemacanproposeadirectedgazebehavior.
Case (6) Walking Away: The engagement schema state machine includes a timeout to notice
whentherehasbeennofaceormotionperceived.Whenthiscaseoccurs,itstopsproposingface
tracking,asksiftheuserisstillavailableandifnot,entersthewaitingforengagementstatede-
scribedinUseCase(1).
Case (7) Scheduled Event: While the user and agent are playing cards together, both the card
schemaandthecalendarschemaarerunning,butthecalendarschemaisnotmakinganybehavior
proposals.Thecardschema’sbehaviorproposalsrequirethefocusstack,sothecard-playinggoal
stays on the top of the stack. Then, triggered by the clock time, the calendar schema proposes
a speech behavior about an upcoming appointment that requires the focus stack. Because the
calendar schema has a higher priority, the arbitrator gives it control of the focus stack, which
causes the calendar reminder goal to be pushed on top of the card-playing goal. The calendar
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:17
reminder goal remains on the top of the stack throughout the (sub) dialogue regarding the
appointment. When this reminder dialogue is completed, the calendar schema stops making
proposals,thecalendargoalispopped,andthearbitratorgivesthefocusstackresourcebackto
thecardschema,whichhasbeencontinuouslyproposingthenextbehaviorinthegamebutnever
gettingtheneededfocusstackresource.
Case (8) Changing Topic: Changing topic is handled similarly to Use Case (7), except that
insteadofthecalendarschemadecidingtomaketheinterruption,thedecisionthatthenewtopic
has a higher priority than the current topic is made by some other schema based on cognitive
reasoning that is outside of the scope of DiscoRT. The mechanism of pushing and popping the
focus stack is identical, however. Furthermore, the interrupted schema may stop proposing the
oldtopic,inwhichcaseitisneverreturnedto.
Case (9) Barge-In: Barge-in is handled in the speech behavior realizer, which in addition
to controlling the text-to-speech engine (voice resource), listens for events from the menu or
speechperceptor(dependingonthetypeofsystem).Whensuchaneventisreceived,therealizer
immediatelystopsthetext-to-speechengineandterminates.
5.3 SoftwareEngineeringandPrivacyConcerns
CreatingtheworkingAlwaysOnsystemwithDiscoRTandwith12differentuseractivities(plu-
gins),somewithdirectmanipulationinterfacesandotherswithon-screenpresentation,required
asignificanttestingeffort.Inaddition,twoplugins,oneforengagementandoneforthesession
plan, also needed testing. Because the team intended for both agents to be available for up to a
monthofuse,reliabilityoftheentiresystemwasamajorconcern.Eachindividualplugin,corre-
sponding to one of the activities, was extensively tested in isolation. When all the plugins were
integratedwiththeDiscoRTsystem,andthevirtualagentorrobotwasintroducedasuserfacing
components,alongwithfacerecognitionsoftwareand,inthecaseoftherobot,controlprograms
foritsgestures,thefinalsystemrequiredanotherroundoftesting,whichtookapproximatelyfour
person-monthstoaccomplish.Followingthattesting,thesystemwiththevirtualagentwasbeta
testedinthehomeoffoureldersafterwhichmoretestinganddebuggingoccurred.
Specialrequirementswereneededtohandleaspectsoftherobotagent.Becauseitmadeuseof
acamerainitseyes(ratherthantheoneontheASUSscreen),adjustmentstothefacerecognition
algorithmtoworkwithamovingrobotheadwereundertaken.Controlsoftwaretomakeitpossible
fortherobottonodatappropriatemomentswasintroducedfortherobotaswell.
Becausetheusersintheinitialstudiesindicatedsubstantialconcernsaboutprivacy,allofthe
data captured by the onboard and on-robot cameras in the study reported below were thrown
awayassoonasitwasusedbythefacerecognitionsoftware.Theonlyvideoretainedwasthat
usedinpersonallifestoryacquisition.Allofthetextofdialogsbetweenusersandtheagentswere
gatheredintextform,downloadedtoaserver,andstoredbehindafirewallforexaminationafter
studycompletion.
6 ASTUDYOFTHEAGENTSINMONTHLONGTRIALS
ToevaluatetheefficacyoftheAlwaysOnsystem,virtualagentandrobotversionsofthesystem
weredeployedintothehomesofisolatedolderadults,wheretheyinteractedwiththesystemdaily
foramonth.
Followingseveralotherstudiesoncomparisonsbetweenvirtualandroboticagents,wehypoth-
esizedthattherobotwouldbesignificantlymoreeffectiveasacompanioncomparedtothevirtual
agent.Ourspecifichypotheseswereasfollows:
H1.ParticipantsintheAlwaysOnrobotconditionwillexperiencesignificantlygreaterdecrease
inlonelinesscomparedtothoseintheAlwaysOnvirtualagentcondition,andthoseinthevirtual
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:18 C.L.Sidneretal.
agentconditionwillexperiencesignificantlygreaterdecreaseinlonelinesscomparedtothosein
theControlconditionoverthe30-daydurationofthestudy.
H2.ParticipantsintheAlwaysOnrobotconditionwillexperiencesignificantlygreaterincrease
inhappinesscomparedtothoseintheAlwaysOnvirtualagentcondition,andthoseinthevirtual
agentconditionwillexperiencesignificantlygreaterincreaseinhappinesscomparedtothosein
theControlconditionoverthe30-daydurationofthestudy.
Experimentalsetup:Recruitmentforthestudyoccurredoverthecourseofoneyearthrough
craigslist’sposts,fliers,presentationsatlocalcommunitycentersandmailedrecruitmentletters.
Theseeffortsresultedin75responses,ofwhich44werefoundeligibleforthestudy.Tobeeligible,
participants need to be at least 55 years old, live alone, not exhibit major depressive symptoms
(below a 3 on the PHQ-2 measurement given below), and be healthy enough to engage in ba-
sic physical activity (as assessed by the PAR-Q, given below). Following informed consent and
screening,participantswererandomlyassignedtotherobot,virtualagent,orcontrolcondition.
Recruitmentofparticipantstookplaceoveranentireyear,andatmostfourparticipantshadan
agentintheirhome.Itwasmanymonthsintotheexperimentbeforeevenahandfulofparticipants’
resultswereavailableforanyoftheconditions.Giventhesmallnumbersofparticipantsassigned
toeachcondition,resultsofthewholestudywerenotavailableuntilafullyearhadpassed.
Intherobotandvirtualagentcondition,participantsscheduledatimefortheAlwaysOnsystem
tobesetupintheirhome.Oncescheduled,aresearchassistanttraveledtotheparticipant’shome
toinstalltherobotand/ortouchscreencomputer.Participantschosewhereintheirdwellingsthey
wishedtoplacethescreen/robot.Almostallsubjectschoosetheirlivingrooms,withtheexception
ofthosewholivedinstudioapartments,inwhichcaseitwasinthemainroom.Participantswere
thengivenabrieftutorialonhowtousethesystemandwereinstructedtotryandinteractwith
it at least once a day for 30 days. No additional instruction was given to the participants. After
the30-dayperiodpassed,theresearchassistantreturnedtotheparticipant’shometohavethem
completethedebriefquestionnairesandtocollectthesystem.
Participantsinthenon-interventioncontrolgroupwererecruitedinthesamemannerasother
participants and underwent the same intake procedure and baseline measurements. Following
this,theyweresenthomeandcontacted30dayslatertoreturntothelaboratoryforfinaloutcome
measurements.
Study Measures: During intake, the following questionnaires were given to participants to
evaluatetheirhealthstatusandeligibilityforthestudy:
• SociodemographicQuestionnaire(Toassessageandrelationshipstatus)
• PAR-Q(Toassessphysicalhealthstatus)[52]
• PHQ-2(Toassessmentalhealthstatus)[25]
Thefollowingmeasuresweregiventoparticipantsatintakeanddebrief:
• SocialSupportQuestionnaire[32]
• UCLALonelinessQuestionnaire[45]
• SF-12HealthStatus[7]
• GeneralHappiness[26]
In addition, three questionnaires that assessed the participants relation with a close friend or
familymemberwasgiventoassessanychangesintheparticipant’srelationshipduetothesystem:
• ABCQuestionnaireforAffectiveBenefits[35]
• RelationshipClosenessInventory[3]
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:19
Table1. PreandPostHealthOutcomes
Measures VirtualAgent Robot Control p
UCLALoneliness −0.09 −0.04 −0.1 0.9
SocialSupport −1.12 −1.62 −0.67 0.55
GeneralHappiness 0.21 0.25 0.58 0.55
Table2. OverallAverageSystemUsage
Measure VirtualAgent Robot p
TotalSessions 30.5(22.3) 27.5(22.6) 0.68
TotalTime(mins) 248.5(291.7) 241.0(201.4) 0.72
DaysUsed 22.2(12.7) 21.5(11.7) 0.57
Finally,thefollowing twoquestionnaires,developedbytheresearchteam,weregivenduring
debrief,alongwithasemi-structuredinterviewthatfocusedonevaluatingthesystem’sefficacy
andanymemorableexperiencestheyhadwithit:
• WorkingAlliancewithAgent
• SocialAgentRating
DailyMeasures:Inadditiontothequestionnairesgivenatintakeanddebrief,participantswere
given diary sheets to fill after each interaction with the system. These diary sheets consisted of
four5-pointLikertscalequestionsthatassessedtheirmoodandrelationshipwiththeagent.An
open-endedsectionwasalsoprovidedforparticipantstowriteanyadditionalthoughtstheyhad
abouttheagent.
Results:Forty-fourpeoplebetweentheagesof55and91(Mean:66,SD:7.89)wererecruitedand
randomizedtooneofthreestudyconditions.Thisdivisionresultedinelevencontrolparticipants,
twenty-four virtual agent participants and nine in the robot condition. Of these 44 participants,
36participants,10inthecontrolcondition,18intheagentcondition,and8intherobotcondition,
completedthestudy.Ofthosewhodroppedout,1wasduetoahardwarefailurewiththerobot,and
7droppedoutvoluntarilyduetoextraneouscircumstances(e.g.,illfamilymembersorunexpected
travel).Twoparticipantsdroppedoutduetoannoyanceswiththesystem,relatedtothesystem’s
brightnessandnoise.
Thereasonfortheimbalanceinrandomizationisthatthestudyteamoriginallyhadtwovirtual
agentconditionstostudytheeffectofdifferentvirtualagentdesigns.However,theteamfoundno
significantdifferencesbetweenthevirtualagentgroupsandsocombinedthemforallremaining
analyses.Althoughthenumbersofparticipantsaredifferentineachresultingcondition,Levene’s
testsdemonstratednosignificantdifferencesinhomogeneityofvariances,supportinguseofthe
one-wayANOVAtestsused.
Health/RelationshipResults:AsshowninTable1,nosignificantchangeswerefoundinthe
participant’shealthorrelationshipstatusacrossthethreeconditions.OnewayANOVAtestswere
usedfortheseresults.
SystemUsage:AspresentedinTable2,nosignificantdifferenceswerefoundinoverallsystem
usage between the robot and the virtual agent. Non-parametric Mann–Whitney tests were used
forsystemusagemeasures.
Furtheranalysisofsystemusage,showninTable3,foundthatacrossalltheconditions,weather
chatwasthemostusedmodule,followedbytheanecdotestheagenttold.Conversely,videocalls
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:20 C.L.Sidneretal.
Table3. AverageUsageperActivity
weretheleastusedmodule(nouserstriedit),followedbytellingstoriestotheagentandtheagent
tellingaboutitself.
AgentRatings:Tables4and5indicatethatnosignificantdifferencesbetweenstudycondition
and agent ratings. Non-parametric Kruskall–Wallis tests were used for this determination. The
desiretohaveaconversationwiththeagentandhowtrustworthyitseemedwerenearsignificance,
however(0.08),bothofwhichfavoringtherobotcondition.
Qualitative Results: Debrief interviews with the participant were recorded and transcribed
foruseinacategoricalanalysisinwhichthemesrelatedtocompanionship,socialsupport,enter-
tainment,realism,andisolationwereidentified.
Companionship and Social Support: During the debrief interviews, multiple participants
remarkedthattheagentprovidedsocialsupportandcompanionshiptothemduringtheirmonth-
longinteraction,claimingthattheagent’spersonalityallowedittobe“supportivebutnotjudg-
mental.Andhumanscanbejudgmentalevenwhentheydonotmeantobesometimes.Yourbody
languagesometimescomesacrossaseww.NotKaren”(P2).Multipleparticipantsalsofoundthat
theagent“kept[them]company”(P31),sinceitprovidedthemwithstoriesondemand,particu-
larlyforwhentherewas“nobodyIcouldtalktoat3inthemorning.And[theagent]wastelling
me storiesaboutherfriends whenmountain climbing.” (P4). However, they did find having her
theirhomedisruptiveattimes,sincetheyoftenfeltlikethey“hadtomeetwithhereveryday.It
wasaninconvenience”(P19).
Entertainment:Inlinewiththerecordedmetrics,manyparticipantsreportedthattheanec-
dotal stories told by the agent were highly engaging, with participants feeling that “the stories,
thejokesandtherecipeswerereallyfun.Shecouldbethelifeoftheparty.”Thebuilt-ingames
werealsohighlyregarded,sincetheparticipantsfounditusefulforkeepingtheir“mindoccupied
because as you get older....” (P31). However, due to the nature of the provided games and their
increased usage, participants seem to quickly exhaust them, mentioning that they wished there
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:21
Table4. AgentandRobotRatings
Question Anchor1 Anchor7 VirtualAgent Robot p
Howclosedo
youfeeltoKaren? Notatallclose Veryclose 3.62(1.98) 3.71(1.97) 0.64
Howsatisfied
areyouwithKaren? Notatallsatisfied Verysatisfied 4.06(1.78) 5(1.29) 0.17
Howmuchwould
youliketo
continueworking
withKaren? Notatall Verymuch 3.18(1.88) 3.14(2.04) 0.97
Howmuchdo
youtrustKaren? Notatall Verymuch 3.88(1.73) 5.14(1.35) 0.08
Howmuchdo
youlikeKaren? Notatall Verymuch 4.53(1.5) 5.14(1.35) 0.35
WasKarenrepetitive? Notatallrepetitive Veryrepetitive 5.82(1.47) 5.29(1.38) 0.41
Howeasywas
talkingtoKaren? Veryeasy verydifficult 3.31(1.89) 4(2.16) 0.48
Howinteresting
wasKaren? Notboring Veryinteresting 3.81(1.94) 4.71(1.98) 0.33
Howwouldyou
characterizeyour
relationshipwith
Karen? CompleteStranger Closefriend 3.81(1.47) 4.14(1.78) 0.67
Howmuchdo
youfeelthat
Karencares
aboutyou? Notatall Verymuch 3.88(1.86) 3.43(1.81) 0.6
Howmuchdo
youfeelthat
youandKaren
understandeach
other? Notatall Verymuch 3.56(1.86) 3.71(2.14) .87
Table5. AgentandRobotRatings(Continued)
Question Anchor1 Anchor7 VirtualAgent Robot p
Howmuchdo
youfeelthat
Karenwashonest
aboutherfeelings
towardsyou? Nothonest Veryhonest 3.94(1.81) 4.57(1.33) 0.32
Karenbehaved
intelligentlywhen
weinteracted. Disagreecompletely Agreecompletely 4.35(2.15) 4.86(1.77) 0.56
Karenunderstood
ourconversations. Disagreecompletely Agreecompletely 4.12(1.76) 5.14(1.35) 0.14
Iwantedtohave
aconversationwith
Karenbutforgot
todoso. Multipletimesaday Never 4.38(1.73) 5.43(0.98) 0.08
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:22 C.L.Sidneretal.
were “more games.” (P14) and that they should be “more challenging games. I would win every
timeandyouwantittobealittlebitofachallengenomatterhowoldyouare;everyoneseemsto
lovegame”(P33).
Realism: While a small set of participants found that interacting with the system “felt like
talkingtoaperson”(P1),manyparticipantswereputoffbytheroboticnatureoftheagent’svoice
andtherepetitiveoptionsinherdialogue.Participantsreportedfeelinglikethey“wouldmissher
moreifshehadabettervoice”(P14)andthatshe“doesnothaveapersonality”(P19).
Isolation: The topics of isolation and the target population for the system came up multiple
timesduringthedebriefinterviews,althoughtheywereoftenusedasawayinwhichthepartic-
ipant distanced themselves from the rest of the older adult population. While most participants
stated that they enjoyed using the system, they felt that it would be “more useful for a home-
bound senior” (P30) and that it was “more geared towards people [their] mother’s age” (P42).
Thesestatementsweremadeacrossalargerangeofages,suggestingthatthesestatementsmay
be more indicative of the type of participants recruited for the study rather than the target age
range.
6.1 DiscussionoftheStudy
Ourresultsdonotsupporteitherofourstudyhypotheses,namely,that:
H1.ParticipantsintheAlwaysOnrobotconditionwillexperiencesignificantlygreaterdecrease
inlonelinesscomparedtothoseintheAlwaysOnvirtualagentcondition,andthoseinthevirtual
agentconditionwillexperiencesignificantlygreaterdecreaseinlonelinesscomparedtothosein
theControlconditionoverthe30-daydurationofthestudy.
H2.ParticipantsintheAlwaysOnrobotconditionwillexperiencesignificantlygreaterincrease
inhappinesscomparedtothoseintheAlwaysOnvirtualagentcondition,andthoseinthevirtual
agentconditionwillexperiencesignificantlygreaterincreaseinhappinesscomparedtothosein
theControlconditionoverthe30-daydurationofthestudy.
Fortwotrendingsignificantmeasuresintheagentratings,itisnotablethattrustingtherobot
more is in keeping with previous studies discussed earlier in this article. Furthermore, the less
humanappearanceoftheReetirobotagentmayhavecontributedtousers’senseoftrustbecause
oftheuncannyvalleyeffectincreatingrobotsthatseemmorehumanlike.Reasonsforthesecond
measure, that users wanted to have conversations more with the robot than the agent, are less
clear.Onepossibleexplanationisthatthephysicalformoftheagentsmattersintheinteractions.
Therobot’sphysicalpresenceandmoreapparentfacetrackingmotionsmayhavecontributedto
thedesireforconversation.Onecouldsaythattherobotseemedmore“real”thanthevirtualagent.
Whileboththerobotandthevirtualagentperformedfacetracking,thisbehaviorwasmuchmore
noticeableintherobotagent.However,whetherthesetwodifferencesorsomethingelseisatplay
isamatterforfuturestudy.
Theonlytwovaluesthatapproachtrending,butarenotlowenoughtobeconsideredtrends,are
satisfaction with Karen (0.17) and Karen understanding the conversation (0.14). Interestingly, in
bothcases,theLikertscoresgivenbytheparticipantsarehigheroverallforbothagentsthanany
ofthescoreswherethereisnosignificance.Higherscoresinthesetwoquestionscanbeseenas
indicatingthat(1)interactingwitheitheragentwasnotachorefortheparticipants,(2)theagents
were capable of enough conversational interaction to create a satisfying interaction, and (3) the
userslikedbothagentsataratingofbetween4.5and5.1onaverage.Onecanalsonotethatusers
onaveragereportedthattheagentswerenotperceivedasstrangers,witharatingbetween3.8and
4.1.Atthesametime,higherscoreswerealsogiventotheclaimthatKarenwasrepetitive,which
wereratedabove5onaveragebyallparticipants.Inanticipationofthisproblem,theAlwaysOn
team attempted to design the conversations to limit repetition, which clearly did not succeed.
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:23
Reducingrepetitivenessinagentswillcontinuetoplagueinteractionthatextendsoverlongspans
oftime.Moreeffortondialogvariabilityaswellastechniquesforagentpersonalityandawareness
ofuseremotionmightaddressthischallengingproblem.
On the whole, the study participants had a positive, though not strongly positive, attitude
toward both agents, virtual and robotic. Furthermore, they interacted with the agent often and
overmanyoftheactivitiesmadeavailabletothem. Fortheextensiveeffortinvestedincreating
this technology, this observation is satisfying to the AlwaysOn team. The reliability of the
technology may have also contributed to the positive values of the study participants although
nodirectmeasuresweremadeaboutparticipants’perceptionsofreliability.
ThereliabilityoftheAlwaysOnagentsisnotedhere.Basedoncullingthelogfiles,therewere
five reliability issues that required in-person visits in the robot condition only. There were nine
reliability issues, three in the robot condition and six in the agent condition, that were fixed
remotely.Consideringthetotalnumberofdaysusedbyallusers(approximately572acrossrobot
andvirtualagentconditions)andthetotalofnumberofminutesbyallusers(approximately4,482
intheagentconditionand1,928intherobotcondition),theteamfeltgratifiedbytheoperation
oftheAlwaysOnagentsandtheAlwaysOnsystem.
The research team believes that a valuable take-home lesson of the AlwaysOn project is
the difficulty of getting participants for a study. Isolated adults are hard to reach by their very
nature.Ayearofeffortintrackingdownparticipantsbyvariousmethodsdidnotyieldasmany
participants as one would have liked, nor ones that were as isolated as statistics indicate exist
in the US. Perhaps teaming with a hospital or large clinic would be a viable path in the future,
althoughtherearemanychallengesinpatientprivacytobeconsideredinsuchanundertaking.
7 CONCLUSIONS
This article has presented the technology developed in the AlwaysOn project to provide a wide
rangeofactivitiestoaparticularuserpopulation,isolatedolderadults.Theinterfacesforthetech-
nologyincludedacartoon-stylevirtualagentandaReetirobot,bothofwhichconversedwitha
userviaspeechoutputandmenuinputonatouchscreen.Theytalkedwithusersaboutactivities
designedtoprovidecompanionshipandtoreduceisolationthroughdigitalconnectionstofriends
andfamilyandtothephysicalcommunity.Thetechnologyprovidedameanstotrackuser’sfaces,
permit users to barge in during agent speech, provide for the agent to turn its face to an activ-
ity displayed onscreen, as well as to initiate interactions on perceiving the user’s face but with
awarenessoftheuser’sdesiresaboutwhethertoconverseatanygiventime.
Thisworkalsopresentedearlyinvestigationsonhowthetechnologymightbeused,followed
bytheresultsofamonth-longstudyinthehomesofelderusers.Thereareveryfewlongitudinal
studiesofagenttechnologyforisolatedeldersofmorethanafewparticipants,andinthisregard,
theeffortwassuccessful.Whiletheresultsarenotasconclusiveastheteamhadhopedfor,they
do indicate that each user used the agents regularly and tried out many, though not all, of the
activitiesdeveloped.Trendingresultssuggestthatuserswillbemoretrustingofrobotsandmore
desirousofconversationswiththem.Overall,usersindicatedthatconversationswithbothagents
weresatisfyingtoalltheusers,anduserslikedthem.Also,notsurprisinggivenpreviousresearch,
usersindicatedthattheagentswerenotcompletestrangerstothem.
The activities provided for the agents in AlwaysOn were pre-determined and introduced by
asimplesetofrules.Forlongertermuse,overmanymonthsoryears,onecouldimaginealess
pre-determinedmethodforintroducingactivitiesaswellasintroducingactivitiesthatwerecreated
afterthesystemwasbeingused,anddroppingoldonesthatwerenotused.Methodsmightinclude
learningfromagroupofusersaboutwhichactivitiestheyfirstchoosetouseorsmallchatsthat
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:24 C.L.Sidneretal.
would focus on a single as yet unused activity to introduce it to the user. Such methods might
alleviatethefailuretouseactivitiesthattheAlwaysOnprojectexperienced.
Oneshouldnotconcludethatthereisnoplaceforvirtualagentsinhometechnologygiventhe
preferencethatseemstoholdforroboticagents.Itisquiteconceivablethatrobotswillbeuseful
inthehome,notonlyforthetypesofactivitiescreatedfortheAlwaysOnprojectbutalsowhen
theycanreliablymovearoundandprovidephysicalservicestoseniors.Atthesametime,virtual
agents,perhapslookingjustliketherobot,willbeusefuloncellphonestohelpwhenasenioris
outgettingexercise,doinggroceryshopping,orprovidingalistofthingstoremembertoaskone’s
physicianabout.Thusthesetechnologiescouldformacontinuumofuseinthelivesofseniorsand
non-seniors.
Finally,somecommentsaboutresearchtechnologyinthehome.Toplacetechnologyformore
thanafewdaysinauser’shome,elderornot,requiresasignificantcommitmenttotesting,de-
bugging, and beta testing to assure that the technology is reliable and bug proof. This level of
effortisnotnormallyassociatedwithresearchprojects.However,reliabletechnologyisessential
tounderstandinghowtechnologyplaysaroleinusers’lives.
ACKNOWLEDGMENTS
We acknowledge the programming and evaluation efforts of a group of students and staff:
Dr. Barbara Barry, Elizabeth Bates, Morteza Behrooz, Bridgette Collado, Will Coon, Teryn
Falkingham,AyeshaFathima,HannahDoolittle,AshleyKline,J.J.Liu,KennethManning,Ramesh
Manuvinakurike,EliseMasson,KarlylePilones,KathleenTotzke,JohnConnorWestfall,Mitchell
Wills,andZheZhang.
REFERENCES
[1] M. Argyle and M. Cook. 1976. Gaze and Mutual Gaze. Cambridge University Press. DOI:https://doi.org/10.1017/
S0033291700018523
[2] M.Behrooz,C.Rich,andC.Sidner.2014.Onthesociabilityofagame-playingagent:asoftwareframeworkand
empiricalstudy.InProceedingsofthe14thInternationalConferenceonIntelligentVirtualAgents.Springer.40–53.
DOI:https://doi.org/10.1007/978-3-319-09767-1_6
[3] E.Berscheid,M.Snyder,andA.M.Omoto.1989.Therelationshipclosenessinventory:Assessingtheclosenessof
interpersonalrelationships.J.Pers.Soc.Psychol.57,5(1989),792.DOI:https://doi.org/10.1037//0022-3514.57.5.792
[4] T.Bickmore,L.Caruso,K.Clough-Gorr,andT.Heeren.2005.“It’sjustlikeyoutalktoafriend”:Relationalagentsfor
olderadults.Interact.Comput.17,6(Dec.2005),711–735.DOI:https://doi.org/10.1016/j.intcom.2005.09.002
[5] T.Bickmore,D.Schulman,andL.Yin.2010.Maintainingengagementinlong-terminterventionswithrelational
agents.Int.J.Appl.Artif.Intell.24,6(Jul.2010),648–666.DOI:https://doi.org/10.1080/08839514.2010.492259
[6] T.Bickmore,R.Silliman,K.Nelson,D.Cheng,M.Winter,L.Henaulat,andM.Paasche-Orlow.2013.Arandomized
controlledtrialofanautomatedexercisecoachforolderadults.J.Am.Geriat.Soc.61,10(Sept.2013),1676–1683.
DOI:https://doi.org/10.1111/jgs.12449
[7] JakobB.BjornerandDianeM.Turner-Bowker.2009.SF-36andSF-12healthsurveys.InEncyclopediaofMedical
DecisionMaking,Vol.2MichaelW.Kattan(Ed.).1030–1036.DOI:http://dx.doi.org/10.4135/9781412971980.n299
[8] RobertN.Butler.1964.Thelifereview:Aninterpretationofreminiscenceintheaged.InNewThoughtsonOldAge.
R.Kastenbaum(Ed.).Springer,Berlin.65–70.DOI:https://doi.org/10.1007/978-3-662-38534-0_20
[9] C.Chao,C.Lee,M.Begum,andA.Thomaz.2011.SimonplaysSimonsays:Thetimingofturn-takinginanimitation
game.InProceedingsoftheInternationalSymposiumonRobotandHumanInteractiveCommunication(RO-MAN’11).
IEEEPress,NewYork,NY,235–240.DOI:https://doi.org/0.1109/ROMAN.2011.6005239
[10] JuanFasolaandMajaJ.Matarić.2013.Asociallyassistiverobotexercisecoachfortheelderly.J.Hum.-RobotInteract.
2,2(2013),3–32.DOI:https://doi.org/10.5898/JHRI.2.2.Fasola
[11] J.FodorandM.Roubens.1994.FuzzyPreferenceModelingandMulticriteriaDecisionSupport.Springer,TheNether-
lands,1994.DOI:10.1007/978-94-017-1648-2_8
[12] MaartjeM.A.deGraaf,SomayaBenAllouch,andJanA.G.M.vanDijk.2017.Long-termevaluationofasocialrobot
inrealhomes.InteractionStudies17,3(Jul2017).DOI:https://doi.org/10.1080/07370024.2017.1312406
[13] M.Granata,A.Chetouani,A.Tapus,P.Bidaud,andA.Dupourque.2010.Voiceandgraphical-basedinterfacesfor
interactionwitharobotdedicatedtoelderlyandpeoplewithcognitivedisorders.InProceedingsofthe19thIEEE
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:25
InternationalSymposiumonRobotandHumanInteractiveCommunication(RO-MAN’10).IEEE,785–790.DOI:https://
doi.org/10.1109/ROMAN.2010.5598698
[14] EricoGuizzo.Robosoftunveilskompairobottoassistelderly,Disabled.IEEESpectrumOnline.(March9,2010).
Retrieved February 1, 2017 from http://spectrum.ieee.org/automaton/robotics/medical-robots/robosoft-kompai-
robot-assist-elderly-disabled.
[15] S.Hanke,E.Sandner,C.Tsiourti,andA.Stainer-Hochgatterer.2015.Thetechnicalspecificationandarchitectureof
avirtualsupportpartner.InProceedingsoftheWorkshoponAffectiveInteractionwithAvatars,inConjunctionwiththe
EuropeanConferenceonAmbientIntelligence(AmI’15).
[16] D.Hasegawa,J.Cassell,andK.Araki.2010.Theroleofembodimentandperspectiveindirection-givingsystems.
Dialogwithrobots:AAAIFallSymposium.2010.RetrievedOctober25,2017fromhttps://www.aaai.org/ocs/index.
php/FSS/FSS10/paper/view/2186.
[17] A.Holroyd,C.Rich,C.Sidner,andB.Ponsler.2011.Generatingconnectioneventsforhuman-robotcollaboration.In
Proceedingsofthe20thIEEEInternationalSymposiumonRobotandHumanInteractiveCommunication(ROMAN’11).
IEEEPress,241–246.DOI:https://doi.org/10.1109/ROMAN.2011.6005245
[18] A.HolroydandC.Rich.2012.Usingthebehaviormarkuplanguageforhuman-robotinteraction.InProceedingsof
theACMConferenceonHuman–RobotInteraction.ACMPress,NewYork,NY,147–148.DOI:https://doi.org/0.1145/
2157689.2157728
[19] C.Huijnen,A.Badii,H.vandenHeuvel,P.Caleb-Solly,andD.Thiemert.2011.Maybeitbecomesabuddy,but
donotcallitarobot-seamlesscooperationbetweencompanionroboticsandsmarthomes.InProceedingsofthe
2ndInternationalJointConferenceonAmbientIntelligence(AmI’11).Springer,NewYork,NY,324–329.DOI:https://
doi.org/10.1007/978-3-642-25167-2
[20] D. O. Johnson, R. H. Cuijpers, J. F. Juola, E. Torta, M. Simonov, A. Frisiello, M. Bazzani, W. Yan, C. Weber, S.
Wermter,N.Meins,J.Oberzaucher,P.Panek,G.Edelmayer,P.Mayer,andC.Beck.2014.Sociallyassistiverobots:
Acomprehensiveapproachtoextendingindependentliving.Int.J.Soc.Robot.6,2(Apr.’14).195–211.DOI:https://
doi.org/10.1007/s12369-013-0217-8
[21] AdamKendon.1967.Somefunctionsofgazedirectionintwopersoninteraction.ActaPsychol.26(1967),22–63.
DOI:https://doi.org/10.1016/0001-6918(67)90005-4
[22] C. Kidd and C. Breazeal. 2004. Effect of a robot on user perceptions. In Proceeings of the IEEE/RSJ International
ConferenceonIntelligentRobotsandSystems(IROS’04),Vol.4.IEEEPress,NewYork,NY,3559–3564.DOI:https://
doi.org/10.1109/IROS.2004.1389967
[23] C.D.KiddandC.Breazeal.2008.Robotsathome:Understandinglong-termhuman-robotinteraction.InProceedings
oftheIEEE/RSJInternationalConferenceonIntelligentRobotsandSystems(IROS’08).IEEEPress,LosAlamitos,CA,
3230–3235.DOI:https://doi.org/10.1109/IROS.2008.4651113
[24] T.Klamer,S.BenAllouch,andD.Heylen.2010.“Adventuresofharvey”:Use,acceptanceofandrelationshipbuilding
withasocialrobotinadomesticenvironment.InProceedingsofthe3rdInternationalConferenceonHuman–Robot
PersonalRelationships(HRPR’10),Springer,Berlin,74–82.DOI:https://doi.org/10.1007/978-3-642-19385-9_10
[25] B.Löwe,K.Kroenke,andK.Gräfe.2005.Detectingandmonitoringdepressionwithatwo-itemquestionnaire(PHQ-
2).J.Psychosomat.Res.58,2(2005),163–171.DOI:https://doi.org/10.1016/j.jpsychores.2004.09.006
[26] S.LyubomirskyandH.Lepper.1999.Ameasureofsubjectivehappiness:Preliminaryreliabilityandconstructvali-
dation.Soc.Indic.Res.46,2(1999),137–155.DOI:https://doi.org/10.1023/A:1006824100041
[27] D.Maciuszek,J.Åberg,andN.Shahmehri.2005.Evaluationandrefinementofadesignframeworkforgenerating
dependablevirtualcompanionsforlaterlife.InProceedingsofthe3rdInternationalConferenceonSmarthomesand
HealthTelematics:FromSmartHomestoSmartCare(ICOST’05),IOSPress,Amsterdam,TheNetherlands,50–64.
[28] MarcusMast,MichaelBurmester,KatjaKrüger,SaschaFatikow,GeorgArbeiter,BirgitGraf,GernotKronreif,Lucia
Pigini,DavidFacal,andRenxiQiu.2012.User-centereddesignofadynamic-autonomyremoteinteractionconcept
formanipulation-capablerobotstoassistelderlypeopleinthehome.J.Hum.-RobotInteract.1,1(2012).DOI:https://
doi.org/10.5898/jhri.1.1.mast
[29] MiraculousLife.2013.RetrievedFebruary1,2017fromhttp://www.miraculous-life.eu/index.php.
[30] M.Nani,P.Caleb-Solly,S.Dogramadgi,C.Fear,andH.vandenHeuvel.2010.MOBISERV:Anintegratedintelligent
homeenvironmentfortheprovisionofhealth,nutritionandmobilityservicestotheelderly.InProceedingsofthe4th
CompanionRoboticsWorkshop.
[31] N.R.Nicholson.Areviewofsocialisolation:Animportantbutunderassessedconditioninolderadults.J.Primary
Prevent.33,2–3(Jun.2012),137–152.DOI:https://doi.org/10.1007/s10935-012-0271-2
[32] J. S. Norbeck, A. M. Lindsey, and V. L. Carrieri. 1983. Further development of the norbeck social support ques-
tionnaire: Normative data and validity testing. Nursing Research 32, 1 (1983), 4–9. DOI:https://doi.org/10.1097/
00006199-198301000-00002
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
17:26 C.L.Sidneretal.
[33] B.Nooraei,C.Rich,andC.Sidner.2014.Areal-timearchitectureforembodiedconversationalagents:Beyondturn-
taking.InProceedingsofthe7thInternationalConferenceonAdvancesinComputer–HumanInteractions.
[34] HugoPinto,YorickWilks,RobertaCatizone,andAlexieiDingli.2008.Theseniorcompanionmultiagentdialogue
system.InProceedingsofthe7thInternationalJointConferenceonAutonomousAgentsandMultiagentSystems.1245–
1248.
[35] L.E.PowellandA.M.Myers.1995.Theactivities-specificbalanceconfidence(ABC)Scale.J.Gerontol.ABiol.Sci.
Med.Sci.50A,1(1995),M28–M34.DOI:https://doi.org/10.1093/gerona/50A.1.M28
[36] M.ReblinandB.N.Uchino.2008.Socialandemotionalsupportanditsimplicationforhealth.Curr.Opin.Psychiatr.
21,2(Mar.2008),201–205.DOI:https://doi.org/10.1097/YCO.0b013e3282f3ad89
[37] Reeti,aSmartCompagnon,aMultimediaTool.2017.RetrievedMarch1,2017fromhttp://www.reeti.fr/index.php/
en/detailen.
[38] P.H.Robert,A.Konig,H.Amieva,S.Andrieu,F.Bremond,R.Bullock,M.Ceccaldi,B.Dubois,S.Gauthier,P.A.
Kenisgberg,S.Nave,J.M.Orgogozo,J.Piano,M.Benoit,J.Touchon,B.Vellas,J.Yesavage,andV.Manera.Recom-
mendationsfortheuseofSeriousGamesinpeoplewithAlzheimer’sDisease,relateddisordersandfrailty.Front.
AgingNeurosci.6,54,(Mar.24,2014).DOI:10.3389/fnagi.2014.00054
[39] L.Ring,L.Shi,K.Totzke,andT.Bickmore.Socialsupportagentsforolderadults:Longitudinalaffectivecomputing
inthehome.J.MultimodalUserInterfaces9,1(2015),79–88.DOI:https://doi.org/10.1007/s12193-014-0157-0.
[40] C.RichandC.Sidner.1999.Collagen:Acollaborationmanagerforsoftwareinterfaceagents.UserModel.User-Adapt.
Interact.8,3/4(Sep.1998),315–350.DOI:10.1023/A:1008204020038
[41] C.Rich,C.Sidner,andN.Lesh.2001.Collagen:Applyingcollaborativediscoursetheorytohuman-computerinter-
action.AIMag.22,4(Winter2001),15–25.DOI:https://doi.org/10.1609/aimag.v22i4.1589
[42] C. Rich. 2009. Building task-based user interfaces with ANSI/CEA-2018. IEEE Comput. 42, 8 (Aug. 2009), 20–27.
DOI:https://doi.org/10.1109/MC.2009.247.
[43] C.Rich,B.Ponsler,A.Holroyd,andC.Sidner,2010.Recognizingengagementinhuman-robotinteraction.InPro-
ceedingsofthe5thACM/IEEEInternationalConferenceonHuman-RobotInteraction.IEEEPress,LosAlamitos,CA.
375–382.DOI:https://doi.org/10.1109/HRI.2010.5453163
[44] C.RichandC.L.Sidner.2012.Usingcollaborativediscoursetheorytopartiallyautomatedialoguetreeauthoring.
InProceedingsofthe12thInternationalConferenceonIntelligentVirtualAgents(IVA’12),Springer,Berlin,327–340.
DOI:https://doi.org/10.1007/978-3-642-33197-8_34.
[45] D.RussellandL.Peplau.1980.TherevisedUCLAlonelinessscale:Concurrentanddiscriminantvalidityevidence.J.
Pers.Soc.Psychol.39(Sep.1980),472–480.DOI:http://dx.doi.org/10.1037/0022-3514.39.3.472
[46] S.Sabanovic,T.Bennett,W.Chang,andL.Huber.2013.PAROrobotaffectsdiverseinteractionmodalitiesingroup
sensorytherapyforolderadultswithdementia.InProceedingsoftheIEEEInternationalConferenceonRehabilitation
Robotics(ICORR’13).IEEEPress,LosAlamitos,CA.1–6.DOI:10.1109/ICORR.2013.6650427
[47] EmanuelA.SchegloffandHarveySacks.1973.Openingupclosings.Semiotica8,4(Nov.2009).289–327.DOI:https://
dx.doi.org/10.1515/semi.1973.8.4.289.
[48] A.Seiderer,S.Hammer,E.Andre,M.Mayr,andT.Rist.2015.Exploringdigitalimageframesforlifestyleintervention
toimprovewell-beingofolderadults.InProceedingsofthe5thInternationalConferenceonDigitalHealth(DH’15).
ACMNewYork,NY71–78.DOI:https://doi.org/10.1145/2750511.2750514.
[49] C.L.Sidner,C.Lee,C.Kidd,N.Lesh,andC.Rich.2005.Explorationsinengagementforhumansandrobots.Artif.
Intell.166,1–2(Aug.2005),140–164.DOI:https://doi.org/10.1016/j.artint.2005.03.005.
[50] C.L.Sidner,C.Rich,M.Shayganfar,T.Bickmore,L.Ring,andZ.Zhang.2015.Aroboticcompanionforsocialsupport
ofisolatedolderadults.InExtendedAbstracts,Proceedingsofthe10thAnnualACM/IEEEInternationalConferenceon
Human-RobotInteractionExtendedAbstracts(HRI’15),ACMPress,NewYork,NY.289.DOI:https://doi.org/10.1145/
2701973.2702103.Videoat:https://www.youtube.com/watch?v=HngGcvEuB60,retrievedJanuary1,2017.
[51] AndrewSteptoe,AparnaShankar,PanayotesDemakakos,andJaneWardle.Socialisolation,lonelinessandall-cause
mortalityinoldermenandwomen.Proc.Natl.Acad.Sci.U.S.A.110,15(Apr.9,2013),5797–5801.DOI:https://doi.org/
10.1073/pnas.1219686110
[52] PaulD.Thompson,RossArena,DeborahRiebe,andLindaPescatello.2013.ACSMsnewpreparticipationhealth
screeningrecommendationsfromACSMsguidelinesforexercisetestingandprescription,ninthedition.JCurr.Sports
Med.Rep.12,4(Jul./Aug.2013),215–217.DOI:https://doi.org/10.1249/jsr.0b013e31829a68cf
[53] ChristianaTsiourti,EmilieJoly,CindyWings,andKatarzynaWac.Virtualassistivecompanionsforolderadults:Qual-
itativefieldstudyanddesignimplication.InProceedingsofthe8thInternationalConferenceonPervasiveComputing
TechnologiesforHealthcare.57–64.DOI:10.4108/icst.pervasivehealth.2014.254943.
[54] L.PfeiferVardoulakis,L.Ring,B.Barry,C.Sidner,andT.Bickmore.2012.Designingrelationalagentsaslongterm
socialcompanionsforolderadults.InProceedingsofthe12thInternationalConferenceonIntelligentVirtualAgents
(IVA’12).Springer-Verlag,Berlin,289–302.DOI:https://doi.org/10.1007/978-3-642-33197-8.
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
CreatingNewTechnologiesforCompanionableAgentstoSupportIsolatedOlderAdults 17:27
[55] H.Vilhjálmsson,N.Cantelmo,J.Cassell,N.E.Chafai,M.Kipp,S.Kopp,M.Mancini,S.Marsella,A.N.Marshall,
C.Pelachaud,Z.Ruttkay,K.R.Thórisson,H.vanWelbergen,andR.J.vanderWerf.2007.Thebehaviormarkup
language:recentdevelopmentsandchallenges.InProceedingsoftheConferenceonIntelligentVirtualAgents(IVA’07).
LectureNotesinComputerScience,Vol.4722.C.Pelachaud,J.C.Martin,E.André,G.Chollet,K.Karpouzis,andD.
Pelé(eds).Springer,Berlin.DOI:https://doi.org/10.1007/978-3-540-74997-4_10
[56] K.Wada,T.Shibata,T.Saito,andK.Tanie.2003.Effectsofrobotassistedactivitytoelderlypeoplewhostayatahealth
servicefacilityfortheaged.InProceedingsofthe2003IEEE/RSJInternationalConferenceonIntelligentRobotsand
Systems(IROS’03),Vol.3.IEEEPress,LosAlamitos,CA,2847–2853.DOI:https://doi.org/10.1109/IROS.2003.1249302
[57] J.Wainer,D.Feil-Seifer,D.A.Shell,andM.J.Matarić.2007.Embodimentandhuman-robotinteraction:Atask-based
perspective.Proceedings,16thIEEEInternationalWorkshoponRobotandHumanInteractiveCommunication(RO-MAN
2007),IEEEPress(2007),872–877.DOI:https://doi.org/10.1109/ROMAN.2007.4415207
[58] K.Windle,F.FrancisandC.Coomber.2011.PreventingLonelinessandSocialIsolation:InterventionsandOutcomes.
(October2011).RetrievedOctober25,2017fromhttps://www.scie.org.uk/publications/briefings/briefing39/.
[59] J.Wrobel,Y.Wu,H.Kerhervé,L.Kamali,A.Rigaud,C.Jost,B.LePévédic,andD.Duhaut.2013.Effectofagent
embodimentontheelderuserenjoymentofagame.InProceedingsofthe6thInternationalConferenceonAdvancesin
Computer-HumanInteractions(ACHI’13).
[60] R.Yaghoubzadeh,M.Kramer,K.Pitsch,andS.Kopp.2013.Virtualagentsasdailyassistantsforelderlyorcogni-
tivelyimpairedpeople,studiesonacceptanceandinteractionfeasibility.In13thInternationalConferenceonIntelli-
gentVirtualAgentsandIntelligentVirtualAgents(IVA’13),Spring-Verlag,Berlin.79–91.DOI:https://doi.org/10.1007/
978-3-642-40415-3
[61] V.Yngve.1970.Ongettingawordinedgewise.InPapersfromthe6thRegionalMeetingoftheChicagoLinguistics
Society.UniversityofChicago,DepartmentofLinguistics,567–578.
ReceivedApril2017;revisedFebruary2018;acceptedMarch2018
ACMTransactionsonInteractiveIntelligentSystems,Vol.8,No.3,Article17.Publicationdate:July2018.
