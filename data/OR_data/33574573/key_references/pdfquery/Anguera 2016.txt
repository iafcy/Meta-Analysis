
Conducting a fully mobile and 
randomised clinical trial for 
depression: access, engagement 
and expense 
Joaquin A Anguera,1 Joshua T Jordan,1 Diego Castaneda,1 
Adam Gazzaley,1 Patricia A Areán2 
▸ Additional material is 
published online only. To view 
please visit the journal online 
(http://dx.doi.org/10.1136/ 
bmjinnov-2015-000098). 
1Departments of Neurology and 
Psychiatry, University of 
California, San Francisco, 
California, USA 
2Department of Psychiatry and 
Behavioral Sciences, University of 
Washington, Seattle, 
Washington, USA 
Correspondence to 
Dr Patricia A Areán, Department 
of Psychiatry and Behavioral 
Sciences, University of 
Washington, 1959 Northeast 
Pacific Street, Seattle, 
WA 98195, USA; 
parean@uw.edu 
Received 19 October 2015 
Accepted 27 December 2015 
Open Access 
Scan to access more 
free content 
To cite: Anguera JA, 
Jordan JT, Castaneda D, et al. 
BMJ Innov 2016;2:14–21. 
ABSTRACT 
Importance Advances in mobile technology 
have resulted in federal and industry-level 
initiatives to facilitate large-scale clinical research 
using smart devices. Although the benefits of 
technology to expand data collection are 
obvious, assumptions about the reach of mobile 
research methods (access), participant willingness 
to engage in mobile research protocols 
(engagement), and the cost of this research 
(cost) remain untested. 
Objective To assess the feasibility of a fully 
mobile randomised controlled trial using 
assessments and treatments delivered entirely 
through mobile devices to depressed individuals. 
Design Using a web-based research portal, 
adult participants with depression who also 
owned a smart device were screened, consented 
and randomised to 1 of 3 mental health apps for 
treatment. Assessments of self-reported mood 
and cognitive function were conducted at 
baseline, 4, 8 and 12 weeks. Physical and social 
activity was monitored daily using passively 
collected phone use data. All treatment and 
assessment tools were housed on each 
participant’s smart phone or tablet. 
Interventions A cognitive training application, 
an application based on problem-solving therapy, 
and a mobile-sensing application promoting daily 
activities. 
Results Access: We screened 2923 people and 
enrolled 1098 participants in 5 months. The 
sample characteristics were comparable to the 
2013 US census data. Recruitment via Craigslist. 
org yielded the largest sample. Engagement: 
Study engagement was high during the 
first 2 weeks of treatment, falling to 44% 
adherence by the 4th week. Cost: The total 
amount spent on for this project, including 
staff costs and β testing, was $314 264 over 
2 years. 
Conclusions and relevance These findings 
suggest that mobile randomised control trials can 
recruit large numbers of participants in a short 
period of time and with minimal cost, but study 
engagement remains challenging. 
Trial registration number NCT00540865. 

INTRODUCTION 
Five hundred million individuals use 
mental health apps worldwide, with these 
numbers expected to reach 1.7 billion by 
2018.1 The potential for mobile devices 
to revolutionise healthcare and clinical 
research has not been lost on either 
academia.4–6 Notable 
industry2 
examples of initiatives to collect behav- 
ioural data using mobile technology are 
the Patient-Centered Outcomes Research 
Institute 
Patient- 
(PCORI)-funded 
Centered Clinical Outcomes Research 
Networks, National Institutes of Health 
(NIH’s) Precision Medicine Initiative, and 
Apple’s Research Kit. 
the use 
technology appears to be a 
of 
research 
increase 
clear 
avenue 
participation.7 8 



Mobile technologies may be particu- 
larly useful 
in improving participant 
access to and reducing expenses of rando- 
mised clinical trials (RCTs). Typical RCTs 
cost millions of dollars and recruit 200– 
300 participants in 3–5 years.9 Sample 
demographics are determined by the 
location of the research institution, limit- 
ing the representativeness of many RCT 
samples. Expense and access problems 
are exacerbated when trying to study 



populations who are challenging to recruit, such as 
those with mental 
illnesses, people living in rural 
areas or racial/ethnic minority populations. 

One solution to overcome access and cost issues has 
been the use of the internet to conduct randomised 
control studies. These trials are beneficial from the 
cost perspective, with estimated cost reductions of 
conventional 
50% compared with 
more 
trials,10 11 and from the access perspective, 
these 
studies recruit very large samples in short periods of 
time.12 13 However, retention issues are particularly 
studies, with one recent 
problematic for internet 
internet-based trial reporting a drop-out rate of over 
90% in a sample of 3000 individuals.14 Drop-out is 
likely due in part to the need to access a WiFi connec- 
tion and dependence on an immobile device (eg, a 
desktop computer). A potential advantage to research 
using mobile devices (smart phones and tablets) is that 
data can be collected anywhere at any time. These 
devices also facilitate passive data collection such as 
Global Positioning System (GPS) information from the 
phone’s accelerometer and media usage to gauge 
social and physical activity that can supplement self- 
reports. However, while mobile technology may be 
able to further expand the reach of clinical research, 
this approach has yet to be tested. 
The purpose of this study is to determine the feasi- 
bility of conducting a fully remote RCT using smart 
devices in depressed adults 18 years old and older. We 
elected to study depression as our clinical focus given 
its ubiquitous presence in mental illnesses and disabil- 
ity.15 It 
is the leading cause of disability world- 
wide,16 17 and the enrolment of depressed individuals 
into clinical trials is difficult.18 19 In this paper, we 
report data on population access (sample representa- 
tiveness), engagement assessment and cost to complete 
the study. 
METHODS 
Ethical approval for the trial was granted by the 
UCSF Committee for Human Research. 
Recruitment 
To test our hypotheses about access, we used three dif- 
ferent types of recruitment approaches: traditional, 
social networking and search engine-based methods. 
Traditional methods were written ads placed in city 
buses, newspapers and Craigslist postings throughout 
the USA. Social networking methods included regular 
postings on sites such as Facebook and Twitter, and 
contextual-targeting methods to identify and directly 
push recruitment ads to potential participants, based 
on their Twitter and other social media comments. 
Our 
search engine-based method included using 
Google Adwords, a historically successful recruitment 
tool.20 Each approach (described further in see online 
potentially 
supplementary materials) 

interested participants a link to our custom study 
website (http://www.brightenstudy.com). 
Participant eligibility 
Participants had to speak English, be 18 years old or 
older, own a smartphone (iPhone or Android) with 
WiFi or 3G/4G capabilities, and own an iPad2 or 
iPad ownership was required as our 
newer device. 
cognitive assessment tool was only available on this 
device at the time of the study. To characterise recruit- 
ing logistics without 
individuals 
this 
without an iPad but with a smartphone were given the 
opportunity to participate in phone-only study arms 
that were not part of 
the randomised sample. A 
Patient Health Questionnaire (PHQ-9),21 score of 5 
or greater, or a score of 2 or greater on PHQ item 10 
(indicating that they felt disabled in their life because 
of their mood), was also required for enrolment. 

Procedure 
Screening 
Potential participants were directed to a website 
(http://www.brightenstudy.com) explaining the study 
purpose and procedures. Interested participants com- 
pleted an online brief screening consisting of ques- 
tions about mobile device ownership. 
Consent 
We used a combination of a written consent and 
custom videos posted on YouTube to explain the 
study. Participants had to pass a quiz that tested their 
understanding that the study was voluntary, was not a 
substitute for treatment and that they were to be ran- 
domised. Each question had to be answered correctly 
before moving on to baseline assessment and random- 
isation. Eligibility was established after consent was 
obtained. 
Randomisation 
Participants were randomised to one of three treat- 
ment arms where they viewed a brief video explaining 
how to download and use the assessment and assigned 
treatment app. Participants were also given a link to 
view a custom dashboard of their study progress. 
Treatment 
Participants were asked to use their assigned app for 
1 month. The first app was a cognitive intervention 
video game (Project: EVO™, or EVO) designed to 
modulate cognitive control abilities, a common neuro- 
logical deficit underlying depression.22 The second 
intervention was an app based on an evidence-based 
treatment for depression ( problem-solving therapy, or 
PST).23 The final 
intervention app, an information 
control, provided daily health tips (HT) for overcom- 
ing depressed mood such as self-care (eg, taking a 
shower) or physical activity (eg, taking a walk; see 
online supplementary materials for further descrip- 
tions of each). 



Assessment 
We used two apps to collect baseline and 4, 8 and 
12 weeks of outcome data. The first app, developed 
by Ginger.io™ was used to collect 
self-reported 
mood, function and passive analytics such as commu- 
nication data (text logs including call/text time, call 
duration, text length and screen usage), and mobility 
data (activity type and distance travelled using the 
phone’s accelerometer and GPS). The second app was 
a mobile 
(Adaptive 
Cognitive Evaluation (ACE)), 
to measure cognitive 
control processes (see online supplementary etable 1). 
Participants were automatically notified every 8 h for 
24 h if they had not completed a survey within 8 h of 
its original delivery. An assessment was considered 
missing if it was not completed within this 24 h time 
frame. 



The baseline assessment included the collection of 
including age, race/ethnicity, martial 
demographics 
and employment status, 
income, education, smart 
device ownership, use of other health apps, and use 
of mental health services, including use of medications 
and psychotherapy. We collected information on 
mental health status using the PHQ-924 for depres- 
sion, the generalized anxiety disorder (GAD)-7,22 for 
generalised anxiety, a four-item mania and psychosis- 
screening instrument25 and the four-item National 
Institute on Alcohol Abuse and Alcoholism (NIAAA) 
Alcohol Screening Test.26 To assess for self-reported 
disability, we used the Sheehan Disability Scale.27 28 
We also asked participants to rate their health on a 
scale of excellent to poor. 
Daily assessments were a combination of self- 
report and passive data collection. Participants com- 
pleted the PHQ-2 (mood and enjoyment) every 
morning. The Ginger.io app collected passive analy- 
tics daily. Private information such as actual content 
of voice calls or text messages or emails was not 
collected. 
The 4-week, 8-week and 12-week assessments 
included the PHQ-9 to measure changes in mood, 
ACE for changes 
in cognitive control, and the 
Sheehan for changes in disability. Participants were 
also asked this question: ‘since using this app, I feel 
that I am: (1) much worse, (2) worse, (3) no different, 
(4) improved, (5) much improved’. 
Payment 
Randomised participants were paid a total of $75 
for completing all assessments over the 12 weeks via 
Amazon gift vouchers, while participants in the 
phone-only arms were paid $45 as they did not 
if 
complete 
increased payment led to increased adherence and 
retention, a subset of participants (n=144) were 
given $75 in bonus pay if 
they completed all 
assessments. 



Procedures to reduce gaming 
‘Gaming’ 
is a situation where a user fraudulently 
enrols in a study solely to acquire research payment. 
We utilised the following safeguards to prevent this: 
(1) locking the eligibility survey if a participant tried 
to change a submitted answer, (2) using study links 
that are valid for one user/device, and (3) tracking IP 
addresses to minimise duplicate enrolment. 





Statistical analyses 
To assess participant access, we describe the sample 
demographics, 
and sample 
comorbidities using the appropriate descriptive statis- 
tics. To assess participant engagement, we examined 
the proportion of study drop-outs and the proportion 
of enrolled individuals who responded to the primary 
mood outcome measures at each time point using a 
mixed-model 
(with 
Greenhouse-Geisser corrections when needed). To cal- 
culate time to drop-out, we tested a survival analysis 
model with the distribution of the ‘survival’ times for 
those assigned each app estimated and non-parametric 
estimates of the survivor function computed by the 
Kaplan-Meier method, with curves tested using the 
log-rank test using Stata V.14.0. We also examined 
whether there was a significant difference in drop-out 
rates among the three interventions using Pearson’s χ2 
test. Pairwise log-rank tests were conducted to 
determine where there were significant differences 
between the distributions, and a Bonferroni correc- 
tion was set at p<0.017 to correct for multiple 
comparisons. We also compared these outcomes for 
the entire sample and by sample type (randomised 
and non-randomised). To assess issues surrounding 
cost, we describe a total study cost approach factor- 
ing in β testing, staff time and efforts beyond those 
payments made for 
recruitment and participant 
remuneration. 
RESULTS 
Access 
Recruitment rate 
National recruitment began in August of 2014, and 
was conducted in five, 2-week advertising waves (total 
of 5 months of recruitment). We recruited a total of 
2923 participants. Of 
these recruited individuals, 
1098 were enrolled to the randomised (N=626) and 
the study (see 
non-randomised (N=472) arms of 
figure 1). Eighty-nine per cent of the sample came 
from traditional recruitment approaches, <1% came 
from social networking, <1% came from search 
from 
engine-based methods, 
unanticipated means (own search, referrals). We were 
able to successfully recruit individuals from 8 of the 
15 most rural states in the USA29 without any targeted 
recruitment efforts (see figure 2A). 





Figure 2 Demographic characteristics. (A) Percentage of recruited participants across the USA. (B) Percentage of participants within 
different age ranges from the recruited sample. (C) Ethnic composition of the recruited individuals, and its comparison to the 
observed ethnic composition reported in the 2013 US Census. 





Age 
Education 
<12 years 
College 
Graduate 

$20 000 or less 
$20 000–$40 000 
$40 000–$60 000 
$60 000–$80 000 
$80 000–$100 000 
$100 000+ 
Number of females 
Per cent of minority 
Marital status 
Single 
Married 
Divorced/separated/widowed 
Psychiatric 
PHQ-9 
GAD 
NIAAA 
Mania Hx 
Psychosis Hx 
Using other health apps 
Per cent of rural 
In treatment 










39 (18.48) 
133 (63.03) 
39 (18.48) 
42 (35.00) 
32 (26.67) 
26 (21.67) 
6 (5.00) 
6 (5.00) 
8 (6.67) 
160 (75.83) 
83 (39.34) 
118 (55.92) 
62 (29.38) 
31 (14.69) 
13.76 (4.91) 
10.36 (4.97) 
3.20 (2.54) 
22 (14.57) 
2 (1.32) 
128 (87.67) 
5 (2.37) 
84 (57.5) 
31 (14.83) 
129 (61.72) 
49 (23.44) 
31 (35.23) 
21 (23.86) 
17 (19.32) 
9 (10.23) 
3 (3.41) 
7 (7.95) 
161 (77.03) 
87 (41.63) 
112 (53.59) 
73 (34.93) 
24 (11.48) 
13.51 (5.06) 
9.15 (4.92) 
3.03 (2.24) 
15 (11.90) 
1 (0.79) 

3 (1.44) 
64 (52.5) 
36 (17.48) 
122 (59.22) 
49 (23.30) 
39 (31.71) 
30 (24.39) 
17 (13.82) 
18 (14.63) 
7 (5.69) 
12 (9.76) 
173 (83.98) 
82 (39.81) 
118 (57.28) 
68 (33.01) 
20 (9.71) 
13.64 (4.90) 
10.39 (5.32) 
3.40 (2.31) 
20 (14.71) 
3 (2.21) 
116 (86.57) 
7 (3.40) 
74 (56.5) 
52 (21.85) 
148 (62.18) 
38 (15.97) 
73 (53.28) 
37 (27.01) 
18 (13.14) 
7 (5.11) 
1 (0.73) 
1 (0.73) 
198 (83.19) 
94 (39.50) 
164 (68.91) 
53 (22.27) 
21 (8.82) 
13.61 (5.02) 
10.54 (5.53) 
3.34 (2.35) 
25 (16.03) 
3 (1.92) 
124 (79.49) 
9 (3.78) 
84 (55.3) 
77 (32.91) 
125 (53.42) 
32 (13.68) 
79 (58.96) 
34 (25.37) 
14 (10.45) 
4 (2.99) 
1 (0.75) 
2 (1.49) 
172 (73.50) 
110 (47.01) 
150 (64.10) 
53 (22.65) 
31 (13.25) 
15.01 (5.23) 
10.38 (5.46) 
2.98 (2.43) 
25 (15.15) 
3 (1.82) 
125 (77.64) 
5 (2.14) 
81 (50.9) 
Mean (SD) for continuous variables; number (percentage) for categorical. 
HT, health tips; Hx, medical history; PHQ, Patient Health Questionnaire; PST, problem solving therapy. 
Sample demographics 
Participants were primarily young adults (see figure 2B), 
although age ranged from 18 to 76, with 79% identify- 
ing as female. Fifty-eight per cent of our sample was 
non-Hispanic white, and an ethnicity distribution com- 
parable to the 2013 US Census 
(see figure 2C). 
Fifty-seven per cent of our participants obtained a 
4-year college degree or higher, with a mean annual 
income of $30–$35 000 (see table 1). Sixty-seven per 
cent of our participants were employed at the time of 
enrolment. There was a difference in age between ran- 
domised and phone-only assigned participants, with 
randomised participants slightly older than phone-only 
t(954.38)=−3.22, p=0.001. However, 
participants, 
there was no difference in gender between these groups 
(x2 
1=0.08, p=0.77). Enrolled individuals who were 
single/never married reported greater symptoms of 
depression (t[528.17]=2.96, p=0.003). 
Clinical characteristics 
The sample was moderately depressed at baseline, 
with a PHQ-9 mean score of 13.9 (SD=5.1). There 
was a significant association between age and depres- 
sion severity, Spearman’s r=−0.11, p<0.001. There 
was no significant difference in depression severity 
among gender (t(365.85)=0.63, p=0.53) or ethnic 
(F(6, 1091)=1.37, p=0.22). Fifty-one per 
groups, 
cent 
reported comorbid anxiety, 53% reported 
comorbid alcohol misuse, 16% reported a history of 
psychosis or mania. In total, 54.5% of our sample was 
receiving mental health treatment for their depression. 
This sample mirrored the ethnic disparities in mental 
health service use found in the general population, 
with 63% of non-Hispanic white participants in treat- 
ment, and only 42% of ethnic minorities were in 
1=28.6, p<0.001, OR=2.29). There 
treatment 
were no significant differences in depression severity 
among individuals randomised to the three primary 
arms (F[2, 623]=0.14, p=0.87; see table 1). 

Engagement 
Sixty-six per cent of the sample completed the 4-week 
assessment, 50% completed the 8-week assessment 
and 41% completed the 12-week assessment 
(see 
figure 3A). There was no adherence difference by 
group (F(2, 241)=2.50, p=0.08) and no time by 
group interaction (F(3.55, 428.14)=1.93, p=0.11). 



and participants with lower education, 
sizes were small (see table 2). 


Kaplan-Meier survival analysis was conducted to 
determine whether intervention assignment or any 
baseline demographic variables predicted drop-out 
status. The log-rank test revealed a significant differ- 
ence between the survival distributions between 
groups (x2 
2=19.27, p<0.001), with the EVO arm 
having significantly earlier time to drop-out than the 
PST arm (x2 
1=17.51, 
p<0.001) arms (see figure 3B). We did not find a sig- 
nificant difference in survival distributions for those 
with high versus low PHQ-9 scores (using a PHQ-9 
score of 10 as a cut-point, x2 
2=2.29, p=0.13). There 
was no significant difference in survival distributions 
between non-Hispanic whites and ethnic minorities 
(x2 
1=2.13, p=0.14). Participants who received bonus 
pay remained in the study longer than those who did 
not receive a bonus (x2 
1=11.82, p<0.001). Bonus pay 
was for assessment completion, not intervention app 
use. 


Cost 
included participant payments 
Total 
($23 320), website/enrolment portal/database develop- 
ment ($46 507), and salaried staff time (3; 2 student 
volunteers also assisted) over the 9 months the study 
was active ($58 917), summing to a total of $128 444. 
The total amount spent on for this project, including 
staff costs, development and β testing of the UCSF 
developed apps (ACE and iPST), and licensing fees for 

0.001 
<0.001 
<0.01 
0.46 
0.06 
0.06 


0.24 
0.36 
0.25 
0.11 
0.23 
0.33 

14.5 (4.9) 
30.7 (10.8) 
95 (25.54) 
211 (56.72) 
66 (17.74) 
75 (20.2) 
161 (43.3) 
91 (47.40) 
52 (27.08) 
30 (15.62) 
7 (3.65) 
6 (3.12) 
6 (3.12) 
Figure 3 Intervention and assessment adherence. (A) 
Percentage of individuals who responded to their mood 
assessment during the treatment phase (first 4 weeks) and 
follow-up periods (weeks 8 and 12). (B) Kaplan-Meier survival 
estimates per study arm illustrating survival distributions of time 
to drop-out (last day of recorded activity) over the course of the 
study (84 days). 
We found similar adherence to the cognitive assess- 
ment tool, with neither a group (F=0.46, p=0.63) 
nor 
(F=0.91, p=0.42). 
Although lower assessment adherence was observed in 
the more depressed participants, younger participants, 


Assessment adherence 
PHQ-9‡ 
Age‡ 
Education§ 
<12 years 
College 
Graduate 
Gender¶ 
Minority** 
Income†† 
$20 000 or less 
$20 000–$40 000 
$40 000–$60 000 
$60 000–$80 000 
$80 000–$100 000 
$100 000+ 

13.25 (5.0) 
34.7 (11.4) 
61 (17.09) 
206 (57.70) 
90 (25.21) 
80 (22.4) 
130 (36.4) 
81 (39.32) 
50 (24.27) 
34 (16.50) 
21 (10.19) 
6 (2.91) 
14 (6.80) 
*Means and SDs unless otherwise specified. 
†All effect sizes converted to Cohen’s d. 
‡Welch t test. 
§Pearson χ2 test; number and percentage. 
¶Pearson χ2 test; number and percentage of males. 
**Pearson χ2 test; number and percentage of ethnic minorities. 
††Fisher’s exact test; number and percentage. 
PHQ, Patient Health Questionnaire. 



the use of the other apps (EVO and Ginger.io) was 
$314 264 over 2 years. 
DISCUSSION 
The results from this study have a number of important 
implications for the future of RCTs in mental health. 
First, we recruited a large sample of depressed partici- 
pants in a short period of time and with minimal cost 
and effort. Currently, the typical RCT takes 4–5 years 
to complete, and another 1–2 years before the out- 
comes from these trials are reported publically. Rapid 
recruitment has the potential for quickly testing inter- 
vention efficacy and effectiveness, and ultimately 
moving effective treatments into practice while identi- 
fying and preventing the proliferation of ineffective, 
treatments. Second, we were able to 
even unsafe, 
recruit a highly representative sample of the US popu- 
lation, without any specific cultural adaptations or tar- 
geted advertising. Remote research methods could 
address decades-long concerns about the generalisabil- 
ity of clinical findings to minority samples not typically 
represented in clinical research. Finally, the cost of a 
fully remote RCT could allow for greater distribution 
of dwindling clinical research and development funds 
foundation and industry sponsors. 
from federal, 
Investment 
trials is a costly 
endeavour, resulting in the need to focus funds on only 
a few research areas. Although not all mental health 
RCTs should be fully remote, particularly those that 
test hypotheses about biological or neurological pro- 
cesses that can only be measured with immobile 
devices, the methods presented here, such as auto- 
mated data collection of neuropsychological processes 
could result in substantial savings, which in turn could 
be invested in a diverse research portfolio. 

This research method is not without its limitations. 
Primary among the challenges of fully remote research 
is the ability to keep participants engaged in the study 
protocol over time. Although there is an appeal to 
quickly recruiting and retaining large numbers of par- 
ticipants in an RCT, researchers and developers need 
to be cautious when interpreting outcomes 
from 
samples with a drop-out rate greater than 70%.30–33 
However, it is important to point out here that the 
project was completely automated with very little 
contact between the participant and research team, 
and our retention rates were higher than in the typical 
internet-based RCT.34 
Internet-based studies have 
shown that when there is more direct contact between 
the research team and participant through technolo- 
gies such as video-over-internet protocols, retention 
rates are greater and less subject to bias,35 suggesting a 
hybrid approach may provide an optimal response. 
Although we experimented with two incentive 
models to encourage retention, we determined that 
participant payment was not enough to keep engage- 
ment from waning across the course of the study, as 
bonus pay only encouraged participants to complete 
their assessments, and did not engender any additional 
motivation to utilise the training apps. Previous work 
has demonstrated that externalised benefits in the 
form of compensation can dull motivation,36 37 indi- 
cating that the creation of internalised reward struc- 
ture 
individualised 
presentation of study progress, personalised encour- 
agements) is critical for improved adherence. 

CONCLUSIONS 
Mobile technology has an important role in broaden- 
ing the reach and representativeness of RCTs, while 
substantially reducing the time to determine interven- 
tion effectiveness and reducing study costs. Although 
study retention remains challenging for technology- 
based research, innovative methods to increase motiv- 
ation and study engagement could easily address this 
important limitation. 
Acknowledgements The authors thank A Brandes-Aitken 
(UCSF), M Brander (UCSF) and A Bodepudi (UCSF) for 
assistance in data monitoring, M Gross (UCSF) and J Camire 
(Ekho.me) for their help in participant recruitment, J Steinmetz 
(Ekho.me) for database architecture, D Ziegler (UCSF) for 
helping with app deployment, D Albert (UCSF) for assistance in 
web design, L Slavik (UCSF) for accounting assistance, C 
Catledge (UCSF) for administrative oversight, A Piper, E 
Martucci, S Kellogg, J Bower, M Omerick and the entire Akili 
Interactive team as well as I Elson, L Kaye, S Goobich and the 
rest of the Ginger.io team for helping with data collection and 
partnering with us on this project. They also thank all the 
participants whose time and efforts made this work possible. 
Support for this research was provided by the National Institute 
of Mental Health (P.A.A.; R34-MH100466, T32 MH0182607, 
K24 MH074717). JAA and JTJ had full access to all of the data 
in the study and take responsibility for the integrity of the data 
and the accuracy of the data analysis. 
Competing interests AG is co-founder, chief science advisor and 
shareholder of Akili Interactive Labs, a company that develops 
cognitive training software. AG has a patent pending for a 
game-based cognitive training intervention, ‘Enhancing 
cognition in the presence of distraction and/or interruption’, on 
which the cognitive training application (PROJECT: EVO) that 
was used in this study was based. 

Provenance and peer review Not commissioned; externally 
peer reviewed. 
Open Access This is an Open Access article distributed in 
accordance with the Creative Commons Attribution Non 
Commercial (CC BY-NC 4.0) license, which permits others to 
distribute, remix, adapt, build upon this work non- 
commercially, and license their derivative works on different 
terms, provided the original work is properly cited and the use 
is non-commercial. See: http://creativecommons.org/licenses/by- 
nc/4.0/ 
REFERENCES 
1 devices UFaDAM. Secondary. http://www.fda.gov/ 
medicaldevices/productsandmedicalprocedures/ 
connectedhealth/mobilemedicalapplications/default.htm 
2 Campbell KR. An apple a day: changing medicine through 



4 Mohr D. Highlight: A Therapist in One’s Pocket: mHealth to 
Improve Access to Mental Health Care. Secondary Highlight: 



A Therapist in One’s Pocket: mHealth to Improve Access to 
Mental Health Care, 2015. http://www.nimh.nih.gov/about/ 
strategic-planning-reports/highlights/highlight-a-therapist-in- 
ones-pocket-mhealth-to-improve-access-to-mental-health-care. 
shtml 

Something Interesting is Happening, 2015. http://www.nimh. 
nih.gov/about/director/2015/something-interesting-is- 
happening.shtml 
6 Price M, Yuen EK, Goetter EM, et al. mHealth: a mechanism 
to deliver more accessible, more effective mental health care. 
Clin Psychol Psychother 2014;21:427–36. 

partnerships between providers and patients. Issue Brief 
(Commonw Fund) 2013;30:1–10. 

mHealth system for supporting self-care in management of 
complex and chronic conditions. JMIR Mhealth Uhealth 
2013;1:e10. 
9 Alexopoulos GS, Raue PJ, McCulloch C, et al. Clinical case 
management versus case management with problem-solving 
therapy in low-income, disabled elders with major depression: 
a randomized clinical trial. Am J Geriatr Psychiatry 
2015;24:50–9. 
10 McAlindon T, Formica M, Kabbara K, et al. Conducting 
clinical trials over the internet: feasibility study. BMJ 
2003;327:484–7. 

recruiting for clinical trials in pregnancy. PLoS ONE 2014;9: 
e92744.. 

recruitment to randomised controlled trials: systematic review. 
PLoS Med 2010;7:e1000368. 

randomised trials: a review of randomised controlled trials. 
BMC Med Res Methodol 2006;6:34. 

controlled trial of Internet cognitive behavioural treatment for 
social phobia with and without motivational enhancement 
strategies. Aust N Z J Psychiatry 2010;44:938–45. 
15 Lopez AD, Mathers CD. Measuring the global burden of 
disease and epidemiological transitions: 2002–2030. Ann Trop 
Med Parasitol 2006;100:481–99. 
16 Torres ER. Disability and comorbidity among major depressive 
disorder and double depression in African-American adults. 
J Affect Disord 2013;150:1230–3. 
17 Ferrari AJ, Charlson FJ, Norman RE, et al. Burden of depressive 
disorders by country, sex, age, and year: findings from the 
global burden of disease study 2010. PLoS Med 2013;10: 
e1001547. 

recruitment into depression trials: systematic review, 
meta-synthesis and conceptual framework. J Affect Disord 
2015;172:274–90. 

opportunities in recruitment of depressed mothers: lessons 
learned from three exemplar studies. Ann Psychiatry Mental 
Health 2015;3:1022. 
20 Gross MS, Liu NH, Contreras O, et al. Using Google AdWords 
for international multilingual recruitment to health research 
websites. J Med Internet Res 2014;16:e18. 

Questionnaire-2: validity of a two-item depression screener. 
Med Care 2003;41:1284–92. 

severity of PRIME-MD diagnosed episodes of panic and 
generalized anxiety disorder in primary care. J Gen Intern Med 
2005;20:623–8. 

approach for unipolar depression. J Consult Clin Psychol 
1986;54:196–202. 

brief depression severity measure. J Gen Intern Med 
2001;16:606–13. 
25 Unutzer J, Katon W, Williams JW Jr, et al. Improving primary 
care for depression in late life: the design of a multicenter 
randomized trial. Med Care 2001;39:785–99. 
26 Vaca FE, Winn D, Anderson CL, et al. Six-month follow-up of 
computerized alcohol screening, brief intervention, and referral 
to treatment in the emergency department. Subst Abus 
2011;32:144–52. 

of disability. Int Clin Psychopharmacol 1996;11(Suppl 3): 
89–95. 

impairment in primary care with the Sheehan Disability Scale. 
Int J Psychiatry Med 1997;27:93–105. 

the states? 2012. http://www.dailyyonder.com/ 
how-rural-are-states/2012/04/03/3847/ 

interviews: a comparison of Facebook, Craigslist, and Snowball 
recruiting. Soc Sci Comput Rev 2015. doi:10.1177/ 
0894439315578240 
31 Ramo DE, Hall SM, Prochaska JJ. Reaching young adult 
smokers through the internet: comparison of three 
recruitment mechanisms. Nicotine Tob Res 2010;12: 
768–75. 

recruitment, screen, tracking, data management, and quality 
control in a dietary assessment clinical validation trial. 
Contemp Clin Trials 2010;31:138–46. 
33 Warren J, Smalley KB, Barefoot KN. Recruiting rural and 
urban LGBT populations online: differences in participant 
characteristics between email and Craigslist approaches. Health 
Technol 2015;5:103–14. 
34 Murray E, Khadjesari Z, White IR, et al. Methodological 
challenges in online trials. J Med Internet Res 2009;11:e9. 
35 Bull SS, Vallejos D, Levine D, et al. Improving recruitment and 
retention for an online randomized controlled trial: experience 
from the Youthnet study. AIDS Care 2008;20:887–93. 

for depressed African Americans. Int J Psychiatry Med 
2008;38:71–80. 





