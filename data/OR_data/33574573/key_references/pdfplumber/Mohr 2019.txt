JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
Original Paper
Comparison of the Effects of Coaching and Receipt of App
Recommendations on Depression, Anxiety, and Engagement in
the IntelliCare Platform: Factorial Randomized Controlled Trial
David C Mohr1, PhD; Stephen M Schueller2, PhD; Kathryn Noth Tomasino3, PhD; Susan M Kaiser1, MPH; Nameyeh
Alam1, MS; Chris Karr4, MS; Jessica L Vergara1, BA; Elizabeth L Gray5, MS; Mary J Kwasny5, PhD; Emily G Lattie1,
PhD
1Center for Behavioral Intervention Technologies, Northwestern University, Chicago, IL, United States
2Department of Psychological Science, University of California, Irvine, Irvine, CA, United States
3Department of Gastroenterology, Northwestern University, Chicago, IL, United States
4Audacious Software, Chicago, IL, United States
5Department of Preventive Medicine, Northwestern University, Chicago, IL, United States
Corresponding Author:
David C Mohr, PhD
Center for Behavioral Intervention Technologies
Northwestern University
750 N Lakeshore Drive
10th Floor
Chicago, IL, 60611
United States
Phone: 1 312 503 1403
Email: d-mohr@northwestern.edu
Abstract
Background: IntelliCare is a modular platform that includes 12 simple apps targeting specific psychological strategies for
common mental health problems.
Objective: This study aimed to examine the effect of 2 methods of maintaining engagement with the IntelliCare platform,
coaching, and receipt of weekly recommendations to try different apps on depression, anxiety, and app use.
Methods: A total of 301 participants with depression or anxiety were randomized to 1 of 4 treatments lasting 8 weeks and were
followed for 6 months posttreatment. The trial used a 2X2 factorial design (coached vs self-guided treatment and weekly app
recommendations vs no recommendations) to compare engagement metrics.
Results: The median time to last use of any app during treatment was 56 days (interquartile range 54-57), with 253 participants
(84.0%, 253/301) continuing to use the apps over a median of 92 days posttreatment. Receipt of weekly recommendations resulted
in a significantly higher number of app use sessions during treatment (overall median=216; P=.04) but only marginal effects for
time to last use (P=.06) and number of app downloads (P=.08). Coaching resulted in significantly more app downloads (P<.001),
but there were no significant effects for time to last download or number of app sessions (P=.36) or time to last download (P=.08).
Participants showed significant reductions in the Patient Health Questionnaire-9 (PHQ-9) and Generalized Anxiety Disorder-7
(GAD-7) across all treatment arms (P s<.001). Coached treatment led to larger GAD-7 reductions than those observed for
self-guided treatment (P=.03), but the effects for the PHQ-9 did not reach significance (P=.06). Significant interaction was
observed between receiving recommendations and time for the PHQ-9 (P=.04), but there were no significant effects for GAD-7
(P=.58).
Conclusions: IntelliCare produced strong engagement with apps across all treatment arms. Coaching was associated with
stronger anxiety outcomes, and receipt of recommendations enhanced depression outcomes.
Trial Registration: ClinicalTrials.gov NCT02801877; https://clinicaltrials.gov/ct2/show/NCT02801877
(J Med Internet Res 2019;21(8):e13609) doi: 10.2196/13609
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 1
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
KEYWORDS
depression; anxiety; mHealth; clinical trial
The IntelliCare platform was designed to address user
Introduction
engagement problems by providing self-help strategies and
skills training in a manner that is consistent with how people
Background
use mobile phones. Rather than a single app containing a
Depression and anxiety are common mental health problems
comprehensive set of behavioral strategies, the IntelliCare
that impose a very high societal burden in terms of cost,
platform currently comprises 12 apps, each of which is focused
morbidity, quality of life, and disability worldwide [1-4]. Most
on a single psychological or behavioral strategy. The time
people experiencing these common mental health problems
required for each use is short, with most uses lasting less than
cannot access treatment because of a variety of barriers including
1 min [18]. Thus, apps can be integrated more seamlessly into
the lack of availability of services, time constraints,
a person’s life. Users are able to select and use apps that they
transportation problems, and high cost [5,6]. A wide variety of
find helpful and ignore the ones they do not like. A Hub app,
digital mental health interventions have demonstrated efficacy.
if downloaded, coordinates the user’s experience and provides
Adherence and outcomes appear to be stronger when coupled
weekly recommendations to try new apps. The provision of
with human coaching through telephone or messaging than in
recommendations appears to be an important component in
self-guided digital interventions [7-9]. Mobile apps, in particular,
maintaining engagement with the IntelliCare platform. Indeed,
have a number of advantages. Smartphones are becoming
the receipt of these recommendations has been shown to increase
ubiquitous in developed countries and are increasingly common
the likelihood that an individual will download the
in developing nations [10]. As people keep their phones with
recommended app [19,20].
them, app-based interventions can fit more seamlessly into the
fabric of people’s lives. IntelliCare apps have been available on the Google Play Store,
beginning in 2014, and have been downloaded more than
Most digital interventions for depression or anxiety are single
100,000 times. An initial field trial, in which participants
Web-based and mobile apps. Very few of the publicly available
received 8 weeks of coaching primarily through text messages,
apps have been rigorously tested, with reviews suggesting that
showed substantial improvements in both depressive and anxiety
the percentage of available apps for depression and anxiety with
symptoms’severity, and strong, consistent engagement of an
any evidence of effectiveness may be around 2.6% to 3.8%
average of 3 to 4 app launches each day over the full 8 weeks
[11,12]. A common design approach is to adapt an effective
[18]. Interestingly, although the coached field trial showed
psychotherapeutic model such as cognitive behavioral therapy
participants used most of the apps, the average use within any
(CBT) and digitize it into an app format. Such apps typically
individual app was substantially different from that observed
contain a multitude of features related to the treatment model
among users who simply downloaded the apps through the
on which they are based. For example, in CBT, these apps might
Google Play Store, suggesting that coaches may have
contain psychoeducation, symptom tracking, activity monitoring,
encouraged exploration of new apps but did not appear to
activity scheduling, and cognitive restructuring [13]. This
influence continued use once users had downloaded and tried
approach of feature-rich apps does not recognize how most
the apps. Thus, there appear to be 2 methods of encouraging
people currently tend to use apps and their smartphones. In
exploration in app platforms such as IntelliCare: coaching and
general, digital technologies have core features that break into
automated recommendations.
basic components, allowing users to piece together those
components that are most useful. For example, people tend not Although sustained behavioral engagement, or app usage, has
to have 1 app to meet their transportation needs; rather, they been noted to be a major problem in digital mental health
usually have multiple apps that search for locations and map interventions [21,22], few investigations have systematically
routes, and different apps for different modes of transportation. explored different methods of maintaining engagement.
Different people likely use different apps according to their Moreover, 1 study explored a factorial design of 5 different
preferences and lifestyles. Typically, popular apps serve singular engagement elements, including automated versus human
purposes, such as searching for restaurants or businesses, support, text messages, tailoring of success stories,
managing flights, or posting pictures. People tend to use apps personalization of content, and multimedia and interactive
in very short bursts of time, and sometimes frequently [14,15]. materials [23]. Human support was the only element that
Thus, apps tend to support a single or limited set of related tasks improved outcomes during the intervention period, which is
through simple, quick interactions. Indeed, even when people consistent with a large body of literature showing human support
do use existing mental health apps, they typically only use 1 or improves engagement and outcomes [7,24]. However, those
2 features. For example, in an evaluation of PE Coach, which who received automated support experienced more change
contains a number of features, it was found that clinicians and during the postintervention period. Given the ubiquity of app
patients mostly used the app to audio-record sessions [16]. This store recommendations, this is a promising element to evaluate.
gap between the design of mental health apps, which is typically
Objectives
based on complex psychotherapy models, and how people use
This study aimed to examine the effect of 2 separate methods
their devices, which commonly occurs in short bursts for single
of maintaining engagement with the IntelliCare platform:
purposes, likely is 1 reason for the low engagement with mental
coaching and receipt of weekly recommendations to try different
health apps seen in real-world settings [17].
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 2
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
apps. We hypothesized that coaching would produce better regulation, positive self-affirmations, coping, exercise for mood,
engagement with the apps and greater reductions in symptoms sleep hygiene, relaxation, and psychoeducation with reminders)
of depression and anxiety than that associated with self-guided and improve symptoms of depression and anxiety through
use, and those who received both coaching and app efficacious treatment strategies. Most apps were designed to
recommendations would have the greatest reductions in require less than 30 seconds to use. Apps included automated
symptoms and highest use of apps. reminders to encourage engagement and for both app use and
implementation of the strategies. The user’s experience with
Methods the clinical apps was coordinated through a Hub app that
consolidated automated notifications and provided app
Participants recommendations for those who were randomized to receive
Participants were recruited from July 5, 2016, to May 5, 2017, recommendations. No substantive changes were made to the
through a variety of digital (eg, Instagram, Facebook, and apps during the course of the trial.
Reddit) and print (eg, advertisements on Chicago Transit
Coaching Versus Self-Guidance
Authority bus and train lines) sources as well as research
Coaching was guided by the IntelliCare coaching manual [29],
registries (eg, ResearchMatch), commercial recruitment firms
which is based on the supportive accountability model [30] and
(eg, Focus Pointe Global), and media coverage using methods
the efficiency model [31], and was aimed primarily at
that have been previously described [25,26]. Participants were
encouraging participants to try the apps, answering questions
included if they met criteria for depression (Patient Health
Questionnaire-9 [PHQ-9]≥10) [27] or anxiety (Generalized about how to use the tools represented in the apps and the
Anxiety Disorder-7 [GAD-7]≥8) [28], were aged 18 years or rationale behind the skills taught by the apps, encouraging
application of the skills in daily life, and providing some
older (aged 19 years if in Nebraska, given age of consent),
technical support as needed. Coaching began with an initial 30-
resided in the United States, could speak and read English, and
to 45-min engagement phone call to explain the program,
had an Android phone with data and text plans. Participants
understand the participant’s goals for mood and anxiety
were excluded if they (1) had visual, voice, motor, or hearing
management, set expectations for the coach-participant
impairments that would prevent participation; (2) met diagnostic
relationship, build rapport, and ensure the Hub app was properly
criteria for a severe psychiatric disorder such as psychotic or
installed on the participant’s phone. After the initial engagement
bipolar disorders for which study treatments would be
call, participants received 2 to 3 text messages per week from
inappropriate; (3) imminent suicidality that included both a plan
their coach to provide support in using apps, offer
and intent; (4) had initiated or modified antidepressant
encouragement, reinforce app use, and check-in on progress or
pharmacotherapy in the previous 14 days; or (5) had used any
challenges. Coaches also responded to all participant-initiated
IntelliCare app more than 1 time in the 3 months before study
text messages within 1 working day. Coaches offered but did
screening.
not require an additional 10-min call around midtreatment to
All procedures were approved by the institutional review board support engagement. The coaches had a dashboard that provided
of Northwestern University. Participants completed a Web-based information about the IntelliCare apps on each participant’s
consent form, and a research assistant reviewed the Web-based phone, including which apps were installed, when they were
consent document to ensure comprehension questions were downloaded, each time an app was used, and which apps were
answered correctly and that the consent form was signed. Any selected as primaryin the Hub app. The dashboard also included
questions or concerns were then reviewed with participants. a short message service text messaging tool, a section for brief
The trial was monitored by an independent data safety notes, and an alert indicating when no IntelliCare app had been
monitoring board. used for 3 days or when a participant sent a text message
indicating they might be at risk for self-harm, which resulted
Treatments
in an automated safety response and prompted coaches to
This trial used a 2 × 2 factorial design (coached vs self-guided
check-in. Coaches had at least a bachelor’s degree in psychology
treatment and weekly app recommendations vs no
or a related field and were trained and monitored by 1 of the
recommendations), resulting in 4 treatment cells. A no treatment
coaching manual authors.
or waitlist control was not included because it would be
impossible to prevent control participants from accessing the Participants assigned to self-guidance received the initial 10-
apps, which are freely available on the Google Play Store, and to 15-min engagement call to ensure the Hub app was properly
it could not be reliably determined which apps were accessed installed and that they understood how to use the IntelliCare
and when. The IntelliCare platform, coaching protocol, and the platform but had no further contact with coaches.
recommended system are described below.
Recommendations
IntelliCare Platform Participants randomized to the recommendation arm received
All participants received access to the IntelliCare platform apps. a weekly tray notification on their phone’s home screen, which
At the time of this trial, the IntelliCare platform consisted of 13 took them to the Hub app, where they were provided with
apps [18,20]. This included 12 clinical apps, each of which was weekly recommendations for new apps. Touching the
designed to target a specific behavioral or psychological recommendation button took them to the app store where they
treatment strategy (eg, goal setting, behavioral activation, social could download the recommended app. The recommendation
support, living one’s values, cognitive restructuring, emotion engine used app usage data from approximately 100,000 users
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 3
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
who had downloaded the IntelliCare apps from the Google Play On the basis of a type I error rate of 5% and 80% power, power
Store to identify, based on the individual user’s app use profile, calculations using a log-rank test indicated a required sample
apps that the individual was more likely to use. Participants size of 135 per arm (total sample of 270). Assuming 15
were asked to at least to try the newly recommended apps but participants would be lost to follow-up in each arm, we aimed
were encouraged to use the apps they found most helpful. to recruit 150 participants in each arm. This provided power to
detect effect sizes of 0.34 for clinical outcomes based on
Those participants who were in the no recommendation arm
independent t tests. Week 7 was selected, rather than week 8,
had the recommendation feature in the Hub app removed and
to avoid any end-of-treatmenteffects that might occur, such as
were simply encouraged to explore the apps on the IntelliCare
participants ceasing or reinitiating engagement as a result of
platform.
approaching end of treatment. Power calculations were
Outcome Assessment performed using PASS 2008. No power calculations were
performed to determine effect sizes detectable when examining
Depression was measured using the PHQ-9 [27], and anxiety
the relationship between use metrics and patient-centered
was measured using the GAD-7 [32]. These measures were
outcomes, as those were secondary aims.
administered as Web-based self-reports through Research
Electronic Data Capture [33] at baseline, week 4, week 8 (end Descriptive statistics are provided for baseline demographic
of treatment), and 3- and 6-month follow-up and completed by variables across the 4 groups. Log-rank tests were performed
the participants themselves. to determine if the time to study dropout was different for each
of the main effects, Kaplan-Meier plots are presented, and the
Engagement was defined using 3 commonly used behavioral
engagement rate at 7 weeks. Cox proportional hazard models
engagement metrics [34]: time to last use, number of app
were used to compare the main effects while adjusting for
sessions, and number of apps downloaded. Number of app
randomization strata, medication use, age, and sex. Mean and
sessions is a very common metric. Time to last usewas defined
standard deviation for PHQ-9 and GAD-7 over time and
as the time between the first launch and the last launch of any
randomization groups are presented. Generalized linear mixed
app during the 8-week trial or posttrial period. Posttrial app use
models were used to compare patient outcomes, adjusting for
data were truncated at 6 months to avoid biases related to time
randomization strata, and baseline values of PHQ-9 or GAD-7,
of entry into the trial. Number of app sessionsis a commonly
and assuming a heterogeneous unstructured covariance structure
used metric.In this study, an app use session was defined as a
by randomization strata. First, 3-way interactions between time
sequence of user-initiated actions or events separated by less
and the main effects of the 2X2 factorial were tested. If those
than 5 min between events. A new app launch (or session) was
were not significant, 2-way interactions with each main effect
defined as a new activity after 5 min of no activity (we note that
and time were modeled and, subsequently, models with main
some apps have audio or video content that may last longer than
effects without the interaction. If interactions were not
5 min, in which case, the running content is counted as activity).
significant, within the main effect of time, least square means
Number of apps downloadedis similar to the number of features
and differences adjusting for randomization strata, relative to
or modules used in feature-rich applications [34]. Given the
baseline, were tested using Dunnett adjustment for multiple
IntelliCare unbundled features into individual apps, this was
comparisons. Owing to the skewed nature of use data, app
defined here as the number of apps downloaded with at least
launches and time to last use were compared using
one launch.
nonparametric Kruskal-Wallis tests when comparing all 4 groups
Randomization and Masking and Wilcoxon rank-sum test if comparing 2 groups. The
A statistician provided a sequentially masked randomization relationship between use data and treatment outcome was
scheme, created before the start of the trial, assigning examined using linear models adjusting for baseline PHQ-9 or
participants to (1) coached with recommendations, (2) coached GAD-7 and randomization strata. All analyses were run in R
without recommendations, (3) self-guided with version 3.5.1 or SAS version 9.4 [36].
recommendations, and (4) self-guided without recommendations,
Results
stratified by current antidepressant medication status and
psychotherapy status, with a block size of 4 within each stratum.
Participants
Statistical Analyses
The flow of participants through the study is depicted in Figure
Power was calculated on the assumption that approximately 1. Lost to follow-up rates differed significantly across treatment
50% of patients stop using the apps by week 7 based on previous cells (P=.02). Table 1 summarizes the baseline demographics
electronic health work [35]. We powered for an effect size of and psychiatric characteristics of the participants.
0.30 or a difference between 50% and 61.6% between groups.
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 4
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
Figure 1. Flow of participants through the trial.
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 5
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
Table 1. Participants’characteristics.
Characteristics Coached or recommen- Self-guided or recom- Recommendations or No recommendations or
dations (N=74) mendations (N=75) coached (N=76) self-guided (N=76)
Age (years), mean (SD) 37.57 (12.22) 36.17 (11.49) 37.09 (12.28) 35.34 (11.46)
Gender, n (%)
Female 57 (77) 54 (72) 62 (81) 55 (72)
Male 15 (20) 21 (28) 14 (18) 21 (27)
Other 2 (2) 0 (0) 0 (0) 0 (0)
Race, n (%)
White 57 (77) 63 (84) 57 (75) 60 (78)
Black 10 (13) 5 (6) 8 (10) 6 (7)
Asian 3 (4) 0 (0) 5 (6) 2 (2)
Other 4 (5) 7 (9) 6 (7) 8 (10)
Ethnicity, n (%)
Non-Hispanic 62 (83) 67 (89) 68 (89) 71 (93)
Hispanic 10 (13) 8 (10) 7 (9) 5 (6)
Missing 2 (2) 0 (0) 1 (1) 0 (0)
Insurance=yes, n (%) 69 (93) 62 (82) 73 (96) 70 (92)
Marital status, n (%)
Married/partnered 36 (48) 36 (48) 36 (47) 43 (56)
Single 30 (40) 29 (38) 31 (40) 26 (34)
Separated/divorced/widowed 8 (10) 10 (13) 9 (11) 7 (9)
Education, n (%)
High school or less 4 (5) 4 (5.3) 4 (5) 3 (3)
Some college 16 (21) 18 (24) 11 (14) 15 (19)
College degree 53 (71) 53 (70) 61 (80) 58 (76)
Missing 1 (1) 0 (0) 0 (0.0) 0 (0.0)
Household income median, US$ (IQRb) 58,000.00 (39,000.00- 50,000.00 (27,000.00- 60,000.00 (32,000.00- 57,500.00 (37,750.00-
100,000.00) 80,000.00) 92,000.00) 100,000.00)
Antidepressant status=yes, n (%) 35 (47) 31 (41) 37 (48) 37 (48)
Baseline GAD-7c, mean (SD) 11.86 (4.05) 11.88 (3.85) 12.33 (4.51) 11.84 (3.66)
Baseline PHQ-9d, mean (SD) 12.78 (4.45) 13.24 (4.55) 13.11 (4.75) 13.70 (4.79)
aIQR: interquartile range.
bGAD-7: Generalized Anxiety Disorder-7.
cPHQ-9: Patient Health Questionnaire-9.
the difference between recommendation versus no
Engagement Outcomes
recommendation did not reach significance (log-rank P=.06).
Time to Last Use The mean engagement percentages and 95% CIs for the number
of last uses at 7 weeks or after for the coached and noncoached
The median time to last use of any app was 56 days (IQR 54-56).
treatment were 90.7% (86.1%-95.4%) and 83.4%
Figure 2shows the Kaplan-Meier estimates for the time to last
(77.7%-89.6%), and for recommendations versus no
engagement by the groups. There was no significant difference
recommendations were 88.6% (83.6%-93.8%) and 85.5%
in coached versus self-guided treatment (log-rank P=.94), and
(80.1%-91.3%), respectively.
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 6
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
Figure 2. Survival analysis: time to last app launch by treatment cell. Recs: recommendations.
Table 2. Median (interquartile range) app sessions by week and treatment arm.
Week Coached Self-guided Recommendations No recommendations All treatments
1 19 (12-27) 21 (7-46) 19 (9-29) 21.5 (11.75-40) 20 (10-35)
2 24.5 (14-38.5) 27 (11-43) 24 (13-40) 27 (13.75-43) 25 (13-41)
3 29 (15-44) 27 (11-42) 27 (12-46) 28 (13.75-40.25) 28 (13-43)
4 29 (14-44) 27 (14-40.5) 29 (16-51) 24.5 (12.75-38) 29 (14-43)
5 30 (13.25-50.75) 26 (11-42) 29 (13-49) 27 (11-41.25) 28 (13-45)
6 32.5 (14.25-49.75) 23 (11-40) 34 (14-54) 22.5 (12.75-39.25) 27 (13-46)
7 28.5 (12-43.75) 20 (7-38) 33 (12-53) 19 (8.75-35) 23 (9-42)
8 27 (11-40) 19 (5.5-39) 29 (9-48) 17.5 (7-34) 22 (8-40)
Total 215 (141-330.75) 218 (113-310) 232 (126-356) 201.5 (125.75-285.5) 216 (126-319)
coaching downloaded a median of 7 apps (IQR 4-10), a
Number of App Sessions
difference that was statistically significant (Wilcoxon P<.001).
Table 2 displays the number of app launches by week across The effect of receipt of recommendations on number of apps
treatment arm. The median number of app sessions was 216 used did not reach significance (Wilcoxon P=.08).
(IQR 126-325) across all apps. There was a significant effect
Use Data During 6-Month Follow-Up
for recommendations, with those receiving app
recommendations having a median of 232 (IQR 126-356) app After completion of the trial, 253 (84.0%, 253/301) participants
sessions versus those who did not receive recommendations, continued using the IntelliCare apps. Among those who
who had a median of 202 (IQR 126-286) app session (P=.04). continued to use the apps, the median time from the end of
There was no significant effect for coaching on number of app treatment to last use was 92 days (IQR 14-178), with a median
sessions (coached median 215 [IQR 141-331]; self-guided of 83 (IQR 11-286) sessions. Neither length of use nor number
median 218 [IQR 113-310]; P=.36). of app sessions varied by treatment group (χ2 =1.4, P=.72;
3
Number of Apps Downloaded χ2 =0.3, P=.97, respectively).
3
Participants who received coaching downloaded a median of
11 apps (IQR 10-12), whereas those who did not receive
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 7
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
Depression and Anxiety Outcomes There was a significant interaction between receiving
recommendations and time for the PHQ-9 (F =2.73; P=.04),
Table 3 displays the unadjusted outcomes across treatment 3,841
groups. Participants showed significant reductions in the PHQ-9 such that those who received recommendations showed stronger
and GAD-7 over time across both treatment arms (F 3,844=16.8, improvements (F 3,841=14.56; P<.001) than those who did not
P<.001; F 3,844=16.8, P<.001, respectively). (F 3,841=5.09; P=.002). Simple effects for recommendations on
PHQ-9 are not reported, given the significant interaction effects.
Coached treatment produced significantly larger reductions in
There was no significant effect of receiving weekly app
the GAD-7 than self-guided treatment (F =4.97; P=.03);
1,844 recommendations on the GAD-7 (F =0.05; P=.82) and no
1,844
however, there was no interaction between coaching and time
significant interaction with time (F =0.65; P=.58).
3,841
(F =0.32; P=.81). The benefits of coaching did not reach
3,841
significance for PHQ-9 (F =3.59; P=.06), and there was no There was no significant interactive effect of coaching and
1,844
receiving recommendations over time for either the PHQ-9 or
evidence of an interaction with time (F =0.81; P=.49).
3,841
GAD-7 (F =0.19, P=.90; and F =0.73, P=.53,
3,835 3,835
respectively).
Table 3. Unadjusted means (standard deviation) for the Patient Health Questionnaire-9 and Generalized Anxiety Disorder-7.
Treatment arm Baseline Week 4 Week 8 After 3 months After 6 months
PHQ-9a
Coached 12.95 (4.59) 8.81 (5.30) 7.17 (5.36) 7.03 (5.03) 6.93 (5.58)
Self-guided 13.47 (4.67) 9.56 (5.01) 8.43 (4.75) 8.45 (5.15) 8.32 (5.32)
Recommendations 13.01 (4.49) 8.81 (5.3) 7.51 (5.15) 7.41 (4.99) 7.74 (5.77)
No recommendations 13.40 (4.77) 8.99 (4.95) 8.13 (5.01) 8.12 (5.27) 7.56 (5.19)
GAD-7b
Coached 12.1 (4.28) 7.86 (4.64) 6.76 (4.80) 6.26 (4.77) 6.24 (4.65)
Self-guided 11.86 (3.75) 8.34 (4.6) 7.45 (4.5) 7.19 (4.59) 6.99 (4.85)
Recommendations 11.87 (3.94) 8.3 (4.64) 7.06 (4.56) 6.65 (4.67) 6.66 (4.95)
No recommendations 12.09 (4.1) 7.91 (4.61) 7.17 (4.75) 6.83 (4.73) 6.59 (4.59)
aPHQ-9: Patient Health Questionnaire-9.
bGAD-7: Generalized Anxiety Disorder-7.
of app downloads (beta=−.16; P=.03), but the effect did not
Secondary Analysis Using Multiple Imputation
reach significance for number of app sessions (beta=−.003;
As there was a small but statistically significant difference in P=.05) and time to last use (beta=−.04; P=.08) did not reach
the lost to follow-up rate, we conducted a secondary analysis significance. There were no significant interaction effects for
using the expectation-maximization algorithm to impute 5 treatment arm and PHQ-9 with number of app sessions (P=0.26),
distinct datasets, in which 4-week outcomes were imputed for time to last use (P=0.70), or number of downloads (P=0.69).
any participant who did not have at least one follow-up Similarly, there were no signification interaction effects for
assessment. This allowed all participants to be included in our treatment arm and GAD-7 with number of app sessions
generalized linear mixed models. Parameter estimates and (P=0.49), time to last use (P=0.77), or number of
corresponding standard errors from each of the 5 models were downloads(P=0.64).
combined and included in the SAS MIANALYZE procedure
to derive valid inferences for the parameters of interest. Discussion
Conclusions drawn from those analyses were consistent with
those presented in our results above, namely, the interaction of Principal Findings
the recommendation system and time for PHQ-9 (P=.04), the
Participants using the IntelliCare app platform showed
effect of coaching on GAD-7 (P=.02), and the changes in PHQ-9
substantial reductions in symptoms of depression and anxiety,
and GAD-7 over time (Ps<.001).
similar to effects previously observed [18]. Coaching resulted
Relationship Between App Use and Outcomes in significantly lower levels of anxiety relative to self-guided
treatment; however, the effect of coaching on depression was
End of treatment PHQ-9, controlling for baseline, was
only marginal (P=.06). Although there was a difference between
significantly related to the number of app sessions (beta=−.01;
depression and anxiety in whether the criterion for significance
P<.001), time to last use (beta=−.09; P=.001), and number of
was met, both Pvalues were close to the .05 cutoff, and thus,
apps downloaded (beta=−.26; P=.001). GAD-7 outcome,
there was no meaningful difference in the effect of coaching on
controlling for baseline, was significantly related to the number
depression versus anxiety. Receiving weekly recommendations
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 8
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
resulted in significantly greater reductions in depression than could have led to nonengagement. It is also possible that the
not receiving recommendations, but there was no similar effect automated reminders to use the apps that are part of each app’s
for anxiety. This difference was large. We speculate that the design fulfilled some of the coaches’function in encouragement.
recommendations are more useful for people with depression, However, such reminders are common features of mobile apps,
as they address motivational challenges faced by people with and thus, we expect these automated reminders alone do not
depression. fully account for the weak coaching effects. The weaker than
expected effects of coaching may be because of the strong app
App use was strong, with a median of 216 app sessions per
usage observed in this study. The design of the IntelliCare
participant (an average of 3.9 sessions per day) and a median
platform emphasized the usability of apps over the application
last day of use being day 56 of 56 days of treatment, with no
of a theory-based approach, such as modeling the design of an
substantial change in the rate of use over the 8 weeks.
app on CBT. Apps were designed to be simple and quick to use,
Furthermore, 84.0% (253/301) of the participants continued
thereby fitting into the fabric of users’lives. Coaches have often
using the apps for a median of 92 days after the completion of
been employed to encourage the use of intervention
the 8-week treatment. This high level of engagement stands in
technologies. It may be that the coach’s role of encouraging
stark contrast to most digital mental health apps, which tend to
adherence becomes less important as we improve the usability
show sharp drop-offs in the first weeks [7,37]. This is likely
of the apps. Although coaches will likely continue to be
because of 2 factors. First, the novelty of having new apps to
beneficial for some people using the IntelliCare platform, these
use over the course of an 8-week treatment likely increases
findings suggest that better design of technologies may limit
engagement [38]. Second, most of the apps are brief, requiring
the need for human support, thereby increasing their scalability.
less than 30 seconds to use, allowing users to fit them into the
context of their lives [18]. This suggests that the strategy of The relationship between engagement metrics and outcomes
providing a platform of simple apps that patients can integrate was mixed, with number of app use sessions being significantly
into the fabric of their lives elicits stronger engagement than related to both depression and anxiety outcomes, but time to
more traditional forms of digital mental health that are based last use and number of app downloads were only related
on psychotherapy models and require greater time commitments. significantly to depression outcomes and not anxiety. However,
consistent with much of the literature, even where relationships
People who received weekly recommendations to try new apps
were significant, they were not strong [40]. There are a number
engaged in significantly more app sessions, compared with
of potential reasons for this. One is that the engagement metrics
those not receiving recommendations. There was a similar trend
were strong with fairly high consistency, and thus, the weaker
for an effect of weekly recommendations on number of apps
findings may be an artifact of this low variability. However, it
downloaded and time to last use, although these did not reach
is also likely that the relationship between these behavioral
significance. These findings are generally consistent with
engagement metrics and overall symptom change during the
findings of studies of IntelliCare downloads from the Google
intervention obscures more complex relationships. For example,
Play Store, in which users who had installed the Hub app and
although engagement may reduce symptoms, higher symptoms
received recommendations were more likely to download
may increase engagement in the immediate time frame [35].
recommended apps and used them more frequently, compared
Thus, simple associations between overall engagement and
with those who did not download the Hub app and therefore
symptom reduction over the course of treatment may obscure
did not receive recommendations [19,20]. These findings support
more complex relationships over shorter time frames. Another
the idea that providing recommendations for new apps on a
problem may be that behavioral engagement metrics do not
regular basis can promote behavioral engagement with an app
capture meaningful engagement. Indeed, the field of
platform.
human-computer interaction has viewed engagement more
Participants in the coached conditions downloaded more apps holistically than psychology, considering not only behavioral
than did those who were self-guided; however, there were no metrics but also many other subjective factors related to the
effects of coaching on any other use metrics. This suggests that user’s cognitive and emotional engagement with the apps and
coaches can help people stay engaged with the platform by intervention [41,42]. This richer conceptualization of
trying new apps. However, we speculate that once an app is on engagement may provide a richer understanding of the user’s
the person’s phone, the user’s determination as to whether it is experience and thus may be more strongly related to clinical
of sufficient value to continue using it is less modifiable by outcomes relative to metrics that rely solely on app usage data.
coaches, at least with the present coaching model.
Limitations
Although the effect of coaching on anxiety and depression was
This study has a number of limitations that should be considered
significant or marginally significant, the effect sizes were
in the interpretation of these results. First, lost to follow-up rates
smaller than we had expected. This stands in contrast to a
were slightly albeit significantly greater in the coached arms
number of meta-analyses that have consistently shown coaching
than in the noncoached. It is notable that most of those in the
to have a strong effect [8,39]. There are a number of potential
coaching arms who were lost to follow-up never initiated
reasons for our weaker than expected findings for coaching.
treatment, suggesting a small number of people may prefer
First, the uncoached participants did have an initial 10-min call
uncoached interventions. Nevertheless, this difference in lost
with a coach to ensure the app was properly installed and that
to follow-up rates across the treatment cells likely did not impact
the person knew how to engage with the platform. This may
the findings, as it was very small (9% in arm with the highest
have provided some motivation and reduced confusion that
rate and 3% overall), and secondary analyses imputing missing
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 9
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
values showed no difference in outcomes. Second, as a research symptoms, user expectancies, or research procedures such as
study, participants had to go through the usual consenting and repeated assessment.
screening procedures and agree to regular follow-up
Conclusions
assessments. This likely resulted in a sample that was more
motivated to engage in digital mental health treatment than the This study explores a new paradigm in digital mental health
average person with depression or anxiety. Thus, the robust interventions. IntelliCare moves away from the single app for
level of engagement seen in this sample may not be strong in a mental health problem and recognizes 1 of the basic properties
real-world treatment settings. It is possible that strategies to of digital tools—that they are broken down into their smallest,
support engagement (ie, coaching and recommendations) may simplest elements possible, thereby allowing people to bundle
be more important for less motivated groups. Similarly, we did them as they see fit [43]. The strong engagement in IntelliCare
not conduct diagnostic evaluations and therefore cannot suggests that this principle also applies to digital mental health
determine how this sample may or may not be similar to interventions and tools. Engagement with the platform is
populations in health care settings. Finally, this trial did not enhanced through weekly recommendations to try new apps.
control for receipt of the IntelliCare apps. Thus, although the There is some support for the use of coaches to enhance anxiety
reductions in depression and anxiety are substantial, we cannot outcomes and recommendations to enhance depression
rule out the possibility that these changes are because of factors outcomes. This suggests that coaching may not be necessary
other than the treatment, such as the natural course of the for all people using modular, platform-based digital mental
health treatments such as IntelliCare.
Acknowledgments
This work was supported by the United States National Institute of Mental Health grant R01 MH100482 to DCM. EL was
supported by a research grant K08 MH112878 from the National Institute of Mental Health. SS is an investigator with the
Implementation Research Institute, Washington University, St. Louis, and received an award from the National Institute of Mental
Health (R25-MH08091607) and the Department of Veterans Affairs, Health Services Research and Development Service, Quality
Enhancement Research Initiative.
Conflicts of Interest
DM has accepted honoraria from Apple Inc and has an ownership interest in Actualize Therapy, which has a license from
Northwestern University for IntelliCare. EL has received consulting fees from Actualize Therapy. SS serves as a scientific advisor
to Joyable, Inc, and has received stock options in Joyable. The other authors have no conflicts of interest to declare.
References
1. Baxter AJ, Scott KM, Vos T, Whiteford HA. Global prevalence of anxiety disorders: a systematic review and meta-regression.
Psychol Med 2013 May;43(5):897-910. [doi: 10.1017/S003329171200147X] [Medline: 22781489]
2. Ferrari AJ, Somerville AJ, Baxter AJ, Norman R, Patten SB, Vos T, et al. Global variation in the prevalence and incidence
of major depressive disorder: a systematic review of the epidemiological literature. Psychol Med 2013 Mar;43(3):471-481.
[doi: 10.1017/S0033291712001511] [Medline: 22831756]
3. GBD 2015 Disease and Injury Incidence and Prevalence Collaborators. Global, regional, and national incidence, prevalence,
and years lived with disability for 310 diseases and injuries, 1990-2015: a systematic analysis for the global burden of
disease study 2015. Lancet 2016 Oct 8;388(10053):1545-1602 [FREE Full text] [doi: 10.1016/S0140-6736(16)31678-6]
[Medline: 27733282]
4. Greenberg PE, Fournier AA, Sisitsky T, Pike CT, Kessler RC. The economic burden of adults with major depressive disorder
in the United States (2005 and 2010). J Clin Psychiatry 2015 Feb;76(2):155-162 [FREE Full text] [doi:
10.4088/JCP.14m09298] [Medline: 25742202]
5. Mohr DC, Ho J, Duffecy J, Baron KG, Lehman KA, Jin L, et al. Perceived barriers to psychological treatments and their
relationship to depression. J Clin Psychol 2010 Apr;66(4):394-409 [FREE Full text] [doi: 10.1002/jclp.20659] [Medline:
20127795]
6. Mohr DC, Hart SL, Howard I, Julian L, Vella L, Catledge C, et al. Barriers to psychotherapy among depressed and
nondepressed primary care patients. Ann Behav Med 2006 Dec;32(3):254-258. [doi: 10.1207/s15324796abm3203_12]
[Medline: 17107299]
7. Andrews G, Basu A, Cuijpers P, Craske MG, McEvoy P, English CL, et al. Computer therapy for the anxiety and depression
disorders is effective, acceptable and practical health care: an updated meta-analysis. J Anxiety Disord 2018 Apr;55:70-78
[FREE Full text] [doi: 10.1016/j.janxdis.2018.01.001] [Medline: 29422409]
8. Firth J, Torous J, Nicholas J, Carney R, Pratap A, Rosenbaum S, et al. The efficacy of smartphone-based mental health
interventions for depressive symptoms: a meta-analysis of randomized controlled trials. World Psychiatry 2017
Oct;16(3):287-298 [FREE Full text] [doi: 10.1002/wps.20472] [Medline: 28941113]
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 10
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
9. Firth J, Torous J, Nicholas J, Carney R, Rosenbaum S, Sarris J. Can smartphone mental health interventions reduce symptoms
of anxiety? A meta-analysis of randomized controlled trials. J Affect Disord 2017 Aug 15;218:15-22 [FREE Full text] [doi:
10.1016/j.jad.2017.04.046] [Medline: 28456072]
10. Poushter J. Pew Research Center. 2017. Smartphones Are Common in Advanced Economies, But Digital Divides Remain
URL: http://www.pewresearch.org/fact-tank/2017/04/21/
smartphones-are-common-in-advanced-economies-but-digital-divides-remain/
11. Larsen ME, Nicholas J, Christensen H. Quantifying app store dynamics: longitudinal tracking of mental health apps. JMIR
Mhealth Uhealth 2016 Aug 9;4(3):e96 [FREE Full text] [doi: 10.2196/mhealth.6020] [Medline: 27507641]
12. Sucala M, Cuijpers P, Muench F, Cardo R, Soflau R, Dobrean A, et al. Anxiety: there is an app for that. A systematic
review of anxiety apps. Depress Anxiety 2017 Jun;34(6):518-525. [doi: 10.1002/da.22654] [Medline: 28504859]
13. Huguet A, Rao S, McGrath PJ, Wozney L, Wheaton M, Conrod J, et al. A systematic review of cognitive behavioral therapy
and behavioral activation apps for depression. PLoS One 2016;11(5):e0154248 [FREE Full text] [doi:
10.1371/journal.pone.0154248] [Medline: 27135410]
14. Vaish R, Wyngarden K, Chen J, Cheung B, Bernstein MS. Twitch Crowdsourcing: Crowd Contributions in Short Bursts
of Time. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 2014 Presented at: CHI'14;
April 26-May 1, 2014; Toronto, Ontario, Canada p. 3645-3654. [doi: 10.1145/2556288.2556996]
15. Andrews S, Ellis DA, Shaw H, Piwek L. Beyond self-report: tools to compare estimated and real-world smartphone use.
PLoS One 2015;10(10):e0139004 [FREE Full text] [doi: 10.1371/journal.pone.0139004] [Medline: 26509895]
16. Reger GM, Browne KC, Campellone TR, Simons C, Kuhn E, Fortney JC, et al. Barriers and facilitators to mobile application
use during PTSD treatment: clinician adoption of PE coach. Prof Psychol: Res Pract 2017 Dec;48(6):510-517. [doi:
10.1037/pro0000153]
17. Torous J, Nicholas J, Larsen ME, Firth J, Christensen H. Clinical review of user engagement with mental health smartphone
apps: evidence, theory and improvements. Evid Based Ment Health 2018 Aug;21(3):116-119. [doi: 10.1136/eb-2018-102891]
[Medline: 29871870]
18. Mohr DC, Tomasino KN, Lattie EG, Palac HL, Kwasny MJ, Weingardt K, et al. IntelliCare: an eclectic, skills-based app
suite for the treatment of depression and anxiety. J Med Internet Res 2017 Jan 5;19(1):e10 [FREE Full text] [doi:
10.2196/jmir.6645] [Medline: 28057609]
19. Cheung K, Ling W, Karr CJ, Weingardt K, Schueller SM, Mohr DC. Evaluation of a recommender app for apps for the
treatment of depression and anxiety: an analysis of longitudinal user engagement. J Am Med Inform Assoc 2018 Aug
1;25(8):955-962 [FREE Full text] [doi: 10.1093/jamia/ocy023] [Medline: 29659857]
20. Lattie EG, Schueller SM, Sargent E, Stiles-Shields C, Tomasino KN, Corden ME, et al. Uptake and usage of IntelliCare:
a publicly available suite of mental health and well-being apps. Internet Interv 2016 May;4(2):152-158 [FREE Full text]
[doi: 10.1016/j.invent.2016.06.003] [Medline: 27398319]
21. Anguera JA, Jordan JT, Castaneda D, Gazzaley A, Areán PA. Conducting a fully mobile and randomised clinical trial for
depression: access, engagement and expense. BMJ Innov 2016 Jan;2(1):14-21 [FREE Full text] [doi:
10.1136/bmjinnov-2015-000098] [Medline: 27019745]
22. Arean PA, Hallgren KA, Jordan JT, Gazzaley A, Atkins DC, Heagerty PJ, et al. The use and effectiveness of mobile apps
for depression: results from a fully remote clinical trial. J Med Internet Res 2016 Dec 20;18(12):e330 [FREE Full text]
[doi: 10.2196/jmir.6482] [Medline: 27998876]
23. Kelders SM, Bohlmeijer ET, Pots WT, van Gemert-Pijnen JE. Comparing human and automated support for depression:
fractional factorial randomized controlled trial. Behav Res Ther 2015 Sep;72:72-80. [doi: 10.1016/j.brat.2015.06.014]
[Medline: 26196078]
24. Richards D, Richardson T, Timulak L, McElvaney J. The efficacy of internet-delivered treatment for generalized anxiety
disorder: a systematic review and meta-analysis. Internet Interv 2015 Sep;2(3):272-282. [doi: 10.1016/j.invent.2015.07.003]
25. Palac HL, Alam N, Kaiser SM, Ciolino JD, Lattie EG, Mohr DC. A practical do-it-yourself recruitment framework for
concurrent ehealth clinical trials: simple architecture (part 1). J Med Internet Res 2018 Nov 1;20(11):e11049 [FREE Full
text] [doi: 10.2196/11049] [Medline: 30389650]
26. Lattie EG, Kaiser SM, Alam N, Tomasino KN, Sargent E, Rubanovich CK, et al. A practical do-it-yourself recruitment
framework for concurrent ehealth clinical trials: identification of efficient and cost-effective methods for decision making
(part 2). J Med Internet Res 2018 Nov 29;20(11):e11050 [FREE Full text] [doi: 10.2196/11050] [Medline: 30497997]
27. Kroenke K, Spitzer RL, Williams JB. The PHQ-9: validity of a brief depression severity measure. J Gen Intern Med 2001
Sep;16(9):606-613 [FREE Full text] [doi: 10.1046/j.1525-1497.2001.016009606.x] [Medline: 11556941]
28. Spitzer RL, Kroenke K, Williams JB, Löwe B. A brief measure for assessing generalized anxiety disorder: the GAD-7.
Arch Intern Med 2006 May 22;166(10):1092-1097. [doi: 10.1001/archinte.166.10.1092] [Medline: 16717171]
29. Noth KN, Bardsley LR, Lattie EG, Mohr DC. DigitalHub - Northwestern University. 2018. IntelliCare Study Coaching
Manual URL: https://digitalhub.northwestern.edu/files/00fa4294-5b9f-4afc-897a-7fffceae8f3f
30. Mohr DC, Cuijpers P, Lehman K. Supportive accountability: a model for providing human support to enhance adherence
to eHealth interventions. J Med Internet Res 2011 Mar 10;13(1):e30 [FREE Full text] [doi: 10.2196/jmir.1602] [Medline:
21393123]
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 11
XSL FO (page number not for citation purposes)
•
RenderX
JOURNAL OF MEDICAL INTERNET RESEARCH Mohr et al
31. Schueller SM, Tomasino KN, Mohr DC. Integrating human support into behavioral intervention technologies: the efficiency
model of support. Clin Psychol: Sci Pract 2016 Nov 17;24(1):27-45. [doi: 10.1111/cpsp.12173]
32. Spitzer RL, Kroenke K, Williams JB. Validation and utility of a self-report version of PRIME-MD: the PHQ primary care
study. Primary care evaluation of mental disorders. Patient health questionnaire. J Am Med Assoc 1999 Nov
10;282(18):1737-1744. [doi: 10.1001/jama.282.18.1737] [Medline: 10568646]
33. Harris PA, Taylor R, Thielke R, Payne J, Gonzalez N, Conde JG. Research electronic data capture (REDCap)--a
metadata-driven methodology and workflow process for providing translational research informatics support. J Biomed
Inform 2009 Apr;42(2):377-381 [FREE Full text] [doi: 10.1016/j.jbi.2008.08.010] [Medline: 18929686]
34. Pham Q, Graham G, Carrion C, Morita PP, Seto E, Stinson JN, et al. A library of analytic indicators to evaluate effective
engagement with consumer mhealth apps for chronic conditions: scoping review. JMIR Mhealth Uhealth 2019 Jan
18;7(1):e11941 [FREE Full text] [doi: 10.2196/11941] [Medline: 30664463]
35. Mohr DC, Duffecy J, Jin L, Ludman EJ, Lewis A, Begale M, et al. Multimodal e-mental health treatment for depression:
a feasibility trial. J Med Internet Res 2010 Dec 19;12(5):e48 [FREE Full text] [doi: 10.2196/jmir.1370] [Medline: 21169164]
36. R Project. 2017. The R Project for Statistical Computing URL: https://www.R-project.org/
37. Gilbody S, Brabyn S, Lovell K, Kessler D, Devlin T, Smith L, REEACT Collaborative. Telephone-supported computerised
cognitive-behavioural therapy: REEACT-2 large-scale pragmatic randomised controlled trial. Br J Psychiatry 2017
May;210(5):362-367. [doi: 10.1192/bjp.bp.116.192435] [Medline: 28254959]
38. Kwasny MJ, Schueller SM, Lattie EG, Gray EL, Mohr DC. Towards managing a platform of mental health apps: a secondary
analysis of the IntelliCare field trial. J Med Internet Res 2019:- (epub ahead of print). [doi: 10.2196/preprints.11572]
39. Richards D, Richardson T. Computer-based psychological treatments for depression: a systematic review and meta-analysis.
Clin Psychol Rev 2012 Jun;32(4):329-342. [doi: 10.1016/j.cpr.2012.02.004] [Medline: 22466510]
40. Fuhr K, Schröder J, Berger T, Moritz S, Meyer B, Lutz W, et al. The association between adherence and outcome in an
internet intervention for depression. J Affect Disord 2018 Mar 15;229:443-449. [doi: 10.1016/j.jad.2017.12.028] [Medline:
29331706]
41. Doherty K, Doherty G. Engagement in HCI: conception, theory and measurement. ACM Comput Surv 2019 Jan 23;51(5):1-39.
[doi: 10.1145/3234149]
42. Perski O, Blandford A, West R, Michie S. Conceptualising engagement with digital behaviour change interventions: a
systematic review using principles from critical interpretive synthesis. Transl Behav Med 2017 Jun;7(2):254-267 [FREE
Full text] [doi: 10.1007/s13142-016-0453-1] [Medline: 27966189]
43. Kelly K. The Inevitable. New York: Viking Press; 2016.
Abbreviations
CBT: cognitive behavioral therapy
GAD-7: Generalized Anxiety Disorder-7
IQR: interquartile range
PHQ-9: Patient Health Questionnaire-9
Edited by S Kitsiou; submitted 05.02.19; peer-reviewed by N Zimmerman, L Cadmus-Bertram, S Kelders; comments to author 11.04.19;
revised version received 06.06.19; accepted 20.07.19; published 28.08.19
Please cite as:
Mohr DC, Schueller SM, Tomasino KN, Kaiser SM, Alam N, Karr C, Vergara JL, Gray EL, Kwasny MJ, Lattie EG
Comparison of the Effects of Coaching and Receipt of App Recommendations on Depression, Anxiety, and Engagement in the IntelliCare
Platform: Factorial Randomized Controlled Trial
J Med Internet Res 2019;21(8):e13609
URL: http://www.jmir.org/2019/8/e13609/
doi: 10.2196/13609
PMID: 31464192
©David C Mohr, Stephen M Schueller, Kathryn Noth Tomasino, Susan M Kaiser, Nameyeh Alam, Chris Karr, Jessica L Vergara,
Elizabeth L Gray, Mary J Kwasny, Emily G Lattie. Originally published in the Journal of Medical Internet Research
(http://www.jmir.org), 28.08.2019. This is an open-access article distributed under the terms of the Creative Commons Attribution
License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any
medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete
bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information
must be included.
http://www.jmir.org/2019/8/e13609/ J Med Internet Res 2019 | vol. 21 | iss. 8 | e13609 | p. 12
XSL FO (page number not for citation purposes)
•
RenderX
