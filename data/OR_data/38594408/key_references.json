{
    "key_references": [
        {
            "title": "Convolutional neural network assistance significantly improves dermatologists' diagnosis of cutaneous tumours using clinical images.",
            "abstract": "## BACKGROUND\nConvolutional neural networks (CNNs) have demonstrated expert-level performance in cutaneous tumour classification using clinical images, but most previous studies have focused on dermatologist-versus-CNN comparisons rather than their combination. The objective of our study was to evaluate the potential impact of CNN assistance on dermatologists for clinical image interpretation.\n## METHODS\nA multi-class CNN was trained and validated using a dataset of 25,773 clinical images comprising 10 categories of cutaneous tumours. The CNN's performance was tested on an independent dataset of 2107 images. A total of 400 images (40 per category) were randomly selected from the test dataset. A fully crossed, self-control, multi-reader multi-case (MRMC) study was conducted to compare the performance of 18 board-certified dermatologists (experience: 13/18\u00a0\u2264\u00a010 years; 5/18\uff1e10 years) in interpreting the 400 clinical images with or without CNN assistance.\n## RESULTS\nThe CNN achieved an overall accuracy of 78.45% and kappa of 0.73 in the classification of 10 types of cutaneous tumours on 2107 images. CNN-assisted dermatologists achieved a higher accuracy (76.60% vs. 62.78%, P\u00a0<\u00a00.001) and kappa (0.74 vs. 0.59, P\u00a0<\u00a00.001) than unassisted dermatologists in interpreting the 400 clinical images. Dermatologists with less experience benefited more from CNN assistance. At the binary classification level (malignant or benign), the sensitivity (89.56% vs. 83.21%, P\u00a0<\u00a00.001) and specificity (87.90% vs. 80.92%, P\u00a0<\u00a00.001) of dermatologists with CNN assistance were also significantly improved than those without.\n## CONCLUSIONS\nCNN assistance improved dermatologist accuracy in interpreting cutaneous tumours and could further boost the acceptance of this new technique.\n",
            "in_text_citation": "Ba et al., 2022",
            "footnote": 21
        },
        {
            "title": "Augmented Intelligence Dermatology: Deep Neural Networks Empower Medical Professionals in Diagnosing Skin Cancer and\u00a0Predicting Treatment Options for 134 Skin\u00a0Disorders.",
            "abstract": "Although deep learning algorithms have demonstrated expert-level performance, previous efforts were mostly binary classifications of limited disorders. We trained an algorithm with 220,680 images of 174 disorders and validated it using Edinburgh (1,300 images; 10 disorders) and SNU datasets (2,201 images; 134 disorders). The algorithm could accurately predict malignancy, suggest primary treatment options, render multi-class classification among 134 disorders, and improve the performance of medical professionals. The area under the curves for malignancy detection were 0.928 \u00b1 0.002 (Edinburgh) and 0.937 \u00b1 0.004 (SNU). The area under the curves of primary treatment suggestion (SNU) were 0.828 \u00b1 0.012, 0.885 \u00b1 0.006, 0.885 \u00b1 0.006, and 0.918 \u00b1 0.006 for steroids, antibiotics, antivirals, and antifungals, respectively. For multi-class classification, the mean top-1 and top-5 accuracies were 56.7 \u00b1 1.6% and 92.0 \u00b1 1.1% (Edinburgh) and 44.8 \u00b1 1.2% and 78.1 \u00b1 0.3% (SNU), respectively. With the assistance of our algorithm, the sensitivity and specificity of 47 clinicians (21 dermatologists and 26 dermatology residents) for malignancy prediction (SNU; 240 images) were improved by 12.1% (P < 0.0001) and 1.1% (P < 0.0001), respectively. The malignancy prediction sensitivity of 23 non-medical professionals was significantly increased by 83.8% (P < 0.0001). The top-1 and top-3 accuracies of four doctors in the multi-class classification of 134 diseases (SNU; 2,201 images) were increased by 7.0% (P\u00a0= 0.045) and 10.1% (P\u00a0= 0.0020), respectively. The results suggest that our algorithm may serve as augmented intelligence that can empower medical professionals in diagnostic dermatology.\n",
            "in_text_citation": "Han et al., 2020",
            "footnote": 14
        },
        {
            "title": "Evaluation of Artificial Intelligence-Assisted Diagnosis of Skin Neoplasms: A Single-Center, Paralleled, Unmasked, Randomized Controlled Trial.",
            "abstract": "## TRIAL DESIGN\nThis was a single-center, unmasked, paralleled, randomized controlled trial.\n## METHODS\nA randomized trial was conducted in a tertiary care institute in South Korea to validate whether artificial intelligence (AI) could augment the accuracy of nonexpert physicians in the real-world settings, which included diverse out-of-distribution conditions. Consecutive patients aged >19 years, having one or more skin lesions suspicious for skin cancer detected by either the patient or physician, were randomly allocated to four nondermatology trainees and four dermatology residents. The attending dermatologists examined the randomly allocated patients with (AI-assisted group) or without (unaided group) the real-time assistance of AI algorithm (https://b2020.modelderm.com#world; convolutional neural networks; unmasked design) after simple randomization of the patients.\n## RESULTS\nUsing 576 consecutive cases (Fitzpatrick skin phototypes III or IV) with suspicious lesions out of the initial 603 recruitments, the accuracy of the AI-assisted group (n\u00a0= 295, 53.9%) was found to be significantly higher than those of the unaided group (n\u00a0= 281, 43.8%; P\u00a0= 0.019). Whereas the augmentation was more significant from 54.7% (n\u00a0= 150) to 30.7% (n\u00a0= 138; P < 0.0001) in the nondermatology trainees who had the least experience in dermatology, it was not significant in the dermatology residents. The algorithm could help trainees in the AI-assisted group include more differential diagnoses than the unaided group (2.09 vs. 1.95 diagnoses; P\u00a0= 0.0005). However, a 12.2% drop in Top-1 accuracy of the trainees was observed in cases in which all Top-3 predictions given by the algorithm were incorrect.\n## CONCLUSIONS\nThe multiclass AI algorithm augmented the diagnostic accuracy of nonexpert physicians in dermatology.\n",
            "in_text_citation": "Han et al., 2022",
            "footnote": 19
        },
        {
            "title": "Over-Detection of Melanoma-Suspect Lesions by a CE-Certified Smartphone App: Performance in Comparison to Dermatologists, 2D and 3D Convolutional Neural Networks in a Prospective Data Set of 1204 Pigmented Skin Lesions Involving Patients' Perception.",
            "abstract": "The exponential increase in algorithm-based mobile health (mHealth) applications (apps) for melanoma screening is a reaction to a growing market. However, the performance of available apps remains to be investigated. In this prospective study, we investigated the diagnostic accuracy of a class 1 CE-certified smartphone app in melanoma risk stratification and its patient and dermatologist satisfaction. Pigmented skin lesions \u2265 3 mm and any suspicious smaller lesions were assessed by the smartphone app SkinVision\n",
            "in_text_citation": "Jahn et al., 2022",
            "footnote": 17
        },
        {
            "title": "Development and Assessment of an Artificial Intelligence-Based Tool for Skin Condition Diagnosis by Primary Care Physicians and Nurse Practitioners in Teledermatology Practices.",
            "abstract": "## IMPORTANCE\nMost dermatologic cases are initially evaluated by nondermatologists such as primary care physicians (PCPs) or nurse practitioners (NPs).\n## OBJECTIVE\nTo evaluate an artificial intelligence (AI)-based tool that assists with diagnoses of dermatologic conditions.\n## DESIGN, SETTING, AND PARTICIPANTS\nThis multiple-reader, multiple-case diagnostic study developed an AI-based tool and evaluated its utility. Primary care physicians and NPs retrospectively reviewed an enriched set of cases representing 120 different skin conditions. Randomization was used to ensure each clinician reviewed each case either with or without AI assistance; each clinician alternated between batches of 50 cases in each modality. The reviews occurred from February 21 to April 28, 2020. Data were analyzed from May 26, 2020, to January 27, 2021.\n## EXPOSURES\nAn AI-based assistive tool for interpreting clinical images and associated medical history.\n## MAIN OUTCOMES AND MEASURES\nThe primary analysis evaluated agreement with reference diagnoses provided by a panel of 3 dermatologists for PCPs and NPs. Secondary analyses included diagnostic accuracy for biopsy-confirmed cases, biopsy and referral rates, review time, and diagnostic confidence.\n## RESULTS\nForty board-certified clinicians, including 20 PCPs (14 women [70.0%]; mean experience, 11.3 [range, 2-32] years) and 20 NPs (18 women [90.0%]; mean experience, 13.1 [range, 2-34] years) reviewed 1048 retrospective cases (672 female [64.2%]; median age, 43 [interquartile range, 30-56] years; 41\u202f920 total reviews) from a teledermatology practice serving 11 sites and provided 0 to 5 differential diagnoses per case (mean [SD], 1.6 [0.7]). The PCPs were located across 12 states, and the NPs practiced in primary care without physician supervision across 9 states. The NPs had a mean of 13.1 (range, 2-34) years of experience and practiced in primary care without physician supervision across 9 states. Artificial intelligence assistance was significantly associated with higher agreement with reference diagnoses. For PCPs, the increase in diagnostic agreement was 10% (95% CI, 8%-11%; P\u2009<\u2009.001), from 48% to 58%; for NPs, the increase was 12% (95% CI, 10%-14%; P\u2009<\u2009.001), from 46% to 58%. In secondary analyses, agreement with biopsy-obtained diagnosis categories of maglignant, precancerous, or benign increased by 3% (95% CI, -1% to 7%) for PCPs and by 8% (95% CI, 3%-13%) for NPs. Rates of desire for biopsies decreased by 1% (95% CI, 0-3%) for PCPs and 2% (95% CI, 1%-3%) for NPs; the rate of desire for referrals decreased by 3% (95% CI, 1%-4%) for PCPs and NPs. Diagnostic agreement on cases not indicated for a dermatologist referral increased by 10% (95% CI, 8%-12%) for PCPs and 12% (95% CI, 10%-14%) for NPs, and median review time increased slightly by 5 (95% CI, 0-8) seconds for PCPs and 7 (95% CI, 5-10) seconds for NPs per case.\n## CONCLUSIONS AND RELEVANCE\nArtificial intelligence assistance was associated with improved diagnoses by PCPs and NPs for 1 in every 8 to 10 cases, indicating potential for improving the quality of dermatologic care.\n",
            "in_text_citation": "Jain et al., 2021",
            "footnote": 15
        },
        {
            "title": "Augmenting the accuracy of trainee doctors in diagnosing skin lesions suspected of skin neoplasms in a real-world setting: A prospective controlled before-and-after study.",
            "abstract": "## BACKGROUND\nAlthough deep neural networks have shown promising results in the diagnosis of skin cancer, a prospective evaluation in a real-world setting could confirm these results. This study aimed to evaluate whether an algorithm (http://b2019.modelderm.com) improves the accuracy of nondermatologists in diagnosing skin neoplasms.\n## METHODS\nA total of 285 cases (random series) with skin neoplasms suspected of malignancy by either physicians or patients were recruited in two tertiary care centers located in South Korea. An artificial intelligence (AI) group (144 cases, mean [SD] age, 57.0 [17.7] years; 62 [43.1%] men) was diagnosed via routine examination with photographic review and assistance by the algorithm, whereas the control group (141 cases, mean [SD] age, 61.0 [15.3] years; 52 [36.9%] men) was diagnosed only via routine examination with a photographic review. The accuracy of the nondermatologists before and after the interventions was compared.\n## RESULTS\nAmong the AI group, the accuracy of the first impression (Top-1 accuracy; 58.3%) after the assistance of AI was higher than that before the assistance (46.5%, P = .008). The number of differential diagnoses of the participants increased from 1.9 \u00b1 0.5 to 2.2 \u00b1 0.6 after the assistance (P < .001). In the control group, the difference in the Top-1 accuracy between before and after reviewing photographs was not significant (before, 46.1%; after, 51.8%; P = .19), and the number of differential diagnoses did not significantly increase (before, 2.0 \u00b1 0.4; after, 2.1 \u00b1 0.5; P = .57).\n## CONCLUSIONS\nIn real-world settings, AI augmented the diagnostic accuracy of trainee doctors. The limitation of this study is that the algorithm was tested only for Asians recruited from a single region. Additional international randomized controlled trials involving various ethnicities are required.\n",
            "in_text_citation": "Kim et al., 2022",
            "footnote": 20
        },
        {
            "title": "Augmented decision-making for acral lentiginous melanoma detection using deep convolutional neural networks.",
            "abstract": "## BACKGROUND\nSeveral studies have achieved high-level performance of melanoma detection using convolutional neural networks (CNNs). However, few have described the extent to which the implementation of CNNs improves the diagnostic performance of the physicians.\n## OBJECTIVE\nThis study is aimed at developing a CNN for detecting acral lentiginous melanoma (ALM) and investigating whether its implementation can improve the initial decision for ALM detection made by the physicians.\n## METHODS\nA CNN was trained using 1072 dermoscopic images of acral benign nevi, ALM and intermediate tumours. To investigate whether the implementation of CNN can improve the initial decision for ALM detection, 60 physicians completed a three-stage survey. In Stage I, they were asked for their decisions solely on the basis of dermoscopic images provided to them. In Stage II, they were also provided with clinical information. In Stage III, they were provided with the additional diagnosis and probability predicted by the CNN.\n## RESULTS\nThe accuracy of ALM detection in the participants was 74.7% (95% confidence interval [CI], 72.6-76.8%) in Stage I and 79.0% (95% CI, 76.7-81.2%) in Stage II. In Stage III, it was 86.9% (95% CI, 85.3-88.4%), which exceeds the accuracy delivered in Stage I by 12.2%p (95% CI, 10.1-14.3%p) and Stage II by 7.9%p (95% CI, 6.0-9.9%p). Moreover, the concordance between the participants considerably increased (Fleiss-\u03ba of 0.436 [95% CI, 0.437-0.573] in Stage I, 0.506 [95% CI, 0.621-0.749] in Stage II and 0.684 [95% CI, 0.621-0.749] in Stage III).\n## CONCLUSIONS\nAugmented decision-making improved the performance of and concordance between the clinical decisions of a diverse group of experts. This study demonstrates the potential use of CNNs as an adjoining, decision-supporting system for physicians' decisions.\n",
            "in_text_citation": "Lee et al., 2020",
            "footnote": 12
        },
        {
            "title": "Deep Neural Frameworks Improve the Accuracy of General Practitioners in the Classification of Pigmented Skin Lesions.",
            "abstract": "This study evaluated whether deep learning frameworks trained in large datasets can help non-dermatologist physicians improve their accuracy in categorizing the seven most common pigmented skin lesions. Open-source skin images were downloaded from the International Skin Imaging Collaboration (ISIC) archive. Different deep neural networks (DNNs) (\n",
            "in_text_citation": "Lucius et al., 2020",
            "footnote": 18
        },
        {
            "title": "Artificial Intelligence and Its Effect on Dermatologists' Accuracy in Dermoscopic Melanoma Image Classification: Web-Based Survey Study.",
            "abstract": "## BACKGROUND\nEarly detection of melanoma can be lifesaving but this remains a challenge. Recent diagnostic studies have revealed the superiority of artificial intelligence (AI) in classifying dermoscopic images of melanoma and nevi, concluding that these algorithms should assist a dermatologist's diagnoses.\n## OBJECTIVE\nThe aim of this study was to investigate whether AI support improves the accuracy and overall diagnostic performance of dermatologists in the dichotomous image-based discrimination between melanoma and nevus.\n## METHODS\nTwelve board-certified dermatologists were presented disjoint sets of 100 unique dermoscopic images of melanomas and nevi (total of 1200 unique images), and they had to classify the images based on personal experience alone (part I) and with the support of a trained convolutional neural network (CNN, part II). Additionally, dermatologists were asked to rate their confidence in their final decision for each image.\n## RESULTS\nWhile the mean specificity of the dermatologists based on personal experience alone remained almost unchanged (70.6% vs 72.4%; P=.54) with AI support, the mean sensitivity and mean accuracy increased significantly (59.4% vs 74.6%; P=.003 and 65.0% vs 73.6%; P=.002, respectively) with AI support. Out of the 10% (10/94; 95% CI 8.4%-11.8%) of cases where dermatologists were correct and AI was incorrect, dermatologists on average changed to the incorrect answer for 39% (4/10; 95% CI 23.2%-55.6%) of cases. When dermatologists were incorrect and AI was correct (25/94, 27%; 95% CI 24.0%-30.1%), dermatologists changed their answers to the correct answer for 46% (11/25; 95% CI 33.1%-58.4%) of cases. Additionally, the dermatologists' average confidence in their decisions increased when the CNN confirmed their decision and decreased when the CNN disagreed, even when the dermatologists were correct. Reported values are based on the mean of all participants. Whenever absolute values are shown, the denominator and numerator are approximations as every dermatologist ended up rating a varying number of images due to a quality control step.\n## CONCLUSIONS\nThe findings of our study show that AI support can improve the overall accuracy of the dermatologists in the dichotomous image-based discrimination between melanoma and nevus. This supports the argument for AI-based tools to aid clinicians in skin lesion classification and provides a rationale for studies of such classifiers in real-life settings, wherein clinicians can integrate additional information such as patient age and medical history into their decisions.\n",
            "in_text_citation": "Maron et al., 2020",
            "footnote": 22
        },
        {
            "title": "Performance of a deep neural network in teledermatology: a single-centre prospective diagnostic study.",
            "abstract": "## BACKGROUND\nThe use of artificial intelligence (AI) algorithms for the diagnosis of skin diseases has shown promise in experimental settings but has not been yet tested in real-life conditions.\n## OBJECTIVE\nTo assess the diagnostic performance and potential clinical utility of a 174-multiclass AI algorithm in a real-life telemedicine setting.\n## METHODS\nProspective, diagnostic accuracy study including consecutive patients who submitted images for teledermatology evaluation. The treating dermatologist chose a single image to upload to a web application during teleconsultation. A follow-up reader study including nine healthcare providers (3 dermatologists, 3 dermatology residents and 3 general practitioners) was performed.\n## RESULTS\nA total of 340 cases from 281 patients met study inclusion criteria. The mean (SD) age of patients was 33.7 (17.5) years; 63% (n\u00a0=\u00a0177) were female. Exposure to the AI algorithm results was considered useful in 11.8% of visits (n\u00a0=\u00a040) and the teledermatologist correctly modified the real-time diagnosis in 0.6% (n\u00a0=\u00a02) of cases. The overall top-1 accuracy of the algorithm (41.2%) was lower than that of the dermatologists (60.1%), residents (57.8%) and general practitioners (49.3%) (all comparisons P\u00a0<\u00a00.05, in the reader study). When the analysis was limited to the diagnoses on which the algorithm had been explicitly trained, the balanced top-1 accuracy of the algorithm (47.6%) was comparable to the dermatologists (49.7%) and residents (47.7%) but superior to the general practitioners (39.7%; P\u00a0=\u00a00.049). Algorithm performance was associated with patient skin type and image quality.\n## CONCLUSIONS\nA 174-disease class AI algorithm appears to be a promising tool in the triage and evaluation of lesions with patient-taken photographs via telemedicine.\n",
            "in_text_citation": "Mu\u00f1oz-L\u00f3pez et al., 2021",
            "footnote": 16
        },
        {
            "title": "Human-computer collaboration for skin cancer recognition.",
            "abstract": "The rapid increase in telemedicine coupled with recent advances in diagnostic artificial intelligence (AI) create the imperative to consider the opportunities and risks of inserting AI-based support into new paradigms of care. Here we build on recent achievements in the accuracy of image-based AI for skin cancer diagnosis to address the effects of varied representations of AI-based support across different levels of clinical expertise and multiple clinical workflows. We find that good quality AI-based support of clinical decision-making improves diagnostic accuracy over that of either AI or physicians alone, and that the least experienced clinicians gain the most from AI-based support. We further find that AI-based multiclass probabilities outperformed content-based image retrieval (CBIR) representations of AI in the mobile technology environment, and AI-based support had utility in simulations of second opinions and of telemedicine triage. In addition to demonstrating the potential benefits associated with good quality AI in the hands of non-expert clinicians, we find that faulty AI can mislead the entire spectrum of clinicians, including experts. Lastly, we show that insights derived from AI class-activation maps can inform improvements in human diagnosis. Together, our approach and findings offer a framework for future studies across the spectrum of image-based diagnostics to improve human-computer collaboration in clinical practice.\n",
            "in_text_citation": "Tschandl et al., 2020",
            "footnote": 10
        },
        {
            "title": "Dermatologist-level classification of malignant lip diseases using a deep convolutional neural network.",
            "abstract": "## BACKGROUND\nDeep convolutional neural networks (DCNNs) can classify skin diseases at a level equivalent to a dermatologist, but their performance in specific areas requires further research.\n## OBJECTIVE\nTo evaluate the performance of a trained DCNN-based algorithm in classifying benign and malignant lip diseases.\n## METHODS\nA training set of 1629 images (743 malignant, 886 benign) was used with Inception-Resnet-V2. Performance was evaluated using another set of 344 images and 281 images from other hospitals. Classifications by 44 participants (six board-certified dermatologists, 12 dermatology residents, nine medical doctors not specialized in dermatology and 17 medical students) were used for comparison.\n## RESULTS\nThe outcomes based on the area under curve, sensitivity and specificity were 0\u00b7827 [95% confidence interval (CI) 0\u00b7782-0\u00b7873], 0\u00b7755 (95% CI 0\u00b7673-0\u00b7827) and 0\u00b7803 (95% CI 0\u00b7752-0\u00b7855), respectively, for the set of 344 images; and 0\u00b7774 (95% CI 0\u00b7699-0\u00b7849), 0\u00b7702 (95% CI 0\u00b7579-0\u00b7808) and 0\u00b7759 (95% CI 0\u00b7701-0\u00b7813), respectively, for the set of 281 images. The DCNN was equivalent to the dermatologists and superior to the nondermatologists in classifying malignancy. After referencing the DCNN result, the mean \u00b1 SD Youden index increased significantly for nondermatologists, from 0\u00b7201 \u00b1 0\u00b7156 to 0\u00b7322 \u00b1 0\u00b7141 (P < 0\u00b7001).\n## CONCLUSIONS\nDCNNs can classify lip diseases at a level similar to dermatologists. This will help unskilled physicians discriminate between benign and malignant lip diseases. What's already known about this topic? Deep convolutional neural networks (DCNNs) can classify malignant and benign skin diseases at a level equivalent to dermatologists. The lips are a unique feature in terms of histology and morphology. Previous studies of DCNNs have not investigated tumours on specific locations. What does this study add? This study shows that DCNNs can distinguish rare malignant and benign lip disorders at the same rate as dermatologists. DCNNs can help nondermatologists to distinguish malignant lip diseases. What are the clinical implications of this work? DCNNs can distinguish malignant and benign skin diseases even at specific locations such as the lips, as well as board-certified dermatologists. Malignant lip diseases are rare and difficult for less trained doctors to differentiate them from benign lesions. This study shows that in dermatology, DCNN can help improve decision-making processes for rare skin diseases in specific areas of the body.\n",
            "in_text_citation": "Cho et al., 2020",
            "footnote": 13
        }
    ]
}