{
    "base_references": [
        {
            "title": "Melanoma Detection Using XGB Classifier Combined with Feature Extraction and K-Means SMOTE Techniques.",
            "abstract": "Melanoma, a very severe form of skin cancer, spreads quickly and has a high mortality rate if not treated early. Recently, machine learning, deep learning, and other related technologies have been successfully applied to computer-aided diagnostic tasks of skin lesions. However, some issues in terms of image feature extraction and imbalanced data need to be addressed. Based on a method for manually annotating image features by dermatologists, we developed a melanoma detection model with four improvement strategies, including applying the transfer learning technique to automatically extract image features, adding gender and age metadata, using an oversampling technique for imbalanced data, and comparing machine learning algorithms. According to the experimental results, the improved strategies proposed in this study have statistically significant performance improvement effects. In particular, our proposed ensemble model can outperform previous related models."
        },
        {
            "title": "Differential diagnosis between small breast phyllodes tumors and fibroadenomas using artificial intelligence and ultrasound data.",
            "abstract": "Background:\n        \n      \n      It is challenging to differentiate between phyllodes tumors (PTs) and fibroadenomas (FAs). Artificial intelligence (AI) can provide quantitative information regarding the morphology and textural features of lesions. This study attempted to use AI to evaluate the ultrasonic images of PTs and FAs and to explore the diagnostic performance of AI features in the differential diagnosis of PTs and FAs.\n    \n\n\n          Methods:\n        \n      \n      A total of 40 PTs and 290 FAs <5 cm in maximum diameter found in female patients were retrospectively analyzed. All tumors were segmented by doctors, and the features of the lesions were collated, including circularity, height-to-width ratio, margin spicules, margin coarseness (MC), margin indistinctness, margin lobulation (ML), internal calcification, angle between the long axis of the lesion and skin, energy, grey entropy, and grey mean. The differences between PTs and FAs were analyzed, and the diagnostic performance of AI features in the differential diagnosis of PTs and FAs was evaluated.\n    \n\n\n          Results:\n        \n      \n      Statistically significant differences (P<0.05) were found in the height-to-width ratio, ML, energy, and grey entropy between the PTs and FAs. Receiver operating characteristic (ROC) curve analysis of single features showed that the area under the curve [(AUC) 0.759] of grey entropy was the largest among the four features with statistically significant differences, and the sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) were 0.925, 0.459, 0.978, and 0.190, respectively. When considering the combinations of the features, the combination of height-to-width ratio, margin indistinctness, ML, energy, grey entropy, and internal calcification was the most optimal of the combinations of features with an AUC of 0.868, and a sensitivity, specificity, PPV, and NPV of 0.734, 0.900, 0.982, and 0.316, respectively.\n    \n\n\n          Conclusions:\n        \n      \n      Quantitative analysis of AI can identify subtle differences in the morphology and textural features between small PTs and FAs. Comprehensive consideration of multiple features is important for the differential diagnosis of PTs and FAs."
        },
        {
            "title": "An integrated clinical-dermoscopic risk scoring system for the differentiation between early melanoma and atypical nevi: the iDScore.",
            "abstract": "Background:\n        \n      \n      Dermoscopy revealed to be extremely useful in the diagnosis of early melanoma, the most important limitation being its subjectivity in giving a final diagnosis. To overcome this problem, several algorithms and checklists have been proposed. However, they generally demonstrated modest level of diagnostic accuracy, unsatisfactory concordance between dermoscopists and/or poor specificity.\n    \n\n\n          Objective:\n        \n      \n      To test a new methodological approach for the differentiation between early melanoma and atypical nevi, based on an integrated clinical-anamnestic dermoscopic risk scoring system (iDScore).\n    \n\n\n          Methods:\n        \n      \n      We selected a total of 435 standardized dermoscopic images of clinically atypical melanocytic skin lesion (MSL) excised in the suspect of malignancy (i.e. 134 early melanomas - MM - and 301 atypical nevi). Data concerning patient age and sex and lesion dimension and site were collected. A scoring classifier was designed based on this data set integrated with the dermoscopic evaluations performed by three experts blinded to histological diagnosis.\n    \n\n\n          Results:\n        \n      \n      A total of seven dermoscopic structures, three age groups (30-40 years, 41-60 years and >60 years), two maximum diameter categories (5-10 mm and >10 mm) and three body areas (i.e. frequently, chronically and seldom photoexposed sites) were selected by the scoring classifier as interdependently significant variables. The total risk score (S) of a lesion resulted from the simple sum of partial scores assigned to each selected variable. The iDScore-aided diagnosis showed an high accuracy (receiver operating characteristic-area under the curve = 0.903; IC: 95% = 0.887-0.918). A risk-based criticality scale corresponding to different S ranges was proposed.\n    \n\n\n          Conclusion:\n        \n      \n      The iDScore checklist is proposed as a feasible and efficient tool to support dermatologists in non-invasive differentiation between atypical nevi and early MM on the basis of few selected clinical-anamnestic data and standardized dermoscopic features."
        },
        {
            "title": "Understanding Flares in Patients With Generalized Pustular Psoriasis Documented in US Electronic Health Records.",
            "abstract": "Importance:\n        \n      \n      Other than single-center case studies, little is known about generalized pustular psoriasis (GPP) flares.\n    \n\n\n          Objective:\n        \n      \n      To assess GPP flares and their treatment, as well as differences between patients with and patients without flares documented in US electronic health records (EHRs).\n    \n\n\n          Design, setting, and participants:\n        \n      \n      This retrospective cohort study included adult patients with GPP (International Statistical Classification of Diseases and Related Health Problems, Tenth Revision code L40.1) identified in Optum deidentified EHR data between July 1, 2015, and June 30, 2020. The index GPP diagnosis was the first occurrence in the EHR, with no coded history of GPP for at least 6 months prior. Flare episodes were identified using an algorithm based on diagnosis coding, care setting, type of clinician, GPP disease terms, and flare terms and attributes in the EHR.\n    \n\n\n          Main outcomes and measures:\n        \n      \n      Flare episodes were characterized by the frequency of occurrence per patient, the care setting in which they were identified, the type of specialist managing the episode, associated symptoms, and the type of treatment before, during, and after the episode. Patients were divided into groups based on whether or not they had a flare episode documented in their EHR. Comparisons were made between the groups based on demographic characteristics, comorbidity burden, health care use, and treatments.\n    \n\n\n          Results:\n        \n      \n      Of 1535 patients with GPP (1018 women [66.3%]; mean [SD] age, 53.4 [14.7] years), 271 had 513 flares documented. Compared with patients without flares, patients with flares had a 34% higher mean (SD) Charlson Comorbidity Index score (2.80 [3.11] vs 2.09 [2.52]), were almost 3 times more likely to have inpatient visits (119 of 271 [44%] vs 194 of 1264 [15%]), were more than twice as likely to have emergency department (ED) visits (126 of 271 [47%] vs 299 of 1264 [24%]), and had higher use of almost all treatment classes. Flares were identified in outpatient (271 of 513 [53%]), inpatient (186 of 513 [36%]), and ED (48 of 513 [9%]) settings. The most common treatments during flares were topical corticosteroids (35% of episodes [178 of 513]), opioids (21% [106 of 513]), other oral treatments, (eg, methotrexate, cyclosporine, tacrolimus; 13% [67 of 513]), and oral corticosteroids (11% [54 of 513]). Almost one-fourth of flare episodes (24% [122 of 513]) had no dermatologic treatment 30 days before, during, or 30 days after a flare episode.\n    \n\n\n          Conclusions and relevance:\n        \n      \n      This cohort study suggests that there is significant unmet need for the treatment of GPP and its flares, as evidenced by patients seeking treatment in inpatient and ED settings, as well as the lack of advanced treatments."
        },
        {
            "title": "DermX: An end-to-end framework for explainable automated dermatological diagnosis.",
            "abstract": "Dermatological diagnosis automation is essential in addressing the high prevalence of skin diseases and critical shortage of dermatologists. Despite approaching expert-level diagnosis performance, convolutional neural network (ConvNet) adoption in clinical practice is impeded by their limited explainability, and by subjective, expensive explainability validations. We introduce DermX, an end-to-end framework for explainable automated dermatological diagnosis. DermX is a clinically-inspired explainable dermatological diagnosis ConvNet, trained using DermXDB, a 554 image dataset annotated by eight dermatologists with diagnoses, supporting explanations, and explanation attention maps. DermX+ extends DermX with guided attention training for explanation attention maps. Both methods achieve near-expert diagnosis performance, with DermX, DermX+, and dermatologist F1 scores of 0.79, 0.79, and 0.87, respectively. We assess the explanation performance in terms of identification and localization by comparing model-selected with dermatologist-selected explanations, and gradient-weighted class-activation maps with dermatologist explanation maps, respectively. DermX obtained an identification F1 score of 0.77, while DermX+ obtained 0.79. The localization F1 score is 0.39 for DermX and 0.35 for DermX+. These results show that explainability does not necessarily come at the expense of predictive power, as our high-performance models provide expert-inspired explanations for their diagnoses without lowering their diagnosis performance."
        },
        {
            "title": "The clinical diagnosis of equine sarcoids-Part 2: Assessment of case features typical of equine sarcoids and validation of a diagnostic protocol to guide equine clinicians in the diagnosis of equine sarcoids.",
            "abstract": "Research has shown that the accuracy of the clinical diagnosis of equine sarcoids (ES) can be improved. Particularly, less experienced veterinarians are often mistaken in their clinical judgement despite a high level of diagnostic confidence. The aim of this study was to develop and assess the performance of a diagnostic protocol (DP) to improve diagnostic accuracy and identify diagnostically challenging cases. The design of the DP was based on typical clinical features of ES and its algorithm was optimised through repeated tests on clinical cases prior to validating its performance in a representative online examination. A total of 22 equine practitioners and 31 veterinary students used the DP to diagnose 40 standardised ES and non-ES cases in an online examination. Scores of these 53 respondents were compared to scores of 128 respondents of comparable levels of expertise, and 14 experts, all assessing the same cases without using the DP. Overall, respondents using the DP were significantly more likely (odds ratio (OR) 1.25; 95% confidence interval (95% CI) 1.09-1.43) to diagnose a case correctly compared to respondents not using the DP and felt significantly more confident of their diagnosis (OR 1.53; 95% CI 1.39-1.67). Thus, the DP proved to be a reliable tool to increase clinical diagnostic accuracy and diagnostic confidence. The DP algorithms may be further improved with experiences gained from its application in equine practice and clinicians will be able to optimise their diagnostic accuracy and selection of lesions requiring a biopsy."
        },
        {
            "title": "Digital dermoscopy monitoring of melanocytic lesions: Two novel calculators combining static and dynamic features to identify melanoma.",
            "abstract": "Background:\n        \n      \n      Early diagnosis is the most effective intervention to improve the prognosis of cutaneous melanoma. Even though the introduction of dermoscopy has improved the diagnostic accuracy, it can still be difficult to distinguish some melanomas from benign melanocytic lesions. Digital dermoscopy monitoring can identify dynamic changes of melanocytic lesions: To date, some algorithms were proposed, but a universally accepted one is still lacking.\n    \n\n\n          Objectives:\n        \n      \n      To identify independent predictive variables associated with the diagnosis of cutaneous melanoma and develop a multivariable dermoscopic prediction model able to discriminate benign from malignant melanocytic lesions undergoing digital dermoscopy monitoring.\n    \n\n\n          Methods:\n        \n      \n      We collected dermoscopic images of melanocytic lesions excised after dermoscopy monitoring and carried out static and dynamic evaluations of dermoscopic features. We built two multivariable predictive models based on logistic regression and random forest.\n    \n\n\n          Results:\n        \n      \n      We evaluated 173 lesions (65 cutaneous melanomas and 108 nevi). Forty-two melanomas were in situ, and the median thickness of invasive melanomas was 0.35 mm. The median follow-up time was 9.8 months for melanomas and 9.1 for nevi. The logistic regression and random forest models performed with AUC values of 0.87 and 0.89, respectively, were substantially higher than those of the static evaluation models (ABCD TDS score, 0.57; 7-point checklist, 0.59). Finally, we built two risk calculators, which translate the proposed models into user-friendly applications, to assist clinicians in the decision-making process.\n    \n\n\n          Conclusions:\n        \n      \n      The present study demonstrates that the integration of dynamic and static evaluations of melanocytic lesions is a safe approach that can significantly boost the diagnostic accuracy for cutaneous melanoma. We propose two diagnostic tools that significantly increase the accuracy in discriminating melanoma from nevi during digital dermoscopy monitoring."
        },
        {
            "title": "Results of Surgical Treatment of Patients with Malignant Eccrine Poroma.",
            "abstract": "Objectives:\n        \n      \n      Malignant eccrine poroma is a rare cutaneous malignancy. This study was a review of a series of patients with malignant eccrine poroma who underwent surgical treatment conducted in order to evaluate the management techniques and outcomes of treatment modalities.\n    \n\n\n          Methods:\n        \n      \n      All cases of surgically excised malignant eccrine poroma performed in a single clinic between 2012 and 2018 were included in the study. The details of patient age, gender, anatomical location of the tumor, histopathological features, and treatment modalities were analyzed.\n    \n\n\n          Results:\n        \n      \n      The average tumor size was 2.53 cm (range: 0.3-7 cm). The average tumor thickness was 3.06 mm (range: 2.5-4 mm). The mean clean tumor margin after the first excision was 1.28 mm and the mean tumor margin after the second excision was 8.83 mm. No recurrence or distant metastasis was detected in any of the patients during the follow-up period.\n    \n\n\n          Conclusion:\n        \n      \n      Unlike frequent skin cancers, rare skin cancers, like malignant eccrine poroma, don't have definite treatment algorithms constituted from randomized trials. The findings of patient series are very useful to guide physicians in these cases."
        },
        {
            "title": "Web-based study on Chinese dermatologists' attitudes towards artificial intelligence.",
            "abstract": "Background:\n        \n      \n      Artificial intelligence (AI) has become a powerful tool and is attracting more attention in the field of medicine. There are a number of AI studies focusing on skin diseases, and there are many AI products that have been applied in dermatology. However, the attitudes of dermatologists, specifically those from China, towards AI, is not clear as few, if any studies have focused on this issue.\n    \n\n\n          Methods:\n        \n      \n      A web-based questionnaire was designed by experts from the Chinese Skin Image Database (CSID) and published on the UMER Doctor platform (an online learning platform for dermatologists developed by the Shanghai Wheat Color Intelligent Technology Company, China). A total of 1,228 Chinese dermatologists were recruited and provided answers to the questionnaire online. The differences of dermatologists' attitudes towards AI among the different groups (stratified by age, gender, hospital level, education degree, professional title, and hospital ownership) were compared by using the Mann-Whitney U test and the Kruskal-Wallis H test. The correlations between stratified factors and dermatologists' attitudes towards AI were calculated by using the Spearman's rank correlation test. SPSS (version 22.0) was utilized for all analyses. A two-sided P value <0.05 was considered statistically significant in all analyses.\n    \n\n\n          Results:\n        \n      \n      A total of 1,228 Chinese dermatologists from 30 provinces, autonomous regions, municipalities, and other regions (including Hong Kong, Macau, and Taiwan) participated in this survey. The dermatologists who participated acquired AI-related information mainly through the Internet, meetings or forums, and 70.51% of participated dermatologists acquired AI-related information by two or more approaches. In total, 99.51% of participated dermatologists pay attention (general, passive-active, and active attention) to information pertaining to AI. Stratified analyses revealed statistically significant differences in their attention levels (unconcerned, general, passive-active, and active attention) to AI-related information by gender, hospital level, education degree, and professional title (P values â‰¤1.79E-02). In total, 95.36% of the participated dermatologists thought the role of AI to be in \"assisting the daily diagnosis and treatment activities for dermatologists\". Stratified analyses about the thought of AI roles (unconcerned, useless, assist, and replace) showed that there was no statistically significant difference except for the hospital level (P value =4.09E-03). The correlations between stratified factors with attention levels and the opinions of AI roles showed extremely weak correlations. Furthermore, 64.17% of participated dermatologists thought secondary hospitals in China are in most need of the application AI, and 91.78% of participated dermatologists thought the priority implementation of AI should be in skin tumors.\n    \n\n\n          Conclusions:\n        \n      \n      The majority of Chinese dermatologists are interested in AI information and acquired information about AI through a variety of approaches. Nearly all dermatologists are attentive to information on AI and think the role of AI is in \"assisting the daily diagnosis and treatment activities for dermatologists\". Future AI implementation should be primarily focused on skin tumors and utilized in in secondary hospitals."
        },
        {
            "title": "Recommendations for the use of corrective makeup after dermatological procedures.",
            "abstract": "Introduction:\n        \n      \n      The number of dermatological or cosmetic procedures carried out has continuously increased over the last decades. Almost all may cause transient local skin reactions such as erythema, blistering, crusts, scaling, hypo- or hyperpigmentation, or hemorrhagic lesions. One issue of dermatological procedures is the downtime, during which patients need to hide their skin, due to these local reactions.\n    \n\n\n          Aim:\n        \n      \n      To provide dermatologists with easy-to-follow recommendations for the right timing of use of corrective makeup for patients who have undergone or who plan to undergo dermatological procedures, according to the invasiveness of the dermatological procedure chosen.\n    \n\n\n          Methodology:\n        \n      \n      A group of experts in dermatological procedures met in 2019 and at the beginning of 2020 to discuss the different procedures, their local reactions and downtime, and the opportunities to use specific corrective makeup in order to hide these transient reactions.\n    \n\n\n          Results:\n        \n      \n      As a result of the discussions, the experts proposed a tabulated algorithm of use based on a classification of the different dermatological procedures according to their invasiveness and recommended timing of the first post-procedure corrective makeup application.\n    \n\n\n          Conclusion:\n        \n      \n      Corrective makeup may be considered as a complement to certain dermatological procedures in order to minimize downtime. However, its use is conditioned by the correct understanding of skin barrier alteration and recovery time. The proposed algorithm of use of corrective makeup after procedures may help the practitioner to indicate his patient the right moment for applying corrective makeup in order to avoid local tolerance issues and post-procedure complications."
        },
        {
            "title": "Assessment of deep neural networks for the diagnosis of benign and malignant skin neoplasms in comparison with dermatologists: A retrospective validation study.",
            "abstract": "Background:\n        \n      \n      The diagnostic performance of convolutional neural networks (CNNs) for diagnosing several types of skin neoplasms has been demonstrated as comparable with that of dermatologists using clinical photography. However, the generalizability should be demonstrated using a large-scale external dataset that includes most types of skin neoplasms. In this study, the performance of a neural network algorithm was compared with that of dermatologists in both real-world practice and experimental settings.\n    \n\n\n          Methods and findings:\n        \n      \n      To demonstrate generalizability, the skin cancer detection algorithm (https://rcnn.modelderm.com) developed in our previous study was used without modification. We conducted a retrospective study with all single lesion biopsied cases (43 disorders; 40,331 clinical images from 10,426 cases: 1,222 malignant cases and 9,204 benign cases); mean age (standard deviation [SD], 52.1 [18.3]; 4,701 men [45.1%]) were obtained from the Department of Dermatology, Severance Hospital in Seoul, Korea between January 1, 2008 and March 31, 2019. Using the external validation dataset, the predictions of the algorithm were compared with the clinical diagnoses of 65 attending physicians who had recorded the clinical diagnoses with thorough examinations in real-world practice. In addition, the results obtained by the algorithm for the data of randomly selected batches of 30 patients were compared with those obtained by 44 dermatologists in experimental settings; the dermatologists were only provided with multiple images of each lesion, without clinical information. With regard to the determination of malignancy, the area under the curve (AUC) achieved by the algorithm was 0.863 (95% confidence interval [CI] 0.852-0.875), when unprocessed clinical photographs were used. The sensitivity and specificity of the algorithm at the predefined high-specificity threshold were 62.7% (95% CI 59.9-65.1) and 90.0% (95% CI 89.4-90.6), respectively. Furthermore, the sensitivity and specificity of the first clinical impression of 65 attending physicians were 70.2% and 95.6%, respectively, which were superior to those of the algorithm (McNemar test; p < 0.0001). The positive and negative predictive values of the algorithm were 45.4% (CI 43.7-47.3) and 94.8% (CI 94.4-95.2), respectively, whereas those of the first clinical impression were 68.1% and 96.0%, respectively. In the reader test conducted using images corresponding to batches of 30 patients, the sensitivity and specificity of the algorithm at the predefined threshold were 66.9% (95% CI 57.7-76.0) and 87.4% (95% CI 82.5-92.2), respectively. Furthermore, the sensitivity and specificity derived from the first impression of 44 of the participants were 65.8% (95% CI 55.7-75.9) and 85.7% (95% CI 82.4-88.9), respectively, which are values comparable with those of the algorithm (Wilcoxon signed-rank test; p = 0.607 and 0.097). Limitations of this study include the exclusive use of high-quality clinical photographs taken in hospitals and the lack of ethnic diversity in the study population.\n    \n\n\n          Conclusions:\n        \n      \n      Our algorithm could diagnose skin tumors with nearly the same accuracy as a dermatologist when the diagnosis was performed solely with photographs. However, as a result of limited data relevancy, the performance was inferior to that of actual medical examination. To achieve more accurate predictive diagnoses, clinical information should be integrated with imaging information."
        },
        {
            "title": "Dermoscopic Lotus of Learning: Implementation and Dissemination of a Multimodal Dermoscopy Curriculum for Primary Care.",
            "abstract": "Dermoscopy is a cost-effective tool for detection of skin cancers yet there is limited training available for primary care. The goal of this project was to develop, implement, and disseminate a multimodal curriculum for primary care across a health system based on a previously validated algorithm (Triage Amalgamated Dermoscopic Algorithm; TADA). This cross-sectional study analyzes the dermoscopy workshop intervention of a dermoscopy multimodal curriculum. Volunteers attended one 120-minute dermoscopy workshop on benign and malignant growths using a validated algorithm. Participants took a 30-image pre- and posttest. Survey questions on dermoscopy use, preferences for learning, and skin biopsy performance were included to enhance curriculum development. About 96 participants completed both pre- and postintervention tests. The mean preintervention score (out of 30) was 18.6 and increased to 24.4 on the postintervention evaluation. There was a statistically significant improvement in scores for both benign and malignant skin growths after the intervention (P < .05). Short dermoscopy workshops have a positive intervention effect when training primary care providers to identify images of benign and malignant dermoscopic skin lesions. A multimodal dermoscopy curriculum allows learners to build on initial training using spaced review and blended learning strategies. The \"Dermoscopic Lotus of Learning\" has the potential to be a model for other primary care residency programs. A healthy partnership between dermatologists and primary care is essential."
        },
        {
            "title": "Digital hair segmentation using hybrid convolutional and recurrent neural networks architecture.",
            "abstract": "Background and objective:\n        \n      \n      Skin melanoma is one of the major health problems in many countries. Dermatologists usually diagnose melanoma by visual inspection of moles. Digital hair removal can provide a non-invasive way to remove hair and hair-like regions as a pre-processing step for skin lesion images. Hair removal has two main steps: hair segmentation and hair gaps inpainting. However, hair segmentation is a challenging task which requires manual tuning of thresholding parameters. Hard-coded threshold leads to over-segmentation (false positives) which in return changes the textural integrity of lesions and or under-segmentation (false negatives) which leaves hair traces and artefacts which affect subsequent diagnosis. Additionally, dermal hair exhibits different characteristics: thin; overlapping; faded; occluded and overlaid on textured lesions.\n    \n\n\n          Methods:\n        \n      \n      In this presented paper, we proposed a deep learning approach based on a hybrid network of convolutional and recurrent layers for hair segmentation using weakly labelled data. We utilised the deep encoded features for accurate detection and delineation of hair in skin images. The encoded features are then fed into recurrent neural network layers to encode the spatial dependencies between disjointed patches. Experiments are conducted on a publicly available dataset, called \"Towards Melanoma Detection: Challenge\". We chose two metrics to evaluate the produced segmentation masks. The first metric is the Jaccard Index which penalises false positives and false negatives. The second metric is the tumour disturb pattern which assesses the overall effect over the lesion texture due to unnecessary inpainting as a result of over segmentation. The qualitative and quantitative evaluations are employed to compare the proposed technique with state-of-the-art methods.\n    \n\n\n          Results:\n        \n      \n      The proposed approach showed superior segmentation accuracy as demonstrated by a Jaccard Index of 77.8% in comparison to a 66.5% reported by the state-of-the-art method. We also achieved tumour disturb pattern as low as 14% compared to 23% for the state-of-the-art method.\n    \n\n\n          Conclusion:\n        \n      \n      The hybrid architecture for segmentation was able to accurately delineate and segment the hair from the background including lesions and the skin using weakly labelled ground truth for training."
        },
        {
            "title": "Toward automated assessment of mole similarity on dermoscopic images.",
            "abstract": "Purpose: Current skin cancer detection relies on dermatologists' visual assessments of moles directly or dermoscopically. Our goal is to show that our similarity assessment algorithm on dermoscopic images can perform as well as a dermatologist's assessment. Approach: Given one target mole and two other moles from the same patient, our model determines which mole is more similar to the target mole. Similarity was quantified as the Euclidean distance in a feature space designed to capture mole properties such as size, shape, and color. We tested our model on 18 patients, each of whom had at least five moles, and compared the model assessments of mole similarity with that of three dermatologists. Fleiss' Kappa agreement coefficients and iteration tests were used to evaluate the agreement in similarity assessment among dermatologists and our model. Results: With the selected features of size, entropy (color variation), and cluster prominence (asymmetry), our algorithm's similarity assessments agreed moderately with the similarity assessments of dermatologists. The mean Kappa of 1000 iteration tests was 0.49 ( confidence interval   ( CI ) = [ 0.23 , 0.74 ]  ) when comparing three dermatologists and our model, which is comparable to the agreement in similarity assessment among the dermatologists themselves (the mean Kappa of 1000 iteration tests for three dermatologists was 0.48, CI = [ 0.19 , 0.77 ]  .) By contrast, the mean Kappa was 0.22 ( CI = [ - 0.00 , 0.43 ]  ) when comparing the similarity assessments of three dermatologists and random guesses. Conclusions: Our study showed that our image feature-engineering-based algorithm can effectively assess the similarity of moles as dermatologists do. Such a similarity assessment could serve as the foundation for computer-assisted intra-patient evaluation of moles."
        },
        {
            "title": "User satisfaction with a smartphone-compatible, artificial intelligence-based cutaneous pigmented lesion evaluator.",
            "abstract": "Introduction:\n        \n      \n      Melanoma is the most aggressive type of skin cancer, and it may arise from a cutaneous pigmented lesion. As artificial intelligence (AI)-based teledermatology services hold promise in redefining the melanoma screening paradigm, a study that evaluates user satisfaction with a smartphone-compatible, AI-based cutaneous pigmented lesion evaluator is lacking.\n    \n\n\n          Methods:\n        \n      \n      Data was collected between April and May 2019 in Taiwan. To assess user satisfaction with MoleMe, an AI-based cutaneous pigmented lesion evaluator on a smartphone, users were asked to complete a questionnaire designed to evaluate four aspects, including interaction, impact on daily life, usability, and overall performance, after completing a MoleMe evaluation session. For each question, users could rank their satisfaction level from 1 to 5, with five showing strongly satisfied and one showing strongly unsatisfied. The Kruskal-Wallis and Wilcoxon rank-sum tests were used to compare user satisfaction among different age groups, genders, and risk predictions received.\n    \n\n\n          Result:\n        \n      \n      A total of 1231 questionnaires were collected for analysis. Over 90% of the participants were satisfied (score = 4 or 5) and over 75% of the participants were strongly satisfied (score 5) with MoleMe, in terms of usability, interaction, and impact on daily life. The user satisfaction did not show a significant difference between genders, age groups, and risk predictions received. (all P > 0.05) CONCLUSION: With high user satisfaction regardless of age group, gender, and risk prediction received, AI-based teledermatology services on a smartphone such as MoleMe may potentially achieve widespread usage and be beneficial to both patients and physicians."
        },
        {
            "title": "Development and validation of two artificial intelligence models for diagnosing benign, pigmented facial skin lesions.",
            "abstract": "Objective:\n        \n      \n      This study used deep learning for diagnosing common, benign hyperpigmentation.\n    \n\n\n          Method:\n        \n      \n      In this study, two convolutional neural networks were used to identify six pigmentary diseases, and a disease diagnosis model was established. Because the distribution of lesions in the original training picture is very complex, we cropped the image around the lesions, trained the network on the extracted lesion images, and fused the verification results of the overall picture and the extracted picture to assess the model performance in identifying hyperpigmented dermatitis pictures. Finally, we evaluated the image recognition performance of the two convolutional neural networks and the converged networks in the test set through a comparison of the converged network and the physicians' assessments.\n    \n\n\n          Results:\n        \n      \n      The AUC of DenseNet-96 for the overall picture was 0.98, whereas the AUC of ResNet-152 was 0.96; therefore, we concluded that DenseNet-96 performed better than ResNet-152. From the AUC, the converged network has the best performance. The converged network model achieved a comprehensive classification performance comparable to that of the doctors.\n    \n\n\n          Conclusions:\n        \n      \n      The diagnostic model for benign, pigmented skin lesions based on convolutional neural networks had a slightly higher overall performance than the skin specialists."
        },
        {
            "title": "Simple and Accurate Border Detection Algorithm for Melanoma Computer Aided Diagnosis.",
            "abstract": "The interest of the scientific community for computer aided skin lesion analysis and characterization has been increased during the last years for the growing incidence of melanoma among cancerous pathologies. The detection of melanoma in its early stage is essential for prognosis improvement and for guaranteeing a high five-year relative survival rate of patients. The clinical diagnosis of skin lesions is challenging and not trivial since it depends on human vision and physician experience and expertise. Therefore, a computer method that makes an accurate extraction of important details of skin lesion image can assist dermatologists in cancer detection. In particular, the border detection is a critical computer vision issue owing to the wide range of lesion shapes, sizes, colours and skin texture types. In this paper, an automatic and effective pigmented skin lesion segmentation method in dermoscopic image is presented. The proposed procedure is adopted to extract a mask of the lesion region without the adoption of other signal processing procedures for image improvement. A quantitative experimental evaluation has been performed on a publicly available database. The achieved results show the method validity and its high robustness towards irregular boundaries, smooth transition between lesion and skin, noise and artifact presence."
        },
        {
            "title": "Clinicopathological Study of Extra-Axial Small Round Cell Tumors of the Cranium.",
            "abstract": "Introduction:\n        \n      \n      The cranium is a host to a variety of neoplasms and includes small round cell tumors (SRCTs) as an important malignant subset. Although SRCTs are histomorphologically similar, they are histogenetically diverse comprising of malignancies of epithelial, hematolymphoid, neuroectodermal, and mesenchymal origin.\n    \n\n\n          Objective:\n        \n      \n      The study aimed to review the clinical and pathological profile of cranial SRCTs.\n    \n\n\n          Materials and methods:\n        \n      \n      Study is a retrospective review (clinical, imaging, and histopathology) of cranial (extra-axial) SRCTs diagnosed on histology (period: 3.5 years).\n    \n\n\n          Results:\n        \n      \n      Study included 126 cases constituting 1.5% of all intracranial neoplasms and age ranging from 11 months to 82 years (mean: 34.3 years; M:F = 1.46:1). Peripheral primitive neuroectodermal tumors (pPNET-8.2%) was the commonest neoplasm followed by plasmacytoma (14.2%), poorly differentiated carcinomas (13.5%), lymphomas (9.5%), and sarcomas (8.7%). Rare tumors included glioma (undifferentiated) deposits, germ cell tumors, melanoma, neuroendocrine neoplasms, and embryonal tumor. Children constituted one-third of the total with PNETs, embryonal tumors, and round cell sarcomas being the common neoplasms. Elderly patients constituted 14% with plasmacytomas and epithelial neoplasms being common. Three percent of the tumors remained unclassified. Clinical symptomology was location dependent, headache being the commonest followed by visual symptoms. Radiopathological discordance was high (60%).\n    \n\n\n          Conclusion:\n        \n      \n      SRCTs are unusual tumors with a wide spectrum of histogenesis, biology and clinical presentation. Their rarity in cranium, atypical localization, overlapping clinical, and imaging features pose significant difficulty for clinicians, radiologists, and pathologists. A combined algorithmic analysis of the clinical, radiological, and histolopathological findings, supplemented with immunohistochemistry can aid in specific diagnosis which is crucial for optimal management."
        },
        {
            "title": "Melanoma detection using adversarial training and deep transfer learning.",
            "abstract": "Skin lesion datasets consist predominantly of normal samples with only a small percentage of abnormal ones, giving rise to the class imbalance problem. Also, skin lesion images are largely similar in overall appearance owing to the low inter-class variability. In this paper, we propose a two-stage framework for automatic classification of skin lesion images using adversarial training and transfer learning toward melanoma detection. In the first stage, we leverage the inter-class variation of the data distribution for the task of conditional image synthesis by learning the inter-class mapping and synthesizing under-represented class samples from the over-represented ones using unpaired image-to-image translation. In the second stage, we train a deep convolutional neural network for skin lesion classification using the original training set combined with the newly synthesized under-represented class samples. The training of this classifier is carried out by minimizing the focal loss function, which assists the model in learning from hard examples, while down-weighting the easy ones. Experiments conducted on a dermatology image benchmark demonstrate the superiority of our proposed approach over several standard baseline methods, achieving significant performance improvements. Interestingly, we show through feature visualization and analysis that our method leads to context based lesion assessment that can reach an expert dermatologist level."
        },
        {
            "title": "Automatic skin lesions detection from images through microscopic hybrid features set and machine learning classifiers.",
            "abstract": "Skin cancer occurrences increase exponentially worldwide due to the lack of awareness of significant populations and skin specialists. Medical imaging can help with early detection and more accurate diagnosis of skin cancer. The physicians usually follow the manual diagnosis method in their clinics but nonprofessional dermatologists sometimes affect the accuracy of the results. Thus, the automated system is required to assist physicians in diagnosing skin cancer at early stage precisely to decrease the mortality rate. This article presents an automatic skin lesions detection through a microscopic hybrid feature set and machine learning-based classification. The employment of deep features through AlexNet architecture with local optimal-oriented pattern can accurately predict skin lesions. The proposed model is tested on two open-access datasets PAD-UFES-20 and MED-NODE comprising melanoma and nevus images. Experimental results on both datasets exhibit the efficacy of hybrid features with the help of machine learning. Finally, the proposed model achieved 94.7% accuracy using an ensemble classifier. RESEARCH HIGHLIGHTS: The deep features accurately predicted skin lesions through AlexNet architecture with local optimal-oriented pattern. Proposed model is tested on two datasets PAD-UFES-20, MED-NODE comprising melanoma, nevus images and exhibited high accuracy."
        },
        {
            "title": "Systematic review of machine learning for diagnosis and prognosis in dermatology.",
            "abstract": "Background: Software systems using artificial intelligence for medical purposes have been developed in recent years. The success of deep neural networks (DNN) in 2012 in the image recognition challenge ImageNet LSVRC 2010 fueled expectations of the potential for using such systems in dermatology.Objective: To evaluate the ways in which machine learning has been utilized in dermatology to date and provide an overview of the findings in current literature on the subject.Methods: We conducted a systematic review of existing literature, identifying the literature through a systematic search of the PubMed database. Two doctors assessed screening and eligibility with respect to pre-determined inclusion and exclusion criteria.Results: A total of 2175 publications were identified, and 64 publications were included. We identified eight major categories where machine learning tools were tested in dermatology. Most systems involved image recognition tools that were primarily aimed at binary classification of malignant melanoma (MM). Short system descriptions and results of all included systems are presented in tables.Conclusions: We present a complete overview of artificial intelligence implemented in dermatology. Impressive outcomes were reported in all of the identified eight categories, but head-to-head comparison proved difficult. The many areas of dermatology where we identified machine learning tools indicate the diversity of machine learning."
        },
        {
            "title": "Artificial Intelligence and Its Effect on Dermatologists' Accuracy in Dermoscopic Melanoma Image Classification: Web-Based Survey Study.",
            "abstract": "Background:\n        \n      \n      Early detection of melanoma can be lifesaving but this remains a challenge. Recent diagnostic studies have revealed the superiority of artificial intelligence (AI) in classifying dermoscopic images of melanoma and nevi, concluding that these algorithms should assist a dermatologist's diagnoses.\n    \n\n\n          Objective:\n        \n      \n      The aim of this study was to investigate whether AI support improves the accuracy and overall diagnostic performance of dermatologists in the dichotomous image-based discrimination between melanoma and nevus.\n    \n\n\n          Methods:\n        \n      \n      Twelve board-certified dermatologists were presented disjoint sets of 100 unique dermoscopic images of melanomas and nevi (total of 1200 unique images), and they had to classify the images based on personal experience alone (part I) and with the support of a trained convolutional neural network (CNN, part II). Additionally, dermatologists were asked to rate their confidence in their final decision for each image.\n    \n\n\n          Results:\n        \n      \n      While the mean specificity of the dermatologists based on personal experience alone remained almost unchanged (70.6% vs 72.4%; P=.54) with AI support, the mean sensitivity and mean accuracy increased significantly (59.4% vs 74.6%; P=.003 and 65.0% vs 73.6%; P=.002, respectively) with AI support. Out of the 10% (10/94; 95% CI 8.4%-11.8%) of cases where dermatologists were correct and AI was incorrect, dermatologists on average changed to the incorrect answer for 39% (4/10; 95% CI 23.2%-55.6%) of cases. When dermatologists were incorrect and AI was correct (25/94, 27%; 95% CI 24.0%-30.1%), dermatologists changed their answers to the correct answer for 46% (11/25; 95% CI 33.1%-58.4%) of cases. Additionally, the dermatologists' average confidence in their decisions increased when the CNN confirmed their decision and decreased when the CNN disagreed, even when the dermatologists were correct. Reported values are based on the mean of all participants. Whenever absolute values are shown, the denominator and numerator are approximations as every dermatologist ended up rating a varying number of images due to a quality control step.\n    \n\n\n          Conclusions:\n        \n      \n      The findings of our study show that AI support can improve the overall accuracy of the dermatologists in the dichotomous image-based discrimination between melanoma and nevus. This supports the argument for AI-based tools to aid clinicians in skin lesion classification and provides a rationale for studies of such classifiers in real-life settings, wherein clinicians can integrate additional information such as patient age and medical history into their decisions."
        },
        {
            "title": "Blood-Based Immune Profiling Combined with Machine Learning Discriminates Psoriatic Arthritis from Psoriasis Patients.",
            "abstract": "Psoriasis (Pso) is a chronic inflammatory skin disease, and up to 30% of Pso patients develop psoriatic arthritis (PsA), which can lead to irreversible joint damage. Early detection of PsA in Pso patients is crucial for timely treatment but difficult for dermatologists to implement. We, therefore, aimed to find disease-specific immune profiles, discriminating Pso from PsA patients, possibly facilitating the correct identification of Pso patients in need of referral to a rheumatology clinic. The phenotypes of peripheral blood immune cells of consecutive Pso and PsA patients were analyzed, and disease-specific immune profiles were identified via a machine learning approach. This approach resulted in a random forest classification model capable of distinguishing PsA from Pso (mean AUC = 0.95). Key PsA-classifying cell subsets selected included increased proportions of differentiated CD4+CD196+CD183-CD194+ and CD4+CD196-CD183-CD194+ T-cells and reduced proportions of CD196+ and CD197+ monocytes, memory CD4+ and CD8+ T-cell subsets and CD4+ regulatory T-cells. Within PsA, joint scores showed an association with memory CD8+CD45RA-CD197- effector T-cells and CD197+ monocytes. To conclude, through the integration of in-depth flow cytometry and machine learning, we identified an immune cell profile discriminating PsA from Pso. This immune profile may aid in timely diagnosing PsA in Pso."
        },
        {
            "title": "[Application of a parallel branches network based on Transformer for skin melanoma segmentation].",
            "abstract": "Cutaneous malignant melanoma is a common malignant tumor. Accurate segmentation of the lesion area is extremely important for early diagnosis of the disease. In order to achieve more effective and accurate segmentation of skin lesions, a parallel network architecture based on Transformer is proposed in this paper. This network is composed of two parallel branches: the former is the newly constructed multiple residual frequency channel attention network (MFC), and the latter is the visual transformer network (ViT). First, in the MFC network branch, the multiple residual module and the frequency channel attention module (FCA) module are fused to improve the robustness of the network and enhance the capability of extracting image detailed features. Second, in the ViT network branch, multiple head self-attention (MSA) in Transformer is used to preserve the global features of the image. Finally, the feature information extracted from the two branches are combined in parallel to realize image segmentation more effectively. To verify the proposed algorithm, we conducted experiments on the dermoscopy image dataset published by the International Skin Imaging Collaboration (ISIC) in 2018. The results show that the intersection-over-union (IoU) and Dice coefficients of the proposed algorithm achieve 90.15% and 94.82%, respectively, which are better than the latest skin melanoma segmentation networks. Therefore, the proposed network can better segment the lesion area and provide dermatologists with more accurate lesion data."
        },
        {
            "title": "[Clinical image identification of basal cell carcinoma and pigmented nevi based on convolutional neural network].",
            "abstract": "To construct an intelligent assistant diagnosis model based on the clinical images of basal cell carcinoma (BCC) and pigmented nevi in Chinese by using the advanced convolutional neural network (CNN). Methods: Based on the Xiangya Medical Big Data Platform, we constructed a large-scale clinical image dataset of skin diseases according to Chinese ethnicity and the Xiangya Skin Disease Dataset. We evaluated the performance of 5 mainstream CNN models (ResNet50, InceptionV3, InceptionResNetV2, DenseNet121, and Xception) on a subset of BCC and pigmented nevi of this dataset. We also analyzed the basis of the diagnosis results in the form of heatmaps. We compared the optimal CNN classification model with 30 professional dermatologists. Results: The Xiangya Skin Disease Dataset contains 150 223 clinical images with lesion annotations, covering 543 skin diseases, and each image in the dataset contains support for pathological gold standards and the patient's overall medical history. On the test set of 349 BCC and 497 pigmented nevi, the optimal CNN model was Xception, and its classification accuracy can reach 93.5%, of which the area under curve (AUC) values were 0.974 and 0.969, respectively. The results of the heatmap showed that the CNN model can indeed learn the characteristics associated with disease identification. The ability of the Xception model to identify clinical images of BCC and Nevi was basically comparable to that of professional dermatologists. Conclusion: This study is the first assistant diagnosis study for skin tumor based on Chinese ethnic clinical dataset. It proves that CNN model has the ability to distinguish between Chinese ethnicity's BCC and Nevi, and lays a solid foundation for the following application of artificial intelligence in the diagnosis and treatment for skin tumors."
        },
        {
            "title": "Detection theory for accurate and non-invasive skin cancer diagnosis using dynamic thermal imaging.",
            "abstract": "Skin cancer is the most common cancer in the United States with over 3.5M annual cases. Presently, visual inspection by a dermatologist has good sensitivity (> 90%) but poor specificity (< 10%), especially for melanoma, which leads to a high number of unnecessary biopsies. Here we use dynamic thermal imaging (DTI) to demonstrate a rapid, accurate and non-invasive imaging system for detection of skin cancer. In DTI, the lesion is cooled down and the thermal recovery is recorded using infrared imaging. The thermal recovery curves of the suspected lesions are then utilized in the context of continuous-time detection theory in order to define an optimal statistical decision rule such that the sensitivity of the algorithm is guaranteed to be at a maximum for every prescribed false-alarm probability. The proposed methodology was tested in a pilot study including 140 human subjects demonstrating a sensitivity in excess of 99% for a prescribed specificity in excess of 99% for detection of skin cancer. To the best of our knowledge, this is the highest reported accuracy for any non-invasive skin cancer diagnosis method."
        },
        {
            "title": "A Deep Learning Based Framework for Diagnosing Multiple Skin Diseases in a Clinical Environment.",
            "abstract": "Background: Numerous studies have attempted to apply artificial intelligence (AI) in the dermatological field, mainly on the classification and segmentation of various dermatoses. However, researches under real clinical settings are scarce. Objectives: This study was aimed to construct a novel framework based on deep learning trained by a dataset that represented the real clinical environment in a tertiary class hospital in China, for better adaptation of the AI application in clinical practice among Asian patients. Methods: Our dataset was composed of 13,603 dermatologist-labeled dermoscopic images, containing 14 categories of diseases, namely lichen planus (LP), rosacea (Rosa), viral warts (VW), acne vulgaris (AV), keloid and hypertrophic scar (KAHS), eczema and dermatitis (EAD), dermatofibroma (DF), seborrheic dermatitis (SD), seborrheic keratosis (SK), melanocytic nevus (MN), hemangioma (Hem), psoriasis (Pso), port wine stain (PWS), and basal cell carcinoma (BCC). In this study, we applied Google's EfficientNet-b4 with pre-trained weights on ImageNet as the backbone of our CNN architecture. The final fully-connected classification layer was replaced with 14 output neurons. We added seven auxiliary classifiers to each of the intermediate layer groups. The modified model was retrained with our dataset and implemented using Pytorch. We constructed saliency maps to visualize our network's attention area of input images for its prediction. To explore the visual characteristics of different clinical classes, we also examined the internal image features learned by the proposed framework using t-SNE (t-distributed Stochastic Neighbor Embedding). Results: Test results showed that the proposed framework achieved a high level of classification performance with an overall accuracy of 0.948, a sensitivity of 0.934 and a specificity of 0.950. We also compared the performance of our algorithm with three most widely used CNN models which showed our model outperformed existing models with the highest area under curve (AUC) of 0.985. We further compared this model with 280 board-certificated dermatologists, and results showed a comparable performance level in an 8-class diagnostic task. Conclusions: The proposed framework retrained by the dataset that represented the real clinical environment in our department could accurately classify most common dermatoses that we encountered during outpatient practice including infectious and inflammatory dermatoses, benign and malignant cutaneous tumors."
        },
        {
            "title": "Squeeze-MNet: Precise Skin Cancer Detection Model for Low Computing IoT Devices Using Transfer Learning.",
            "abstract": "Cancer remains a deadly disease. We developed a lightweight, accurate, general-purpose deep learning algorithm for skin cancer classification. Squeeze-MNet combines a Squeeze algorithm for digital hair removal during preprocessing and a MobileNet deep learning model with predefined weights. The Squeeze algorithm extracts important image features from the image, and the black-hat filter operation removes noise. The MobileNet model (with a dense neural network) was developed using the International Skin Imaging Collaboration (ISIC) dataset to fine-tune the model. The proposed model is lightweight; the prototype was tested on a Raspberry Pi 4 Internet of Things device with a Neo pixel 8-bit LED ring; a medical doctor validated the device. The average precision (AP) for benign and malignant diagnoses was 99.76% and 98.02%, respectively. Using our approach, the required dataset size decreased by 66%. The hair removal algorithm increased the accuracy of skin cancer detection to 99.36% with the ISIC dataset. The area under the receiver operating curve was 98.9%."
        },
        {
            "title": "Fully Automated Approach for Early Detection of Pigmented Skin Lesion Diagnosis Using ABCD.",
            "abstract": "Computerized analysis of pigmented skin lesions (PSLs) is a lively space of survey that dates back over 25 years. Recently, different automated computer-based systems stand to be a helpful tool. Physicians' usage for ABCD worldwide as the main tool of diagnosis and self-examination make it the common reference for different skin cancer diagnosis models. This system is comprised of the main four key warning signs of the ABCD model that can be detected by visual inspection and more accurately identified by the automated system to diagnose melanoma. Based on the image area identified as PSL, through pre-processing and segmentation step, the features will then be detected regarding ABCD rule. According to what ABCD stands for, the proposed study extracts Asymmetry, Border and Color features, in addition to various parameters introduce parameter \"D.\" Finally, as the worldwide definition of ABCD rule of cancer diagnoses was discussed, this research also makes the final decision according to the Total Dermoscopic Score (TDS) Index, in addition to another three popular machine learning classifiers. ANN, SVM, and K-nearest neighbor were used for classification of the segmented lesions in addition to the traditional TDS. This research shows perfect results for calculating the ABCD score automatically, which reflects its viability. Different experiments developed in regard to features variety and different classification methods to reach 98.1%, 95%, and 98.75% classification accuracy when dermoscopic images were classified by TDS, Automatic ANN, and linear SVM, respectively, where the clinical images reached perfect accuracy 100% when classified by linear SVM, and very promising result 98.75% as per automatic ANN. This system considered to be the first promising digitalized system for traditional TDS regarding the achieved accuracy and using of a simple Graphical User Interface (GUI) to facilitate user easy use."
        },
        {
            "title": "Multi skin lesions classification using fine-tuning and data-augmentation applying NASNet.",
            "abstract": "Skin lesions are one of the typical symptoms of many diseases in humans and indicative of many types of cancer worldwide. Increased risks caused by the effects of climate change and a high cost of treatment, highlight the importance of skin cancer prevention efforts like this. The methods used to detect these diseases vary from a visual inspection performed by dermatologists to computational methods, and the latter has widely used automatic image classification applying Convolutional Neural Networks (CNNs) in medical image analysis in the last few years. This article presents an approach that uses CNNs with a NASNet architecture to recognize in a more accurate way, without segmentation, eight skin diseases. The model was trained end-to-end on Keras with augmented skin diseases images from the International Skin Imaging Collaboration (ISIC). The CNN architectures were initialized with weight from ImageNet, fine-tuned in order to discriminate well among the different types of skin lesions, and then 10-fold cross-validation was applied. Finally, some evaluation metrics are calculated as accuracy, sensitivity, and specificity and compare with other CNN trained architectures. This comparison shows that the proposed system offers higher accuracy results, with a significant reduction on the training paraments. To the best of our knowledge and based in the state-of-art recompiling in this work, the application of the NASNet architecture training with skin image lesion from ISIC archive for multi-class classification and evaluated by cross-validation, represents a novel skin disease classification system."
        },
        {
            "title": "Toward Augmented Intelligence: The First Prospective, Randomized Clinical Trial Assessing Clinician and Artificial Intelligence Collaboration in Dermatology.",
            "abstract": "Han et al. (2022) report the first randomized, prospective clinical trial in dermatology evaluating the performance of clinicians working in collaboration with artificial intelligence (AI). This foundational work shows the limitations of AI in a real-world clinical setting and shows its potential for improving the performance of nonspecialists diagnosing skin diseases."
        },
        {
            "title": "Long-term management of moderate-to-severe adult atopic dermatitis: a consensus by the Italian Society of Dermatology and Venereology (SIDeMaST), the Association of Italian Territorial and Hospital Allergists and Immunologists (AAIITO), the Italian Association of Hospital Dermatologists (ADOI), the Italian Society of Allergological, Environmental and Occupational Dermatology (SIDAPA), and the Italian Society of Allergy, Asthma and Clinical Immunology (SIAAIC).",
            "abstract": "Atopic dermatitis (AD) is a common chronic-relapsing inflammatory skin disease, burdened by various comorbidities. AD most commonly occurs in children but may persist or present in adulthood becoming a lifelong condition. Therefore, AD requires an effective long-term treatment improving disease signs and symptoms but also of patients' quality of life (QoL). However continuous long-term use of most traditional AD immunosuppressive treatments is not recommended for safety reasons or insufficient efficacy data. Despite the available guidelines, there is still need for knowledge of AD long-term treatment, taking into account new disease measures and recent treatment options. Five Italian scientific societies implemented a joint consensus procedure to define the most appropriate clinical practice for the long-term management of adult moderate-severe AD. Through a modified Delphi procedure, consensus was reached by overall 51 Italian dermatologists and allergists (The Italian AD Study Group) experienced in the management of adult AD on 14 statements covering three AD areas of interest, namely diagnosis, definition of disease severity and clinimetrics, and a treat-to-target approach. This paper reports and discusses the agreed statements, which define disease and patient impact measures, therapeutic approach, and a treatment decision algorithm to support clinicians in the long-term management of adult patients with moderate-to-severe AD in their daily clinical practice."
        },
        {
            "title": "Compliance with medical recommendations depending on the use of artificial intelligence as a diagnostic method.",
            "abstract": "Background:\n        \n      \n      Advanced analytics, such as artificial intelligence (AI), increasingly gain relevance in medicine. However, patients' responses to the involvement of AI in the care process remains largely unclear. The study aims to explore whether individuals were more likely to follow a recommendation when a physician used AI in the diagnostic process considering a highly (vs. less) severe disease compared to when the physician did not use AI or when AI fully replaced the physician.\n    \n\n\n          Methods:\n        \n      \n      Participants from the USA (n = 452) were randomly assigned to a hypothetical scenario where they imagined that they received a treatment recommendation after a skin cancer diagnosis (high vs. low severity) from a physician, a physician using AI, or an automated AI tool. They then indicated their intention to follow the recommendation. Regression analyses were used to test hypotheses. Beta coefficients (ÃŸ) describe the nature and strength of relationships between predictors and outcome variables; confidence intervals [CI] excluding zero indicate significant mediation effects.\n    \n\n\n          Results:\n        \n      \n      The total effects reveal the inferiority of automated AI (ÃŸ = .47, p = .001 vs. physician; ÃŸ = .49, p = .001 vs. physician using AI). Two pathways increase intention to follow the recommendation. When a physician performs the assessment (vs. automated AI), the perception that the physician is real and present (a concept called social presence) is high, which increases intention to follow the recommendation (ÃŸ = .22, 95% CI [.09; 0.39]). When AI performs the assessment (vs. physician only), perceived innovativeness of the method is high, which increases intention to follow the recommendation (ÃŸ = .15, 95% CI [- .28; - .04]). When physicians use AI, social presence does not decrease and perceived innovativeness increases.\n    \n\n\n          Conclusion:\n        \n      \n      Pairing AI with a physician in medical diagnosis and treatment in a hypothetical scenario using topical therapy and oral medication as treatment recommendations leads to a higher intention to follow the recommendation than AI on its own. The findings might help develop practice guidelines for cases where AI involvement benefits outweigh risks, such as using AI in pathology and radiology, to enable augmented human intelligence and inform physicians about diagnoses and treatments."
        },
        {
            "title": "Effects of Label Noise on Deep Learning-Based Skin Cancer Classification.",
            "abstract": "Recent studies have shown that deep learning is capable of classifying dermatoscopic images at least as well as dermatologists. However, many studies in skin cancer classification utilize non-biopsy-verified training images. This imperfect ground truth introduces a systematic error, but the effects on classifier performance are currently unknown. Here, we systematically examine the effects of label noise by training and evaluating convolutional neural networks (CNN) with 804 images of melanoma and nevi labeled either by dermatologists or by biopsy. The CNNs are evaluated on a test set of 384 images by means of 4-fold cross validation comparing the outputs with either the corresponding dermatological or the biopsy-verified diagnosis. With identical ground truths of training and test labels, high accuracies with 75.03% (95% CI: 74.39-75.66%) for dermatological and 73.80% (95% CI: 73.10-74.51%) for biopsy-verified labels can be achieved. However, if the CNN is trained and tested with different ground truths, accuracy drops significantly to 64.53% (95% CI: 63.12-65.94%, p < 0.01) on a non-biopsy-verified and to 64.24% (95% CI: 62.66-65.83%, p < 0.01) on a biopsy-verified test set. In conclusion, deep learning methods for skin cancer classification are highly sensitive to label noise and future work should use biopsy-verified training images to mitigate this problem."
        },
        {
            "title": "Automated Identification of Patients With Immune-Related Adverse Events From Clinical Notes Using Word Embedding and Machine Learning.",
            "abstract": "Purpose:\n        \n      \n      Although immune checkpoint inhibitors (ICIs) have substantially improved survival in patients with advanced malignancies, they are associated with a unique spectrum of side effects termed immune-related adverse events (irAEs). To ensure treatment safety, research efforts are needed to comprehensively detect and understand irAEs. Retrospective analysis of data from electronic health records can provide knowledge to characterize these toxicities. However, such information is not captured in a structured format within the electronic health record and requires manual chart review.\n    \n\n\n          Materials and methods:\n        \n      \n      In this work, we propose a natural language processing pipeline that can automatically annotate clinical notes and determine whether there is evidence that a patient developed an irAE. Seven hundred eighty-one cases were manually reviewed by clinicians and annotated for irAEs at the patient level. A dictionary of irAEs keywords was used to perform text reduction on clinical notes belonging to each patient; only sentences with relevant expressions were kept. Word embeddings were then used to generate vector representations over the reduced text, which served as input for the machine learning classifiers. The output of the models was presence or absence of any irAEs. Additional models were built to classify skin-related toxicities, endocrine toxicities, and colitis.\n    \n\n\n          Results:\n        \n      \n      The model for any irAE achieved an average F1-score = 0.75 and area under the receiver operating characteristic curve = 0.85. This outperformed a basic keyword filtering approach. Although the classifier of any irAEs achieved good accuracy, individual irAE classification still has room for improvement.\n    \n\n\n          Conclusion:\n        \n      \n      We demonstrate that patient-level annotations combined with a machine learning approach using keywords filtering and word embeddings can achieve promising accuracy in classifying irAEs in clinical notes. This model may facilitate annotation and analysis of large irAEs data sets."
        },
        {
            "title": "Automated detection of erythema migrans and other confounding skin lesions via deep learning.",
            "abstract": "Lyme disease can lead to neurological, cardiac, and rheumatologic complications when untreated. Timely recognition of the erythema migrans rash of acute Lyme disease by patients and clinicians is crucial to early diagnosis and treatment. Our objective in this study was to develop deep learning approaches using deep convolutional neural networks for detecting acute Lyme disease from erythema migrans images of varying quality and acquisition conditions. This study used a cross-sectional dataset of images to train a model employing a deep convolutional neural network to perform classification of erythema migrans versus other skin conditions including tinea corporis and herpes zoster, and normal, non-pathogenic skin. Evaluation of the machine's ability to classify skin types was also performed on a validation set of images. Machine performance for detecting erythema migrans was further tested against a panel of non-medical humans. Online, publicly available images of both erythema migrans and non-Lyme confounding skin lesions were mined, and combined with erythema migrans images from an ongoing, longitudinal study of participants with acute Lyme disease enrolled in 2016 and 2017 who were recruited from primary and urgent care centers. The final dataset had 1834 images, including 1718 expert clinician-curated online images from unknown individuals with erythema migrans, tinea corporis, herpes zoster, and normal skin. It also included 116 images taken of 63 research participants from the Mid-Atlantic region. Two clinicians carefully annotated all lesion images. A convenience sample of 7 non-medically-trained humans were used as a panel to compare against machine performance. We calculated several performance metrics, including accuracy and Kappa (characterizing agreement with gold standard), as well as a receiver operating characteristic curve and associated area under the curve. For detecting erythema migrans, the machine had an accuracy (95% confidence interval error margin) of 86.53% (2.70), ROCAUC of 0.9510 (0.0171) and Kappa of 0.7143. Our results suggested substantial agreement between machine and clinician criterion standard. Comparison of machine with non-medical expert human performance indicated that the machine almost always exceeded acceptable specificity, and could operate with higher sensitivity. This could have benefits for prescreening prior to physician referral, earlier treatment, and reductions in morbidity."
        },
        {
            "title": "Dermoscopic diagnostic performance of Japanese dermatologists for skin tumors differs by patient origin: A deep learning convolutional neural network closes the gap.",
            "abstract": "In the dermoscopic diagnosis of skin tumors, it remains unclear whether a deep neural network (DNN) trained with images from fair-skinned-predominant archives is helpful when applied for patients with darker skin. This study compared the performance of 30 Japanese dermatologists with that of a DNN for the dermoscopic diagnosis of International Skin Imaging Collaboration (ISIC) and Shinshu (Japanese only) datasets to classify malignant melanoma, melanocytic nevus, basal cell carcinoma and benign keratosis on the non-volar skin. The DNN was trained using 12 254 images from the ISIC set and 594 images from the Shinshu set. The sensitivity for malignancy prediction by the dermatologists was significantly higher for the Shinshu set than for the ISIC set (0.853 [95% confidence interval, 0.820-0.885] vs 0.608 [0.553-0.664], P < 0.001). The specificity of the DNN at the dermatologists' mean sensitivity value was 0.962 for the Shinshu set and 1.00 for the ISIC set and significantly higher than that for the human readers (both P < 0.001). The dermoscopic diagnostic performance of dermatologists for skin tumors tended to be less accurate for patients of non-local populations, particularly in relation to the dominant skin type. A DNN may help close this gap in the clinical setting."
        },
        {
            "title": "Antimicrobial stewardship in the treatment of skin and soft tissue infections.",
            "abstract": "Background:\n        \n      \n      Research on treating skin and soft tissue infections (SSTI) has shown improved patient outcomes with effective pharmaceutic prescribing. Antimicrobial stewardship programs can reduce consequences of broad-spectrum antimicrobial administration in SSTI treatment.\n    \n\n\n          Methods:\n        \n      \n      Prospective and historic control data were collected during two 7-month periods. Intervention consisted of implementing a new SSTI evidence-based treatment algorithm and provider education, including calls and medical record notes targeted at physicians.\n    \n\n\n          Results:\n        \n      \n      Of 412 patients, 76 and 86 were found eligible from the historic and intervention groups, respectively. The intervention group had a higher prevalence of appropriate antibiotic usage (33% vs 19%, respectively; P = .04). There was a lower median number of days from intravenous antibiotic therapy to oral conversion (3 vs 5; P < .0001) and a lower median number of days of antipseudomonal antibiotic use (3 vs 5; P = .03) in the intervention group, respectively. The intervention group also had fewer documented SSTI treatment complications (1% vs 8%, respectively; P = .04). The positive outcomes outlined demonstrate potential impacts made from the use of multidisciplinary antibiotic stewardship initiatives.\n    \n\n\n          Conclusions:\n        \n      \n      Appropriate use of antimicrobial agents under the direction of an antimicrobial stewardship program can lead to improved outcomes for patients being treated for SSTIs."
        },
        {
            "title": "Discriminative deep learning based benignity/malignancy diagnosis of dermatologic ultrasound skin lesions with pretrained artificial intelligence architecture.",
            "abstract": "Background:\n        \n      \n      Deep-learning algorithms (DLAs) have been used in artificial intelligence aided ultrasonography diagnosis of thyroid and breast lesions. However, its use has not been described in the case of dermatologic ultrasound lesions. Our purpose was to train a DLA to discriminate benign form malignant lesions in dermatologic ultrasound images.\n    \n\n\n          Materials and methods:\n        \n      \n      We trained a prebuilt neural network architecture (EfficientNet B4) in a commercial artificial intelligence platform (Peltarion, Stockholm, Sweden) with 235 color Doppler images of both benign and malignant ultrasound images of 235 excised and histologically confirmed skin lesions (84.3% training, 15.7% validation). An additional 35 test images were used for testing the algorithm discrimination for correct benign/malignant diagnosis. One dermatologist with more than 5 years of experience in dermatologic ultrasound blindly evaluated the same 35 test images for malignancy or benignity.\n    \n\n\n          Results:\n        \n      \n      EfficientNet B4 trained dermatologic ultrasound algorithm sensitivity; specificity; predictive positive values, and predicted negative values for validation algorithm were 0.8, 0.86, 0.86, and 0.8, respectively for malignancy diagnosis. When tested with 35 previously unevaluated images sets, the algorithmÂ´s accuracy for correct benign/malignant diagnosis was 77.1%, not statistically significantly different from the dermatologist's evaluation (74.1%).\n    \n\n\n          Conclusion:\n        \n      \n      An adequately trained algorithm, even with a limited number of images, is at least as accurate as a dermatologic-ultrasound experienced dermatologist in the evaluation of benignity/malignancy of ultrasound skin tumor images devoid of clinical data."
        },
        {
            "title": "ExAID: A multimodal explanation framework for computer-aided diagnosis of skin lesions.",
            "abstract": "Background and objectives:\n        \n      \n      One principal impediment in the successful deployment of Artificial Intelligence (AI) based Computer-Aided Diagnosis (CAD) systems in everyday clinical workflows is their lack of transparent decision-making. Although commonly used eXplainable AI (XAI) methods provide insights into these largely opaque algorithms, such explanations are usually convoluted and not readily comprehensible. The explanation of decisions regarding the malignancy of skin lesions from dermoscopic images demands particular clarity, as the underlying medical problem definition is ambiguous in itself. This work presents ExAID (Explainable AI for Dermatology), a novel XAI framework for biomedical image analysis that provides multi-modal concept-based explanations, consisting of easy-to-understand textual explanations and visual maps, to justify the predictions.\n    \n\n\n          Methods:\n        \n      \n      Our framework relies on Concept Activation Vectors to map human-understandable concepts to those learned by an arbitrary Deep Learning (DL) based algorithm, and Concept Localisation Maps to highlight those concepts in the input space. This identification of relevant concepts is then used to construct fine-grained textual explanations supplemented by concept-wise location information to provide comprehensive and coherent multi-modal explanations. All decision-related information is presented in a diagnostic interface for use in clinical routines. Moreover, the framework includes an educational mode providing dataset-level explanation statistics as well as tools for data and model exploration to aid medical research and education processes.\n    \n\n\n          Results:\n        \n      \n      Through rigorous quantitative and qualitative evaluation of our framework on a range of publicly available dermoscopic image datasets, we show the utility of multi-modal explanations for CAD-assisted scenarios even in case of wrong disease predictions. We demonstrate that concept detectors for the explanation of pre-trained networks reach accuracies of up to 81.46%, which is comparable to supervised networks trained end-to-end.\n    \n\n\n          Conclusions:\n        \n      \n      We present a new end-to-end framework for the multi-modal explanation of DL-based biomedical image analysis in Melanoma classification and evaluate its utility on an array of datasets. Since perspicuous explanation is one of the cornerstones of any CAD system, we believe that ExAID will accelerate the transition from AI research to practice by providing dermatologists and researchers with an effective tool that they can both understand and trust. ExAID can also serve as the basis for similar applications in other biomedical fields."
        },
        {
            "title": "Computer-aided detection and segmentation of malignant melanoma lesions on whole-body (18)F-FDG PET/CT using an interpretable deep learning approach.",
            "abstract": "Background and objective:\n        \n      \n      In oncology, 18-fluorodeoxyglucose (18F-FDG) positron emission tomography (PET) / computed tomography (CT) is widely used to identify and analyse metabolically-active tumours. The combination of the high sensitivity and specificity from 18F-FDG PET and the high resolution from CT makes accurate assessment of disease status and treatment response possible. Since cancer is a systemic disease, whole-body imaging is of high interest. Moreover, whole-body metabolic tumour burden is emerging as a promising new biomarker predicting outcome for innovative immunotherapy in different tumour types. However, this comes with certain challenges such as the large amount of data for manual reading, different appearance of lesions across the body and cumbersome reporting, hampering its use in clinical routine. Automation of the reading can facilitate the process, maximise the information retrieved from the images and support clinicians in making treatment decisions.\n    \n\n\n          Methods:\n        \n      \n      This work proposes a fully automated system for lesion detection and segmentation on whole-body 18F-FDG PET/CT. The novelty of the method stems from the fact that the same two-step approach used when manually reading the images was adopted, consisting of an intensity-based thresholding on PET followed by a classification that specifies which regions represent normal physiological uptake and which are malignant tissue. The dataset contained 69 patients treated for malignant melanoma. Baseline and follow-up scans together offered 267 images for training and testing.\n    \n\n\n          Results:\n        \n      \n      On an unseen dataset of 53 PET/CT images, a median F1-score of 0.7500 was achieved with, on average, 1.566 false positive lesions per scan. Metabolically-active tumours were segmented with a median dice score of 0.8493 and absolute volume difference of 0.2986 ml.\n    \n\n\n          Conclusions:\n        \n      \n      The proposed fully automated method for the segmentation and detection of metabolically-active lesions on whole-body 18F-FDG PET/CT achieved competitive results. Moreover, it was compared to a direct segmentation approach which it outperformed for all metrics."
        },
        {
            "title": "Results of the 2016 International Skin Imaging Collaboration International Symposium on Biomedical Imaging challenge: Comparison of the accuracy of computer algorithms to dermatologists for the diagnosis of melanoma from dermoscopic images.",
            "abstract": "Background:\n        \n      \n      Computer vision may aid in melanoma detection.\n    \n\n\n          Objective:\n        \n      \n      We sought to compare melanoma diagnostic accuracy of computer algorithms to dermatologists using dermoscopic images.\n    \n\n\n          Methods:\n        \n      \n      We conducted a cross-sectional study using 100 randomly selected dermoscopic images (50 melanomas, 44 nevi, and 6 lentigines) from an international computer vision melanoma challenge dataset (n = 379), along with individual algorithm results from 25 teams. We used 5 methods (nonlearned and machine learning) to combine individual automated predictions into \"fusion\" algorithms. In a companion study, 8 dermatologists classified the lesions in the 100 images as either benign or malignant.\n    \n\n\n          Results:\n        \n      \n      The average sensitivity and specificity of dermatologists in classification was 82% and 59%. At 82% sensitivity, dermatologist specificity was similar to the top challenge algorithm (59% vs. 62%, P = .68) but lower than the best-performing fusion algorithm (59% vs. 76%, P = .02). Receiver operating characteristic area of the top fusion algorithm was greater than the mean receiver operating characteristic area of dermatologists (0.86 vs. 0.71, P = .001).\n    \n\n\n          Limitations:\n        \n      \n      The dataset lacked the full spectrum of skin lesions encountered in clinical practice, particularly banal lesions. Readers and algorithms were not provided clinical data (eg, age or lesion history/symptoms). Results obtained using our study design cannot be extrapolated to clinical practice.\n    \n\n\n          Conclusion:\n        \n      \n      Deep learning computer vision systems classified melanoma dermoscopy images with accuracy that exceeded some but not all dermatologists."
        },
        {
            "title": "A Computer-Aided Decision Support System for Detection and Localization of Cutaneous Vasculature in Dermoscopy Images Via Deep Feature Learning.",
            "abstract": "Vascular structures of skin are important biomarkers in diagnosis and assessment of cutaneous conditions. Presence and distribution of lesional vessels are associated with specific abnormalities. Therefore, detection and localization of cutaneous vessels provide critical information towards diagnosis and stage status of diseases. However, cutaneous vessels are highly variable in shape, size, color and architecture, which complicate the detection task. Considering the large variability of these structures, conventional vessel detection techniques lack the generalizability to detect different vessel types and require separate algorithms to be designed for each type. Furthermore, such techniques are highly dependent on precise hand-crafted features which are time-consuming and computationally inefficient. As a solution, we propose a data-driven feature learning framework based on stacked sparse auto-encoders (SSAE) for comprehensive detection of cutaneous vessels. Each training image is divided into small patches of either containing or non-containing vasculature. A multilayer SSAE is designed to learn hidden features of the data in hierarchical layers in an unsupervised manner. The high-level learned features are subsequently fed into a classifier which categorizes each patch into absence or presence of vasculature and localizes vessels within the lesion. Over a test set of 3095 patches derived from 200 images, the proposed framework demonstrated superior performance of 95.4% detection accuracy over a variety of vessel patterns; outperforming other techniques by achieving the highest positive predictive value of 94.7%. The proposed Computer-Aided Diagnosis (CAD) framework can serve as a decision support system assisting dermatologists for more accurate diagnosis, especially in teledermatology applications in remote areas."
        },
        {
            "title": "Local edge-enhanced active contour for accurate skin lesion border detection.",
            "abstract": "Background:\n        \n      \n      Dermoscopy is one of the common and effective imaging techniques in diagnosis of skin cancer, especially for pigmented lesions. Accurate skin lesion border detection is the key to extract important dermoscopic features of the skin lesion. In current clinical settings, border delineation is performed manually by dermatologists. Operator based assessments lead to intra- and inter-observer variations due to its subjective nature. Moreover it is a tedious process. Because of aforementioned hurdles, the automation of lesion boundary detection in dermoscopic images is necessary. In this study, we address this problem by developing a novel skin lesion border detection method with a robust edge indicator function, which is based on a meshless method.\n    \n\n\n          Result:\n        \n      \n      Our results are compared with the other image segmentation methods. Our skin lesion border detection algorithm outperforms other state-of-the-art methods. Based on dermatologist drawn ground truth skin lesion borders, the results indicate that our method generates reasonable boundaries than other prominent methods having Dice score of 0.886 Â±0.094 and Jaccard score of 0.807 Â±0.133.\n    \n\n\n          Conclusion:\n        \n      \n      We prove that smoothed particle hydrodynamic (SPH) kernels can be used as edge features in active contours segmentation and probability map can be employed to avoid the evolving contour from leaking into the object of interest."
        },
        {
            "title": "Deep learning with transfer learning in pathology. Case study: classification of basal cell carcinoma.",
            "abstract": "Establishing basal cell carcinoma (BCC) subtype is sometimes challenging for pathologists. Deep-learning (DL) algorithms are an emerging approach in image classification due to their performance, accompanied by a new concept - transfer learning, which implies replacing the final layers of a trained network and retraining it for a new task, while keeping the weights from the imported layers. A DL convolution-based software, capable of classifying 10 subtypes of BCC, was designed. Transfer learning from three general-purpose image classification networks (AlexNet, GoogLeNet, and ResNet-18) was used. Three pathologists independently labeled 2249 patches. Ninety percent of data was used for training and 10% for testing on 100 independent training sequences. Each of the resulted networks independently labeled the whole dataset. Mean and standard deviation (SD) accuracy (ACC) [%]âˆ•sensitivity (SN) [%]âˆ•specificity (SP) [%]âˆ•area under the curve (AUC) for all the networks was 82.53Â±2.63âˆ•72.52Â±3.63âˆ•97.94Â±0.3/0.99. The software was validated on another 50-image dataset, and its results are comparable with the result of three pathologists in terms of agreement. All networks had similar classification accuracies, which demonstrated that they reached a maximum classification rate on the dataset. The software shows promising results, and with further development can be successfully used on histological images, assisting pathologists' diagnosis and teaching."
        },
        {
            "title": "Total-body photography in skin cancer screening: the clinical utility of standardized imaging.",
            "abstract": "Early detection of skin cancer is essential to reducing morbidity and mortality from both melanoma and nonmelanoma skin cancers. Total-body skin examinations (TBSEs) may improve early detection of malignant melanomas (MMs) but are controversial due to the poor quality of data available to establish a mortality benefit from skin cancer screening. Total-body photography (TBP) promises to provide a way forward by lowering the costs of dermatologic screening while simultaneously leveraging technology to increase patient access to dermatologic care. Standardized TBP also offers the ability for dermatologists to work synergistically with modern computer technology involving algorithms capable of analyzing high-quality images to flag concerning lesions that may require closer evaluation. On a population level, inexpensive TBP has the potential to increase access to skin cancer screening and it has several specific applications in a military population. The utility of standardized TBP is reviewed in the context of skin cancer screening and teledermatology."
        },
        {
            "title": "Concatenated Xception-ResNet50 - A novel hybrid approach for accurate skin cancer prediction.",
            "abstract": "Skin cancer is a malignant disease that affects millions of people around the world every year. It is an invasive disease characterised by an abnormal proliferation of skin cells in the body that multiply and spread through the lymph nodes, killing the surrounding tissue. The number of skin cancer cases is on the rise due to lifestyle changes and sun-seeking behaviour. As skin cancer is a deadly disease, early diagnosis and grading are crucial to save lives. In this work, state-of-the-art AI approaches are applied to develop a unique deep learning model that integrates Xception and ResNet50. This network achieves maximum accuracy by combining the properties of two robust networks. The proposed concatenated Xception-ResNet50 (X-R50) model can classify skin tumours as basal cell carcinoma, melanoma, melanocytic nevi, dermatofibroma, actinic keratoses and intraepithelial carcinoma, vascular and non-cancerous benign keratosis-like lesions. The performance of the proposed method is compared with a DeepCNN and other state-of-the-art transfer learning models. The Human Against Machine (HAM10000) dataset assesses the suggested method's performance. For this study, 10,500 skin images were used. The model is trained and tested with the sliding window technique. The proposed concatenated X-R50 model is cutting-edge, with a 97.8% prediction accuracy. The performance of the model is also validated by a statistical hypothesis test using analysis of variance (ANOVA). The reported approach is both accurate and efficient and can help dermatologists and clinicians detect skin cancer at an early stage of the clinical process."
        },
        {
            "title": "SEACU-Net: Attentive ConvLSTM U-Net with squeeze-and-excitation layer for skin lesion segmentation.",
            "abstract": "Background and objective:\n        \n      \n      Accurate segmentation of skin lesions is a pivotal step in dermoscopy image classification, which provides a powerful means for dermatologists to diagnose skin diseases. However, due to blurred boundaries, low contrast between the lesion and its surrounding skin, and changes in color and shape, most existing segmentation methods still face great challenges in obtaining receptive fields and extracting image feature information. To settle the above issues, we construct a new framework, named SEACU-Net, to analyze and segment skin lesion images.\n    \n\n\n          Methods:\n        \n      \n      Inspired by the U-Net, we utilize dense convolution blocks to obtain more discriminative information. Then, at each encoding and decoding stage, a channel and spatial squeeze & excitation layer are designed after each convolution, to adaptively enhance useful information features and suppress low-value ones from different feature channels. In addition, the attention mechanism is integrated into the convolutional long short-term memory (ConvLSTM) structure, which improves sensitivity and prediction accuracy. Furthermore, this network introduces a novel loss based on binary cross-entropy and Jaccard losses, which can ensure more balanced segmentation.\n    \n\n\n          Results:\n        \n      \n      The proposed method is applied to the ISIC 2017 and 2018 publicly image databases, then obtains a better performance in Dice, Jaccard, and Accuracy, with 89.11% and 87.58% Dice value, 80.50% and 78.12% Jaccard value, 95.01%, and 93.60% Accuracy value, respectively.\n    \n\n\n          Conclusion:\n        \n      \n      The results of quantitative and qualitative experiments show that our method reaches high-performance skin lesion segmentation, and can help radiologists make radiotherapy treatment plans in clinical practice."
        },
        {
            "title": "Development and Assessment of an Artificial Intelligence-Based Tool for Skin Condition Diagnosis by Primary Care Physicians and Nurse Practitioners in Teledermatology Practices.",
            "abstract": "Importance:\n        \n      \n      Most dermatologic cases are initially evaluated by nondermatologists such as primary care physicians (PCPs) or nurse practitioners (NPs).\n    \n\n\n          Objective:\n        \n      \n      To evaluate an artificial intelligence (AI)-based tool that assists with diagnoses of dermatologic conditions.\n    \n\n\n          Design, setting, and participants:\n        \n      \n      This multiple-reader, multiple-case diagnostic study developed an AI-based tool and evaluated its utility. Primary care physicians and NPs retrospectively reviewed an enriched set of cases representing 120 different skin conditions. Randomization was used to ensure each clinician reviewed each case either with or without AI assistance; each clinician alternated between batches of 50 cases in each modality. The reviews occurred from February 21 to April 28, 2020. Data were analyzed from May 26, 2020, to January 27, 2021.\n    \n\n\n          Exposures:\n        \n      \n      An AI-based assistive tool for interpreting clinical images and associated medical history.\n    \n\n\n          Main outcomes and measures:\n        \n      \n      The primary analysis evaluated agreement with reference diagnoses provided by a panel of 3 dermatologists for PCPs and NPs. Secondary analyses included diagnostic accuracy for biopsy-confirmed cases, biopsy and referral rates, review time, and diagnostic confidence.\n    \n\n\n          Results:\n        \n      \n      Forty board-certified clinicians, including 20 PCPs (14 women [70.0%]; mean experience, 11.3 [range, 2-32] years) and 20 NPs (18 women [90.0%]; mean experience, 13.1 [range, 2-34] years) reviewed 1048 retrospective cases (672 female [64.2%]; median age, 43 [interquartile range, 30-56] years; 41 920 total reviews) from a teledermatology practice serving 11 sites and provided 0 to 5 differential diagnoses per case (mean [SD], 1.6 [0.7]). The PCPs were located across 12 states, and the NPs practiced in primary care without physician supervision across 9 states. The NPs had a mean of 13.1 (range, 2-34) years of experience and practiced in primary care without physician supervision across 9 states. Artificial intelligence assistance was significantly associated with higher agreement with reference diagnoses. For PCPs, the increase in diagnostic agreement was 10% (95% CI, 8%-11%; P < .001), from 48% to 58%; for NPs, the increase was 12% (95% CI, 10%-14%; P < .001), from 46% to 58%. In secondary analyses, agreement with biopsy-obtained diagnosis categories of maglignant, precancerous, or benign increased by 3% (95% CI, -1% to 7%) for PCPs and by 8% (95% CI, 3%-13%) for NPs. Rates of desire for biopsies decreased by 1% (95% CI, 0-3%) for PCPs and 2% (95% CI, 1%-3%) for NPs; the rate of desire for referrals decreased by 3% (95% CI, 1%-4%) for PCPs and NPs. Diagnostic agreement on cases not indicated for a dermatologist referral increased by 10% (95% CI, 8%-12%) for PCPs and 12% (95% CI, 10%-14%) for NPs, and median review time increased slightly by 5 (95% CI, 0-8) seconds for PCPs and 7 (95% CI, 5-10) seconds for NPs per case.\n    \n\n\n          Conclusions and relevance:\n        \n      \n      Artificial intelligence assistance was associated with improved diagnoses by PCPs and NPs for 1 in every 8 to 10 cases, indicating potential for improving the quality of dermatologic care."
        },
        {
            "title": "Universal in vivo Textural Model for Human Skin based on Optical Coherence Tomograms.",
            "abstract": "Currently, diagnosis of skin diseases is based primarily on the visual pattern recognition skills and expertise of the physician observing the lesion. Even though dermatologists are trained to recognize patterns of morphology, it is still a subjective visual assessment. Tools for automated pattern recognition can provide objective information to support clinical decision-making. Noninvasive skin imaging techniques provide complementary information to the clinician. In recent years, optical coherence tomography (OCT) has become a powerful skin imaging technique. According to specific functional needs, skin architecture varies across different parts of the body, as do the textural characteristics in OCT images. There is, therefore, a critical need to systematically analyze OCT images from different body sites, to identify their significant qualitative and quantitative differences. Sixty-three optical and textural features extracted from OCT images of healthy and diseased skin are analyzed and, in conjunction with decision-theoretic approaches, used to create computational models of the diseases. We demonstrate that these models provide objective information to the clinician to assist in the diagnosis of abnormalities of cutaneous microstructure, and hence, aid in the determination of treatment. Specifically, we demonstrate the performance of this methodology on differentiating basal cell carcinoma (BCC) and squamous cell carcinoma (SCC) from healthy tissue."
        },
        {
            "title": "Optical Spectroscopy as a Method for Skin Cancer Risk Assessment.",
            "abstract": "Skin cancer is the most prevalent cancer, and its assessment remains a challenge for physicians. This study reports the application of an optical sensing method, elastic scattering spectroscopy (ESS), coupled with a classifier that was developed with machine learning, to assist in the discrimination of skin lesions that are concerning for malignancy. The method requires no special skin preparation, is non-invasive, easy to administer with minimal training, and allows rapid lesion classification. This novel approach was tested for all common forms of skin cancer. ESS spectra from a total of 1307 lesions were analyzed in a multi-center, non-randomized clinical trial. The classification algorithm was developed on a 950-lesion training dataset, and its diagnostic performance was evaluated against a 357-lesion testing dataset that was independent of the training dataset. The observed sensitivity was 100% (14/14) for melanoma and 94% (105/112) for non-melanoma skin cancer. The overall observed specificity was 36% (84/231). ESS has potential, as an adjunctive assessment tool, to assist physicians to differentiate between common benign and malignant skin lesions."
        },
        {
            "title": "Development and validation of the interpretability analysis system based on deep learning model for smart image follow-up of nail pigmentation.",
            "abstract": "Background:\n        \n      \n      Nail pigmentation can be a clinical manifestation of malignant melanoma and a variety of benign diseases. Nail matrix biopsy for pathologic examination, the gold standard for diagnosis of subungual melanoma, is a painful procedure and may result in nail damage. Therefore, there is a great need for non-invasive methods and long-term follow-up for nail pigmentation. The objective of this study is to establish an intelligent precursor system to provide convenient monitoring for nail pigmentation, early warning subungual melanoma, and reduce nail biopsies to the minimum necessary.\n    \n\n\n          Methods:\n        \n      \n      Dermoscopic images of nail lesions were obtained from outpatients between 2019 and 2020. The images were divided into the training set and the test set using k-fold cross validation at a ratio of 10:1. The deep learning model is developed based on the Pytorch framework. The model structure is optimized using the image segmentation model U-Net. An image segmentation module analyzed the contours of the whole nail plate and pigmented area according to the boundary features of the input images and a rule calculation module used the output information of the segmentation model to automatically analyze specific indicators referring to the \"ABCDEF\" rule. The model's results were compared with those of clinical experts.\n    \n\n\n          Results:\n        \n      \n      From 550 dermoscopic images of nail lesions obtained, 500 were selected randomly as the training set, and the remaining 50 as the test set. Our image segmentation module realized automatic segmentation of the pigmented area and the whole nail plate with dice coefficient to be 0.8711 and 0.9652, respectively. Five qualitative indicators were selected in the interpretability analysis system and the models showed a certain degree of consistency with the evaluation by clinical experts, i.e., R2 for area ratio vs. breadth score was 0.8179 (P<0.001), for mean pixel value vs. pigment score was 0.7149 (P<0.001), for evenness vs. pigment score was 0.5247 (P<0.001).\n    \n\n\n          Conclusions:\n        \n      \n      The proposed system made accurate segmentation of the nail plate and pigmented area and achieved medically interpretable index analysis. It is potentially a primer of an intelligent follow-up system that will enable convenient and spatially unaffected management and monitoring of nail pigmentation. It may provide clinicians with understandable auxiliary information for diagnosis."
        },
        {
            "title": "Augmented Intelligence Dermatology: Deep Neural Networks Empower Medical Professionals in Diagnosing Skin Cancer andÂ Predicting Treatment Options for 134 SkinÂ Disorders.",
            "abstract": "Although deep learning algorithms have demonstrated expert-level performance, previous efforts were mostly binary classifications of limited disorders. We trained an algorithm with 220,680 images of 174 disorders and validated it using Edinburgh (1,300 images; 10 disorders) and SNU datasets (2,201 images; 134 disorders). The algorithm could accurately predict malignancy, suggest primary treatment options, render multi-class classification among 134 disorders, and improve the performance of medical professionals. The area under the curves for malignancy detection were 0.928 Â± 0.002 (Edinburgh) and 0.937 Â± 0.004 (SNU). The area under the curves of primary treatment suggestion (SNU) were 0.828 Â± 0.012, 0.885 Â± 0.006, 0.885 Â± 0.006, and 0.918 Â± 0.006 for steroids, antibiotics, antivirals, and antifungals, respectively. For multi-class classification, the mean top-1 and top-5 accuracies were 56.7 Â± 1.6% and 92.0 Â± 1.1% (Edinburgh) and 44.8 Â± 1.2% and 78.1 Â± 0.3% (SNU), respectively. With the assistance of our algorithm, the sensitivity and specificity of 47 clinicians (21 dermatologists and 26 dermatology residents) for malignancy prediction (SNU; 240 images) were improved by 12.1% (P < 0.0001) and 1.1% (P < 0.0001), respectively. The malignancy prediction sensitivity of 23 non-medical professionals was significantly increased by 83.8% (P < 0.0001). The top-1 and top-3 accuracies of four doctors in the multi-class classification of 134 diseases (SNU; 2,201 images) were increased by 7.0% (PÂ = 0.045) and 10.1% (PÂ = 0.0020), respectively. The results suggest that our algorithm may serve as augmented intelligence that can empower medical professionals in diagnostic dermatology.\n"
        },
        {
            "title": "Predicting the clinical management of skin lesions using deep learning.",
            "abstract": "Automated machine learning approaches to skin lesion diagnosis from images are approaching dermatologist-level performance. However, current machine learning approaches that suggest management decisions rely on predicting the underlying skin condition to infer a management decision without considering the variability of management decisions that may exist within a single condition. We present the first work to explore image-based prediction of clinical management decisions directly without explicitly predicting the diagnosis. In particular, we use clinical and dermoscopic images of skin lesions along with patient metadata from the Interactive Atlas of Dermoscopy dataset (1011 cases; 20 disease labels; 3 management decisions) and demonstrate that predicting management labels directly is more accurate than predicting the diagnosis and then inferring the management decision ([Formula: see text] and [Formula: see text] improvement in overall accuracy and AUROC respectively), statistically significant at [Formula: see text]. Directly predicting management decisions also considerably reduces the over-excision rate as compared to management decisions inferred from diagnosis predictions (24.56% fewer cases wrongly predicted to be excised). Furthermore, we show that training a model to also simultaneously predict the seven-point criteria and the diagnosis of skin lesions yields an even higher accuracy (improvements of [Formula: see text] and [Formula: see text] in overall accuracy and AUROC respectively) of management predictions. Finally, we demonstrate our model's generalizability by evaluating on the publicly available MClass-D dataset and show that our model agrees with the clinical management recommendations of 157 dermatologists as much as they agree amongst each other."
        },
        {
            "title": "Generative Adversarial Network Image Synthesis Method for Skin Lesion Generation and Classification.",
            "abstract": "Background:\n        \n      \n      One of the common limitations in the treatment of cancer is in the early detection of this disease. The customary medical practice of cancer examination is a visual examination by the dermatologist followed by an invasive biopsy. Nonetheless, this symptomatic approach is timeconsuming and prone to human errors. An automated machine learning model is essential to capacitate fast diagnoses and early treatment.\n    \n\n\n          Objective:\n        \n      \n      The key objective of this study is to establish a fully automatic model that helps Dermatologists in skin cancer handling process in a way that could improve skin lesion classification accuracy.\n    \n\n\n          Method:\n        \n      \n      The work is conducted following an implementation of a Deep Convolutional Generative Adversarial Network (DCGAN) using the Python-based deep learning library Keras. We incorporated effective image filtering and enhancement algorithms such as bilateral filter to enhance feature detection and extraction during training. The Deep Convolutional Generative Adversarial Network (DCGAN) needed slightly more fine-tuning to ripe a better return. Hyperparameter optimization was utilized for selecting the best-performed hyperparameter combinations and several network hyperparameters. In this work, we decreased the learning rate from the default 0.001 to 0.0002, and the momentum for Adam optimization algorithm from 0.9 to 0.5, in trying to reduce the instability issues related to GAN models and at each iteration the weights of the discriminative and generative network were updated to balance the loss between them. We endeavour to address a binary classification which predicts two classes present in our dataset, namely benign and malignant. More so, some wellknown metrics such as the receiver operating characteristic -area under the curve and confusion matrix were incorporated for evaluating the results and classification accuracy.\n    \n\n\n          Results:\n        \n      \n      The model generated very conceivable lesions during the early stages of the experiment and we could easily visualise a smooth transition in resolution along the way. Thus, we have achieved an overall test accuracy of 93.5% after fine-tuning most parameters of our network.\n    \n\n\n          Conclusion:\n        \n      \n      This classification model provides spatial intelligence that could be useful in the future for cancer risk prediction. Unfortunately, it is difficult to generate high quality images that are much like the synthetic real samples and to compare different classification methods given the fact that some methods use non-public datasets for training."
        },
        {
            "title": "AI outperformed every dermatologist in dermoscopic melanoma diagnosis, using an optimized deep-CNN architecture with custom mini-batch logic and loss function.",
            "abstract": "Melanoma, one of the most dangerous types of skin cancer, results in a very high mortality rate. Early detection and resection are two key points for a successful cure. Recent researches have used artificial intelligence to classify melanoma and nevus and to compare the assessment of these algorithms to that of dermatologists. However, training neural networks on an imbalanced dataset leads to imbalanced performance, the specificity is very high but the sensitivity is very low. This study proposes a method for improving melanoma prediction on an imbalanced dataset by reconstructed appropriate CNN architecture and optimized algorithms. The contributions involve three key features as custom loss function, custom mini-batch logic, and reformed fully connected layers. In the experiment, the training dataset is kept up to date including 17,302 images of melanoma and nevus which is the largest dataset by far. The model performance is compared to that of 157 dermatologists from 12 university hospitals in Germany based on the same dataset. The experimental results prove that our proposed approach outperforms all 157 dermatologists and achieves higher performance than the state-of-the-art approach with area under the curve of 94.4%, sensitivity of 85.0%, and specificity of 95.0%. Moreover, using the best threshold shows the most balanced measure compare to other researches, and is promisingly application to medical diagnosis, with sensitivity of 90.0% and specificity of 93.8%. To foster further research and allow for replicability, we made the source code and data splits of all our experiments publicly available."
        },
        {
            "title": "Acral melanoma detection using dermoscopic images and convolutional neural networks.",
            "abstract": "Acral melanoma (AM) is a rare and lethal type of skin cancer. It can be diagnosed by expert dermatologists, using dermoscopic imaging. It is challenging for dermatologists to diagnose melanoma because of the very minor differences between melanoma and non-melanoma cancers. Most of the research on skin cancer diagnosis is related to the binary classification of lesions into melanoma and non-melanoma. However, to date, limited research has been conducted on the classification of melanoma subtypes. The current study investigated the effectiveness of dermoscopy and deep learning in classifying melanoma subtypes, such as, AM. In this study, we present a novel deep learning model, developed to classify skin cancer. We utilized a dermoscopic image dataset from the Yonsei University Health System South Korea for the classification of skin lesions. Various image processing and data augmentation techniques have been applied to develop a robust automated system for AM detection. Our custom-built model is a seven-layered deep convolutional network that was trained from scratch. Additionally, transfer learning was utilized to compare the performance of our model, where AlexNet and ResNet-18 were modified, fine-tuned, and trained on the same dataset. We achieved improved results from our proposed model with an accuracy of more than 90 % for AM and benign nevus, respectively. Additionally, using the transfer learning approach, we achieved an average accuracy of nearly 97 %, which is comparable to that of state-of-the-art methods. From our analysis and results, we found that our model performed well and was able to effectively classify skin cancer. Our results show that the proposed system can be used by dermatologists in the clinical decision-making process for the early diagnosis of AM."
        },
        {
            "title": "Best practices in surgical and nonsurgical management of head and neck Merkel cell carcinoma: An update.",
            "abstract": "Merkel cell carcinoma (MCC) is a rare, highly aggressive cutaneous neuroendocrine carcinoma. Controversy exists regarding optimal management of MCC as high-quality randomized studies and clinical trials are limited, and physicians are bound to interpret highly heterogeneous, retrospective literature in their clinical practice. Furthermore, the rising incidence and notably poor prognosis of MCC urges the establishment of best practices for optimal management of the primary tumor and its metastases. Herein, we summarized the relevant evidence and provided an algorithm for decision-making in MCC management based on the latest 2021 National Comprehensive Cancer Network guidelines. Additionally, we report current active MCC clinical trials in the United States. The initial management of MCC is dependent upon the pathology of the primary tumor and presence of metastatic disease. Patients with no clinical evidence of regional lymph node involvement generally require sentinel node biopsy (SLNB) while clinically node-positive patients should undergo fine needle aspiration (FNA) or core biopsy and full imaging workup. If SLNB or FNA/core biopsy are positive, a multidisciplinary team should be assembled to discuss if additional node dissection or adjuvant therapy is necessary. Wide local excision is optimal for primary tumor management and SLNB remains the preferred staging and predictive tool in MCC. The management of MCC has progressively improved in the last decade, particularly due to the establishment of immunotherapy as a new treatment option in advanced MCC. Ongoing trials and prospective studies are needed to further establish the best practices for MCC management."
        },
        {
            "title": "A convolutional neural network trained with dermoscopic images performed on par with 145 dermatologists in a clinical melanoma image classification task.",
            "abstract": "Background:\n        \n      \n      Recent studies have demonstrated the use of convolutional neural networks (CNNs) to classify images of melanoma with accuracies comparable to those achieved by board-certified dermatologists. However, the performance of a CNN exclusively trained with dermoscopic images in a clinical image classification task in direct competition with a large number of dermatologists has not been measured to date. This study compares the performance of a convolutional neuronal network trained with dermoscopic images exclusively for identifying melanoma in clinical photographs with the manual grading of the same images by dermatologists.\n    \n\n\n          Methods:\n        \n      \n      We compared automatic digital melanoma classification with the performance of 145 dermatologists of 12 German university hospitals. We used methods from enhanced deep learning to train a CNN with 12,378 open-source dermoscopic images. We used 100 clinical images to compare the performance of the CNN to that of the dermatologists. Dermatologists were compared with the deep neural network in terms of sensitivity, specificity and receiver operating characteristics.\n    \n\n\n          Findings:\n        \n      \n      The mean sensitivity and specificity achieved by the dermatologists with clinical images was 89.4% (range: 55.0%-100%) and 64.4% (range: 22.5%-92.5%). At the same sensitivity, the CNN exhibited a mean specificity of 68.2% (range 47.5%-86.25%). Among the dermatologists, the attendings showed the highest mean sensitivity of 92.8% at a mean specificity of 57.7%. With the same high sensitivity of 92.8%, the CNN had a mean specificity of 61.1%.\n    \n\n\n          Interpretation:\n        \n      \n      For the first time, dermatologist-level image classification was achieved on a clinical image classification task without training on clinical images. The CNN had a smaller variance of results indicating a higher robustness of computer vision compared with human assessment for dermatologic image classification tasks."
        },
        {
            "title": "Color-invariant skin lesion semantic segmentation based on modified U-Net deep convolutional neural network.",
            "abstract": "Melanoma is a type of skin lesion that is less common than other types of skin lesions, but it is fast growing and spreading. Therefore, it is classified as a serious disease that directly threatens human health and life. Recently, the number of deaths due to this disease has increased significantly. Thus, researchers are interested in creating computer-aided diagnostic systems that aid in the proper diagnosis and detection of these lesions from dermoscopy images. Relying on manual diagnosis is time consuming in addition to requiring enough experience from dermatologists. Current skin lesion segmentation systems use deep convolutional neural networks to detect skin lesions from RGB dermoscopy images. However, relying on RGB color model is not always the optimal choice to train such networks because some fine details of lesion parts in the dermoscopy images can not clearly appear using RGB color model. Other color models exhibit invariant features of the dermoscopy images so that they can improve the performance of deep neural networks. In the proposed Color Invariant U-Net (CIU-Net) model, a color mixture block is added at the beginning of the contracting path of U-Net. The color mixture block acts as a mixer to learn the fusion of various input color models and create a new one with three channels. Furthermore, a new channel-attention module is included in the connection path between encoder and decoder paths. This channel attention module is developed to enrich the extracted color features. From the experimental result, we found that the proposed CIU-Net works in harmony with the new proposed hybrid loss function to enhance skin segmentation results. The performance of the proposed CIU-Net architecture is evaluated using ISIC 2018 dataset and the results are compared with other recent approaches. Our proposed method outperformed other recent approaches and achieved the best Dice and Jaccard coefficient with values 92.56% and 91.40%, respectively."
        },
        {
            "title": "Accuracy of a smartphone application for triage of skin lesions based on machine learning algorithms.",
            "abstract": "Background:\n        \n      \n      Machine learning algorithms achieve expert-level accuracy in skin lesion classification based on clinical images. However, it is not yet shown whether these algorithms could have high accuracy when embedded in a smartphone app, where image quality is lower and there is high variability in image taking scenarios by users. In the past, these applications were criticized due to lack of accuracy.\n    \n\n\n          Objective:\n        \n      \n      In this study, we evaluate the accuracy of the newest version of a smartphone application (SA) for risk assessment of skin lesions.\n    \n\n\n          Methods:\n        \n      \n      This SA uses a machine learning algorithm to compute a risk rating. The algorithm is trained on 131 873 images taken by 31 449 users in multiple countries between January 2016 and August 2018 and rated for risk by dermatologists. To evaluate the sensitivity of the algorithm, we use 285 histopathologically validated skin cancer cases (including 138 malignant melanomas), from two previously published clinical studies (195 cases) and from the SA user database (90 cases). We calculate the specificity on a separate set from the SA user database containing 6000 clinically validated benign cases.\n    \n\n\n          Results:\n        \n      \n      The algorithm scored a 95.1% (95% CI, 91.9-97.3%) sensitivity in detecting (pre)malignant conditions (93% for malignant melanoma and 97% for keratinocyte carcinomas and precursors). This level of sensitivity was achieved with a 78.3% (95% CI, 77.2-79.3%) specificity.\n    \n\n\n          Conclusions:\n        \n      \n      This SA provides a high sensitivity to detect skin cancer; however, there is still room for improvement in terms of specificity. Future studies are needed to assess the impact of this SA on the health systems and its users."
        },
        {
            "title": "Machine Learning Applications in the Evaluation and Management of Psoriasis: A Systematic Review.",
            "abstract": "Background:\n        \n      \n      Machine learning (ML), a subset of artificial intelligence (AI) that aims to teach machines to automatically learn tasks by inferring patterns from data, holds significant promise to aid psoriasis care. Applications include evaluation of skin images for screening and diagnosis as well as clinical management including treatment and complication prediction.\n    \n\n\n          Objective:\n        \n      \n      To summarize literature on ML applications to psoriasis evaluation and management and to discuss challenges and opportunities for future advances.\n    \n\n\n          Methods:\n        \n      \n      We searched MEDLINE, Google Scholar, ACM Digital Library, and IEEE Xplore for peer-reviewed publications published in English through December 1, 2019. Our search queries identified publications with any of the 10 computing-related keywords and \"psoriasis\" in the title and/or abstract.\n    \n\n\n          Results:\n        \n      \n      Thirty-three studies were identified. Articles were organized by topic and synthesized as evaluation- or management-focused articles covering 5 content categories: (A) Evaluation using skin images: (1) identification and differential diagnosis of psoriasis lesions, (2) lesion segmentation, and (3) lesion severity and area scoring; (B) clinical management: (1) prediction of complications and (2) treatment.\n    \n\n\n          Conclusion:\n        \n      \n      Machine learning has significant potential to aid psoriasis evaluation and management. Current topics popular in ML research on psoriasis are the evaluation of medical images, prediction of complications, and treatment discovery. For patients to derive the greatest benefit from ML advancements, it is helpful for dermatologists to have an understanding of ML and how it can effectively aid their assessments and decision-making."
        },
        {
            "title": "Diagnostic Accuracy of Clinical and Microbiological Signs in Patients With Skin Lesions Resembling Buruli Ulcer in an Endemic Region.",
            "abstract": "Background:\n        \n      \n      The diagnosis of the neglected tropical skin and soft tissue disease Buruli ulcer (BU) is made on clinical and epidemiological grounds, after which treatment with BU-specific antibiotics is initiated empirically. Given the current decline in BU incidence, clinical expertise in the recognition of BU is likely to wane and laboratory confirmation of BU becomes increasingly important. We therefore aimed to determine the diagnostic accuracy of clinical signs and microbiological tests in patients presenting with lesions clinically compatible with BU.\n    \n\n\n          Methods:\n        \n      \n      A total of 227 consecutive patients were recruited in southern Benin and evaluated by clinical diagnosis, direct smear examination (DSE), polymerase chain reaction (PCR), culture, and histopathology. In the absence of a gold standard, the final diagnosis in each patient was made using an expert panel approach. We estimated the accuracy of each test in comparison to the final diagnosis and evaluated the performance of 3 diagnostic algorithms.\n    \n\n\n          Results:\n        \n      \n      Among the 205 patients with complete data, the attending clinicians recognized BU with a sensitivity of 92% (95% confidence interval [CI], 85%-96%), which was higher than the sensitivity of any of the laboratory tests. However, 14% (95% CI, 7%-24%) of patients not suspected to have BU at diagnosis were classified as BU by the expert panel. The specificities of all diagnostics were high (â‰¥91%). All diagnostic algorithms had similar performances.\n    \n\n\n          Conclusions:\n        \n      \n      A broader clinical suspicion should be recommended to reduce missed BU diagnoses. Taking into consideration diagnostic accuracy, time to results, cost-effectiveness, and clinical generalizability, a stepwise diagnostic approach reserving PCR to DSE-negative patients performed best."
        },
        {
            "title": "Classification of the Clinical Images for Benign and Malignant Cutaneous Tumors Using a Deep Learning Algorithm.",
            "abstract": "We tested the use of a deep learning algorithm to classify the clinical images of 12 skin diseases-basal cell carcinoma, squamous cell carcinoma, intraepithelial carcinoma, actinic keratosis, seborrheic keratosis, malignant melanoma, melanocytic nevus, lentigo, pyogenic granuloma, hemangioma, dermatofibroma, and wart. The convolutional neural network (Microsoft ResNet-152 model; Microsoft Research Asia, Beijing, China) was fine-tuned with images from the training portion of the Asan dataset, MED-NODE dataset, and atlas site images (19,398 images in total). The trained model was validated with the testing portion of the Asan, Hallym and Edinburgh datasets. With the Asan dataset, the area under the curve for the diagnosis of basal cell carcinoma, squamous cell carcinoma, intraepithelial carcinoma, and melanoma was 0.96 Â± 0.01, 0.83 Â± 0.01, 0.82 Â± 0.02, and 0.96 Â± 0.00, respectively. With the Edinburgh dataset, the area under the curve for the corresponding diseases was 0.90 Â± 0.01, 0.91 Â± 0.01, 0.83 Â± 0.01, and 0.88 Â± 0.01, respectively. With the Hallym dataset, the sensitivity for basal cell carcinoma diagnosis was 87.1% Â± 6.0%. The tested algorithm performance with 480 Asan and Edinburgh images was comparable to that of 16 dermatologists. To improve the performance of convolutional neural network, additional images with a broader range of ages and ethnicities should be collected."
        },
        {
            "title": "Automated decision support in melanocytic lesion management.",
            "abstract": "An automated melanocytic lesion image-analysis algorithm is described that aims to reproduce the decision-making of a dermatologist. The utility of the algorithm lies in its ability to identify lesions requiring excision from lesions not requiring excision. Using only wavelet coefficients as features, and testing three different machine learning algorithms, a cohort of 250 images of pigmented lesions is classified based on expert dermatologists' recommendations of either excision (165 images) or no excision (85 images). It is shown that the best algorithm utilises the Shannon4 wavelet coupled to the support vector machine, where the latter is used as the classifier. In this case the algorithm, utilising only 22 othogonal features, achieves a 10-fold cross validation sensitivity and specificity of 0.96 and 0.87, resulting in a diagnostic-odds ratio of 261. The advantages of this method over diagnostic algorithms-which make a melanoma/no melanoma decision-are twofold: first, by reproducing the decision-making of a dermatologist, the average number of lesions excised per melanoma among practioners in general can be reduced without compromising the detection of melanoma; and second, the intractable problem of clinically differentiating between many atypical dysplastic naevi and melanoma is avoided. Since many atypical naevi that require excision on clinical grounds will not be melanoma, the algorithm-in contrast to diagnostic algorithms-can aim for perfect specificities without clinical concerns, thus lowering the excision rate of non-melanoma. Finally, the algorithm has been implemented as a smart phone application to investigate its utility in clinical practice and to streamline the assimilation of hitherto unseen tested images into the training set."
        },
        {
            "title": "Feasibility of equivalent performance of 3D TOF [18F]-FDG PET/CT with reduced acquisition time using clinical and semiquantitative parameters.",
            "abstract": "Background:\n        \n      \n      High-performance time-of-flight (TOF) positron emission tomography (PET) systems have the capability for rapid data acquisition while preserving diagnostic image quality. However, determining a reliable and clinically applicable cut-off of the acquisition time plays an important role in routine practice. This study aimed to assess the diagnostic equivalence of short acquisition time of 57 with routine 75 seconds per bed position (s/BP) of [18F]-fluoro-deoxy-glucose (FDG) PET. Phantom studies applying EARL criteria suggested the feasibility of shortened acquisition time in routine clinical imaging by 3D TOF PET/CT scanners. Ninety-six patients with melanoma, lung or head and neck cancer underwent a standard whole-body, skull base-to-thigh or vertex-to-thigh [18F]-FDG PET/CT examination using the 3D TOF Ingenuity TF PET/CT system (Philips, Cleveland, OH). The [18F]-FDG activity applied was equal to 4MBq per kg body weight. Retrospectively, PET list-mode data were used to calculate a second PET study per patient with a reduced acquisition time of 57 s instead of routine 75 s/BP. PET/CT data were reconstructed using a 3D OSEM TOF algorithm. Blinded patient data were analysed by two nuclear medicine physicians. The number of [18F]-FDG-avid lesions per body region (head&neck, thorax, abdomen, bone, extremity) and image quality (grade 1-5) were evaluated. Semiquantitative analyses were performed by standardized uptake value (SUV) measurements using 3D volume of interests (VOI). The visual and semiquantitative diagnostic equivalence of 214 [18F]-FDG-avid lesions were analysed in the routine standard (75 s/BP) as well as the calculated PET/CT studies with short acquisition time. Statistical analyses were performed by equivalence testing and Bland-Altman plots.\n    \n\n\n          Results:\n        \n      \n      Lesion detection rate per patient's body region agreed in > 98% comparing 57 s/BP and 75 s/BP datasets. Overall image quality was determined as equal or superior to 75 s in 80% and 69%, respectively. In the semiquantitative lesion-based analyses, a significant equivalence was found between the 75 s/BP and 57 s/BP PET/CT images both for SUVmax (p = 0.004) and SUVmean (p = 0.003).\n    \n\n\n          Conclusion:\n        \n      \n      The results of this study demonstrate significant clinical and semiquantitative equivalence between short acquisition time of 57 s/BP and standard 75 s/BP 3D TOF [18F]-FDG PET/CT scanning, which may improve the patient's workflow in routine practice."
        },
        {
            "title": "Smartphone applications for triaging adults with skin lesions that are suspicious for melanoma.",
            "abstract": "Background:\n        \n      \n      Melanoma accounts for a small proportion of all skin cancer cases but is responsible for most skin cancer-related deaths. Early detection and treatment can improve survival. Smartphone applications are readily accessible and potentially offer an instant risk assessment of the likelihood of malignancy so that the right people seek further medical attention from a clinician for more detailed assessment of the lesion. There is, however, a risk that melanomas will be missed and treatment delayed if the application reassures the user that their lesion is low risk.\n    \n\n\n          Objectives:\n        \n      \n      To assess the diagnostic accuracy of smartphone applications to rule out cutaneous invasive melanoma and atypical intraepidermal melanocytic variants in adults with concerns about suspicious skin lesions.\n    \n\n\n          Search methods:\n        \n      \n      We undertook a comprehensive search of the following databases from inception to August 2016: Cochrane Central Register of Controlled Trials; MEDLINE; Embase; CINAHL; CPCI; Zetoc; Science Citation Index; US National Institutes of Health Ongoing Trials Register; NIHR Clinical Research Network Portfolio Database; and the World Health Organization International Clinical Trials Registry Platform. We studied reference lists and published systematic review articles.\n    \n\n\n          Selection criteria:\n        \n      \n      Studies of any design evaluating smartphone applications intended for use by individuals in a community setting who have lesions that might be suspicious for melanoma or atypical intraepidermal melanocytic variants versus a reference standard of histological confirmation or clinical follow-up and expert opinion.\n    \n\n\n          Data collection and analysis:\n        \n      \n      Two review authors independently extracted all data using a standardised data extraction and quality assessment form (based on QUADAS-2). Due to scarcity of data and poor quality of studies, we did not perform a meta-analysis for this review. For illustrative purposes, we plotted estimates of sensitivity and specificity on coupled forest plots for each application under consideration.\n    \n\n\n          Main results:\n        \n      \n      This review reports on two cohorts of lesions published in two studies. Both studies were at high risk of bias from selective participant recruitment and high rates of non-evaluable images. Concerns about applicability of findings were high due to inclusion only of lesions already selected for excision in a dermatology clinic setting, and image acquisition by clinicians rather than by smartphone app users.We report data for five mobile phone applications and 332 suspicious skin lesions with 86 melanomas across the two studies. Across the four artificial intelligence-based applications that classified lesion images (photographs) as melanomas (one application) or as high risk or 'problematic' lesions (three applications) using a pre-programmed algorithm, sensitivities ranged from 7% (95% CI 2% to 16%) to 73% (95% CI 52% to 88%) and specificities from 37% (95% CI 29% to 46%) to 94% (95% CI 87% to 97%). The single application using store-and-forward review of lesion images by a dermatologist had a sensitivity of 98% (95% CI 90% to 100%) and specificity of 30% (95% CI 22% to 40%).The number of test failures (lesion images analysed by the applications but classed as 'unevaluable' and excluded by the study authors) ranged from 3 to 31 (or 2% to 18% of lesions analysed). The store-and-forward application had one of the highest rates of test failure (15%). At least one melanoma was classed as unevaluable in three of the four application evaluations.\n    \n\n\n          Authors' conclusions:\n        \n      \n      Smartphone applications using artificial intelligence-based analysis have not yet demonstrated sufficient promise in terms of accuracy, and they are associated with a high likelihood of missing melanomas. Applications based on store-and-forward images could have a potential role in the timely presentation of people with potentially malignant lesions by facilitating active self-management health practices and early engagement of those with suspicious skin lesions; however, they may incur a significant increase in resource and workload. Given the paucity of evidence and low methodological quality of existing studies, it is not possible to draw any implications for practice. Nevertheless, this is a rapidly advancing field, and new and better applications with robust reporting of studies could change these conclusions substantially."
        },
        {
            "title": "Teaching Benign Skin Lesions as a Strategy to Improve the Triage Amalgamated Dermoscopic Algorithm (TADA).",
            "abstract": "Introduction:\n        \n      \n      Dermoscopy aids family physicians (FPs) in skin cancer detection. The triage amalgamated dermoscopic algorithm (TADA) was created to simplify the dermoscopic evaluation of a skin growth. The purpose of this image-based study was to evaluate the effect of teaching the clinical and dermoscopic features of benign skin lesions on the diagnostic accuracy of skin cancer identification using TADA. We also sought to determine the best method to teach benign neoplasms.\n    \n\n\n          Methods:\n        \n      \n      In this cross-sectional study of an educational intervention, FPs participated in dermoscopy training. Participants were divided into 3 groups for teaching of common benign neoplasms (dermatofibroma, angioma, and seborrheic keratosis/lentigo): didactic + interactive, didactic + heuristic, and didactic. For each group, the benign teaching was followed by skin cancer identification training with TADA. All participants took a 30 image pre-test and 30 image post-test.\n    \n\n\n          Results:\n        \n      \n      Fifty-nine participants completed the study. The mean preintervention score (out of 30 correct responses) was 17.9 (SD, 4.5) and increased to 23.5 (SD, 3.0) on the postintervention evaluation (P < .001). Sensitivity for skin cancer increased from 62.5% to 88.1% following the intervention. Postintervention specificity for skin cancer was 87.8%. Sensitivity and specificity increased following the intervention for all 3 types of benign neoplasms. Diagnostic accuracy was not impacted by the method of benign teaching.\n    \n\n\n          Conclusion:\n        \n      \n      Short dermoscopy training sessions with dedicated time for benign growths followed by TADA training for malignant growths are an effective means of teaching FPs dermoscopy and result in a high sensitivity and specificity for the identification of benign and malignant skin neoplasms."
        },
        {
            "title": "Classification of Basal Cell Carcinoma in Ex Vivo Confocal Microscopy Images from Freshly Excised Tissues Using a Deep Learning Algorithm.",
            "abstract": "Ex vivo confocal microscopy (EVCM) generates digitally colored purple-pink images similar to H&E without time-consuming tissue processing. It can be used during Mohs surgery for rapid detection of basal cell carcinoma (BCC); however, reading EVCM images requires specialized training. An automated approach using a deep learning algorithm for BCC detection in EVCM images can aid in diagnosis. A total of 40 BCCs and 28 negative (not-BCC) samples were collected at Memorial Sloan Kettering Cancer Center to create three training datasets: (i) EVCM image dataset (663 images), (ii) H&E image dataset (516 images), and (iii) a combination of the two datasets. A total of seven BCCs and four negative samples were collected to create an EVCM test dataset (107 images). The model trained with the EVCM dataset achieved 92% diagnostic accuracy, similar to the H&E model (93%). The area under the receiver operator characteristic curve was 0.94, 0.95, and 0.94 for EVCM-, H&E-, and combination-trained models, respectively. We developed an algorithm for automatic BCC detection in EVCM images (comparable accuracy to dermatologists). This approach could be used to assist with BCC detection during Mohs surgery. Furthermore, we found that a model trained with only H&E images (which are more available than EVCM images) can accurately detect BCC in EVCM images."
        },
        {
            "title": "A Novel Hybrid Convolutional Neural Network Approach for the Stomach Intestinal Early Detection Cancer Subtype Classification.",
            "abstract": "There may be different types of cancer that cause fatal effects in the human body. In general, cancer is nothing but the unnatural growth of blood cells in different parts of the body and is named accordingly. It may be skin cancer, breast cancer, uterus cancer, intestinal cancer, stomach cancer, etc. However, every type of cancer consists of unwanted blood cells which cause issues in the body starting from the minor to death. Cancer cells have the common features in them, and these common features we have used in our work for the processing. Cancer has a significant death rate; however, it is frequently curable with simple surgery if detected in its early stages. A quick and correct diagnosis may be extremely beneficial to both doctors and patients. In several medical domains, the latest deep-learning-based model's performance is comparable to or even exceeds that of human specialists. We have proposed a novel methodology based on a convolutional neural network that may be used for almost all types of cancer detection. We have collected different datasets of different types of common cancer from different sources and used 90% of the sample data for the training purpose, then we reduced it by 10%, and an 80% image set was used for the validation of the model. After that for testing purposes, we fed a sample dataset and obtain the results. The final output clearly shows that the proposed model outperforms the previous model when we compared our methodology with the existing work."
        },
        {
            "title": "A study on skin tumor classification based on dense convolutional networks with fused metadata.",
            "abstract": "Skin cancer is the most common cause of death in humans. Statistics show that competent dermatologists have a diagnostic accuracy rate of less than 80%, while inexperienced dermatologists have a diagnostic accuracy rate of less than 60%. The higher rate of misdiagnosis will cause many patients to miss the most effective treatment window, risking the patients' life safety. However, the majority of the current study of neural network-based skin cancer diagnosis remains at the image level without patient clinical data. A deep convolutional network incorporating clinical patient metadata of skin cancer is presented to realize the classification model of skin cancer in order to further increase the accuracy of skin cancer diagnosis. There are three basic steps in the approach. First, the high-level features (edge features, color features, texture features, form features, etc.). Implied by the image were retrieved using the pre-trained DenseNet-169 model on the ImageNet dataset. Second, the MetaNet module is introduced, which uses metadata to control a certain portion of each feature channel in the DenseNet-169 network in order to produce weighted features. The MetaBlock module was added at the same time to improve the features retrieved from photos using metadata, choosing the most pertinent characteristics in accordance with the metadata data. The features of the MetaNet and MetaBlock modules were finally combined to create the MD-Net module, which was then used as input into the classifier to get the classification results for skin cancers. On the PAD-UFES-20 and ISIC 2019 datasets, the suggested methodology was assessed. The DenseNet-169 network model combined with this module, according to experimental data, obtains 81.4% in the balancing accuracy index, and its diagnostic accuracy is up between 8% and 15.6% compared to earlier efforts. Additionally, it solves the problem of actinic keratosis and poorly classified skin fibromas."
        },
        {
            "title": "Classification of skin cancer using convolutional neural networks analysis of Raman spectra.",
            "abstract": "Background and objective:\n        \n      \n      Skin cancer is the most common malignancy in whites accounting for about one third of all cancers diagnosed per year. Portable Raman spectroscopy setups for skin cancer \"optical biopsy\" are utilized to detect tumors based on their spectral features caused by the comparative presence of different chemical components. However, low signal-to-noise ratio in such systems may prevent accurate tumors classification. Thus, there is a challenge to develop methods for efficient skin tumors classification.\n    \n\n\n          Methods:\n        \n      \n      We compare the performance of convolutional neural networks and the projection on latent structures with discriminant analysis for discriminating skin cancer using the analysis of Raman spectra with a high autofluorescence background stimulated by a 785 nm laser. We have registered the spectra of 617 cases of skin neoplasms (615 patients, 70 melanomas, 122 basal cell carcinomas, 12 squamous cell carcinomas and 413 benign tumors) in vivo with a portable Raman setup and created classification models both for convolutional neural networks and projection on latent structures approaches. To check the classification models stability, a 10-fold cross-validation was performed for all created models. To avoid models overfitting, the data was divided into a training set (80% of spectral dataset) and a test set (20% of spectral dataset).\n    \n\n\n          Results:\n        \n      \n      The results for different classification tasks demonstrate that the convolutional neural networks significantly (p<0.01) outperforms the projection on latent structures. For the convolutional neural networks implementation we obtained ROC AUCs of 0.96 (0.94 - 0.97; 95% CI), 0.90 (0.85-0.94; 95% CI), and 0.92 (0.87 - 0.97; 95% CI) for classifying a) malignant vs benign tumors, b) melanomas vs pigmented tumors and c) melanomas vs seborrheic keratosis respectively.\n    \n\n\n          Conclusions:\n        \n      \n      The performance of the convolutional neural networks classification of skin tumors based on Raman spectra analysis is higher or comparable to the accuracy provided by trained dermatologists. The increased accuracy with the convolutional neural networks implementation is due to a more precise accounting of low intensity Raman bands in the intense autofluorescence background. The achieved high performance of skin tumors classifications with convolutional neural networks analysis opens a possibility for wide implementation of Raman setups in clinical setting."
        },
        {
            "title": "Deep neural networks are superior to dermatologists in melanoma image classification.",
            "abstract": "Background:\n        \n      \n      Melanoma is the most dangerous type of skin cancer but is curable if detected early. Recent publications demonstrated that artificial intelligence is capable in classifying images of benign nevi and melanoma with dermatologist-level precision. However, a statistically significant improvement compared with dermatologist classification has not been reported to date.\n    \n\n\n          Methods:\n        \n      \n      For this comparative study, 4204 biopsy-proven images of melanoma and nevi (1:1) were used for the training of a convolutional neural network (CNN). New techniques of deep learning were integrated. For the experiment, an additional 804 biopsy-proven dermoscopic images of melanoma and nevi (1:1) were randomly presented to dermatologists of nine German university hospitals, who evaluated the quality of each image and stated their recommended treatment (19,296 recommendations in total). Three McNemar's tests comparing the results of the CNN's test runs in terms of sensitivity, specificity and overall correctness were predefined as the main outcomes.\n    \n\n\n          Findings:\n        \n      \n      The respective sensitivity and specificity of lesion classification by the dermatologists were 67.2% (95% confidence interval [CI]: 62.6%-71.7%) and 62.2% (95% CI: 57.6%-66.9%). In comparison, the trained CNN achieved a higher sensitivity of 82.3% (95% CI: 78.3%-85.7%) and a higher specificity of 77.9% (95% CI: 73.8%-81.8%). The three McNemar's tests in 2 Ã— 2 tables all reached a significance level of p < 0.001. This significance level was sustained for both subgroups.\n    \n\n\n          Interpretation:\n        \n      \n      For the first time, automated dermoscopic melanoma image classification was shown to be significantly superior to both junior and board-certified dermatologists (p < 0.001)."
        },
        {
            "title": "Classification of Skin Cancer Lesions Using Explainable Deep Learning.",
            "abstract": "Skin cancer is among the most prevalent and life-threatening forms of cancer that occur worldwide. Traditional methods of skin cancer detection need an in-depth physical examination by a medical professional, which is time-consuming in some cases. Recently, computer-aided medical diagnostic systems have gained popularity due to their effectiveness and efficiency. These systems can assist dermatologists in the early detection of skin cancer, which can be lifesaving. In this paper, the pre-trained MobileNetV2 and DenseNet201 deep learning models are modified by adding additional convolution layers to effectively detect skin cancer. Specifically, for both models, the modification includes stacking three convolutional layers at the end of both the models. A thorough comparison proves that the modified models show their superiority over the original pre-trained MobileNetV2 and DenseNet201 models. The proposed method can detect both benign and malignant classes. The results indicate that the proposed Modified DenseNet201 model achieves 95.50% accuracy and state-of-the-art performance when compared with other techniques present in the literature. In addition, the sensitivity and specificity of the Modified DenseNet201 model are 93.96% and 97.03%, respectively."
        },
        {
            "title": "Integrating Domain Knowledge into Deep Learning for Skin Lesion Risk Prioritization to Assist Teledermatology Referral.",
            "abstract": "Teledermatology has developed rapidly in recent years and is nowadays an essential tool for early diagnosis. In this work, we aim to improve existing Teledermatology processes for skin lesion diagnosis by developing a deep learning approach for risk prioritization with a dataset of retrospective data from referral requests of the Portuguese National Health System. Given the high complexity of this task, we propose a new prioritization pipeline guided and inspired by domain knowledge. We explored automatic lesion segmentation and tested different learning schemes, namely hierarchical classification and curriculum learning approaches, optionally including additional patient metadata. The final priority level prediction can then be obtained by combining predicted diagnosis and a baseline priority level accounting for explicit expert knowledge. In both the differential diagnosis and prioritization branches, lesion segmentation with 30% tolerance for contextual information was shown to improve classification when compared with a flat baseline model trained on original images; furthermore, the addition of patient information was not beneficial for most experiments. Curriculum learning delivered better results than a flat or hierarchical approach. The combination of diagnosis information and a knowledge map, created in collaboration with dermatologists, together with the priority achieved interesting results (best macro F1 of 43.93% for a validated test set), paving the way for new data-centric and knowledge-driven approaches."
        },
        {
            "title": "Management of MDA-5 antibody-positive dermatomyositis with interstitial lung disease-an Auckland case series.",
            "abstract": "Objective:\n        \n      \n      The aim was to present our experience of managing six cases of anti-melanoma differentiation-associated gene 5 (anti-MDA-5) DM with associated interstitial lung disease (ILD), presenting between June 2017 and October 2020.\n    \n\n\n          Methods:\n        \n      \n      The electronic notes were reviewed for six patients being followed up by the Rheumatology service at Auckland District Health Board. Three patients were initially diagnosed and treated in neighbouring Counties Manukau District Health Board and later transferred to Auckland District Health Board. All had different initial treating clinicians at a time before any predefined treatment algorithm. Emphasis was placed on initial diagnosis and treatment, subsequent disease activity and changes in management. Local management was compared retrospectively with existing evidence relating to the treatment of anti-MDA-5 DM with ILD. Ethical approval was not obtained, according to the New Zealand Health and Disability Ethics Committee exemption for audits and related activities.\n    \n\n\n          Results:\n        \n      \n      Six patients with a variety of clinical presentations were identified appropriately as having anti-MDA-5 DM with ILD. They were commenced on different immunosuppressive regimens, with treatment adjusted according to response and on-going disease activity. Four have achieved clinical and biochemical remission, a fifth has improving active disease, and the sixth is in the early stages of their illness.\n    \n\n\n          Conclusion:\n        \n      \n      Anti-MDA-5 DM is commonly associated with ILD. This can be rapidly progressive, with a poor prognosis in spite of treatment, particularly among Asian patients. Disease activity can seemingly be monitored with serum ferritin. The most effective management of this condition remains poorly researched; however, increasing retrospective evidence favours early aggressive multi-agent immunosuppression and a low threshold for escalation of therapy."
        },
        {
            "title": "Development and clinical validation of a novel photography-based skin erythema evaluation system: a comparison with the calculated consensus of dermatologists.",
            "abstract": "Objective:\n        \n      \n      Erythema is the most common presenting sign in patients with skin diseases, and various methods to treat erythema symptoms have become common. To evaluate changes in erythema, a reliable device that can support objective diagnosis is required. We developed a novel photography-based system for erythema diagnosis that provides a high-resolution three-view photograph taken in a consistent photography environment with a curved surface light source and can be integrated with optimized image processing algorithms.\n    \n\n\n          Methods:\n        \n      \n      A new diagnostic algorithm was applied to photographs from 32 patients to determine areas of erythema automatically. To assess the performance in comparison to dermatologists' evaluations, five dermatologists independently evaluate the areas of erythema, and we defined an area called the clinical consensus area of erythema (CCAE), which is based on the majority opinion of dermatologists during evaluation. The CCAE values obtained were compared with the erythema areas determined by the system's diagnostic algorithm.\n    \n\n\n          Results:\n        \n      \n      Forty-one photographs with areas of erythema were evaluated by the proposed system and by dermatologists. The results obtained with the proposed system had a mean accuracy of 93.18% with a standard deviation of 3.52% when compared with the CCAE results. The results also showed that the proposed system could detect erythema areas without any pigmentation. In contrast to assessments by individual dermatologists, use of the CCAE reduced the amount of error that occurred owing to bias or subjectivity.\n    \n\n\n          Conclusion:\n        \n      \n      A new erythema evaluation system was developed and validated through CCAE, suggesting that the system can support dermatologists' objective diagnoses of erythema."
        },
        {
            "title": "Validation of artificial intelligence prediction models for skin cancer diagnosis using dermoscopy images: the 2019 International Skin Imaging Collaboration Grand Challenge.",
            "abstract": "Background:\n        \n      \n      Previous studies of artificial intelligence (AI) applied to dermatology have shown AI to have higher diagnostic classification accuracy than expert dermatologists; however, these studies did not adequately assess clinically realistic scenarios, such as how AI systems behave when presented with images of disease categories that are not included in the training dataset or images drawn from statistical distributions with significant shifts from training distributions. We aimed to simulate these real-world scenarios and evaluate the effects of image source institution, diagnoses outside of the training set, and other image artifacts on classification accuracy, with the goal of informing clinicians and regulatory agencies about safety and real-world accuracy.\n    \n\n\n          Methods:\n        \n      \n      We designed a large dermoscopic image classification challenge to quantify the performance of machine learning algorithms for the task of skin cancer classification from dermoscopic images, and how this performance is affected by shifts in statistical distributions of data, disease categories not represented in training datasets, and imaging or lesion artifacts. Factors that might be beneficial to performance, such as clinical metadata and external training data collected by challenge participants, were also evaluated. 25 331 training images collected from two datasets (in Vienna [HAM10000] and Barcelona [BCN20000]) between Jan 1, 2000, and Dec 31, 2018, across eight skin diseases, were provided to challenge participants to design appropriate algorithms. The trained algorithms were then tested for balanced accuracy against the HAM10000 and BCN20000 test datasets and data from countries not included in the training dataset (Turkey, New Zealand, Sweden, and Argentina). Test datasets contained images of all diagnostic categories available in training plus other diagnoses not included in training data (not trained category). We compared the performance of the algorithms against that of 18 dermatologists in a simulated setting that reflected intended clinical use.\n    \n\n\n          Findings:\n        \n      \n      64 teams submitted 129 state-of-the-art algorithm predictions on a test set of 8238 images. The best performing algorithm achieved 58Â·8% balanced accuracy on the BCN20000 data, which was designed to better reflect realistic clinical scenarios, compared with 82Â·0% balanced accuracy on HAM10000, which was used in a previously published benchmark. Shifted statistical distributions and disease categories not included in training data contributed to decreases in accuracy. Image artifacts, including hair, pen markings, ulceration, and imaging source institution, decreased accuracy in a complex manner that varied based on the underlying diagnosis. When comparing algorithms to expert dermatologists (2460 ratings on 1269 images), algorithms performed better than experts in most categories, except for actinic keratoses (similar accuracy on average) and images from categories not included in training data (26% correct for experts vs 6% correct for algorithms, p<0Â·0001). For the top 25 submitted algorithms, 47Â·1% of the images from categories not included in training data were misclassified as malignant diagnoses, which would lead to a substantial number of unnecessary biopsies if current state-of-the-art AI technologies were clinically deployed.\n    \n\n\n          Interpretation:\n        \n      \n      We have identified specific deficiencies and safety issues in AI diagnostic systems for skin cancer that should be addressed in future diagnostic evaluation protocols to improve safety and reliability in clinical practice.\n    \n\n\n          Funding:\n        \n      \n      Melanoma Research Alliance and La MaratÃ³ de TV3."
        },
        {
            "title": "Expert-Level Diagnosis of Nonpigmented Skin Cancer by Combined Convolutional Neural Networks.",
            "abstract": "Importance:\n        \n      \n      Convolutional neural networks (CNNs) achieve expert-level accuracy in the diagnosis of pigmented melanocytic lesions. However, the most common types of skin cancer are nonpigmented and nonmelanocytic, and are more difficult to diagnose.\n    \n\n\n          Objective:\n        \n      \n      To compare the accuracy of a CNN-based classifier with that of physicians with different levels of experience.\n    \n\n\n          Design, setting, and participants:\n        \n      \n      A CNN-based classification model was trained on 7895 dermoscopic and 5829 close-up images of lesions excised at a primary skin cancer clinic between January 1, 2008, and July 13, 2017, for a combined evaluation of both imaging methods. The combined CNN (cCNN) was tested on a set of 2072 unknown cases and compared with results from 95 human raters who were medical personnel, including 62 board-certified dermatologists, with different experience in dermoscopy.\n    \n\n\n          Main outcomes and measures:\n        \n      \n      The proportions of correct specific diagnoses and the accuracy to differentiate between benign and malignant lesions measured as an area under the receiver operating characteristic curve served as main outcome measures.\n    \n\n\n          Results:\n        \n      \n      Among 95 human raters (51.6% female; mean age, 43.4 years; 95% CI, 41.0-45.7 years), the participants were divided into 3 groups (according to years of experience with dermoscopy): beginner raters (<3 years), intermediate raters (3-10 years), or expert raters (>10 years). The area under the receiver operating characteristic curve of the trained cCNN was higher than human ratings (0.742; 95% CI, 0.729-0.755 vs 0.695; 95% CI, 0.676-0.713; P < .001). The specificity was fixed at the mean level of human raters (51.3%), and therefore the sensitivity of the cCNN (80.5%; 95% CI, 79.0%-82.1%) was higher than that of human raters (77.6%; 95% CI, 74.7%-80.5%). The cCNN achieved a higher percentage of correct specific diagnoses compared with human raters (37.6%; 95% CI, 36.6%-38.4% vs 33.5%; 95% CI, 31.5%-35.6%; P = .001) but not compared with experts (37.3%; 95% CI, 35.7%-38.8% vs 40.0%; 95% CI, 37.0%-43.0%; P = .18).\n    \n\n\n          Conclusions and relevance:\n        \n      \n      Neural networks are able to classify dermoscopic and close-up images of nonpigmented lesions as accurately as human experts in an experimental setting."
        },
        {
            "title": "Hyperspectral imaging in automated digital dermoscopy screening for melanoma.",
            "abstract": "Objectives:\n        \n      \n      Early melanoma detection decreases morbidity and mortality. Early detection classically involves dermoscopy to identify suspicious lesions for which biopsy is indicated. Biopsy and histological examination then diagnose benign nevi, atypical nevi, or cancerous growths. With current methods, a considerable number of unnecessary biopsies are performed as only 11% of all biopsied, suspicious lesions are actually melanomas. Thus, there is a need for more advanced noninvasive diagnostics to guide the decision of whether or not to biopsy. Artificial intelligence can generate screening algorithms that transform a set of imaging biomarkers into a risk score that can be used to classify a lesion as a melanoma or a nevus by comparing the score to a classification threshold. Melanoma imaging biomarkers have been shown to be spectrally dependent in Red, Green, Blue (RGB) color channels, and hyperspectral imaging may further enhance diagnostic power. The purpose of this study was to use the same melanoma imaging biomarkers previously described, but over a wider range of wavelengths to determine if, in combination with machine learning algorithms, this could result in enhanced melanoma detection.\n    \n\n\n          Methods:\n        \n      \n      We used the melanoma advanced imaging dermatoscope (mAID) to image pigmented lesions assessed by dermatologists as requiring a biopsy. The mAID is a 21-wavelength imaging device in the 350-950 nm range. We then generated imaging biomarkers from these hyperspectral dermoscopy images, and, with the help of artificial intelligence algorithms, generated a melanoma Q-score for each lesion (0 = nevus, 1 = melanoma). The Q-score was then compared to the histopathologic diagnosis.\n    \n\n\n          Results:\n        \n      \n      The overall sensitivity and specificity of hyperspectral dermoscopy in detecting melanoma when evaluated in a set of lesions selected by dermatologists as requiring biopsy was 100% and 36%, respectively.\n    \n\n\n          Conclusion:\n        \n      \n      With widespread application, and if validated in larger clinical trials, this non-invasive methodology could decrease unnecessary biopsies and potentially increase life-saving early detection events. Lasers Surg. Med. 51:214-222, 2019. Â© 2019 The Authors. Lasers in Surgery and Medicine Published by Wiley Periodicals, Inc."
        },
        {
            "title": "Predicting melanoma survival and metastasis with interpretable histopathological features and machine learning models.",
            "abstract": "Introduction:\n        \n      \n      Melanoma is the fifth most common cancer in US, and the incidence is increasing 1.4% annually. The overall survival rate for early-stage disease is 99.4%. However, melanoma can recur years later (in the same region of the body or as distant metastasis), and results in a dramatically lower survival rate. Currently there is no reliable method to predict tumor recurrence and metastasis on early primary tumor histological images.\n    \n\n\n          Methods:\n        \n      \n      To identify rapid, accurate, and cost-effective predictors of metastasis and survival, in this work, we applied various interpretable machine learning approaches to analyze melanoma histopathological H&E images. The result is a set of image features that can help clinicians identify high-risk-of-metastasis patients for increased clinical follow-up and precision treatment. We use simple models (i.e., logarithmic classification and KNN) and \"human-interpretable\" measures of cell morphology and tissue architecture (e.g., cell size, staining intensity, and cell density) to predict the melanoma survival on public and local Stage I-III cohorts as well as the metastasis risk on a local cohort.\n    \n\n\n          Results:\n        \n      \n      We use penalized survival regression to limit features available to downstream classifiers and investigate the utility of convolutional neural networks in isolating tumor regions to focus morphology extraction on only the tumor region. This approach allows us to predict survival and metastasis with a maximum F1 score of 0.72 and 0.73, respectively, and to visualize several high-risk cell morphologies.\n    \n\n\n          Discussion:\n        \n      \n      This lays the foundation for future work, which will focus on using our interpretable pipeline to predict metastasis in Stage I & II melanoma."
        },
        {
            "title": "Human-computer collaboration for skin cancer recognition.",
            "abstract": "The rapid increase in telemedicine coupled with recent advances in diagnostic artificial intelligence (AI) create the imperative to consider the opportunities and risks of inserting AI-based support into new paradigms of care. Here we build on recent achievements in the accuracy of image-based AI for skin cancer diagnosis to address the effects of varied representations of AI-based support across different levels of clinical expertise and multiple clinical workflows. We find that good quality AI-based support of clinical decision-making improves diagnostic accuracy over that of either AI or physicians alone, and that the least experienced clinicians gain the most from AI-based support. We further find that AI-based multiclass probabilities outperformed content-based image retrieval (CBIR) representations of AI in the mobile technology environment, and AI-based support had utility in simulations of second opinions and of telemedicine triage. In addition to demonstrating the potential benefits associated with good quality AI in the hands of non-expert clinicians, we find that faulty AI can mislead the entire spectrum of clinicians, including experts. Lastly, we show that insights derived from AI class-activation maps can inform improvements in human diagnosis. Together, our approach and findings offer a framework for future studies across the spectrum of image-based diagnostics to improve human-computer collaboration in clinical practice."
        },
        {
            "title": "Development of a light-weight deep learning model for cloud applications and remote diagnosis of skin cancers.",
            "abstract": "Skin cancer is among the 10 most common cancers. Recent research revealed the superiority of artificial intelligence (AI) over dermatologists to diagnose skin cancer from predesignated and cropped images. However, there remain several uncertainties for AI in diagnosing skin cancers, including lack of testing for consistency, lack of pathological proof or ambiguous comparisons. Hence, to develop a reliable, feasible and user-friendly platform to facilitate the automatic diagnostic algorithm is important. The aim of this study was to build a light-weight skin cancer classification model based on deep learning methods for aiding first-line medical care. The developed model can be deployed on cloud platforms as well as mobile devices for remote diagnostic applications. We reviewed the medical records and clinical images of patients who received a histological diagnosis of basal cell carcinoma, squamous cell carcinoma, melanoma, seborrheic keratosis and melanocytic nevus in 2006-2017 in the Department of Dermatology in Kaohsiung Chang Gung Memorial Hospital (KCGMH). We used the deep learning models to identify skin cancers and benign skin tumors in the manner of binary classification and multi-class classification in the KCGMH and HAM10000 datasets to construct a skin cancer classification model. The accuracy reached 89.5% for the binary classifications (benign vs malignant) in the KCGMH dataset; the accuracy was 85.8% in the HAM10000 dataset in seven-class classification and 72.1% in the KCGMH dataset in five-class classification. Our results demonstrate that our skin cancer classification model based on deep learning methods is a highly promising aid for the clinical diagnosis and early identification of skin cancers and benign tumors."
        },
        {
            "title": "Efficacy of smartphone applications in high-risk pigmented lesions.",
            "abstract": "Background/objectives:\n        \n      \n      Melanoma apps are smartphone applications that assess risk of pigmented lesions using a smartphone camera and underlying algorithm. We aimed to assess the capability of melanoma smartphone applications (apps) in making clinical decisions about risk, compared with lesion assessment by specialist trained dermatologists.\n    \n\n\n          Methods:\n        \n      \n      A prospective study of 3 melanoma apps was conducted between 2015 and 2016, recruiting 30 patients with 57 pigmented lesions. Risk categories assigned by the apps were compared with the clinical decisions of two consultant dermatologists classifying lesions as 'suspicious' or 'benign'.\n    \n\n\n          Results:\n        \n      \n      Of the 42 lesions deemed clinically suspicious to a dermatologist, from 9 to 26 were classified as suspicious by the apps; of the 15 clinically benign lesions 3 to 15 were correctly classified as benign by the apps. The apps' sensitivity and specificity ranged from 21 to 72% and 27 to 100.0%, respectively, when compared with the specialists' decisions. Two apps were unable to analyse 14 and 18% of lesions submitted, respectively. Interrater agreement between dermatologists and apps was poor (Îº = -0.01 SE = 0.16; P = 0.97) to slight (Îº = 0.16 SE = 0.09; P = 0.12).\n    \n\n\n          Conclusions:\n        \n      \n      None of the melanoma apps tested had high enough agreement with the dermatologist's clinical opinion to be considered to provide additional benefit to patients in assessing their skin for high-risk pigmented lesions. The low sensitivity in detecting lesions that are suspicious to a trained specialist may mean false reassurance is being given to patients. Development of highly sensitive and specific melanoma apps remains a work in progress."
        },
        {
            "title": "[Estimated Effect of COVID-19 Lockdown on Skin Tumor Size and Survival: An Exponential Growth Model].",
            "abstract": "Background and objectives:\n        \n      \n      Spain is in a situation of indefinite lockdown due to the ongoing coronavirus disease 2019 (COVID-19) pandemic. One of the consequences of this lockdown is delays in medical and surgical procedures for common diseases. The aim of this study was to model the impact on survival of tumor growth caused by such delays in patients with squamous cell carcinoma (SCC) and melanoma.\n    \n\n\n          Material and methods:\n        \n      \n      Multicenter, retrospective, observational cohort study. We constructed an exponential growth model for both SCC and melanoma to estimate tumor growth between patient-reported onset and surgical excision at different time points.\n    \n\n\n          Results:\n        \n      \n      Data from 200 patients with SCC of the head and neck and 1000 patients with cutaneous melanoma were included. An exponential growth curve was calculated for each tumor type and we estimated tumor size after 1, 2, and 3 months of potential surgical delay. The proportion of patients with T3 SCC (diameter >4cm or thickness >6 mm) increased from 41.5% (83 patients) in the initial study group to an estimated 58.5%, 70.5%, and 72% after 1, 2, and 3 months of delay. Disease-specific survival at 2, 5, and 10 years in patients whose surgery was delayed by 3 months decreased by 6.2%, 8.2%, and 5.2%, respectively. The proportion of patients with ultrathick melanoma (>6 mm) increased from 6.9% in the initial study group to 21.9%, 30.2%, and 30.2% at 1, 2, and 3 months. Five- and 10-year disease-specific survival both decreased by 14.4% in patients treated after a potential delay of 3 months.\n    \n\n\n          Conclusions:\n        \n      \n      In the absence of adequate diagnosis and treatment of SCC and melanoma in the current lockdown situation in Spain, we can expect to see to a considerable increase in large and thick SCCs and melanomas. Efforts must be taken to encourage self-examination and facilitate access to dermatologists in order to prevent further delays."
        },
        {
            "title": "PRiMeUM: A Model for Predicting Risk of Metastasis in Uveal Melanoma.",
            "abstract": "Purpose:\n        \n      \n      To create an interactive web-based tool for the Prediction of Risk of Metastasis in Uveal Melanoma (PRiMeUM) that can provide a personalized risk estimate of developing metastases within 48 months of primary uveal melanoma (UM) treatment. The model utilizes routinely collected clinical and tumor characteristics on 1227 UM, with the option of including chromosome information when available.\n    \n\n\n          Methods:\n        \n      \n      Using a cohort of 1227 UM cases, Cox proportional hazard modeling was used to assess significant predictors of metastasis including clinical and chromosomal characteristics. A multivariate model to predict risk of metastasis was evaluated using machine learning methods including logistic regression, decision trees, survival random forest, and survival-based regression models. Based on cross-validation results, a logistic regression classifier was developed to compute an individualized risk of metastasis based on clinical and chromosomal information.\n    \n\n\n          Results:\n        \n      \n      The PRiMeUM model provides prognostic information for personalized risk of metastasis in UM. The accuracy of the risk prediction ranged between 80% (using chromosomal features only), 83% using clinical features only (age, sex, tumor location, and size), and 85% (clinical and chromosomal information). Kaplan-Meier analysis showed these risk scores to be highly predictive of metastasis (P < 0.0001).\n    \n\n\n          Conclusions:\n        \n      \n      PRiMeUM provides a tool for predicting an individual's personal risk of metastasis based on their individual and tumor characteristics. It will aid physicians with decisions concerning frequency of systemic surveillance and can be used as a criterion for entering clinical trials for adjuvant therapies."
        },
        {
            "title": "Enhanced classifier training to improve precision of a convolutional neural network to identify images of skin lesions.",
            "abstract": "Background:\n        \n      \n      In recent months, multiple publications have demonstrated the use of convolutional neural networks (CNN) to classify images of skin cancer as precisely as dermatologists. However, these CNNs failed to outperform the International Symposium on Biomedical Imaging (ISBI) 2016 challenge which ranked the average precision for classification of dermoscopic melanoma images. Accordingly, the technical progress represented by these studies is limited. In addition, the available reports are impossible to reproduce, due to incomplete descriptions of training procedures and the use of proprietary image databases or non-disclosure of used images. These factors prevent the comparison of various CNN classifiers in equal terms.\n    \n\n\n          Objective:\n        \n      \n      To demonstrate the training of an image-classifier CNN that outperforms the winner of the ISBI 2016 CNNs challenge by using open source images exclusively.\n    \n\n\n          Methods:\n        \n      \n      A detailed description of the training procedure is reported while the used images and test sets are disclosed fully, to insure the reproducibility of our work.\n    \n\n\n          Results:\n        \n      \n      Our CNN classifier outperforms all recent attempts to classify the original ISBI 2016 challenge test data (full set of 379 test images), with an average precision of 0.709 (vs. 0.637 of the ISBI winner) and with an area under the receiver operating curve of 0.85.\n    \n\n\n          Conclusion:\n        \n      \n      This work illustrates the potential for improving skin cancer classification with enhanced training procedures for CNNs, while avoiding the use of costly equipment or proprietary image data."
        },
        {
            "title": "Artificial Intelligence in Hair and Nail Disorders.",
            "abstract": "Artificial intelligence (AI), a field of computer science, aims at simulating human intelligence with computers. Though AI has surpassed dermatologists in skin cancer detection, it still lags behind various other specialties like radiologists in broader adoption. Newer AI applications are becoming increasingly accessible. AI plays a role in various areas, such as medical image recognition, auxiliary diagnosis, and drug research and development. Dermatology has a prime position in implementation of AI in medical research due to its larger clinical, dermoscopic, and histopathological image database. Hence, it is crucial to consider the potential and emerging role of AI in dermatology clinical practice. There are already studies focusing on various skin disorders like cancer, psoriasis, atopic dermatitis, etc. This article provides an overview of AI and its applications in hair and nail disorders at present and its future potential. J Drugs Dermatol. 2022;21(10):1049-1052. doi:10.36849/JDD.6519."
        },
        {
            "title": "Dermoscopy, with and without visual inspection, for diagnosing melanoma in adults.",
            "abstract": "Background:\n        \n      \n      Melanoma has one of the fastest rising incidence rates of any cancer. It accounts for a small percentage of skin cancer cases but is responsible for the majority of skin cancer deaths. Although history-taking and visual inspection of a suspicious lesion by a clinician are usually the first in a series of 'tests' to diagnose skin cancer, dermoscopy has become an important tool to assist diagnosis by specialist clinicians and is increasingly used in primary care settings. Dermoscopy is a magnification technique using visible light that allows more detailed examination of the skin compared to examination by the naked eye alone. Establishing the additive value of dermoscopy over and above visual inspection alone across a range of observers and settings is critical to understanding its contribution for the diagnosis of melanoma and to future understanding of the potential role of the growing number of other high-resolution image analysis techniques.\n    \n\n\n          Objectives:\n        \n      \n      To determine the diagnostic accuracy of dermoscopy alone, or when added to visual inspection of a skin lesion, for the detection of cutaneous invasive melanoma and atypical intraepidermal melanocytic variants in adults. We separated studies according to whether the diagnosis was recorded face-to-face (in-person), or based on remote (image-based), assessment.\n    \n\n\n          Search methods:\n        \n      \n      We undertook a comprehensive search of the following databases from inception up to August 2016: CENTRAL; MEDLINE; Embase; CINAHL; CPCI; Zetoc; Science Citation Index; US National Institutes of Health Ongoing Trials Register; NIHR Clinical Research Network Portfolio Database; and the World Health Organization International Clinical Trials Registry Platform. We studied reference lists and published systematic review articles.\n    \n\n\n          Selection criteria:\n        \n      \n      Studies of any design that evaluated dermoscopy in adults with lesions suspicious for melanoma, compared with a reference standard of either histological confirmation or clinical follow-up. Data on the accuracy of visual inspection, to allow comparisons of tests, was included only if reported in the included studies of dermoscopy.\n    \n\n\n          Data collection and analysis:\n        \n      \n      Two review authors independently extracted all data using a standardised data extraction and quality assessment form (based on QUADAS-2). We contacted authors of included studies where information related to the target condition or diagnostic threshold were missing. We estimated accuracy using hierarchical summary receiver operating characteristic (SROC),methods. Analysis of studies allowing direct comparison between tests was undertaken. To facilitate interpretation of results, we computed values of sensitivity at the point on the SROC curve with 80% fixed specificity and values of specificity with 80% fixed sensitivity. We investigated the impact of in-person test interpretation; use of a purposely developed algorithm to assist diagnosis; observer expertise; and dermoscopy training.\n    \n\n\n          Main results:\n        \n      \n      We included a total of 104 study publications reporting on 103 study cohorts with 42,788 lesions (including 5700 cases), providing 354 datasets for dermoscopy. The risk of bias was mainly low for the index test and reference standard domains and mainly high or unclear for participant selection and participant flow. Concerns regarding the applicability of study findings were largely scored as 'high' concern in three of four domains assessed. Selective participant recruitment, lack of reproducibility of diagnostic thresholds and lack of detail on observer expertise were particularly problematic.The accuracy of dermoscopy for the detection of invasive melanoma or atypical intraepidermal melanocytic variants was reported in 86 datasets; 26 for evaluations conducted in person (dermoscopy added to visual inspection), and 60 for image-based evaluations (diagnosis based on interpretation of dermoscopic images). Analyses of studies by prior testing revealed no obvious effect on accuracy; analyses were hampered by the lack of studies in primary care, lack of relevant information and the restricted inclusion of lesions selected for biopsy or excision. Accuracy was higher for in-person diagnosis compared to image-based evaluations (relative diagnostic odds ratio (RDOR) 4.6, 95% confidence interval (CI) 2.4 to 9.0; P < 0.001).We compared accuracy for (a), in-person evaluations of dermoscopy (26 evaluations; 23,169 lesions and 1664 melanomas),versus visual inspection alone (13 evaluations; 6740 lesions and 459 melanomas), and for (b), image-based evaluations of dermoscopy (60 evaluations; 13,475 lesions and 2851 melanomas),versus image-based visual inspection (11 evaluations; 1740 lesions and 305 melanomas). For both comparisons, meta-analysis found dermoscopy to be more accurate than visual inspection alone, with RDORs of (a), 4.7 (95% CI 3.0 to 7.5; P < 0.001), and (b), 5.6 (95% CI 3.7 to 8.5; P < 0.001). For a), the predicted difference in sensitivity at a fixed specificity of 80% was 16% (95% CI 8% to 23%; 92% for dermoscopy + visual inspection versus 76% for visual inspection), and predicted difference in specificity at a fixed sensitivity of 80% was 20% (95% CI 7% to 33%; 95% for dermoscopy + visual inspection versus 75% for visual inspection). For b) the predicted differences in sensitivity was 34% (95% CI 24% to 46%; 81% for dermoscopy versus 47% for visual inspection), at a fixed specificity of 80%, and predicted difference in specificity was 40% (95% CI 27% to 57%; 82% for dermoscopy versus 42% for visual inspection), at a fixed sensitivity of 80%.Using the median prevalence of disease in each set of studies ((a), 12% for in-person and (b), 24% for image-based), for a hypothetical population of 1000 lesions, an increase in sensitivity of (a), 16% (in-person), and (b), 34% (image-based), from using dermoscopy at a fixed specificity of 80% equates to a reduction in the number of melanomas missed of (a), 19 and (b), 81 with (a), 176 and (b), 152 false positive results. An increase in specificity of (a), 20% (in-person), and (b), 40% (image-based), at a fixed sensitivity of 80% equates to a reduction in the number of unnecessary excisions from using dermoscopy of (a), 176 and (b), 304 with (a), 24 and (b), 48 melanomas missed.The use of a named or published algorithm to assist dermoscopy interpretation (as opposed to no reported algorithm or reported use of pattern analysis), had no significant impact on accuracy either for in-person (RDOR 1.4, 95% CI 0.34 to 5.6; P = 0.17), or image-based (RDOR 1.4, 95% CI 0.60 to 3.3; P = 0.22), evaluations. This result was supported by subgroup analysis according to algorithm used. We observed higher accuracy for observers reported as having high experience and for those classed as 'expert consultants' in comparison to those considered to have less experience in dermoscopy, particularly for image-based evaluations. Evidence for the effect of dermoscopy training on test accuracy was very limited but suggested associated improvements in sensitivity.\n    \n\n\n          Authors' conclusions:\n        \n      \n      Despite the observed limitations in the evidence base, dermoscopy is a valuable tool to support the visual inspection of a suspicious skin lesion for the detection of melanoma and atypical intraepidermal melanocytic variants, particularly in referred populations and in the hands of experienced users. Data to support its use in primary care are limited, however, it may assist in triaging suspicious lesions for urgent referral when employed by suitably trained clinicians. Formal algorithms may be of most use for dermoscopy training purposes and for less expert observers, however reliable data comparing approaches using dermoscopy in person are lacking."
        },
        {
            "title": "S1 Guidelines -Â Dermatoses associated with dermal lymphostasis.",
            "abstract": "The objective of the present S1 guidelines is to present current knowledge about dermatologically relevant diseases associated with localized dermal lymphostasis, thus facilitating their early detection, diagnostic workup, and targeted treatment. Whenever possible, treatment should be based on stage-appropriate and clearly defined algorithms. The numerous issues regarding differential diagnosis and treatment clinicians are confronted with in everyday clinical practice seem to warrant the publication of up-to-date guidelines. These guidelines focus on patients of all age groups and genders exhibiting skin lesions caused by dermal lymphostasis. Specific recommendations are provided with respect to the diagnosis and differential diagnosis of the various clinical manifestations. In this context, comorbid skin diseases such as atopic dermatitis, psoriasis, hidradenitis suppurativa, urticaria, and contact dermatitis will be highlighted, including their treatment and associated specific risks. Several other relevant current guidelines are referenced as regards the distinction from and treatment of common cofactors and comorbid conditions."
        },
        {
            "title": "Assistant Diagnosis of Basal Cell Carcinoma and Seborrheic Keratosis in Chinese Population Using Convolutional Neural Network.",
            "abstract": "Objectives:\n        \n      \n      To evaluate CNN models' performance of identifying the clinical images of basal cell carcinoma (BCC) and seborrheic keratosis (SK) and to compare their performance with that of dermatologists.\n    \n\n\n          Methods:\n        \n      \n      We constructed a Chinese skin diseases dataset which includes 1456 BCC and 1843 SK clinical images and the corresponding medical history. We evaluated the performance using four mainstream CNN structures and transfer learning techniques. We explored the interpretability of the CNN model and compared its performance with that of 21 dermatologists.\n    \n\n\n          Results:\n        \n      \n      The fine-tuned InceptionResNetV2 achieved the best performance, with an accuracy and area under the curve of 0.855 and 0.919, respectively. Further experimental results suggested that the CNN model was not only interpretable but also had a performance comparable to that of dermatologists.\n    \n\n\n          Conclusions:\n        \n      \n      This study is the first on the assistant diagnosis of BCC and SK based on the proposed dataset. The promising results suggested that CNN model's performance was comparable to that of expert dermatologists."
        },
        {
            "title": "Diagnostic capacity of skin tumor artificial intelligence-assisted decision-making software in real-world clinical settings.",
            "abstract": "Background:\n        \n      \n      Youzhi artificial intelligence (AI) software is the AI-assisted decision-making system for diagnosing skin tumors. The high diagnostic accuracy of Youzhi AI software was previously validated in specific datasets. The objective of this study was to compare the performance of diagnostic capacity between Youzhi AI software and dermatologists in real-world clinical settings.\n    \n\n\n          Methods:\n        \n      \n      A total of 106 patients who underwent skin tumor resection in the Dermatology Department of China-Japan Friendship Hospital from July 2017 to June 2019 and were confirmed as skin tumors by pathological biopsy were selected. Dermoscopy and clinical images of 106 patients were diagnosed by Youzhi AI software and dermatologists at different dermoscopy diagnostic levels. The primary outcome was to compare the diagnostic accuracy of the Youzhi AI software with that of dermatologists and that measured in the laboratory using specific data sets. The secondary results included the sensitivity, specificity, positive predictive value, negative predictive value, F-measure, and Matthews correlation coefficient of Youzhi AI software in the real-world.\n    \n\n\n          Results:\n        \n      \n      The diagnostic accuracy of Youzhi AI software in real-world clinical settings was lower than that of the laboratory data (P < 0.001). The output result of Youzhi AI software has good stability after several tests. Youzhi AI software diagnosed benign and malignant diseases by recognizing dermoscopic images and diagnosed disease types with higher diagnostic accuracy than by recognizing clinical images (P = 0.008, P = 0.016, respectively). Compared with dermatologists, Youzhi AI software was more accurate in the diagnosis of skin tumor types through the recognition of dermoscopic images (P = 0.01). By evaluating the diagnostic performance of dermatologists under different modes, the diagnostic accuracy of dermatologists in diagnosing disease types by matching dermoscopic and clinical images was significantly higher than that by identifying dermoscopic and clinical images in random sequence (P = 0.022). The diagnostic accuracy of dermatologists in the diagnosis of benign and malignant diseases by recognizing dermoscopic images was significantly higher than that by recognizing clinical images (P = 0.010).\n    \n\n\n          Conclusion:\n        \n      \n      The diagnostic accuracy of Youzhi AI software for skin tumors in real-world clinical settings was not as high as that of using special data sets in the laboratory. However, there was no significant difference between the diagnostic capacity of Youzhi AI software and the average diagnostic capacity of dermatologists. It can provide assistant diagnostic decisions for dermatologists in the current state."
        },
        {
            "title": "A Novel Convolutional Neural Network for the Diagnosis and Classification of Rosacea: Usability Study.",
            "abstract": "Background:\n        \n      \n      Rosacea is a chronic inflammatory disease with variable clinical presentations, including transient flushing, fixed erythema, papules, pustules, and phymatous changes on the central face. Owing to the diversity in the clinical manifestations of rosacea, the lack of objective biochemical examinations, and nonspecificity in histopathological findings, accurate identification of rosacea is a big challenge. Artificial intelligence has emerged as a potential tool in the identification and evaluation of some skin diseases such as melanoma, basal cell carcinoma, and psoriasis.\n    \n\n\n          Objective:\n        \n      \n      The objective of our study was to utilize a convolutional neural network (CNN) to differentiate the clinical photos of patients with rosacea (taken from 3 different angles) from those of patients with other skin diseases such as acne, seborrheic dermatitis, and eczema that could be easily confused with rosacea.\n    \n\n\n          Methods:\n        \n      \n      In this study, 24,736 photos comprising of 18,647 photos of patients with rosacea and 6089 photos of patients with other skin diseases such as acne, facial seborrheic dermatitis, and eczema were included and analyzed by our CNN model based on ResNet-50.\n    \n\n\n          Results:\n        \n      \n      The CNN in our study achieved an overall accuracy and precision of 0.914 and 0.898, with an area under the receiver operating characteristic curve of 0.972 for the detection of rosacea. The accuracy of classifying 3 subtypes of rosacea, that is, erythematotelangiectatic rosacea, papulopustular rosacea, and phymatous rosacea was 83.9%, 74.3%, and 80.0%, respectively. Moreover, the accuracy and precision of our CNN to distinguish rosacea from acne reached 0.931 and 0.893, respectively. For the differentiation between rosacea, seborrheic dermatitis, and eczema, the overall accuracy of our CNN was 0.757 and the precision was 0.667. Finally, by comparing the CNN diagnosis with the diagnoses by dermatologists of different expertise levels, we found that our CNN system is capable of identifying rosacea with a performance superior to that of resident doctors or attending physicians and comparable to that of experienced dermatologists.\n    \n\n\n          Conclusions:\n        \n      \n      The findings of our study showed that by assessing clinical images, the CNN system in our study could identify rosacea with accuracy and precision comparable to that of an experienced dermatologist."
        },
        {
            "title": "Point-of-care, multispectral, smartphone-based dermascopes for dermal lesion screening and erythema monitoring.",
            "abstract": "Significance:\n        \n      \n      The rates of melanoma and nonmelanoma skin cancer are rising across the globe. Due to a shortage of board-certified dermatologists, the burden of dermal lesion screening and erythema monitoring has fallen to primary care physicians (PCPs). An adjunctive device for lesion screening and erythema monitoring would be beneficial because PCPs are not typically extensively trained in dermatological care.\n    \n\n\n          Aim:\n        \n      \n      We aim to examine the feasibility of using a smartphone-camera-based dermascope and a USB-camera-based dermascope utilizing polarized white-light imaging (PWLI) and polarized multispectral imaging (PMSI) to map dermal chromophores and erythema.\n    \n\n\n          Approach:\n        \n      \n      Two dermascopes integrating LED-based PWLI and PMSI with both a smartphone-based camera and a USB-connected camera were developed to capture images of dermal lesions and erythema. Image processing algorithms were implemented to provide chromophore concentrations and redness measures.\n    \n\n\n          Results:\n        \n      \n      PWLI images were successfully converted to an alternate colorspace for erythema measures, and the spectral bandwidth of the PMSI LED illumination was sufficient for mapping of deoxyhemoglobin, oxyhemoglobin, and melanin chromophores. Both types of dermascopes were able to achieve similar relative concentration results.\n    \n\n\n          Conclusion:\n        \n      \n      Chromophore mapping and erythema monitoring are feasible with PWLI and PMSI using LED illumination and smartphone-based cameras. These systems can provide a simpler, more portable geometry and reduce device costs compared with interference-filter-based or spectrometer-based clinical-grade systems. Future research should include a rigorous clinical trial to collect longitudinal data and a large enough dataset to train and implement a machine learning-based image classifier."
        },
        {
            "title": "Medical Image Classification Using Transfer Learning and Chaos Game Optimization on the Internet of Medical Things.",
            "abstract": "The Internet of Medical Things (IoMT) has dramatically benefited medical professionals that patients and physicians can access from all regions. Although the automatic detection and prediction of diseases such as melanoma and leukemia is still being investigated and studied in IoMT, existing approaches are not able to achieve a high degree of efficiency. Thus, with a new approach that provides better results, patients would access the adequate treatments earlier and the death rate would be reduced. Therefore, this paper introduces an IoMT proposal for medical images' classification that may be used anywhere, i.e., it is an ubiquitous approach. It was designed in two stages: first, we employ a transfer learning (TL)-based method for feature extraction, which is carried out using MobileNetV3; second, we use the chaos game optimization (CGO) for feature selection, with the aim of excluding unnecessary features and improving the performance, which is key in IoMT. Our methodology was evaluated using ISIC-2016, PH2, and Blood-Cell datasets. The experimental results indicated that the proposed approach obtained an accuracy of 88.39% on ISIC-2016, 97.52% on PH2, and 88.79% on Blood-cell datsets. Moreover, our approach had successful performances for the metrics employed compared to other existing methods."
        },
        {
            "title": "Artificial intelligence for melanoma diagnosis.",
            "abstract": "Convolutional neural networks (CNN) have shown unprecedented accuracy in digital image analysis, which can be harnessed for melanoma recognition through automated evaluation of clinical and dermatoscopic images. In experimental studies, modern CNN architectures perform single image analysis at the level of dermatologists and domain-experts, also for multiclass predictions including a multitude of possible diagnoses. This may not necessarily translate to good clinical performance, and reliable randomized controlled prospective clinical trials for modern CNNs are essentially missing. Weaknesses of CNNs are that limitations of available training image datasets propagate to limitations of CNN predictions, and they cannot provide a reliable estimate of uncertainty. Recent research focuses on human-computer collaboration, where gains in accuracy were measured even with imperfect CNNs. With missing academic and clinical agreement on equivocal melanocytic lesions, fully automating histologic assessment of them with CNNs appear problematic, and applications in the near future are probably limited to supporting, referencing or recommendation roles."
        },
        {
            "title": "Untangling Classification Methods for Melanoma Skin Cancer.",
            "abstract": "Skin cancer is the most common cancer in the USA, and it is a leading cause of death worldwide. Every year, more than five million patients are newly diagnosed in the USA. The deadliest and most serious form of skin cancer is called melanoma. Skin cancer can affect anyone, regardless of skin color, race, gender, and age. The diagnosis of melanoma has been done by visual examination and manual techniques by skilled doctors. It is a time-consuming process and highly prone to error. The skin images captured by dermoscopy eliminate the surface reflection of skin and give a better visualization of deeper levels of the skin. However, the existence of many artifacts and noise such as hair, veins, and water residue make the lesion images very complex. Due to the complexity of images, the border detection, feature extraction, and classification process are challenging. Without a proper mechanism, it is hard to identify and predict melanoma at an early stage. Therefore, there is a need to provide precise details, identify early skin cancer, and classify skin cancer with appropriate sensitivity and precision. This article aims to review and analyze two deep neural network-based classification algorithms (convolutional neural network, CNN; recurrent neural network, RNN) and a decision tree-based algorithm (XG-Boost) on skin lesion images (ISIC dataset) and find which of these provides the best classification performance metric. Also, the performance of algorithms is compared using six different metrics-loss, accuracy, precision, recall, F1 score, and ROC."
        },
        {
            "title": "Validation of an integrated dermoscopic scoring method in an European teledermoscopy web platform: the iDScore project for early detection of melanoma.",
            "abstract": "Background:\n        \n      \n      Although live and teledermoscopic examination has been successfully used to achieve non-invasive diagnosis of melanocytic skin lesions (MSLs), early melanoma (EM) and atypical nevi (AN) continue to be a challenge, and none of the various algorithms proposed have been sufficiently accurate. We designed a scoring classifier diagnostic method, the iDScore that combines clinical data of the patient with dermoscopic features of the MSL.\n    \n\n\n          Objective:\n        \n      \n      To test the accuracy of the iDScore in differentiating EM from AN in a teledermoscopy setting and to compare it with intuitive diagnosis, the ABCD rule and the seven-point checklist.\n    \n\n\n          Materials and methods:\n        \n      \n      A dedicated teledermoscopy web platform was designed. This involved the following: (i) collecting a large integrated clinical-historical-dermoscopic data set of difficult MSLs from eight European dermatology centres; (ii) online testing, education and training in using the iDScore. A total of 904 images were combined with age, sex, lesion diameter and body site data and evaluated on the platform by 111 participants with four levels of skill in dermoscopy. Each testing session consisted of 30 blind cases to examine consecutively by the above four methods. 'Management decisions' and personal participant data were also recorded.\n    \n\n\n          Results:\n        \n      \n      iDScore-aided diagnosis achieved satisfactory diagnostic accuracy for all lesions, irrespective of centre of affiliation, showing an average AUC of 0.776 in all participant testing sessions. All skill groups improved their accuracy by 10-16% with respect to intuitive diagnosis and the other methods, showing high concordance and avoiding wrong management decisions.\n    \n\n\n          Conclusion:\n        \n      \n      We demonstrated the validity of the iDScore method for managing suspicious MSLs in a large multicentric data set and a teledermoscopic setting. The platform designed for the iDScore project provides ready support for physicians of any dermoscopy skill level and is useful for education and training."
        },
        {
            "title": "Skin Disease Classification using Neural Network.",
            "abstract": "Background:\n        \n      \n      In this study, a novel and fully automatic skin disease classification approach is proposed using statistical feature extraction and Artificial Neural Network (ANN) based classification using first and second order statistical moments, the entropy of different color channels and texture-based features.\n    \n\n\n          Aims:\n        \n      \n      The basic aim of our study is to develop an automated system for skin disease classification that can help a general physician to automatically detect the lesion and classify it to disease types.\n    \n\n\n          Method:\n        \n      \n      The performance of the proposed approach is corroborated by extensive experiments performed on a dataset of 588 images containing 6907 lesion regions.\n    \n\n\n          Results:\n        \n      \n      The results show that the proposed methodology can be effectively used to construct a skin disease classification system.\n    \n\n\n          Conclusion:\n        \n      \n      Our proposed method is designed for a specific skin tone. Future investigation is needed to analyze the impact of different skin tones on the performance of lesions detection and classification system."
        },
        {
            "title": "Thresholding methods for lesion segmentation of basal cell carcinoma in dermoscopy images.",
            "abstract": "Purpose:\n        \n      \n      Algorithms employed for pigmented lesion segmentation perform poorly on dermoscopy images of basal cell carcinoma (BCC), the most common skin cancer. The main objective was to develop better methods for BCC segmentation.\n    \n\n\n          Methods:\n        \n      \n      Fifteen thresholding methods were implemented for BCC lesion segmentation. We propose two error metrics that better measure the type II error: Relative XOR Error and Lesion Capture Ratio.\n    \n\n\n          Results:\n        \n      \n      On training/test sets of 305 and 34 BCC images, respectively, five new techniques outperform two state-of-the-art methods used in segmentation of melanomas, based on the new error metrics.\n    \n\n\n          Conclusion:\n        \n      \n      The proposed algorithms, which include solutions for image vignetting correction and border expansion to achieve dermatologist-like borders, provide more inclusive and feature-preserving border detection, favoring better BCC classification accuracy, in future work."
        },
        {
            "title": "Dermatologist-level classification of malignant lip diseases using a deep convolutional neural network.",
            "abstract": "## BACKGROUND\nDeep convolutional neural networks (DCNNs) can classify skin diseases at a level equivalent to a dermatologist, but their performance in specific areas requires further research.\n## OBJECTIVE\nTo evaluate the performance of a trained DCNN-based algorithm in classifying benign and malignant lip diseases.\n## METHODS\nA training set of 1629 images (743 malignant, 886 benign) was used with Inception-Resnet-V2. Performance was evaluated using another set of 344 images and 281 images from other hospitals. Classifications by 44 participants (six board-certified dermatologists, 12 dermatology residents, nine medical doctors not specialized in dermatology and 17 medical students) were used for comparison.\n## RESULTS\nThe outcomes based on the area under curve, sensitivity and specificity were 0Â·827 [95% confidence interval (CI) 0Â·782-0Â·873], 0Â·755 (95% CI 0Â·673-0Â·827) and 0Â·803 (95% CI 0Â·752-0Â·855), respectively, for the set of 344 images; and 0Â·774 (95% CI 0Â·699-0Â·849), 0Â·702 (95% CI 0Â·579-0Â·808) and 0Â·759 (95% CI 0Â·701-0Â·813), respectively, for the set of 281 images. The DCNN was equivalent to the dermatologists and superior to the nondermatologists in classifying malignancy. After referencing the DCNN result, the mean Â± SD Youden index increased significantly for nondermatologists, from 0Â·201 Â± 0Â·156 to 0Â·322 Â± 0Â·141 (P < 0Â·001).\n## CONCLUSIONS\nDCNNs can classify lip diseases at a level similar to dermatologists. This will help unskilled physicians discriminate between benign and malignant lip diseases. What's already known about this topic? Deep convolutional neural networks (DCNNs) can classify malignant and benign skin diseases at a level equivalent to dermatologists. The lips are a unique feature in terms of histology and morphology. Previous studies of DCNNs have not investigated tumours on specific locations. What does this study add? This study shows that DCNNs can distinguish rare malignant and benign lip disorders at the same rate as dermatologists. DCNNs can help nondermatologists to distinguish malignant lip diseases. What are the clinical implications of this work? DCNNs can distinguish malignant and benign skin diseases even at specific locations such as the lips, as well as board-certified dermatologists. Malignant lip diseases are rare and difficult for less trained doctors to differentiate them from benign lesions. This study shows that in dermatology, DCNN can help improve decision-making processes for rare skin diseases in specific areas of the body.\n"
        },
        {
            "title": "Definition of treatment goals in terms of clinician-reported disease severity and patient-reported outcomes in moderate-to-severe adult atopic dermatitis: a systematic review.",
            "abstract": "Background:\n        \n      \n      Atopic dermatitis (AD) is a chronically relapsing skin disease. Although a definitive cure is not available, appropriate treatment can control the disease. The advent of biologic drugs has led to the need for a clear definition of the disease severity and treatment response. A standardized list of outcomes that defines clinician-reported disease severity and patients' reported severity are therefore essential. Solid criteria to define the response to treatment and treatment failure are lacking to date.\n    \n\n\n          Objective:\n        \n      \n      This systematic review defines treatment goals in terms of clinician-reported disease severity and patient-reported outcomes, referring to the published moderate-to-severe AD clinical trials. The application of these goals in daily clinical practice will ensure a better selection of available treatment options, thus increasing patient quality of care.\n    \n\n\n          Materials and methods:\n        \n      \n      A systematic literature search was performed to identify the treatments goals of randomized controlled clinical trials (RCTs) on moderate-to-severe adult AD published between January 2000 and October 2020.\n    \n\n\n          Results:\n        \n      \n      In total, 14 studies met the eligibility criteria. The most widely used tools in terms of clinician-reported disease severity were the Scoring of Atopic Dermatitis (SCORAD) followed by the Eczema Area Severity Score (EASI) and Investigator Global Assessment (IGA). For disease severity scales as efficacy outcome in RCTs, the greatest standardization and reproducibility was for improvement of at least 50% in EASI score and IGA score reduction of â‰¥2 grades from baseline. The most widely used tools from the patients' perspective were the Dermatology Life Quality Index (DLQI), Numeric Rate Scale (NRS)-itch and Patient Oriented Eczema Measure Score (POEM). In terms of patients' reported efficacy outcomes in RCTs, a numerical DLQI, NRS-itch and POEM score improvement of at least 4 points from baseline was reported.\n    \n\n\n          Conclusions:\n        \n      \n      This systematic review highlights the need for collaboration between experts in order to define and optimize treatment outcomes. Despite considerable progress in harmonizing outcome measures, promoted by the foundation of the Harmonizing Outcome Measures for Eczema (HOME) initiative in 2008, our results demonstrate that this endpoint is still an unmet need. Based on the literature data we propose a minimum treatment goal algorithm for use in daily clinical practice aimed at stimulating a discussion on how the care of AD patients could be further improved."
        },
        {
            "title": "The Application of Differing Machine Learning Algorithms and Their Related Performance in Detecting Skin Cancers and Melanomas.",
            "abstract": "Skin cancer, and its less common form melanoma, is a disease affecting a wide variety of people. Since it is usually detected initially by visual inspection, it makes for a good candidate for the application of machine learning. With early detection being key to good outcomes, any method that can enhance the diagnostic accuracy of dermatologists and oncologists is of significant interest. When comparing different existing implementations of machine learning against public datasets and several we seek to create, we attempted to create a more accurate model that can be readily adapted to use in clinical settings. We tested combinations of models, including convolutional neural networks (CNNs), and various layers of data manipulation, such as the application of Gaussian functions and trimming of images to improve accuracy. We also created more traditional data models, including support vector classification, K-nearest neighbor, NaÃ¯ve Bayes, random forest, and gradient boosting algorithms, and compared them to the CNN-based models we had created. Results had indicated that CNN-based algorithms significantly outperformed other data models we had created. Partial results of this work were presented at the CSET Presentations for Research Month at the Minnesota State University, Mankato."
        },
        {
            "title": "SkiNet: A deep learning framework for skin lesion diagnosis with uncertainty estimation and explainability.",
            "abstract": "Skin cancer is considered to be the most common human malignancy. Around 5 million new cases of skin cancer are recorded in the United States annually. Early identification and evaluation of skin lesions are of great clinical significance, but the disproportionate dermatologist-patient ratio poses a significant problem in most developing nations. Therefore a novel deep architecture, named as SkiNet, is proposed to provide faster screening solution and assistance to newly trained physicians in the process of clinical diagnosis of skin cancer. The main motive behind SkiNet's design and development is to provide a white box solution, addressing a critical problem of trust and interpretability which is crucial for the wider adoption of Computer-aided diagnosis systems by medical practitioners. The proposed SkiNet is a two-stage pipeline wherein the lesion segmentation is followed by the lesion classification. Monte Carlo dropout and test time augmentation techniques have been employed in the proposed method to estimate epistemic and aleatoric uncertainty. A novel segmentation model named Bayesian MultiResUNet is used to estimate the uncertainty on the predicted segmentation map. Saliency-based methods like XRAI, Grad-CAM and Guided Backprop are explored to provide post-hoc explanations of the deep learning models. The ISIC-2018 dataset is used to perform the experimentation and ablation studies. The results establish the robustness of the proposed model on the traditional benchmarks while addressing the black-box nature of such models to alleviate the skepticism of medical practitioners by incorporating transparency and confidence to the model's prediction."
        },
        {
            "title": "Personalized risk prediction for breast cancer pre-screening using artificial intelligence and thermal radiomics.",
            "abstract": "Motivation:\n        \n      \n      Breast cancer is the leading cause of cancer deaths among women today. Survival rates in developing countries are around 50%-60% due to late detection. A personalized, accurate risk scoring method can help in targeting the right population for follow-up tests and enables early detection of breast abnormalities. Most of the available risk assessment tools use generic and weakly correlated features like age, weight, height etc. While a personalized risk scoring from screening modalities such as mammography and ultrasound could be helpful, these tests are limited to very few metropolitan hospitals in developing countries due to high capital cost, operational expenses and interpretation expertise needed for a large screening population.\n    \n\n\n          Methods:\n        \n      \n      We propose and analyze a new personalized risk framework called Thermalytix Risk Score (TRS) to identify a high-risk target population for regular screening and enable early stage breast cancer detection at scale. This technique uses Artificial Intelligence (AI) over thermal images to automatically generate a breast health risk score. This risk score is mainly derived from two sub-scores namely, vascular score and hotspot score. A hotspot score signifies the abnormality seen from irregular asymmetric heat patterns seen on the skin surface, whereas vascular score predicts the presence of asymmetric vascular activity. These scores are generated using machine learning algorithms over medically interpretable parameters that describes the metabolic activity inside the breast tissue and indicate the presence of a possible malignancy even in asymptomatic women.\n    \n\n\n          Results:\n        \n      \n      The proposed personalized risk score was tested on 769 subjects in four breast cancer screening facilities. The subjects' age ranged from 18 to 82 years with a median of around 45 years. Out of the 769 subjects, 185 subjects were diagnosed with a breast malignancy by an expert radiologist after mammography, ultrasound and/or histopathology. Our personalized AI based risk score achieved an area under the receiver-operator curve (AUC) of 0.89 when compared to an age normalized risk score that showed an AUC of 0.68. We also found that if the computed risk score is used to place individuals into four risk groups, the likelihood of malignancy also increases monotonically with the risk grouping level.\n    \n\n\n          Conclusion:\n        \n      \n      The proposed AI based personalized risk score uses breast thermal image patterns for risk computation and compares favorably to other generic risk estimation approaches. The proposed risk framework solution is automated, affordable, non-invasive, non-contact and radiation free and works for a wide age range of women from 18 to 82 years, including young women with dense breasts. The proposed score might be further used to assign subjects into one of the four risk groups and provide guidance on the periodicity of screening needed. In addition, the automatically annotated thermal images localizes the potential abnormal regions and might empower the physician to create a better personalized care."
        },
        {
            "title": "Exploring convolutional neural networks with transfer learning for diagnosing Lyme disease from skin lesion images.",
            "abstract": "Background and objective:\n        \n      \n      Lyme disease which is one of the most common infectious vector-borne diseases manifests itself in most cases with erythema migrans (EM) skin lesions. Recent studies show that convolutional neural networks (CNNs) perform well to identify skin lesions from images. Lightweight CNN based pre-scanner applications for resource-constrained mobile devices can help users with early diagnosis of Lyme disease and prevent the transition to a severe late form thanks to appropriate antibiotic therapy. Also, resource-intensive CNN based robust computer applications can assist non-expert practitioners with an accurate diagnosis. The main objective of this study is to extensively analyze the effectiveness of CNNs for diagnosing Lyme disease from images and to find out the best CNN architectures considering resource constraints.\n    \n\n\n          Methods:\n        \n      \n      First, we created an EM dataset with the help of expert dermatologists from Clermont-Ferrand University Hospital Center of France. Second, we benchmarked this dataset for twenty-three CNN architectures customized from VGG, ResNet, DenseNet, MobileNet, Xception, NASNet, and EfficientNet architectures in terms of predictive performance, computational complexity, and statistical significance. Third, to improve the performance of the CNNs, we used custom transfer learning from ImageNet pre-trained models as well as pre-trained the CNNs with the skin lesion dataset HAM10000. Fourth, for model explainability, we utilized Gradient-weighted Class Activation Mapping to visualize the regions of input that are significant to the CNNs for making predictions. Fifth, we provided guidelines for model selection based on predictive performance and computational complexity.\n    \n\n\n          Results:\n        \n      \n      Customized ResNet50 architecture gave the best classification accuracy of 84.42% Â±1.36, AUC of 0.9189Â±0.0115, precision of 83.1%Â±2.49, sensitivity of 87.93%Â±1.47, and specificity of 80.65%Â±3.59. A lightweight model customized from EfficientNetB0 also performed well with an accuracy of 83.13%Â±1.2, AUC of 0.9094Â±0.0129, precision of 82.83%Â±1.75, sensitivity of 85.21% Â±3.91, and specificity of 80.89%Â±2.95. All the trained models are publicly available at https://dappem.limos.fr/download.html, which can be used by others for transfer learning and building pre-scanners for Lyme disease.\n    \n\n\n          Conclusion:\n        \n      \n      Our study confirmed the effectiveness of even some lightweight CNNs for building Lyme disease pre-scanner mobile applications to assist people with an initial self-assessment and referring them to expert dermatologist for further diagnosis."
        },
        {
            "title": "Machine-learning algorithm to predict multidisciplinary team treatment recommendations in the management of basal cell carcinoma.",
            "abstract": "Background:\n        \n      \n      Basal cell carcinoma (BCC) is the most common human cancer. Facial BCCs most commonly occur on the nose and the management of these lesions is particularly complex, given the functional and complex implications of treatment. Multidisciplinary team (MDT) meetings are routinely held to integrate expertise from dermatologists, surgeons, oncologists, radiologists, pathologists and allied health professionals. The aim of this research was to develop a supervised machine-learning algorithm to predict MDT recommendations for nasal BCC to potentially reduce MDT caseload, provide automatic decision support and permit data audit in a health service context.\n    \n\n\n          Methods:\n        \n      \n      The study population included all consecutive patients who were discussed at skin cancer-specialised MDT (SSMDT) with a diagnosis of nasal BCC between January 1, 2015 and December 31, 2015. We conducted analyses for gender, age, anatomical location, histological subtype, tumour size, tumour recurrence, anticoagulation, pacemaker, immunosuppressants and therapeutic modalities (Mohs surgery, conventional excision or radiotherapy). We used S-statistic computing language to develop a supervised machine-learning algorithm.\n    \n\n\n          Results:\n        \n      \n      We found that 37.5% of patients could be reliably predicted to be triaged to Mohs micrographic surgery (MMS), based on tumour location and age. Similarly, the choice of conventional treatment (surgical excision or radiotherapy) by the MDT could be reliably predicted based on the patient's age, tumour phenotype and lesion size. Accordingly, the algorithm reliably predicted the MDT decision outcome of 45.1% of nasal BCCs.\n    \n\n\n          Conclusions:\n        \n      \n      Our study suggests that the machine-learning approach is a potentially useful tool for predicting MDT decisions for MMS vs conventional surgery or radiotherapy for a significant group of patients. We suggest that utilising this algorithm gives the MDT more time to consider more complex patients, where multiple factors, including recurrence, financial costs and cosmetic outcome, contribute to the final decision, but cannot be reliably predicted to determine that outcome. This approach has the potential to reduce the burden and improve the efficiency of the specialist skin MDT and, in turn, improve patient care, reduce waiting times and reduce the financial burden. Such an algorithm would need to be updated regularly to take into account any changes in patient referral patterns, treatment options or local clinical expertise.\n    \n\n\n          Clinical trial registration:\n        \n      \n      lPLAS_20-21_A08."
        },
        {
            "title": "Predicting Mohs surgery complexity by applying machine learning to patient demographics and tumor characteristics.",
            "abstract": "Mohs micrographic surgery (MMS) is considered the gold standard for difficult-to-treat malignant skin tumors, whose incidence is on the rise. Currently, there are no agreed upon classifiers to predict complex MMS procedures. Such classifiers could enable better patient scheduling, reduce staff burnout and improve patient education. Our goal was to create an accessible and interpretable classifier(s) that would predict complex MMS procedures. A retrospective study applying machine learning models to a dataset of 8644 MMS procedures to predict complex wound reconstruction and number of MMS procedure stages. Each procedure record contained preoperative data on patient demographics, estimated clinical tumor size prior to surgery (mean diameter), tumor characteristics and tumor location, and postoperative procedure outcomes included the wound reconstruction technique and the number of MMS stages performed in order to achieve tumor-free margins. For the number of stages complexity classification model, the area under the receiver operating characteristic curve (AUROC) was 0.79 (good performance), with model accuracy of 77%, sensitivity of 71%, specificity of 77%, positive prediction value (PPV) of 14% and negative prediction value (NPV) of 98%. The results for the wound reconstruction complexity classification model were 0.84 for the AUROC (excellent performance), with model accuracy of 75%, sensitivity of 72%, specificity of 76%, PPV of 39% and NPV of 93%. The ML models we created predict the complexity of the components that comprise the MMS procedure. Using the accessible and interpretable tool we provide online, clinicians can improve the management and well-being of their patients. Study limitation is that models are based on data generated from a single surgeon."
        },
        {
            "title": "Computed Tomography Image Characteristics before and after Interventional Treatment of Children's Lymphangioma under Artificial Intelligence Algorithm.",
            "abstract": "The artificial intelligence algorithm was used to analyze the characteristics of computed tomography (CT) images before and after interventional treatment of children's lymphangioma. Retrospective analysis was performed, and 30 children with lymphangioma from the hospital were recruited as the study subjects. The ultrasound-guided bleomycin interventional therapy was adopted and applied to CT scanning through convolutional neural network (CNN). The CT imaging-related indicators before and after interventional therapy were detected, and feature analysis was performed. In addition, the CNN algorithm was adopted to segment the image of the tumor was clearer and more accurate. At the same time, the Dice similarity coefficient (DSC) of the CNN algorithm was 0.9, which had a higher degree of agreement. In terms of clinical symptoms, the cured children's lesions disappeared, the skin surface returned to normal color, and the treatment was smooth. In the two cases with effective treatment, the cystic mass at the lesion site was significantly smaller, and the nodules disappeared. CT images before interventional therapy showed that lymphangiomas in children were more common in the neck. The cystic masses at all lesion sites varied in diameter and size, and most of them were similar to round and irregular, with uniform density distribution. The boundary was clear, the cyst was solid, and there were different degrees of compression and spread to the surrounding structure. Most of them were polycystic, and a few of them were single cystic. After interventional treatment, CT images showed that 27 cases of cured children's lymphangioma completely disappeared. Lymphangioma was significantly reduced in two children with effective treatment. Edema around the tumor also decreased significantly. Patients who did not respond to the treatment received interventional treatment again, and the tumors disappeared completely on CT imaging. No recurrence or new occurrence was found in three-month follow-up. The total effective rate of interventional therapy for lymphangioma in children was 96.67%. The CNN algorithm can effectively compare the CT image features before and after interventional treatment for children's lymphangioma. It was suggested that the artificial intelligence algorithm-aided CT imaging examination was helpful to guide physicians in the accurate treatment of children's lymphangioma."
        },
        {
            "title": "Attitudes towards Trusting Artificial Intelligence Insights and Factors to Prevent the Passive Adherence of GPs: A Pilot Study.",
            "abstract": "Artificial Intelligence (AI) systems could improve system efficiency by supporting clinicians in making appropriate referrals. However, they are imperfect by nature and misdiagnoses, if not correctly identified, can have consequences for patient care. In this paper, findings from an online survey are presented to understand the aptitude of GPs (n = 50) in appropriately trusting or not trusting the output of a fictitious AI-based decision support tool when assessing skin lesions, and to identify which individual characteristics could make GPs less prone to adhere to erroneous diagnostics results. The findings suggest that, when the AI was correct, the GPs' ability to correctly diagnose a skin lesion significantly improved after receiving correct AI information, from 73.6% to 86.8% (X2 (1, N = 50) = 21.787, p < 0.001), with significant effects for both the benign (X2 (1, N = 50) = 21, p < 0.001) and malignant cases (X2 (1, N = 50) = 4.654, p = 0.031). However, when the AI provided erroneous information, only 10% of the GPs were able to correctly disagree with the indication of the AI in terms of diagnosis (d-AIW M: 0.12, SD: 0.37), and only 14% of participants were able to correctly decide the management plan despite the AI insights (d-AIW M:0.12, SD: 0.32). The analysis of the difference between groups in terms of individual characteristics suggested that GPs with domain knowledge in dermatology were better at rejecting the wrong insights from AI."
        },
        {
            "title": "Using Dermoscopy to Identify Melanoma and Improve Diagnostic Discrimination.",
            "abstract": "Use of dermoscopy and detection algorithms by primary care physicians can enhance assessment of clinically suspicious lesions compared with that of naked eye examinations."
        },
        {
            "title": "mHealth App for Risk Assessment of Pigmented and Nonpigmented Skin Lesions-A Study on Sensitivity and Specificity in Detecting Malignancy.",
            "abstract": "Background:\n        \n      \n      With the advent of smartphone devices, an increasing number of mHealth applications that target melanoma identification have been developed, but none addresses the general context of melanoma and nonmelanoma skin cancer identification.\n    \n\n\n          Introduction:\n        \n      \n      In this study a smartphone application using fractal and classical image analysis for the risk assessment of skin lesions is systematically evaluated to determine its sensitivity and specificity in the diagnosis of melanoma and nonmelanoma skin cancer along with actinic keratosis and Bowen's disease.\n    \n\n\n          Materials and methods:\n        \n      \n      In the Department of Dermatology, Catharina Hospital Eindhoven, The Netherlands, 341 melanocytic and nonmelanocytic lesions were imaged using SkinVision app; 239 underwent histopathological examination, while the rest of 102 lesions were clinically diagnosed as clearly benign and not removed. The algorithm has been calibrated using the images of the first 233 lesions. The calibrated version of the algorithm was used in a subset of 108 lesions, and the obtained results were compared with the medical findings.\n    \n\n\n          Results:\n        \n      \n      On the 108 cases used for evaluation the algorithm scored 80% sensitivity and 78% specificity in detecting (pre)malignant conditions.\n    \n\n\n          Discussion:\n        \n      \n      Although less accurate than the dermatologist's clinical eye, the app may offer support to other professionals who are less familiar with differentiating between benign and malignant lesions.\n    \n\n\n          Conclusion:\n        \n      \n      An mHealth application for the risk assessment of skin lesions was evaluated. It adds value to diagnosis tools of its type by taking into consideration pigmented and nonpigmented lesions all together and detecting signs of malignancy with high sensitivity."
        },
        {
            "title": "Does sex matter? Analysis of sex-related differences in the diagnostic performance of a market-approved convolutional neural network for skin cancer detection.",
            "abstract": "Background:\n        \n      \n      Advances in biomedical artificial intelligence may introduce or perpetuate sex and gender discriminations. Convolutional neural networks (CNN) have proven a dermatologist-level performance in image classification tasks but have not been assessed for sex and gender biases that may affect training data and diagnostic performance. In this study, we investigated sex-related imbalances in training data and diagnostic performance of a market-approved CNN for skin cancer classification (Moleanalyzer ProÂ®, Fotofinder Systems GmbH, Bad Birnbach, Germany).\n    \n\n\n          Methods:\n        \n      \n      We screened open-access dermoscopic image repositories widely used for CNN training for distribution of sex. Moreover, the sex-related diagnostic performance of the market-approved CNN was tested in 1549 dermoscopic images stratified by sex (female n = 773; male n = 776).\n    \n\n\n          Results:\n        \n      \n      Most open-access repositories showed a marked under-representation of images originating from female (40%) versus male (60%) patients. Despite these imbalances and well-known sex-related differences in skin anatomy or skin-directed behaviour, the tested CNN achieved a comparable sensitivity of 87.0% [80.9%-91.3%] versus 87.1% [81.1%-91.4%], specificity of 98.7% [97.4%-99.3%] versus 96.9% [95.2%-98.0%] and ROC-AUC of 0.984 [0.975-0.993] versus 0.979 [0.969-0.988] in dermoscopic images of female versus male origin, respectively. In the sample at hand, sex-related differences in ROC-AUCs were not statistically significant in the per-image analysis nor in an additional per-individual analysis (p â‰¥ 0.59).\n    \n\n\n          Conclusion:\n        \n      \n      Design and training of artificial intelligence algorithms for medical applications should generally acknowledge sex and gender dimensions. Despite sex-related imbalances in open-access training data, the diagnostic performance of the tested CNN showed no sex-related bias in the classification of skin lesions."
        },
        {
            "title": "Multi-Grid Phase Field Skin Tumor Segmentation in 3D Ultrasound Images.",
            "abstract": "The aim of this paper is to present a new method for skin tumor segmentation in the 3D ultrasound images. We consider a variational formulation, the energy of which combines a diffuse interface phase field model (regularization term) and a log-likelihood computed using nonparametric estimates (data attachment term). We propose a multi-grid implementation with the exact solutions which has the advantage to avoid space discretization and numerical instabilities. The resulting algorithm is simple and easy to implement in multi-dimensions. Concerning applications, we focus on skin tumor segmentation. The clinical dataset used for the experiments is composed of 12 images with the ground truth given by a dermatologist. Comparisons with the reference methods show that the proposed method is more robust to the choice of the volume initialization. Moreover, thanks to the flexibility introduced by the diffuse interface, the sensitivity increases by 12% if the initialization is inside the lesion, and the Dice index increases by 59%, if the initialization covers the entire lesion. These results show that this new method is well designed to tackle the problem of underestimation of tumor volumes."
        },
        {
            "title": "Comparison of computer systems and ranking criteria for automatic melanoma detection in dermoscopic images.",
            "abstract": "Melanoma is the deadliest form of skin cancer, and early detection is crucial for patient survival. Computer systems can assist in melanoma detection, but are not widespread in clinical practice. In 2016, an open challenge in classification of dermoscopic images of skin lesions was announced. A training set of 900 images with corresponding class labels and semi-automatic/manual segmentation masks was released for the challenge. An independent test set of 379 images, of which 75 were of melanomas, was used to rank the participants. This article demonstrates the impact of ranking criteria, segmentation method and classifier, and highlights the clinical perspective. We compare five different measures for diagnostic accuracy by analysing the resulting ranking of the computer systems in the challenge. Choice of performance measure had great impact on the ranking. Systems that were ranked among the top three for one measure, dropped to the bottom half when changing performance measure. Nevus Doctor, a computer system previously developed by the authors, was used to participate in the challenge, and investigate the impact of segmentation and classifier. The diagnostic accuracy when using an automatic versus the semi-automatic/manual segmentation is investigated. The unexpected small impact of segmentation method suggests that improvements of the automatic segmentation method w.r.t. resemblance to semi-automatic/manual segmentation will not improve diagnostic accuracy substantially. A small set of similar classification algorithms are used to investigate the impact of classifier on the diagnostic accuracy. The variability in diagnostic accuracy for different classifier algorithms was larger than the variability for segmentation methods, and suggests a focus for future investigations. From a clinical perspective, the misclassification of a melanoma as benign has far greater cost than the misclassification of a benign lesion. For computer systems to have clinical impact, their performance should be ranked by a high-sensitivity measure."
        },
        {
            "title": "Semi-Supervised Medical Image Classification With Relation-Driven Self-Ensembling Model.",
            "abstract": "Training deep neural networks usually requires a large amount of labeled data to obtain good performance. However, in medical image analysis, obtaining high-quality labels for the data is laborious and expensive, as accurately annotating medical images demands expertise knowledge of the clinicians. In this paper, we present a novel relation-driven semi-supervised framework for medical image classification. It is a consistency-based method which exploits the unlabeled data by encouraging the prediction consistency of given input under perturbations, and leverages a self-ensembling model to produce high-quality consistency targets for the unlabeled data. Considering that human diagnosis often refers to previous analogous cases to make reliable decisions, we introduce a novel sample relation consistency (SRC) paradigm to effectively exploit unlabeled data by modeling the relationship information among different samples. Superior to existing consistency-based methods which simply enforce consistency of individual predictions, our framework explicitly enforces the consistency of semantic relation among different samples under perturbations, encouraging the model to explore extra semantic information from unlabeled data. We have conducted extensive experiments to evaluate our method on two public benchmark medical image classification datasets, i.e., skin lesion diagnosis with ISIC 2018 challenge and thorax disease classification with ChestX-ray14. Our method outperforms many state-of-the-art semi-supervised learning methods on both single-label and multi-label image classification scenarios."
        },
        {
            "title": "A GAN-based image synthesis method for skin lesion classification.",
            "abstract": "Background and objective:\n        \n      \n      There are many types of skin cancer, and melanoma is the most lethal one. Dermoscopy is an important imaging technique to screen melanoma and other skin lesions. However, Skin lesion classification based on computer-aided diagnostic techniques is a challenging task owing to the scarcity of labeled data and class-imbalanced dataset. It is necessary to apply data augmentation technique based on generative adversarial networks (GANs) to skin lesion classification for helping dermatologists in more accurate diagnostic decisions.\n    \n\n\n          Methods:\n        \n      \n      A whole process of using GAN-based data augmentation technology to improve the skin lesion classification performance has been established in this article. First of all, the skin lesion style-based GANs is proposed according to the basic architecture of style-based GANs. The proposed model modifies the structure of style control and noise input in the original generator, adjusts both the generator and discriminator to efficiently synthesize high-quality skin lesion images. As for image classification, the classifier is constructed on the pretrained deep neural network using transfer learning method. The synthetic images from the proposed skin lesion style-based GANs are finally added to the training set to help train the classifier for better classification performance.\n    \n\n\n          Results:\n        \n      \n      The proposed skin lesion style-based GAN has been evaluated by Inception Score (IS), FrÃ©chet Inception Distance (FID), Precision and Recall, and is superior to other compared GAN models in these quantitative evaluation metrics. By adding the synthesized images to the training set, the main classification indicators like accuracy, sensitivity, specificity, average precision and balanced multiclass accuracy are 95.2%, 83.2%, 74.3%, 96.6% and 83.1% on the dataset of International Skin Imaging Collaboration (ISIC) 2018 Challenge, which have been improved by 1.6%, 24.4%, 3.6%, 23.2% and 5.6% respectively compared to the CNN model.\n    \n\n\n          Conclusions:\n        \n      \n      The proposed skin lesion style-based GANs can generate high-quality skin lesion images efficiently, leading to the performance improvement of the classification model. This work provides a valuable reference for medical image analysis based on deep learning."
        },
        {
            "title": "Adapting Scoring Based Classification to Simplify and Automate Phenotype Creation for Cohort Identification in Clinical Data.",
            "abstract": "EHR-based phenotype development and validation are extremely time-consuming and have considerable monetary cost. The creation of a phenotype currently requires clinical experts and experts in the data to be queried. The new approach presented here demonstrates a computational alternative to the classification of patient cohorts based on automatic weighting of ICD codes. This approach was applied to data from six different clinics within the University of Arkansas for Medical Science (UAMS) health system. The results were compared with phenotype algorithms designed by clinicians and informaticians for asthma and melanoma. Relative to traditional phenotype development, this method shows potential to considerably reduce time requirements and monetary costs with comparable results."
        },
        {
            "title": "DermaKNet: Incorporating the Knowledge of Dermatologists to Convolutional Neural Networks for Skin Lesion Diagnosis.",
            "abstract": "Traditional approaches to automatic diagnosis of skin lesions consisted of classifiers working on sets of hand-crafted features, some of which modeled lesion aspects of special importance for dermatologists. Recently, the broad adoption of convolutional neural networks (CNNs) in most computer vision tasks has brought about a great leap forward in terms of performance. Nevertheless, with this performance leap, the CNN-based computer-aided diagnosis (CAD) systems have also brought a notable reduction of the useful insights provided by hand-crafted features. This paper presents DermaKNet, a CAD system based on CNNs that incorporates specific subsystems modeling properties of skin lesions that are of special interest to dermatologists aiming to improve the interpretability of its diagnosis. Our results prove that the incorporation of these subsystems not only improves the performance, but also enhances the diagnosis by providing more interpretable outputs."
        },
        {
            "title": "Leveraging Artificial Intelligence to Improve the Diversity of Dermatological Skin Color Pathology: Protocol for an Algorithm Development and Validation Study.",
            "abstract": "Background:\n        \n      \n      The paucity of dark skin images in dermatological textbooks and atlases is a reflection of racial injustice in medicine. The underrepresentation of dark skin images makes diagnosing skin pathology in people of color challenging. For conditions such as skin cancer, in which early diagnosis makes a difference between life and death, people of color have worse prognoses and lower survival rates than people with lighter skin tones as a result of delayed or incorrect diagnoses. Recent advances in artificial intelligence, such as deep learning, offer a potential solution that can be achieved by diversifying the mostly light-skin image repositories through generating images for darker skin tones. Thus, facilitating the development of inclusive cancer early diagnosis systems that are trained and tested on diverse images that truly represent human skin tones.\n    \n\n\n          Objective:\n        \n      \n      We aim to develop and evaluate an artificial intelligence-based skin cancer early detection system for all skin tones using clinical images.\n    \n\n\n          Methods:\n        \n      \n      This study consists of four phases: (1) Publicly available skin image repositories will be analyzed to quantify the underrepresentation of darker skin tones, (2) Images will be generated for the underrepresented skin tones, (3) Generated images will be extensively evaluated for realism and disease presentation with quantitative image quality assessment as well as qualitative human expert and nonexpert ratings, and (4) The images will be utilized with available light-skin images to develop a robust skin cancer early detection model.\n    \n\n\n          Results:\n        \n      \n      This study started in September 2020. The first phase of quantifying the underrepresentation of darker skin tones was completed in March 2021. The second phase of generating the images is in progress and will be completed by March 2022. The third phase is expected to be completed by May 2022, and the final phase is expected to be completed by September 2022.\n    \n\n\n          Conclusions:\n        \n      \n      This work is the first step toward expanding skin tone diversity in existing image databases to address the current gap in the underrepresentation of darker skin tones. Once validated, the image bank will be a valuable resource that can potentially be utilized in physician education and in research applications. Furthermore, generated images are expected to improve the generalizability of skin cancer detection. When completed, the model will assist family physicians and general practitioners in evaluating skin lesion severity and in efficient triaging for referral to expert dermatologists. In addition, the model can assist dermatologists in diagnosing skin lesions.\n    \n\n\n          International registered report identifier (irrid):\n        \n      \n      DERR1-10.2196/34896."
        },
        {
            "title": "Employing the Local Radon Transform for Melanoma Segmentation in Dermoscopic Images.",
            "abstract": "In recent years, the number of patients suffering from melanoma, as the deadliest type of skin cancer, has grown significantly in the world. The most common technique to observe and diagnosis of such cancer is the use of noninvasive dermoscope lens. Since this approach is based on the expert ocular inference, early stage of melanoma diagnosis is a difficult task for dermatologist. The main purpose of this article is to introduce an efficient algorithm to analyze the dermoscopic images. The proposed algorithm consists of four stages including converting the image color space from the RGB to CIE, adjusting the color space by applying the combined histogram equalization and the Otsu thresholding-based approach, border extraction of the lesion through the local Radon transform, and recognizing the melanoma and nonmelanoma lesions employing the ABCD rule. Simulation results in the designed user-friendly software package environment confirmed that the proposed algorithm has the higher quantities of accuracy, sensitivity, and approximation correlation in comparison with the other state-of-the-art methods. These values are obtained 98.81 (98.92), 94.85 (89.51), and 90.99 (86.06) for melanoma (nonmelanoma) lesions, respectively."
        },
        {
            "title": "The Value of High-Resolution Ultrasound Combined with Shear-Wave Elastography under Artificial Intelligence Algorithm in Quantitative Evaluation of Skin Thickness in Localized Scleroderma.",
            "abstract": "The aim of this study was to explore the value of high-resolution ultrasound combined with shear-wave elastography (SWE) in measuring skin thickness in patients with localized scleroderma (LS). Fifty patients with LS diagnosed by pathology in the hospital were selected as the research object, with a total of 96 lesions. Healthy people (50 cases) in the same period were selected as the control group. The skin thickness of the abdomen, chest, and left finger of the two groups was compared. The traditional nonlocal means (NLM) algorithm was improved by changing the Euclidean distance and introducing a cosine function, which was applied to the ultrasonic imaging intelligent diagnosis of patients with localized scleroderma. SWE imaging was evaluated, and the results demonstrated that LS lesion edema stage accounted for 7.29%, hardening stage occupied 43.75%, and the proportion of atrophy stage reached 48.96%. When the size of shell was 1 mm, maximum elastic modulus (E max) was 0.984, mean of elastic modulus (Emean) was 0.926, and electro-static discharge (Esd) was 0.965. When the size of shell was 2 mm, the elastic moduli around lesions were as follows: Emax was 0.998, Emean was 0.968, and Esd was 0.997. By comparing the skin thickness of the abdomen, chest, and left finger, it was found that there was a significant difference between the LS group and the control group (P < 0.05). When the shell was 2 mm, the effect of sensitivity specificity on SWE imaging was better than that when the shell was 1 mm. In summary, the improved NLM algorithm showed excellent denoising effects on the ultrasonic images of LS patients. Besides, it could assist clinicians in ultrasonic imaging diagnosis for LS patients and effectively improve the diagnostic accuracy of diseases."
        },
        {
            "title": "The easy-to-hard training advantage with real-world medical images.",
            "abstract": "Many medical professions require practitioners to perform visual categorizations in domains such as radiology, dermatology, and neurology. However, acquiring visual expertise is tedious and time-consuming and the perceptual strategies mediating visual categorization skills are poorly understood. In this paper, the Ease algorithm was developed to predict an item's categorization difficulty (Ease value) based on the item's perceptual similarity to all within-category items versus between-category items in the dataset. In this study, Ease values were used to construct an easy-to-hard and hard-to-easy training schedule for teaching melanoma diagnosis. Whereas previous visual training studies suggest that an easy-to-hard schedule benefits learning outcomes, no studies to date have demonstrated the easy-to-hard advantage with complex, real-world images. In our study, 237 melanoma and benign images were collected for training and testing purposes. The diagnostic accuracy of images was verified by an expert dermatologist. Based on their Ease values, the items were grouped into easy, medium, and hard categories, each containing an equal number of melanoma and benign lesions. During training, participants categorized images of skin lesions as either benign or melanoma and were given corrective feedback after each trial. In the easy-to-hard training condition, participants learned to categorize all the easy items first, followed by the medium items, and finally the hard items. Participants in the hard-to-easy training condition learned items in the reverse order. Post-training results showed that training in both conditions transferred to the classification of new melanoma and benign images. Participants in the easy-to-hard condition showed modest advantages both in the acquisition and retention of the melanoma diagnosis skills, but neither scheduling condition exhibited a gross advantage. The Ease values of the items predicted categorization accuracy after, but not before training, suggesting that the Ease algorithm is a promising tool for optimizing medical training in visual categorization."
        },
        {
            "title": "Optimization of psoriasis assessment system based on patch images.",
            "abstract": "Psoriasis is a chronic inflammatory skin disease that occurs in various forms throughout the body and is associated with certain conditions such as heart disease, diabetes, and depression. The psoriasis area severity index (PASI) score, a tool used to evaluate the severity of psoriasis, is currently used in clinical trials and clinical research. The determination of severity is based on the subjective judgment of the clinician. Thus, the disease evaluation deviations are induced. Therefore, we propose optimal algorithms that can effectively segment the lesion area and classify the severity. In addition, a new dataset on psoriasis was built, including patch images of erythema and scaling. We performed psoriasis lesion segmentation and classified the disease severity. In addition, we evaluated the best-performing segmentation method and classifier and analyzed features that are highly related to the severity of psoriasis. In conclusion, we presented the optimal techniques for evaluating the severity of psoriasis. Our newly constructed dataset improved the generalization performance of psoriasis diagnosis and evaluation. It proposed an optimal system for specific evaluation indicators of the disease and a quantitative PASI scoring method. The proposed system can help to evaluate the severity of localized psoriasis more accurately."
        },
        {
            "title": "Automatic eczema classification in clinical images based on hybrid deep neural network.",
            "abstract": "The healthcare sector is the highest priority sector, and people demand the highest services and care. The fast rise of deep learning, particularly in clinical decision support tools, has provided exciting solutions primarily in medical imaging. In the past, ANNs (artificial neural networks) have been used extensively in dermatology and have shown promising results for detecting various skin diseases. Eczema represents a group of skin conditions characterized by irritated, dry, inflamed, and itchy skin. This study extends great help to automate the diagnosis process of various kinds of eczema through a Hybrid model that uses concatenated ReliefF optimized handcrafted and deep activated features and a support vector machine for classification. Deep learning models and standard image processing techniques have been used to classify eczema from images automatically. This work contributes to the first multiclass image dataset, namely EIR (Eczema image resource). The EIR dataset consists of 2039 labeled eczema images belonging to seven categories. We performed a comparative analysis of multiple ensemble models, attention mechanisms, and data augmentation techniques for this task. The respective accuracy, sensitivity, and specificity, for eczema classification by classifiers were recorded. In comparison, the proposed Hybrid 6 network achieved the highest accuracy of 88.29%, sensitivity of 85.19%, and specificity of 90.33%% among all employed models. Our findings suggest that deep learning models can classify eczema with high accuracy, and their performance is comparable to dermatologists. However, many factors have been elucidated that contribute to reducing accuracy and potential scope for improvement."
        },
        {
            "title": "Visual inspection for diagnosing cutaneous melanoma in adults.",
            "abstract": "Background:\n        \n      \n      Melanoma has one of the fastest rising incidence rates of any cancer. It accounts for a small percentage of skin cancer cases but is responsible for the majority of skin cancer deaths. History-taking and visual inspection of a suspicious lesion by a clinician is usually the first in a series of 'tests' to diagnose skin cancer. Establishing the accuracy of visual inspection alone is critical to understating the potential contribution of additional tests to assist in the diagnosis of melanoma.\n    \n\n\n          Objectives:\n        \n      \n      To determine the diagnostic accuracy of visual inspection for the detection of cutaneous invasive melanoma and atypical intraepidermal melanocytic variants in adults with limited prior testing and in those referred for further evaluation of a suspicious lesion. Studies were separated according to whether the diagnosis was recorded face-to-face (in-person) or based on remote (image-based) assessment.\n    \n\n\n          Search methods:\n        \n      \n      We undertook a comprehensive search of the following databases from inception up to August 2016: CENTRAL; CINAHL; CPCI; Zetoc; Science Citation Index; US National Institutes of Health Ongoing Trials Register; NIHR Clinical Research Network Portfolio Database; and the World Health Organization International Clinical Trials Registry Platform. We studied reference lists and published systematic review articles.\n    \n\n\n          Selection criteria:\n        \n      \n      Test accuracy studies of any design that evaluated visual inspection in adults with lesions suspicious for melanoma, compared with a reference standard of either histological confirmation or clinical follow-up. We excluded studies reporting data for 'clinical diagnosis' where dermoscopy may or may not have been used.\n    \n\n\n          Data collection and analysis:\n        \n      \n      Two review authors independently extracted all data using a standardised data extraction and quality assessment form (based on QUADAS-2). We contacted authors of included studies where information related to the target condition or diagnostic threshold were missing. We estimated summary sensitivities and specificities per algorithm and threshold using the bivariate hierarchical model. We investigated the impact of: in-person test interpretation; use of a purposely developed algorithm to assist diagnosis; and observer expertise.\n    \n\n\n          Main results:\n        \n      \n      We included 49 publications reporting on a total of 51 study cohorts with 34,351 lesions (including 2499 cases), providing 134 datasets for visual inspection. Across almost all study quality domains, the majority of study reports provided insufficient information to allow us to judge the risk of bias, while in three of four domains that we assessed we scored concerns regarding applicability of study findings as 'high'. Selective participant recruitment, lack of detail regarding the threshold for deciding on a positive test result, and lack of detail on observer expertise were particularly problematic.Attempts to analyse studies by degree of prior testing were hampered by a lack of relevant information and by the restricted inclusion of lesions selected for biopsy or excision. Accuracy was generally much higher for in-person diagnosis compared to image-based evaluations (relative diagnostic odds ratio of 8.54, 95% CI 2.89 to 25.3, P < 0.001). Meta-analysis of in-person evaluations that could be clearly placed on the clinical pathway showed a general trade-off between sensitivity and specificity, with the highest sensitivity (92.4%, 95% CI 26.2% to 99.8%) and lowest specificity (79.7%, 95% CI 73.7% to 84.7%) observed in participants with limited prior testing (n = 3 datasets). Summary sensitivities were lower for those referred for specialist assessment but with much higher specificities (e.g. sensitivity 76.7%, 95% CI 61.7% to 87.1%) and specificity 95.7%, 95% CI 89.7% to 98.3%) for lesions selected for excision, n = 8 datasets). These differences may be related to differences in the spectrum of included lesions, differences in the definition of a positive test result, or to variations in observer expertise. We did not find clear evidence that accuracy is improved by the use of any algorithm to assist diagnosis in all settings. Attempts to examine the effect of observer expertise in melanoma diagnosis were hindered due to poor reporting.\n    \n\n\n          Authors' conclusions:\n        \n      \n      Visual inspection is a fundamental component of the assessment of a suspicious skin lesion; however, the evidence suggests that melanomas will be missed if visual inspection is used on its own. The evidence to support its accuracy in the range of settings in which it is used is flawed and very poorly reported. Although published algorithms do not appear to improve accuracy, there is insufficient evidence to suggest that the 'no algorithm' approach should be preferred in all settings. Despite the volume of research evaluating visual inspection, further prospective evaluation of the potential added value of using established algorithms according to the prior testing or diagnostic difficulty of lesions may be warranted."
        },
        {
            "title": "Visual inspection and dermoscopy, alone or in combination, for diagnosing keratinocyte skin cancers in adults.",
            "abstract": "Background:\n        \n      \n      Early accurate detection of all skin cancer types is important to guide appropriate management, to reduce morbidity and to improve survival. Basal cell carcinoma (BCC) is almost always a localised skin cancer with potential to infiltrate and damage surrounding tissue, whereas a minority of cutaneous squamous cell carcinomas (cSCCs) and invasive melanomas are higher-risk skin cancers with the potential to metastasise and cause death. Dermoscopy has become an important tool to assist specialist clinicians in the diagnosis of melanoma, and is increasingly used in primary-care settings. Dermoscopy is a precision-built handheld illuminated magnifier that allows more detailed examination of the skin down to the level of the superficial dermis. Establishing the value of dermoscopy over and above visual inspection for the diagnosis of BCC or cSCC in primary- and secondary-care settings is critical to understanding its potential contribution to appropriate skin cancer triage, including referral of higher-risk cancers to secondary care, the identification of low-risk skin cancers that might be treated in primary care and to provide reassurance to those with benign skin lesions who can be safely discharged.\n    \n\n\n          Objectives:\n        \n      \n      To determine the diagnostic accuracy of visual inspection and dermoscopy, alone or in combination, for the detection of (a) BCC and (b) cSCC, in adults. We separated studies according to whether the diagnosis was recorded face-to-face (in person) or based on remote (image-based) assessment.\n    \n\n\n          Search methods:\n        \n      \n      We undertook a comprehensive search of the following databases from inception up to August 2016: Cochrane Central Register of Controlled Trials; MEDLINE; Embase; CINAHL; CPCI; Zetoc; Science Citation Index; US National Institutes of Health Ongoing Trials Register; NIHR Clinical Research Network Portfolio Database; and the World Health Organization International Clinical Trials Registry Platform. We studied reference lists and published systematic review articles.\n    \n\n\n          Selection criteria:\n        \n      \n      Studies of any design that evaluated visual inspection or dermoscopy or both in adults with lesions suspicious for skin cancer, compared with a reference standard of either histological confirmation or clinical follow-up.\n    \n\n\n          Data collection and analysis:\n        \n      \n      Two review authors independently extracted all data using a standardised data extraction and quality assessment form (based on QUADAS-2). We contacted authors of included studies where information related to the target condition or diagnostic thresholds were missing. We estimated accuracy using hierarchical summary ROC methods. We undertook analysis of studies allowing direct comparison between tests. To facilitate interpretation of results, we computed values of sensitivity at the point on the SROC curve with 80% fixed specificity and values of specificity with 80% fixed sensitivity. We investigated the impact of in-person test interpretation; use of a purposely-developed algorithm to assist diagnosis; and observer expertise.\n    \n\n\n          Main results:\n        \n      \n      We included 24 publications reporting on 24 study cohorts, providing 27 visual inspection datasets (8805 lesions; 2579 malignancies) and 33 dermoscopy datasets (6855 lesions; 1444 malignancies). The risk of bias was mainly low for the index test (for dermoscopy evaluations) and reference standard domains, particularly for in-person evaluations, and high or unclear for participant selection, application of the index test for visual inspection and for participant flow and timing. We scored concerns about the applicability of study findings as of 'high' or 'unclear' concern for almost all studies across all domains assessed. Selective participant recruitment, lack of reproducibility of diagnostic thresholds and lack of detail on observer expertise were particularly problematic.The detection of BCC was reported in 28 datasets; 15 on an in-person basis and 13 image-based. Analysis of studies by prior testing of participants and according to observer expertise was not possible due to lack of data. Studies were primarily conducted in participants referred for specialist assessment of lesions with available histological classification. We found no clear differences in accuracy between dermoscopy studies undertaken in person and those which evaluated images. The lack of effect observed may be due to other sources of heterogeneity, including variations in the types of skin lesion studied, in dermatoscopes used, or in the use of algorithms and varying thresholds for deciding on a positive test result.Meta-analysis found in-person evaluations of dermoscopy (7 evaluations; 4683 lesions and 363 BCCs) to be more accurate than visual inspection alone for the detection of BCC (8 evaluations; 7017 lesions and 1586 BCCs), with a relative diagnostic odds ratio (RDOR) of 8.2 (95% confidence interval (CI) 3.5 to 19.3; P < 0.001). This corresponds to predicted differences in sensitivity of 14% (93% versus 79%) at a fixed specificity of 80% and predicted differences in specificity of 22% (99% versus 77%) at a fixed sensitivity of 80%. We observed very similar results for the image-based evaluations.When applied to a hypothetical population of 1000 lesions, of which 170 are BCC (based on median BCC prevalence across studies), an increased sensitivity of 14% from dermoscopy would lead to 24 fewer BCCs missed, assuming 166 false positive results from both tests. A 22% increase in specificity from dermoscopy with sensitivity fixed at 80% would result in 183 fewer unnecessary excisions, assuming 34 BCCs missed for both tests. There was not enough evidence to assess the use of algorithms or structured checklists for either visual inspection or dermoscopy.Insufficient data were available to draw conclusions on the accuracy of either test for the detection of cSCCs.\n    \n\n\n          Authors' conclusions:\n        \n      \n      Dermoscopy may be a valuable tool for the diagnosis of BCC as an adjunct to visual inspection of a suspicious skin lesion following a thorough history-taking including assessment of risk factors for keratinocyte cancer. The evidence primarily comes from secondary-care (referred) populations and populations with pigmented lesions or mixed lesion types. There is no clear evidence supporting the use of currently-available formal algorithms to assist dermoscopy diagnosis."
        },
        {
            "title": "Past and present of computer-assisted dermoscopic diagnosis: performance of a conventional image analyser versus a convolutional neural network in a prospective data set of 1,981 skin lesions.",
            "abstract": "Background:\n        \n      \n      Convolutional neural networks (CNNs) have shown a dermatologist-level performance in the classification of skin lesions. We aimed to deliver a head-to-head comparison of a conventional image analyser (CIA), which depends on segmentation and weighting of handcrafted features, to a CNN trained by deep learning.\n    \n\n\n          Methods:\n        \n      \n      Cross-sectional study using a real-world, prospectively acquired, dermoscopic dataset of 1981 skin lesions to compare the diagnostic performance of a market-approved CNN (Moleanalyzer-Proâ„¢, developed in 2018) to a CIA (Moleanalyzer-3â„¢/Dynamoleâ„¢; developed in 2004, all FotoFinder Systems Inc, Germany). As a reference standard, we used histopathological diagnoses (n = 785) or, in non-excised benign lesions (n = 1196), expert consensus plus an uneventful follow-up by sequential digital dermoscopy for at least 2 years.\n    \n\n\n          Results:\n        \n      \n      A total of 281 malignant lesions and 1700 benign lesions from 435 patients (62.2% male, mean age: 52 years) were prospectively imaged. The CNN showed a sensitivity of 77.6% (95% confidence interval [CI]: [72.4%-82.1%]), specificity of 95.3% (95% CI: [94.2%-96.2%]), and receiver operating characteristic (ROC)-area under the curve (AUC) of 0.945 (95% CI: [0.930-0.961]). In contrast, the CIA achieved a sensitivity of 53.4% (95% CI: [47.5%-59.1%]), specificity of 86.6% (95% CI: [84.9%-88.1%]) and ROC-AUC of 0.738 (95% CI: [0.701-0.774]). The data set included melanomas originally diagnosed by dynamic changes during sequential digital dermoscopy (52 of 201, 20.6%), which reduced the sensitivities of both classifiers. Pairwise comparisons of sensitivities, specificities, and ROC-AUCs indicated a clear outperformance by the CNN (all p < 0.001).\n    \n\n\n          Conclusions:\n        \n      \n      The superior diagnostic performance of the CNN argues against a continued application of former CIAs as an aide to physicians' clinical management decisions."
        },
        {
            "title": "Pathologist initiated reflex BRAF mutation testing in metastatic melanoma: experience at a specialist melanoma treatment centre.",
            "abstract": "Testing for BRAF mutations in metastatic melanoma is pivotal to identifying patients suitable for targeted therapy and influences treatment decisions regarding single agent versus combination immunotherapy. Knowledge of BRAF V600E immunohistochemistry (IHC) results can streamline decisions during initial oncology consultations, prior to DNA-based test results. In the absence of formal guidelines that require pathologist initiated ('reflex') BRAF mutation testing, our institution developed a local protocol to perform BRAF V600E IHC on specimens from all stage III/IV melanoma patients when the status is otherwise unknown. This study was designed to evaluate the application of this protocol in a tertiary referral pathology department. A total of 408 stage III/IV melanoma patients had tissue specimens accessioned between 1 January and 31 March in three consecutive years (from 2019 to 2021), reported by 32 individual pathologists. The BRAF mutation status was established by pathologists in 87% (352/408) of cases. When a prior BRAF mutation status was previously known, as confirmed in linked electronic records (202/408), this status had been communicated by the clinician on the pathology request form in 1% of cases (3/202). Pathologists performed BRAF V600E IHC in 153 cases (74% of cases where the status was unknown, 153/206) and testing was duplicated in 5% of cases (20/408). Reflex BRAF IHC testing was omitted in 26% of cases (53/206), often on specimens with small volume disease (cytology specimens or sentinel node biopsies) despite adequate tissue for testing. Incorporating BRAF IHC testing within routine diagnostic protocols of stage III/IV melanoma was both feasible and successful in most cases. Communication of a patient's BRAF mutation status via the pathology request form will likely improve implementation of pathologist initiated BRAF mutation testing and may result in a reduction of duplicate tests. To improve pathologist reflex testing rates, we advocate for the use of an algorithmic approach to pathologist initiated BRAF mutation testing utilising both IHC and DNA-based methodologies for stage III/IV melanoma patients."
        },
        {
            "title": "Skin Cancer Detection Based on Extreme Learning Machine and a Developed Version of Thermal Exchange Optimization.",
            "abstract": "Melanoma is defined as a disease that has been incurable in advanced stages, which shows the vital importance of timely diagnosis and treatment. To diagnose this type of cancer early, various methods and equipment have been used, almost all of which required a visit to the doctor and were not available to the public. In this study, an automated and accurate process to differentiate between benign skin pigmented lesions and malignant melanoma is presented, so that it can be used by the general public, and it does not require special equipment and special conditions in imaging. In this study, after preprocessing of the input images, the region of interest is segmented based on the Otsu method. Then, a new feature extraction is implemented on the segmented image to mine the beneficial characteristics. The process is then finalized by using an optimized Deep Believe Network (DBN) for categorization into 2 classes of normal and melanoma cases. The optimization process in DBN has been performed by a developed version of the newly introduced Thermal Exchange Optimization (dTEO) algorithm to obtain higher efficacy in different terms. To show the method's superiority, its performance is compared with 7 different techniques from the literature."
        },
        {
            "title": "Views on mobile health apps for skin cancer screening in the general population: an in-depth qualitative exploration of perceived barriers and facilitators.",
            "abstract": "Background:\n        \n      \n      Mobile health (mHealth) applications (apps) incorporating artificial intelligence for skin cancer screening are increasingly reimbursed by health insurers. However, an in-depth exploration of the general public's views towards these apps is lacking.\n    \n\n\n          Objectives:\n        \n      \n      To explore the perceived barriers and facilitators towards mHealth apps for skin cancer screening among the Dutch general population.\n    \n\n\n          Methods:\n        \n      \n      A qualitative study consisting of four focus groups with 27 participants was conducted. A two-stage purposive sampling method was used to include information-rich participants from the Dutch general population with varying experience of mHealth. A topic guide was used to structure the sessions. All focus group meetings were transcribed verbatim and analysed in thematic content analysis by two researchers using several coding phases, resulting in an overview of themes and subthemes, categorized as (sub-)barriers and (sub)facilitators.\n    \n\n\n          Results:\n        \n      \n      Main barriers to using mHealth apps included a perceived lack of value, perception of untrustworthiness, preference for a doctor, privacy concerns, a complex user interface, and high costs. The main factors facilitating the use of mHealth among the general population were a high perceived value, a transparent and trustworthy identity of app developers, endorsement by healthcare providers and government regulating bodies, and ease and low costs of use.\n    \n\n\n          Conclusions:\n        \n      \n      To increase successful adoption in skin cancer screening apps, developers should create a transparent identity and build trustworthy apps. Collaboration between app developers, general practitioners and dermatologists is advocated to improve mHealth integration with skin cancer care. Special attention should be given to the development of low-cost, privacy-friendly, easy-to-use apps."
        },
        {
            "title": "Application of generated mask method based on Mask R-CNN in classification and detection of melanoma.",
            "abstract": "Objective:\n        \n      \n      Melanoma is a type of malignant skin cancer with high mortality, and its incidence is increasing rapidly in recent years. At present, the best treatment is surgical resection after early diagnosis. However, due to the high visual similarity between melanoma and benign melanocytic nevus, coupled with the scarcity and imbalance of data, traditional methods are difficult to achieve good recognition and detection results. Similarly, many machine learning methods have been applied to the task of skin disease detection and classification. However, the accuracy and sensitivity of the experiments are still not satisfactory. Therefore, this paper proposed a method to identify melanoma more efficiently and accurately.\n    \n\n\n          Method:\n        \n      \n      We implemented a Mixed Skin Lesion Picture Generate method based on Mask R-CNN (MSLP-MR) to solve the problem of data imbalance. Besides, we designed a melanoma detection framework of Mask-DenseNet+ based on MSLP-MR. This method used Mask R-CNN to introduce the method of mask segmentation, and combined with the idea of ensemble learning to integrate multiple classifiers for weighted prediction. Compared with the ablation experiments, the accuracy, sensitivity and AUC of the proposed network classification are improved by 2.56%, 29.33% and 0.0345.\n    \n\n\n          Result:\n        \n      \n      The experimental results on the ISIC dataset shown that the accuracy of the algorithm is 90.61%, the sensitivity reaches 78.00%, which is higher than the original methods; the specificity reaches 93.43%; and the AUC reaches 0.9502.\n    \n\n\n          Conclusion:\n        \n      \n      The method is feasible and effective, and achieves the preliminary goal of melanoma detection. It is greatly improved the detection accuracy and reached the level of visual diagnosis of doctors."
        },
        {
            "title": "Diagnostic performance of a deep learning convolutional neural network in the differentiation of combined naevi and melanomas.",
            "abstract": "Background:\n        \n      \n      Deep learning convolutional neural networks (CNN) may assist physicians in the diagnosis of melanoma. The capacity of a CNN to differentiate melanomas from combined naevi, the latter representing well-known melanoma simulators, has not been investigated.\n    \n\n\n          Objective:\n        \n      \n      To assess the diagnostic performance of a CNN when used to differentiate melanomas from combined naevi in comparison with dermatologists.\n    \n\n\n          Methods:\n        \n      \n      In this study, a CNN with regulatory approval for the European market (Moleanalyzer-Pro, FotoFinder Systems GmbH, Bad Birnbach, Germany) was used. We attained a dichotomous classification (benign, malignant) in dermoscopic images of 36 combined naevi and 36 melanomas with a mean Breslow thickness of 1.3 mm. Primary outcome measures were the CNN's sensitivity, specificity and the diagnostic odds ratio (DOR) in comparison with 11 dermatologists with different levels of experience.\n    \n\n\n          Results:\n        \n      \n      The CNN revealed a sensitivity, specificity and DOR of 97.1% (95% CI [82.7-99.6]), 78.8% (95% CI [62.8-89.1.3]) and 34 (95% CI [4.8-239]), respectively. Dermatologists showed a lower mean sensitivity, specificity and DOR of 90.6% (95% CI [84.1-94.7]; P = 0.092), 71.0% (95% CI [62.6-78.1]; P = 0.256) and 24 (95% CI [11.6-48.4]; P = 0.1114). Under the assumption that dermatologists use the CNN to verify their (initial) melanoma diagnosis, dermatologists achieve an increased specificity of 90.3% (95% CI [79.8-95.6]) at an almost unchanged sensitivity. The largest benefit was observed in 'beginners', who performed worst without CNN verification (DOR = 12) but best with CNN verification (DOR = 98).\n    \n\n\n          Conclusion:\n        \n      \n      The tested CNN more accurately classified combined naevi and melanomas in comparison with trained dermatologists. Their diagnostic performance could be improved if the CNN was used to confirm/overrule an initial melanoma diagnosis. Application of a CNN may therefore be of benefit to clinicians."
        },
        {
            "title": "Monitoring patients at risk for melanoma: May convolutional neural networks replace the strategy of sequential digital dermoscopy?",
            "abstract": "Background:\n        \n      \n      Sequential digital dermoscopy (SDD) is applied for early melanoma detection by uncovering dynamic changes of monitored lesions. Convolutional neural networks (CNN) are capable of high diagnostic accuracies similar to trained dermatologists.\n    \n\n\n          Objectives:\n        \n      \n      To investigate the capability of CNN to correctly classify melanomas originally diagnosed by mere dynamic changes during SDD.\n    \n\n\n          Methods:\n        \n      \n      A retrospective cross-sectional study using image quartets of 59 high-risk patients each containing one melanoma diagnosed by dynamic changes during SDD and three nevi (236 lesions). Two validated CNN classified quartets at baseline or after SDD follow-up at the time of melanoma diagnosis. Moreover, baseline quartets were rated by 26 dermatologists. The main outcome was the number of quartets with correct classifications.\n    \n\n\n          Results:\n        \n      \n      CNN-1 correctly classified 9 (15.3%) and CNN-2 8 (13.6%) of 59 baseline quartets. In baseline images, CNN-1 attained a sensitivity of 25.4% (16.1%-37.8%) and specificity of 92.7% (87.8%-95.7%), whereas CNN-2 of 28.8% (18.8%-41.4%) and 75.7% (68.9%-81.4%). Expectedly, after SDD follow-up CNN more readily detected melanomas resulting in improved sensitivities (CNN-1: 44.1% [32.2%-56.7%]; CNN-2: 49.2% [36.8%-61.6%]). Dermatologists were told that each baseline quartet contained one melanoma, and on average, correctly classified 24 (22-27) of 59 quartets. Correspondingly, accepting a baseline quartet to be appropriately classified whenever the highest malignancy score was assigned to the melanoma within, CNN-1 and CNN-2 correctly classified 28 (47.5%) and 22 (37.3%) of 59 quartets, respectively.\n    \n\n\n          Conclusions:\n        \n      \n      The tested CNN could not replace the strategy of SDD. There is a need for CNN capable of integrating information on dynamic changes into analyses."
        },
        {
            "title": "Melanoma segmentation using deep learning with test-time augmentations and conditional random fields.",
            "abstract": "In a computer-aided diagnostic (CAD) system for skin lesion segmentation, variations in shape and size of the skin lesion makes the segmentation task more challenging. Lesion segmentation is an initial step in CAD schemes as it leads to low error rates in quantification of the structure, boundary, and scale of the skin lesion. Subjective clinical assessment of the skin lesion segmentation results provided by current state-of-the-art deep learning segmentation techniques does not offer the required results as per the inter-observer agreement of expert dermatologists. This study proposes a novel deep learning-based, fully automated approach to skin lesion segmentation, including sophisticated pre and postprocessing approaches. We use three deep learning models, including UNet, deep residual U-Net (ResUNet), and improved ResUNet (ResUNet++). The preprocessing phase combines morphological filters with an inpainting algorithm to eliminate unnecessary hair structures from the dermoscopic images. Finally, we used test time augmentation (TTA) and conditional random field (CRF) in the postprocessing stage to improve segmentation accuracy. The proposed method was trained and evaluated on ISIC-2016 and ISIC-2017 skin lesion datasets. It achieved an average Jaccard Index of 85.96% and 80.05% for ISIC-2016 and ISIC-2017 datasets, when trained individually. When trained on combined dataset (ISIC-2016 and ISIC-2017), the proposed method achieved an average Jaccard Index of 80.73% and 90.02% on ISIC-2017 and ISIC-2016 testing datasets. The proposed methodological framework can be used to design a fully automated computer-aided skin lesion diagnostic system due to its high scalability and robustness."
        },
        {
            "title": "Diagnostic accuracy of dermatofluoroscopy in cutaneous melanoma detection: results of a prospective multicentre clinical study in 476 pigmented lesions.",
            "abstract": "Background:\n        \n      \n      Early detection is a key factor in improving survival from melanoma. Today, the clinical diagnosis of cutaneous melanoma is based mostly on visual inspection and dermoscopy. Preclinical studies in freshly excised or paraffin-embedded tissue have shown that the melanin fluorescence spectra after stepwise two-photon excitation, a process termed dermatofluoroscopy, differ between cutaneous melanoma and melanocytic naevi. However, confirmation from a larger prospective clinical study is lacking.\n    \n\n\n          Objectives:\n        \n      \n      The primary end point of this study was to determine the diagnostic accuracy of dermatofluoroscopy in melanoma detection. Secondary end points included the collection of data for improving the computer algorithm that classifies skin lesions based on melanin fluorescence and the assessment of safety aspects.\n    \n\n\n          Methods:\n        \n      \n      This was a prospective, blinded, multicentre clinical study in patients with pigmented skin lesions (PSLs) indicated for excision either to rule out or to confirm cutaneous melanoma. All included lesions underwent dermoscopy and dermatofluoroscopy in vivo before lesions were excised and subjected to histopathological examination.\n    \n\n\n          Results:\n        \n      \n      In total, 369 patients and 476 PSLs were included in the final analysis. In 101 of 476 lesions (21Â·2%) histopathology revealed melanoma. The observed sensitivity of dermatofluoroscopy was 89Â·1% (90 of 101 melanomas identified), with an observed specificity of 44Â·8%. The positive and negative predictive values were 30Â·3% and 93Â·9%, respectively. No adverse events occurred.\n    \n\n\n          Conclusions:\n        \n      \n      Dermatofluoroscopy is a safe and accurate diagnostic method to aid physicians in diagnosing cutaneous melanoma. Limitations arise from largely amelanotic or regressing lesions lacking sufficient melanin fluorescence."
        },
        {
            "title": "Deep-learning-based, computer-aided classifier developed with a small dataset of clinical images surpasses board-certified dermatologists in skin tumour diagnosis.",
            "abstract": "Background:\n        \n      \n      Application of deep-learning technology to skin cancer classification can potentially improve the sensitivity and specificity of skin cancer screening, but the number of training images required for such a system is thought to be extremely large.\n    \n\n\n          Objectives:\n        \n      \n      To determine whether deep-learning technology could be used to develop an efficient skin cancer classification system with a relatively small dataset of clinical images.\n    \n\n\n          Methods:\n        \n      \n      A deep convolutional neural network (DCNN) was trained using a dataset of 4867 clinical images obtained from 1842 patients diagnosed with skin tumours at the University of Tsukuba Hospital from 2003 to 2016. The images consisted of 14 diagnoses, including both malignant and benign conditions. Its performance was tested against 13 board-certified dermatologists and nine dermatology trainees.\n    \n\n\n          Results:\n        \n      \n      The overall classification accuracy of the trained DCNN was 76Â·5%. The DCNN achieved 96Â·3% sensitivity (correctly classified malignant as malignant) and 89Â·5% specificity (correctly classified benign as benign). Although the accuracy of malignant or benign classification by the board-certified dermatologists was statistically higher than that of the dermatology trainees (85Â·3% Â± 3Â·7% and 74Â·4% Â± 6Â·8%, P < 0Â·01), the DCNN achieved even greater accuracy, as high as 92Â·4% Â± 2Â·1% (P < 0Â·001).\n    \n\n\n          Conclusions:\n        \n      \n      We have developed an efficient skin tumour classifier using a DCNN trained on a relatively small dataset. The DCNN classified images of skin tumours more accurately than board-certified dermatologists. Collectively, the current system may have capabilities for screening purposes in general medical practice, particularly because it requires only a single clinical image for classification."
        },
        {
            "title": "Segmentation of dermoscopy images based on deformable 3D convolution and ResU-NeXt +.",
            "abstract": "Melanoma is one of the most dangerous skin cancers. The current melanoma segmentation is mainly based on FCNs (fully connected networks) and U-Net. Nevertheless, these two kinds of neural networks are prone to parameter redundancy, and the gradient of neural networks disappears that occurs when the neural network backpropagates as the neural network gets deeper, which will reduce the Jaccard index of the skin lesion image segmentation model. To solve the above problems and improve the survival rate of melanoma patients, an improved skin lesion segmentation model based on deformable 3D convolution and ResU-NeXt++ (D3DC- ResU-NeXt++) is proposed in this paper. The new modules in D3DC-ResU-NeXt++ can replace ordinary modules in the existing 2D convolutional neural networks (CNNs) that can be trained efficiently through standard backpropagation with high segmentation accuracy. In particular, we introduce a new data preprocessing method with dilation, crop operation, resizing, and hair removal (DCRH), which improves the Jaccard index of skin lesion image segmentation. Because rectified Adam (RAdam) does not easily fall into a local optimal solution and can converge quickly in segmentation model training, we also introduce RAdam as the training optimizer. The experiments show that our model has excellent performance on the segmentation of the ISIC2018 Task I dataset, and the Jaccard index achieves 86.84%. The proposed method improves the Jaccard index of segmentation of skin lesion images and can also assist dermatological doctors in determining and diagnosing the types of skin lesions and the boundary between lesions and normal skin, so as to improve the survival rate of skin cancer patients. Overview of the proposed model. An improved skin lesion segmentation model based on deformable 3D convolution and ResU-NeXt++ (D3DC- ResU-NeXt++) is proposed in this paper. D3DC-ResU-NeXt++ has strong spatial geometry processing capabilities, it is used to segment the skin lesion sample image; DCRH and transfer learning are used to preprocess the data set and D3DC-ResU-NeXt++ respectively, which can highlight the difference between the lesion area and the normal skin, and enhance the segmentation efficiency and robustness of the neural network; RAdam is used to speed up the convergence speed of neural network and improve the efficiency of segmentation."
        },
        {
            "title": "Dermoscopy use in UK primary care: a survey of GPs with a special interest in dermatology.",
            "abstract": "Background:\n        \n      \n      Melanoma accounts for 90% of skin cancer mortality and typically presents in primary care, where it can be challenging to distinguish from benign lesions. Dermoscopy is a tool for skin visualization that is routinely used for melanoma diagnosis in secondary care. However, the role of dermoscopy in primary care remains unclear.\n    \n\n\n          Objectives:\n        \n      \n      To determine views on, and use of, dermoscopy by dermatology-interested general practitioners (GPs).\n    \n\n\n          Methods:\n        \n      \n      An online questionnaire was emailed to the UK Primary Care Dermatology Society members in February 2018, and responses collected over the following 4 weeks.\n    \n\n\n          Results:\n        \n      \n      A total of 205 responses were analysed. Most respondents were GPs (94%), aged over 50 (53%), had a postgraduate dermatological qualification (67%) and used dermoscopy regularly when reviewing pigmented skin lesions (97%). Dermoscopy use was commoner amongst GPs who had worked longer in primary care and had experience of secondary care dermatology. Most had undertaken training in dermoscopy (91%), although one-fifth (20%) had not updated their training in over 5 years. Most of those who had received only 1 day of face-to-face training reported feeling confident using a dermatoscope. Few respondents (11%) reported access to teledermatology or teledermoscopy for urgent or routine referrals.\n    \n\n\n          Conclusions:\n        \n      \n      UK GPs with a special interest in dermatology are routinely using dermoscopy in the primary care setting. More research is needed to establish optimal approaches to training and updating GP dermoscopy skills. When dermoscopy has been shown to be safe, effective, acceptable and cost-effective in this setting, more GPs may also be able to gain and maintain the skills to implement dermoscopy into routine primary care. Technological advances, including incorporation of artificial intelligence (AI) and algorithms to guide GPs, could also contribute to widening use of dermoscopy among GPs."
        },
        {
            "title": "Cross With Caution: Antibiotic Cross-Reactivity and Co-Reactivity Patterns in Severe Cutaneous Adverse Reactions.",
            "abstract": "Current understanding of cross-reactivity in severe cutaneous adverse reactions to beta-lactam antibiotics is limited, thereby making recommendations for future prescribing difficult. The underlying immunopathogenesis of these reactions is not completely understood but involves interactions between small molecule drugs, T cells and HLA molecules. Historically, these reactions were considered to be specific to the inciting antibiotic and therefore likely to have minimal cross-reactivity. We assessed patients presenting with non-SJS/TEN severe cutaneous adverse reactions to a tertiary hospital drug allergy clinic. In our case series cross-reactivity or co-reactivity commonly occurred among the beta-lactam antibiotic class, however further research is required to investigate and understand patterns of cross-reactivity. Based on our experience we provide clinicians with a practical algorithm for testing for cross-reactivity in non-SJS/TEN severe cutaneous adverse reactions."
        },
        {
            "title": "Automatic Acne Object Detection and Acne Severity Grading Using Smartphone Images and Artificial Intelligence.",
            "abstract": "Skin image analysis using artificial intelligence (AI) has recently attracted significant research interest, particularly for analyzing skin images captured by mobile devices. Acne is one of the most common skin conditions with profound effects in severe cases. In this study, we developed an AI system called AcneDet for automatic acne object detection and acne severity grading using facial images captured by smartphones. AcneDet includes two models for two tasks: (1) a Faster R-CNN-based deep learning model for the detection of acne lesion objects of four types, including blackheads/whiteheads, papules/pustules, nodules/cysts, and acne scars; and (2) a LightGBM machine learning model for grading acne severity using the Investigator's Global Assessment (IGA) scale. The output of the Faster R-CNN model, i.e., the counts of each acne type, were used as input for the LightGBM model for acne severity grading. A dataset consisting of 1572 labeled facial images captured by both iOS and Android smartphones was used for training. The results show that the Faster R-CNN model achieves a mAP of 0.54 for acne object detection. The mean accuracy of acne severity grading by the LightGBM model is 0.85. With this study, we hope to contribute to the development of artificial intelligent systems to help acne patients better understand their conditions and support doctors in acne diagnosis."
        },
        {
            "title": "Educational and practice gaps in the management of volar melanocytic lesions.",
            "abstract": "Background:\n        \n      \n      The benign and malignant patterns of acral melanocytic naevi (AMN) and acral melanomas (AM) have been defined in a series of retrospective studies. A three-step algorithm was developed to determine when to biopsy acral melanocytic lesions. This algorithm has only been applied to a Japanese population.\n    \n\n\n          Objectives:\n        \n      \n      Our study aimed to review the current management strategy of acral melanocytic lesions and to investigate the utility of the three-step algorithm in a predominately Caucasian cohort.\n    \n\n\n          Methods:\n        \n      \n      A retrospective search of the pathology and image databases at Mayo Clinic was performed between the years 2006 and 2016. Only cases located on a volar surface with dermoscopic images were included. Two dermatologists reviewed all dermoscopic images and assigned a global dermoscopic pattern. Clinical and follow-up data were gathered by chart review. All lesions with known diameter and pathological diagnosis were used for the three-step algorithm.\n    \n\n\n          Results:\n        \n      \n      Regular fibrillar and ridge patterns were more likely to be biopsied (P = 0.01). The majority of AMN (58.1%) and AM (60%) biopsied were due to physician-deemed concerning dermoscopic patterns. 39.2% of these cases were parallel furrow, lattice-like or regular fibrillar. When patients were asked to follow-up within a 3- to 6-month period, only 16.7% of the patients returned within that interval. The three-step algorithm would have correctly identified four of five AM for biopsy, missing a 6 mm, multicomponent, invasive melanoma.\n    \n\n\n          Conclusion:\n        \n      \n      We found one major educational gap in the recognition of low-risk lesions with high rates of biopsy of the fibrillary pattern. Recognizing low-risk dermoscopic patterns could reduce the rate of biopsy of AMN by 23.3%. We identified two major practice gaps, poor patient compliance with follow-up and the potential insensitivity of the three-step algorithm to small multicomponent acral melanocytic lesions."
        },
        {
            "title": "Non-melanoma skin cancer diagnosis: a comparison between dermoscopic and smartphone images by unified visual and sonification deep learning algorithms.",
            "abstract": "Purpose:\n        \n      \n      Non-melanoma skin cancer (NMSC) is the most frequent keratinocyte-origin skin tumor. It is confirmed that dermoscopy of NMSC confers a diagnostic advantage as compared to visual face-to-face assessment. COVID-19 restrictions diagnostics by telemedicine photos, which are analogous to visual inspection, displaced part of in-person visits. This study evaluated by a dual convolutional neural network (CNN) performance metrics in dermoscopic (DI) versus smartphone-captured images (SI) and tested if artificial intelligence narrows the proclaimed gap in diagnostic accuracy.\n    \n\n\n          Methods:\n        \n      \n      A CNN that receives a raw image and predicts malignancy, overlaid by a second independent CNN which processes a sonification (image-to-sound mapping) of the original image, were combined into a unified malignancy classifier. All images were histopathology-verified in a comparison between NMSC and benign skin lesions excised as suspected NMSCs. Study criteria outcomes were sensitivity and specificity for the unified output.\n    \n\n\n          Results:\n        \n      \n      Images acquired by DI (n = 132 NMSC, n = 33 benign) were compared to SI (n = 170 NMSC, n = 28 benign). DI and SI analysis metrics resulted in an area under the curve (AUC) of the receiver operator characteristic curve of 0.911 and 0.821, respectively. Accuracy was increased by DI (0.88; CI 81.9-92.4) as compared to SI (0.75; CI 68.1-80.6, p < 0.005). Sensitivity of DI was higher than SI (95.3%, CI 90.4-98.3 vs 75.3%, CI 68.1-81.6, p < 0.001), but not specificity (p = NS).\n    \n\n\n          Conclusion:\n        \n      \n      Telemedicine use of smartphone images might result in a substantial decrease in diagnostic performance as compared to dermoscopy, which needs to be considered by both healthcare providers and patients."
        },
        {
            "title": "Texture based skin lesion abruptness quantification to detect malignancy.",
            "abstract": "Background:\n        \n      \n      Abruptness of pigment patterns at the periphery of a skin lesion is one of the most important dermoscopic features for detection of malignancy. In current clinical setting, abrupt cutoff of a skin lesion determined by an examination of a dermatologist. This process is subjective, nonquantitative, and error-prone. We present an improved computational model to quantitatively measure abruptness of a skin lesion over our previous method. To achieve this, we quantitatively analyze the texture features of a region within the lesion boundary. This region is bounded by an interior border line of the lesion boundary which is determined using level set propagation (LSP) method. This method provides a fast border contraction without a need for extensive boolean operations. Then, we build feature vectors of homogeneity, standard deviation of pixel values, and mean of the pixel values of the region between the contracted border and the original border. These vectors are then classified using neural networks (NN) and SVM classifiers.\n    \n\n\n          Results:\n        \n      \n      As lower homogeneity indicates sharp cutoffs, suggesting melanoma, we carried out our experiments on two dermoscopy image datasets, which consist of 800 benign and 200 malignant melanoma cases. LSP method helped produce better results than Kaya et al., 2016 study. By using texture homogeneity at the periphery of a lesion border determined by LSP, as a classification results, we obtained 87% f1-score and 78% specificity; that we obtained better results than in the previous study. We also compared the performances of two different NN classifiers and support vector machine classifier. The best results obtained using combination of RGB color spaces with the fully-connected multi-hidden layer NN.\n    \n\n\n          Conclusions:\n        \n      \n      Computational results also show that skin lesion abrupt cutoff is a reliable indicator of malignancy. Results show that computational model of texture homogeneity along the periphery of skin lesion borders based on LSP is an effective way of quantitatively measuring abrupt cutoff of a lesion."
        },
        {
            "title": "The Development of a Skin Cancer Classification System for Pigmented Skin Lesions Using Deep Learning.",
            "abstract": "Recent studies have demonstrated the usefulness of convolutional neural networks (CNNs) to classify images of melanoma, with accuracies comparable to those achieved by dermatologists. However, the performance of a CNN trained with only clinical images of a pigmented skin lesion in a clinical image classification task, in competition with dermatologists, has not been reported to date. In this study, we extracted 5846 clinical images of pigmented skin lesions from 3551 patients. Pigmented skin lesions included malignant tumors (malignant melanoma and basal cell carcinoma) and benign tumors (nevus, seborrhoeic keratosis, senile lentigo, and hematoma/hemangioma). We created the test dataset by randomly selecting 666 patients out of them and picking one image per patient, and created the training dataset by giving bounding-box annotations to the rest of the images (4732 images, 2885 patients). Subsequently, we trained a faster, region-based CNN (FRCNN) with the training dataset and checked the performance of the model on the test dataset. In addition, ten board-certified dermatologists (BCDs) and ten dermatologic trainees (TRNs) took the same tests, and we compared their diagnostic accuracy with FRCNN. For six-class classification, the accuracy of FRCNN was 86.2%, and that of the BCDs and TRNs was 79.5% (p = 0.0081) and 75.1% (p < 0.00001), respectively. For two-class classification (benign or malignant), the accuracy, sensitivity, and specificity were 91.5%, 83.3%, and 94.5% by FRCNN; 86.6%, 86.3%, and 86.6% by BCD; and 85.3%, 83.5%, and 85.9% by TRN, respectively. False positive rates and positive predictive values were 5.5% and 84.7% by FRCNN, 13.4% and 70.5% by BCD, and 14.1% and 68.5% by TRN, respectively. We compared the classification performance of FRCNN with 20 dermatologists. As a result, the classification accuracy of FRCNN was better than that of the dermatologists. In the future, we plan to implement this system in society and have it used by the general public, in order to improve the prognosis of skin cancer."
        },
        {
            "title": "Melanoma lesion detection and segmentation using deep region based convolutional neural network and fuzzy C-means clustering.",
            "abstract": "Objective:\n        \n      \n      Melanoma is a dangerous form of the skin cancer responsible for thousands of deaths every year. Early detection of melanoma is possible through visual inspection of pigmented lesions over the skin, treated with simple excision of the cancerous cells. However, due to the limited availability of dermatologists, the visual inspection alone has the limited and variable accuracy that leads the patient to undergo a series of biopsies and complicates the treatment. In this work, a deep learning method is proposed for automated Melanoma region segmentation using dermoscopic images to overcome the challenges of automated Melanoma region segmentation within dermoscopic images.\n    \n\n\n          Materials and methods:\n        \n      \n      A deep region based convolutional neural network (RCNN) precisely detects the multiple affected regions in the form of bounding boxes that simplify localization through Fuzzy C-mean (FCM) clustering. Our method constitutes of three step process: skin refinement, localization of Melanoma region, and finally segmentation of Melanoma. We applied the proposed method on benchmark dataset ISIC-2016 by International Symposium on biomedical images (ISBI) having 900 training and 376 testing Melanoma dermatological images.\n    \n\n\n          Main findings:\n        \n      \n      The performance is evaluated for Melanoma segmentation using various quantitative measures. Our method achieved average values of pixel level specificity (SP) as 0.9417, pixel level sensitivity (SE) as 0.9781, F1 _ s core as 0.9589, pixel level accuracy (Ac) as 0.948. In addition, average dice score (Di) of segmentation was recorded as 0.94, which represents good segmentation performance. Moreover, Jaccard coefficient (Jc) averaged value on entire testing images was 0.93. Comparative analysis with the state of art methods and the results have demonstrated the superiority of the proposed method.\n    \n\n\n          Conclusion:\n        \n      \n      In contrast with state of the art systems, the RCNN is capable to compute deep features with amen representation of Melanoma, and hence improves the segmentation performance. The RCNN can detect features for multiple skin diseases of the same patient as well as various diseases of different patients with efficient training mechanism. Series of experiments towards Melanoma detection and segmentation validates the effectiveness of our method."
        },
        {
            "title": "Incorporating clinical knowledge with constrained classifier chain into a multimodal deep network for melanoma detection.",
            "abstract": "In recent years, vast developments in Computer-Aided Diagnosis (CAD) for skin diseases have generated much interest from clinicians and other eventual end-users of this technology. Introducing clinical domain knowledge to these machine learning strategies can help dispel the black box nature of these tools, strengthening clinician trust. Clinical domain knowledge also provides new information channels which can improve CAD diagnostic performance. In this paper, we propose a novel framework for malignant melanoma (MM) detection by fusing clinical images and dermoscopic images. The proposed method combines a multi-labeled deep feature extractor and clinically constrained classifier chain (CC). This allows the 7-point checklist, a clinician diagnostic algorithm, to be included in the decision level while maintaining the clinical importance of the major and minor criteria in the checklist. Our proposed framework achieved an average accuracy of 81.3% for detecting all criteria and melanoma when testing on a publicly available 7-point checklist dataset. This is the highest reported results, outperforming state-of-the-art methods in the literature by 6.4% or more. Analyses also show that the proposed system surpasses the single modality system of using either clinical images or dermoscopic images alone and the systems without adopting the approach of multi-label and clinically constrained classifier chain. Our carefully designed system demonstrates a substantial improvement over melanoma detection. By keeping the familiar major and minor criteria of the 7-point checklist and their corresponding weights, the proposed system may be more accepted by physicians as a human-interpretable CAD tool for automated melanoma detection."
        },
        {
            "title": "A Point-of-Care, Real-Time Artificial Intelligence System to Support Clinician Diagnosis of a Wide Range of Skin Diseases.",
            "abstract": "Dermatological diagnosis remains challenging for nonspecialists because the morphologies of primary skin lesions widely vary from patient to patient. Although previous studies have used artificial intelligence (AI) to classify lesions as benign or malignant, there have not been extensive studies examining the use of AI on identifying and categorizing a primary skin lesion's morphology. In this study, we evaluate the performance of a standalone AI tool to correctly categorize a skin lesion's morphology from a test bank of images. To provide a marker of performance, we evaluate the accuracy of primary care physicians to categorize skin lesion morphology in the same test bank of images without any aids and then with the aid of a simple visual guide. The AI system achieved an accuracy of 68% in determining the single most likely morphology from the test image bank. When the AI's top prediction was broadened to its top three most likely predictions, accuracy improved to 80%. In comparison, the diagnostic accuracy of primary care physicians was 36% without any aids and 68% with the visual guide (P < 0.001). The AI was subsequently tested on an additional set of 222 heterogeneous images of varying Fitzpatrick skin types and achieved an overall accuracy of 70% in the Fitzpatrick I-III skin type group and 68% in the Fitzpatrick IV-VI skin type group (P = 0.79). An AI is a powerful tool to assist physicians in the diagnosis of skin lesions while still requiring the user to critically consider other possible diagnoses."
        },
        {
            "title": "Improved boundary segmentation of skin lesions in high-frequency 3D ultrasound.",
            "abstract": "In this article, we propose a segmentation algorithm for skin lesions in 3D high-frequency ultrasound images. The segmentation is done on melanoma and Basal-cell carcinoma tumors, the most common skin cancer types, and could be used for diagnosis and surgical excision planning in a clinical context. Compared with previously proposed algorithms, which tend to underestimate the size of the lesion, we propose two new boundary terms which provide significant improvements of the accuracy. The first is a probabilistic boundary expansion (PBE) term designed to broaden the segmented area at the boundaries, which uses the feature asymmetry criterion. The second is a curvature dependent regularization (CDR), which aims at overcoming the tendency of standard regularization to shrink segmented areas. On a clinical dataset of 12 patients annotated by a dermatologist, the proposed algorithm has a comparable Dice index but increases the sensitivity by 26%. The proposed algorithm improves the sensitivity for all lesions, and the obtained sensitivity is close to that of the intra-observer variability."
        },
        {
            "title": "A Novel Approach to Skin Lesion Segmentation: Multipath Fusion Model with Fusion Loss.",
            "abstract": "Segmentation of skin lesions plays a very important role in the early detection of skin cancer. However, indistinguishability due to various artifacts such as hair and contrast between normal skin and lesioned skin is an important challenge for specialist dermatologists. Computer-aided diagnostic systems using deep convolutional neural networks are gaining importance in order to cope with difficulties. This study focuses on deep learning-based fusion networks and fusion loss functions. For the automatic segmentation of skin lesions, U-Net (U-Net + ResNet 2D) with 2D residual blocks and 2D volumetric convolutional neural networks were fused for the first time in this study. Also, a new fusion loss function is proposed by combining Dice Loss (DL) and Focal Tversky Loss (FTL) to make the proposed fused model more robust. Of the 2594 image dataset, 20% is reserved for test data and 80% for training data. In test data training, a Jaccard score of 0.837 and a dice score of 0.918 were obtained. The proposed model was also scored on the ISIC 2018 Task 1 test images, whose ground truths were not shared. The proposed model performed well and achieved a Jaccard index of 0.800 and a dice score of 0.880 in the ISIC 2018 Task 1 test set. In addition, it has been observed that the new fused loss function obtained by fusing Focal Tversky Loss and Dice Loss functions in the proposed model increases the robustness of the model in the tests. The proposed new loss function fusion model has outstripped the cutting-edge approaches in the literature."
        },
        {
            "title": "Rash Decisions: An Approach to Dangerous Rashes Based on Morphology.",
            "abstract": "Background:\n        \n      \n      Rash is a common complaint in the emergency department. Many causes of rash are benign; however, some patients may have a life-threatening diagnosis.\n    \n\n\n          Objective:\n        \n      \n      This review will present an algorithmic approach to rashes, focusing on life-threatening causes of rash in each category.\n    \n\n\n          Discussion:\n        \n      \n      Rash is common, with a wide range of etiologies. The differential is broad, consisting of many conditions that are self-resolving. However, several conditions associated with rash are life threatening. Several keys can be utilized to rapidly diagnose and manage these deadly rashes. Thorough history and physical examination, followed by consideration of red flags, are essential. This review focuses on four broad categories based on visual and tactile characteristic patterns of rashes: petechial/purpuric, erythematous, maculopapular, and vesiculobullous. Rashes in each morphologic group will be further categorized based on clinical features such as the presence or absence of fever and distribution of skin lesions.\n    \n\n\n          Conclusions:\n        \n      \n      Rashes can be divided into petechial/purpuric, erythematous, maculopapular, and vesiculobullous. After this differentiation, the presence of fever and systemic signs of illness should be assessed. Through the breakdown of rashes into these classes, emergency providers can ensure deadly conditions are considered."
        },
        {
            "title": "Automatic Extraction of Dermatological Parameters from Nevi Using an Inexpensive Smartphone Microscope: A Proof of Concept.",
            "abstract": "The evolution of smartphone technology has made their use more common in dermatological applications. Here we studied the feasibility of using an inexpensive smartphone microscope for the extraction of dermatological parameters and compared the results obtained with a portable dermoscope, commonly used in clinical practice. Forty-two skin lesions were imaged with both devices and visually analyzed by an expert dermatologist. The presence of a reticular pattern was observed in 22 dermoscopic images, but only in 10 smartphone images. The proposed paradigm segments the image and extracts texture features which are used to train and validate a neural network to classify the presence of a reticular pattern. Using 5-fold cross-validation, an accuracy of 100% and 95% was obtained with the dermoscopic and smartphone images, respectively. This approach can be useful for general practitioners and as a triage tool for skin lesion analysis."
        },
        {
            "title": "Utilizing Machine Learning for Image Quality Assessment for Reflectance Confocal Microscopy.",
            "abstract": "In vivo reflectance confocal microscopy (RCM) enables clinicians to examine lesions' morphological and cytological information in epidermal and dermal layers while reducing the need for biopsies. As RCM is being adopted more widely, the workflow is expanding from real-time diagnosis at the bedside to include a capture, store, and forward model with image interpretation and diagnosis occurring offsite, similar to radiology. As the patient may no longer be present at the time of image interpretation, quality assurance is key during image acquisition. Herein, we introduce a quality assurance process by means of automatically quantifying diagnostically uninformative areas within the lesional area by using RCM and coregistered dermoscopy images together. We trained and validated a pixel-level segmentation model on 117 RCM mosaics collected by international collaborators. The model delineates diagnostically uninformative areas with 82% sensitivity and 93% specificity. We further tested the model on a separate set of 372 coregistered RCM-dermoscopic image pairs and illustrate how the results of the RCM-only model can be improved via a multimodal (RCM + dermoscopy) approach, which can help quantify the uninformative regions within the lesional area. Our data suggest that machine learning-based automatic quantification offers a feasible objective quality control measure for RCM imaging."
        },
        {
            "title": "Systematic outperformance of 112 dermatologists in multiclass skin cancer image classification by convolutional neural networks.",
            "abstract": "Background:\n        \n      \n      Recently, convolutional neural networks (CNNs) systematically outperformed dermatologists in distinguishing dermoscopic melanoma and nevi images. However, such a binary classification does not reflect the clinical reality of skin cancer screenings in which multiple diagnoses need to be taken into account.\n    \n\n\n          Methods:\n        \n      \n      Using 11,444 dermoscopic images, which covered dermatologic diagnoses comprising the majority of commonly pigmented skin lesions commonly faced in skin cancer screenings, a CNN was trained through novel deep learning techniques. A test set of 300 biopsy-verified images was used to compare the classifier's performance with that of 112 dermatologists from 13 German university hospitals. The primary end-point was the correct classification of the different lesions into benign and malignant. The secondary end-point was the correct classification of the images into one of the five diagnostic categories.\n    \n\n\n          Findings:\n        \n      \n      Sensitivity and specificity of dermatologists for the primary end-point were 74.4% (95% confidence interval [CI]: 67.0-81.8%) and 59.8% (95% CI: 49.8-69.8%), respectively. At equal sensitivity, the algorithm achieved a specificity of 91.3% (95% CI: 85.5-97.1%). For the secondary end-point, the mean sensitivity and specificity of the dermatologists were at 56.5% (95% CI: 42.8-70.2%) and 89.2% (95% CI: 85.0-93.3%), respectively. At equal sensitivity, the algorithm achieved a specificity of 98.8%. Two-sided McNemar tests revealed significance for the primary end-point (p < 0.001). For the secondary end-point, outperformance (p < 0.001) was achieved except for basal cell carcinoma (on-par performance).\n    \n\n\n          Interpretation:\n        \n      \n      Our findings show that automated classification of dermoscopic melanoma and nevi images is extendable to a multiclass classification problem, thus better reflecting clinical differential diagnoses, while still outperforming dermatologists at a significant level (p < 0.001)."
        },
        {
            "title": "An attention-based weakly supervised framework for spitzoid melanocytic lesion diagnosis in whole slide images.",
            "abstract": "Melanoma is an aggressive neoplasm responsible for the majority of deaths from skin cancer. Specifically, spitzoid melanocytic tumors are one of the most challenging melanocytic lesions due to their ambiguous morphological features. The gold standard for its diagnosis and prognosis is the analysis of skin biopsies. In this process, dermatopathologists visualize skin histology slides under a microscope, in a highly time-consuming and subjective task. In the last years, computer-aided diagnosis (CAD) systems have emerged as a promising tool that could support pathologists in daily clinical practice. Nevertheless, no automatic CAD systems have yet been proposed for the analysis of spitzoid lesions. Regarding common melanoma, no system allows both the selection of the tumor region and the prediction of the benign or malignant form in the diagnosis. Motivated by this, we propose a novel end-to-end weakly supervised deep learning model, based on inductive transfer learning with an improved convolutional neural network (CNN) to refine the embedding features of the latent space. The framework is composed of a source model in charge of finding the tumor patch-level patterns, and a target model focuses on the specific diagnosis of a biopsy. The latter retrains the backbone of the source model through a multiple instance learning workflow to obtain the biopsy-level scoring. To evaluate the performance of the proposed methods, we performed extensive experiments on a private skin database with spitzoid lesions. Test results achieved an accuracy of 0.9231 and 0.80 for the source and the target models, respectively. In addition, the heat map findings are directly in line with the clinicians' medical decision and even highlight, in some cases, patterns of interest that were overlooked by the pathologist."
        },
        {
            "title": "A deep learning, image based approach for automated diagnosis for inflammatory skin diseases.",
            "abstract": "Background:\n        \n      \n      As the booming of deep learning era, especially the advances in convolutional neural networks (CNNs), CNNs have been applied in medicine fields like radiology and pathology. However, the application of CNNs in dermatology, which is also based on images, is very limited. Inflammatory skin diseases, such as psoriasis (Pso), eczema (Ecz), and atopic dermatitis (AD), are very easily to be mis-diagnosed in practice.\n    \n\n\n          Methods:\n        \n      \n      Based on the EfficientNet-b4 CNN algorithm, we developed an artificial intelligence dermatology diagnosis assistant (AIDDA) for Pso, Ecz & AD and healthy skins (HC). The proposed CNN model was trained based on 4,740 clinical images, and the performance was evaluated on experts-confirmed clinical images grouped into 3 different dermatologist-labelled diagnosis classifications (HC, Pso, Ecz & AD).\n    \n\n\n          Results:\n        \n      \n      The overall diagnosis accuracy of AIDDA is 95.80%Â±0.09%, with the sensitivity of 94.40%Â±0.12% and specificity 97.20%Â±0.06%. AIDDA showed accuracy for Pso is 89.46%, with sensitivity of 91.4% and specificity of 95.48%, and accuracy for AD & Ecz 92.57%, with sensitivity of 94.56% and specificity of 94.41%.\n    \n\n\n          Conclusions:\n        \n      \n      AIDDA is thus already achieving an impact in the diagnosis of inflammatory skin diseases, highlighting how deep learning network tools can help advance clinical practice."
        },
        {
            "title": "Non-invasive scoring of cellular atypia in keratinocyte cancers in 3D LC-OCT images using Deep Learning.",
            "abstract": "Diagnosis based on histopathology for skin cancer detection is today's gold standard and relies on the presence or absence of biomarkers and cellular atypia. However it suffers drawbacks: it requires a strong expertise and is time-consuming. Moreover the notion of atypia or dysplasia of the visible cells used for diagnosis is very subjective, with poor inter-rater agreement reported in the literature. Lastly, histology requires a biopsy which is an invasive procedure and only captures a small sample of the lesion, which is insufficient in the context of large fields of cancerization. Here we demonstrate that the notion of cellular atypia can be objectively defined and quantified with a non-invasive in-vivo approach in three dimensions (3D). A Deep Learning (DL) algorithm is trained to segment keratinocyte (KC) nuclei from Line-field Confocal Optical Coherence Tomography (LC-OCT) 3D images. Based on these segmentations, a series of quantitative, reproducible and biologically relevant metrics is derived to describe KC nuclei individually. We show that, using those metrics, simple and more complex definitions of atypia can be derived to discriminate between healthy and pathological skins, achieving Area Under the ROC Curve (AUC) scores superior than 0.965, largely outperforming medical experts on the same task with an AUC of 0.766. All together, our approach and findings open the door to a precise quantitative monitoring of skin lesions and treatments, offering a promising non-invasive tool for clinical studies to demonstrate the effects of a treatment and for clinicians to assess the severity of a lesion and follow the evolution of pre-cancerous lesions over time."
        },
        {
            "title": "Artificial Intelligence for the Objective Evaluation of Acne Investigator Global Assessment.",
            "abstract": "Introduction:\n        \n      \n      The evaluation of Acne using ordinal scales reflects the clinical perception of severity but has shown low reproducibility both intra- and inter-rater. In this study, we investigated if Artificial Intelligence trained on images of Acne patients could perform acne grading with high accuracy and reliabilities superior to those of expert physicians.\n    \n\n\n          Methods:\n        \n      \n      479 patients with acne grading ranging from clear to severe and sampled from three ethnic groups participated in this study. Multi-polarization images of facial skin of each patient were acquired from five different angles using the visible spectrum. An Artificial Intelligence was trained using the acquired images to output automatically a measure of Acne severity in the 0-4 numerical range of the Investigator Global Assessment (IGA).\n    \n\n\n          Results:\n        \n      \n      The Artificial Intelligence recognized the IGA of a patient with an accuracy of 0.854 and a correlation between manual and automatized evaluation of r=0.958 (P less than .001).\n    \n\n\n          Discussion:\n        \n      \n      This is the first work where an Artificial Intelligence was able to directly classify acne patients according to an IGA ordinal scale with high accuracy, no human intervention and no need to count lesions. J Drugs Dermatol. 2018;17(9):1006-1009."
        },
        {
            "title": "Identification of Cancerous Skin Lesions Using Vibrational Optical Coherence Tomography (VOCT): Use of VOCT in Conjunction with Machine Learning to Diagnose Skin Cancer Remotely Using Telemedicine.",
            "abstract": "In this pilot study, we used vibrational optical tomography (VOCT), along with machine learning, to evaluate the specificity and sensitivity of using light and audible sound to differentiate between normal skin and skin cancers. The results reported indicate that the use of machine learning, and the height and location of the VOCT mechanovibrational peaks, have potential for being used to noninvasively differentiate between normal skin and different cancerous lesions. VOCT data, along with machine learning, is shown to predict the differences between normal skin and different skin cancers with a sensitivity and specificity at rates between 78 and 90%. The sensitivity and specificity will be improved using a larger database and by using other AI techniques. Ultimately, VOCT data, visual inspection, and dermoscopy, in conjunction with machine learning, will be useful in telemedicine to noninvasively identify potentially malignant skin cancers in remote areas of the country where dermatologists are not readily available."
        },
        {
            "title": "Characterization of the Workspace and Limits of Operation of Laser Treatments for Vascular Lesions of the Lower Limbs.",
            "abstract": "The increase of the aging population brings numerous challenges to health and aesthetic segments. Here, the use of laser therapy for dermatology is expected to increase since it allows for non-invasive and infection-free treatments. However, existing laser devices require doctors' manually handling and visually inspecting the skin. As such, the treatment outcome is dependent on the user's expertise, which frequently results in ineffective treatments and side effects. This study aims to determine the workspace and limits of operation of laser treatments for vascular lesions of the lower limbs. The results of this study can be used to develop a robotic-guided technology to help address the aforementioned problems. Specifically, workspace and limits of operation were studied in eight vascular laser treatments. For it, an electromagnetic tracking system was used to collect the real-time positioning of the laser during the treatments. The computed average workspace length, height, and width were 0.84 Â± 0.15, 0.41 Â± 0.06, and 0.78 Â± 0.16 m, respectively. This corresponds to an average volume of treatment of 0.277 Â± 0.093 m3. The average treatment time was 23.2 Â± 10.2 min, with an average laser orientation of 40.6 Â± 5.6 degrees. Additionally, the average velocities of 0.124 Â± 0.103 m/s and 31.5 + 25.4 deg/s were measured. This knowledge characterizes the vascular laser treatment workspace and limits of operation, which may ease the understanding for future robotic system development."
        },
        {
            "title": "Attitudes Toward Artificial Intelligence Within Dermatopathology: An International Online Survey.",
            "abstract": "Background: Artificial intelligence (AI) has recently surfaced as a research topic in dermatology and dermatopathology. In a recent survey, dermatologists were overall positive toward a development with an increased use of AI, but little is known about the corresponding attitudes among pathologists working with dermatopathology. The objective of this investigation was to make an inventory of these attitudes. Participants and Methods: An anonymous and voluntary online survey was prepared and distributed to pathologists who regularly analyzed dermatopathology slides/images. The survey consisted of 39 question divided in five sections; (1) AI as a topic in pathology; (2) previous exposure to AI as a topic in general; (3) applications for AI in dermatopathology; (4) feelings and attitudes toward AI and (5) self-reported tech-savviness and demographics. The survey opened on March 13, 2020 and closed on May 5, 2020. Results: Overall, 718 responders (64.1% females) representing 91 countries were analyzed. While 81.5% of responders were aware of AI as an emerging topic in pathology, only 18.8% had either good or excellent knowledge about AI. In terms of diagnosis classification, 42.6% saw strong or very strong potential for automated suggestion of skin tumor diagnoses. The corresponding figure for inflammatory skin diseases was 23.0% (Padj < 0.0001). For specific applications, the highest potential was considered for automated detection of mitosis (79.2%), automated suggestion of tumor margins (62.1%) and immunostaining evaluation (62.7%). The potential for automated suggestion of immunostaining (37.6%) and genetic panels (48.3%) were lower. Age did not impact the overall attitudes toward AI. Only 6.0% of the responders agreed or strongly agreed that the human pathologist will be replaced by AI in the foreseeable future. For the entire group, 72.3% agreed or strongly agreed that AI will improve dermatopathology and 84.1% thought that AI should be a part of medical training. Conclusions: Pathologists are generally optimistic about the impact and potential benefit of AI in dermatopathology. The highest potential is expected for narrow specified tasks rather than a global automated suggestion of diagnoses. There is a strong need for education about AI and its use within dermatopathology."
        },
        {
            "title": "Deep Learning for Diagnostic Binary Classification of Multiple-Lesion Skin Diseases.",
            "abstract": "Background: Diagnosis of skin diseases is often challenging and computer-aided diagnostic tools are urgently needed to underpin decision making. Objective: To develop a convolutional neural network model to classify clinically relevant selected multiple-lesion skin diseases, this in accordance to the STARD guidelines. Methods: This was an image-based retrospective study using multi-task learning for binary classification. A VGG-16 model was trained on 16,543 non-standardized images. Image data was distributed in training set (80%), validation set (10%), and test set (10%). All images were collected from a clinical database of a Danish population attending one dermatological department. Included was patients categorized with ICD-10 codes related to acne, rosacea, psoriasis, eczema, and cutaneous t-cell lymphoma. Results: Acne was distinguished from rosacea with a sensitivity of 85.42% CI 72.24-93.93% and a specificity of 89.53% CI 83.97-93.68%, cutaneous t-cell lymphoma was distinguished from eczema with a sensitivity of 74.29% CI 67.82-80.05% and a specificity of 84.09% CI 80.83-86.99%, and psoriasis from eczema with a sensitivity of 81.79% CI 78.51-84.76% and a specificity of 73.57% CI 69.76-77.13%. All results were based on the test set. Conclusion: The performance rates reported were equal or superior to those reported for general practitioners with dermatological training, indicating that computer-aided diagnostic models based on convolutional neural network may potentially be employed for diagnosing multiple-lesion skin diseases."
        },
        {
            "title": "A cell phone app for facial acne severity assessment.",
            "abstract": "Acne vulgaris, the most common skin disease, can cause substantial economic and psychological impacts to the people it affects, and its accurate grading plays a crucial role in the treatment of patients. In this paper, we firstly proposed an acne grading criterion that considers lesion classifications and a metric for producing accurate severity ratings. Due to similar appearance of acne lesions with comparable severities and difficult-to-count lesions, severity assessment is a challenging task. We cropped facial skin images of several lesion patches and then addressed the acne lesion with a lightweight acne regular network (Acne-RegNet). Acne-RegNet was built by using a median filter and histogram equalization to improve image quality, a channel attention mechanism to boost the representational power of network, a region-based focal loss to handle classification imbalances and a model pruning and feature-based knowledge distillation to reduce model size. After the application of Acne-RegNet, the severity score is calculated, and the acne grading is further optimized by the metadata of the patients. The entire acne assessment procedure was deployed to a mobile device, and a phone app was designed. Compared with state-of-the-art lightweight models, the proposed Acne-RegNet significantly improves the accuracy of lesion classifications. The acne app demonstrated promising results in severity assessments (accuracy: 94.56%) and showed a dermatologist-level diagnosis on the internal clinical dataset.The proposed acne app could be a useful adjunct to assess acne severity in clinical practice and it enables anyone with a smartphone to immediately assess acne, anywhere and anytime."
        },
        {
            "title": "Design and Assessment of Convolutional Neural Network Based Methods for Vitiligo Diagnosis.",
            "abstract": "Background: Today's machine-learning based dermatologic research has largely focused on pigmented/non-pigmented lesions concerning skin cancers. However, studies on machine-learning-aided diagnosis of depigmented non-melanocytic lesions, which are more difficult to diagnose by unaided eye, are very few. Objective: We aim to assess the performance of deep learning methods for diagnosing vitiligo by deploying Convolutional Neural Networks (CNNs) and comparing their diagnosis accuracy with that of human raters with different levels of experience. Methods: A Chinese in-house dataset (2,876 images) and a world-wide public dataset (1,341 images) containing vitiligo and other depigmented/hypopigmented lesions were constructed. Three CNN models were trained on close-up images in both datasets. The results by the CNNs were compared with those by 14 human raters from four groups: expert raters (>10 years of experience), intermediate raters (5-10 years), dermatology residents, and general practitioners. F1 score, the area under the receiver operating characteristic curve (AUC), specificity, and sensitivity metrics were used to compare the performance of the CNNs with that of the raters. Results: For the in-house dataset, CNNs achieved a comparable F1 score (mean [standard deviation]) with expert raters (0.8864 [0.005] vs. 0.8933 [0.044]) and outperformed intermediate raters (0.7603 [0.029]), dermatology residents (0.6161 [0.068]) and general practitioners (0.4964 [0.139]). For the public dataset, CNNs achieved a higher F1 score (0.9684 [0.005]) compared to the diagnosis of expert raters (0.9221 [0.031]). Conclusion: Properly designed and trained CNNs are able to diagnose vitiligo without the aid of Wood's lamp images and outperform human raters in an experimental setting."
        },
        {
            "title": "Electrochemotherapy as palliative treatment in patients with recurrent and/or metastatic head and neck tumours: features analysis for an early determination of the partial responsive patients.",
            "abstract": "Objective:\n        \n      \n      The aim of this study was to identify features mainly involved in determining the partial response (PR) to the Electrochemotherapy (ECT) in patients with recurrent and/or metastatic head and neck (H&N) tumor; the identified features were also used in a decision chart in order to provide the clinician with a support tool in deciding further therapies.\n    \n\n\n          Patients and methods:\n        \n      \n      131 patients (186 treatment sessions) with recurrent and/or metastatic H&N neoplasm were subjected to ECT. Treatment response was evaluated based on Response Evaluation Criteria in Solid Tumors (RECIST) v. 1.1 two months after the ECT. The grade of bleeding and pain before, at the end and one week after ECT treatment were evaluated. Univariate and multivariate analysis were performed to identify features involved in determining the patient PR.\n    \n\n\n          Results:\n        \n      \n      In the context of the univariate analysis, tumor size significantly influenced the response to ECT, with higher PR rate of 58.3%: 28 among 48 patients with lesion size â‰¤ 3 centimeters (p-value < 0.001 at Chi-square test). Pain and bleeding pre-treatment were positively correlated to PR (p-value < 0.001 at Chi-square test). A difference in the current flowing in the tissue during treatment was also observed in partially responsive patients, where the median current value (6.6 A) was higher than that achieved in patients that did not show PR (3.3 A). In the context of the multivariate analysis, the best performances are achieved with the BART method (accuracy of 84%). The main clinical factors to predict the partial response, among investigated features, that have shown to be considered were the pain value felt before performing the treatment and the median current delivered during the ECT treatment. A decision-making support tool to predict the patient prognosis in terms of response rate could be represented by the decision tree obtained with CART algorithm, where a pain pre-treatment more than 5 and a median delivered current not less than 2.8 A led to the prediction a partial responsive patient with an accuracy of 75%.\n    \n\n\n          Conclusions:\n        \n      \n      The study confirmed that ECT is an interesting antitumoral therapy in advanced chemo- and radio-refractory H&N neoplasms, able to reduce frequent symptoms and to improve the quality of life. Pain pre-treatment and delivered current are the most important variables when predicting the partial response of patients."
        },
        {
            "title": "Augmenting the accuracy of trainee doctors in diagnosing skin lesions suspected of skin neoplasms in a real-world setting: A prospective controlled before-and-after study.",
            "abstract": "Background:\n        \n      \n      Although deep neural networks have shown promising results in the diagnosis of skin cancer, a prospective evaluation in a real-world setting could confirm these results. This study aimed to evaluate whether an algorithm (http://b2019.modelderm.com) improves the accuracy of nondermatologists in diagnosing skin neoplasms.\n    \n\n\n          Methods:\n        \n      \n      A total of 285 cases (random series) with skin neoplasms suspected of malignancy by either physicians or patients were recruited in two tertiary care centers located in South Korea. An artificial intelligence (AI) group (144 cases, mean [SD] age, 57.0 [17.7] years; 62 [43.1%] men) was diagnosed via routine examination with photographic review and assistance by the algorithm, whereas the control group (141 cases, mean [SD] age, 61.0 [15.3] years; 52 [36.9%] men) was diagnosed only via routine examination with a photographic review. The accuracy of the nondermatologists before and after the interventions was compared.\n    \n\n\n          Results:\n        \n      \n      Among the AI group, the accuracy of the first impression (Top-1 accuracy; 58.3%) after the assistance of AI was higher than that before the assistance (46.5%, P = .008). The number of differential diagnoses of the participants increased from 1.9 Â± 0.5 to 2.2 Â± 0.6 after the assistance (P < .001). In the control group, the difference in the Top-1 accuracy between before and after reviewing photographs was not significant (before, 46.1%; after, 51.8%; P = .19), and the number of differential diagnoses did not significantly increase (before, 2.0 Â± 0.4; after, 2.1 Â± 0.5; P = .57).\n    \n\n\n          Conclusions:\n        \n      \n      In real-world settings, AI augmented the diagnostic accuracy of trainee doctors. The limitation of this study is that the algorithm was tested only for Asians recruited from a single region. Additional international randomized controlled trials involving various ethnicities are required."
        },
        {
            "title": "Skin cancer detection from dermoscopic images using deep learning and fuzzy k-means clustering.",
            "abstract": "Melanoma skin cancer is the most life-threatening and fatal disease among the family of skin cancer diseases. Modern technological developments and research methodologies made it possible to detect and identify this kind of skin cancer more effectively; however, the automated localization and segmentation of skin lesion at earlier stages is still a challenging task due to the low contrast between melanoma moles and skin portion and a higher level of color similarity between melanoma-affected and -nonaffected areas. In this paper, we present a fully automated method for segmenting the skin melanoma at its earliest stage by employing a deep-learning-based approach, namely faster region-based convolutional neural networks (RCNN) along with fuzzy k-means clustering (FKM). Several clinical images are utilized to test the presented method so that it may help the dermatologist in diagnosing this life-threatening disease at its earliest stage. The presented method first preprocesses the dataset images to remove the noise and illumination problems and enhance the visual information before applying the faster-RCNN to obtain the feature vector of fixed length. After that, FKM has been employed to segment the melanoma-affected portion of skin with variable size and boundaries. The performance of the presented method is evaluated on the three standard datasets, namely ISBI-2016, ISIC-2017, and PH2, and the results show that the presented method outperforms the state-of-the-art approaches. The presented method attains an average accuracy of 95.40, 93.1, and 95.6% on the ISIC-2016, ISIC-2017, and PH2 datasets, respectively, which is showing its robustness to skin lesion recognition and segmentation."
        },
        {
            "title": "Intelligent Diagnostic Assistant for Complicated Skin Diseases through C5's Algorithm.",
            "abstract": "Introduction:\n        \n      \n      Intelligent Diagnostic Assistant can be used for complicated diagnosis of skin diseases, which are among the most common causes of disability. The aim of this study was to design and implement a computerized intelligent diagnostic assistant for complicated skin diseases through C5's Algorithm.\n    \n\n\n          Method:\n        \n      \n      An applied-developmental study was done in 2015. Knowledge base was developed based on interviews with dermatologists through questionnaires and checklists. Knowledge representation was obtained from the train data in the database using Excel Microsoft Office. Clementine Software and C5's Algorithms were applied to draw the decision tree. Analysis of test accuracy was performed based on rules extracted using inference chains. The rules extracted from the decision tree were entered into the CLIPS programming environment and the intelligent diagnostic assistant was designed then.\n    \n\n\n          Results:\n        \n      \n      The rules were defined using forward chaining inference technique and were entered into Clips programming environment as RULE. The accuracy and error rates obtained in the training phase from the decision tree were 99.56% and 0.44%, respectively. The accuracy of the decision tree was 98% and the error was 2% in the test phase.\n    \n\n\n          Conclusion:\n        \n      \n      Intelligent diagnostic assistant can be used as a reliable system with high accuracy, sensitivity, specificity, and agreement."
        },
        {
            "title": "Algorithm based smartphone apps to assess risk of skin cancer in adults: systematic review of diagnostic accuracy studies.",
            "abstract": "Objective:\n        \n      \n      To examine the validity and findings of studies that examine the accuracy of algorithm based smartphone applications (\"apps\") to assess risk of skin cancer in suspicious skin lesions.\n    \n\n\n          Design:\n        \n      \n      Systematic review of diagnostic accuracy studies.\n    \n\n\n          Data sources:\n        \n      \n      Cochrane Central Register of Controlled Trials, MEDLINE, Embase, CINAHL, CPCI, Zetoc, Science Citation Index, and online trial registers (from database inception to 10 April 2019).\n    \n\n\n          Eligibility criteria for selecting studies:\n        \n      \n      Studies of any design that evaluated algorithm based smartphone apps to assess images of skin lesions suspicious for skin cancer. Reference standards included histological diagnosis or follow-up, and expert recommendation for further investigation or intervention. Two authors independently extracted data and assessed validity using QUADAS-2 (Quality Assessment of Diagnostic Accuracy Studies 2 tool). Estimates of sensitivity and specificity were reported for each app.\n    \n\n\n          Results:\n        \n      \n      Nine studies that evaluated six different identifiable smartphone apps were included. Six verified results by using histology or follow-up (n=725 lesions), and three verified results by using expert recommendations (n=407 lesions). Studies were small and of poor methodological quality, with selective recruitment, high rates of unevaluable images, and differential verification. Lesion selection and image acquisition were performed by clinicians rather than smartphone users. Two CE (Conformit Europenne) marked apps are available for download. SkinScan was evaluated in a single study (n=15, five melanomas) with 0% sensitivity and 100% specificity for the detection of melanoma. SkinVision was evaluated in two studies (n=252, 61 malignant or premalignant lesions) and achieved a sensitivity of 80% (95% confidence interval 63% to 92%) and a specificity of 78% (67% to 87%) for the detection of malignant or premalignant lesions. Accuracy of the SkinVision app verified against expert recommendations was poor (three studies).\n    \n\n\n          Conclusions:\n        \n      \n      Current algorithm based smartphone apps cannot be relied on to detect all cases of melanoma or other skin cancers. Test performance is likely to be poorer than reported here when used in clinically relevant populations and by the intended users of the apps. The current regulatory process for awarding the CE marking for algorithm based apps does not provide adequate protection to the public.\n    \n\n\n          Systematic review registration:\n        \n      \n      PROSPERO CRD42016033595."
        },
        {
            "title": "Topical Tacrolimus 0.1% for treatment of cutaneous microcystic lymphatic malformations.",
            "abstract": "Microcystic lymphatic malformations as described in the international literature form a subgroup of low-flow congenital vascular malformations (VM) resulting from irregular embryological development. Microcystic lesions normally manifest as an accumulation of lymph- and blood-filled vesicles that, when externalized, cause skin maceration with consequent pain and potential infection resulting in the impairment of the patient's quality of life. There is no consensus on a standardized algorithm nor clear guidelines for successful treatment of this type of lymphatic malformation, and treatment options employed often result in ambivalent and transient outcomes with a high rate of recurrence. The topical formulation of tacrolimus is a well-known FDAapproved anti-T cell agent that was recently identified as a potent activator of ALK1, which is involved in several processes and functions including angiogenesis. We investigated if topical administration of tacrolimus may be an effective therapy for directly targeting cutaneous microcystic lymphatic malformations as a complement to systemic treatment. The study enrolled four patients with cutaneous microcystic lymphatic malformations: three male (ages: 13,15,18) and one female (age: 30). Two of the patients presented lesions on their backs, one patient on the left hand and one on the left lower limb. All four patients received treatment with topical tacrolimus 0.1% twice a day for 10 weeks on a previously selected area for application. Weekly clinical follow-ups were conducted along with close physician-patient contact. All patients displayed a satisfactory response after treatment. Lymphorrhea and bleeding were stopped in all cases and the esthetic aspect of lesions improved in two patients. To date, all patients presented no clinically significant changes to the size or extension of the lesion. Topical tacrolimus treatment is a promising and reasonable option for microcystic lymphatic malformations. Our results encourage further exploration in larger populations with the consideration that it is a safe and effective alternative or complementary therapy to systemic treatment."
        },
        {
            "title": "Automatic Quality Assessment of Reflectance Confocal Microscopy Mosaics using Attention-Based Deep Neural Network.",
            "abstract": "Skin cancers are the most common cancers with an increased incidence, and a valid, early diagnosis may significantly reduce its morbidity and mortality. Reflectance confocal microscopy (RCM) is a relatively new, non-invasive imaging technique that allows screening lesions at a cellular resolution. However, one of the main disadvantages of the RCM is frequently occurring artifacts which makes the diagnostic process more time consuming and hard to automate using e.g. end-to-end deep learning approach. A tool to automatically determine the RCM mosaic quality could be beneficial for both the lesion classification and informing the user (dermatologist) about its quality in real-time, during the examination procedure. In this work, we propose an attention-based deep network to automatically determine if a given RCM mosaic has an acceptable quality. We achieved accuracy above 87% on the test set which may considerably improve further classification results and the RCM-based examination."
        },
        {
            "title": "Melanoma patterns of care in Ontario: A call for a strategic alignment of multidisciplinary care.",
            "abstract": "Background and objectives:\n        \n      \n      Variability in melanoma management has prompted concerns about equitable and timely treatment. We investigated patterns of melanoma diagnosis and treatment using population-level data.\n    \n\n\n          Methods:\n        \n      \n      Patients with invasive cutaneous melanoma were identified retrospectively from the Ontario Cancer Registry (2003-2012) and deterministically linked with administrative databases to identify incidence, disease characteristics, geographic origin, and multimodal treatment within a year of diagnosis. Melanoma treatment was categorized as inadequate or adequate based on multidisciplinary clinical algorithms. Multivariable logistic regression was used to model factors associated with treatment adequacy.\n    \n\n\n          Results:\n        \n      \n      From 2003 to 2012, 22 918 patients with invasive melanoma were identified with annual age/sex standardized incidence rates of 11.7-14.3/100 000 for females and 13.4-15.9/100 000 for males. Melanoma occurred at median age of 62 and primarily on extremities (43.9%). Within 1 year after diagnosis, 86.7% of patients received surgery as primary therapy. A total of 2312 (10.6%) patients received inadequate or no treatment after diagnosis. Receiving adequate treatment was associated with consultation with dermatology (OR 1.92, CI 1.71-2.14), plastic surgery (OR 4.80, CI 4.32-5.34), or general surgery (OR 2.15, CI 1.94-2.38).\n    \n\n\n          Conclusions:\n        \n      \n      Significant variation exists in melanoma management and nearly one in nine patients is inadequately treated. Referral to sub-specialized providers is critical for ensuring appropriate care."
        },
        {
            "title": "[Image segmentation of skin lesions based on dense atrous spatial pyramid pooling and attention mechanism].",
            "abstract": "The skin is the largest organ of the human body, and many visceral diseases will be directly reflected on the skin, so it is of great clinical significance to accurately segment the skin lesion images. To address the characteristics of complex color, blurred boundaries, and uneven scale information, a skin lesion image segmentation method based on dense atrous spatial pyramid pooling (DenseASPP) and attention mechanism is proposed. The method is based on the U-shaped network (U-Net). Firstly, a new encoder is redesigned to replace the ordinary convolutional stacking with a large number of residual connections, which can effectively retain key features even after expanding the network depth. Secondly, channel attention is fused with spatial attention, and residual connections are added so that the network can adaptively learn channel and spatial features of images. Finally, the DenseASPP module is introduced and redesigned to expand the perceptual field size and obtain multi-scale feature information. The algorithm proposed in this paper has obtained satisfactory results in the official public dataset of the International Skin Imaging Collaboration (ISIC 2016). The mean Intersection over Union (mIOU), sensitivity (SE), precision (PC), accuracy (ACC), and Dice coefficient (Dice) are 0.901 8, 0.945 9, 0.948 7, 0.968 1, 0.947 3, respectively. The experimental results demonstrate that the method in this paper can improve the segmentation effect of skin lesion images, and is expected to provide an auxiliary diagnosis for professional dermatologists."
        },
        {
            "title": "Multiple skin lesions diagnostics via integrated deep convolutional networks for segmentation and classification.",
            "abstract": "Background and objective:\n        \n      \n      Computer automated diagnosis of various skin lesions through medical dermoscopy images remains a challenging task.\n    \n\n\n          Methods:\n        \n      \n      In this work, we propose an integrated diagnostic framework that combines a skin lesion boundary segmentation stage and a multiple skin lesions classification stage. Firstly, we segment the skin lesion boundaries from the entire dermoscopy images using deep learning full resolution convolutional network (FrCN). Then, a convolutional neural network classifier (i.e., Inception-v3, ResNet-50, Inception-ResNet-v2, and DenseNet-201) is applied on the segmented skin lesions for classification. The former stage is a critical prerequisite step for skin lesion diagnosis since it extracts prominent features of various types of skin lesions. A promising classifier is selected by testing well-established classification convolutional neural networks. The proposed integrated deep learning model has been evaluated using three independent datasets (i.e., International Skin Imaging Collaboration (ISIC) 2016, 2017, and 2018, which contain two, three, and seven types of skin lesions, respectively) with proper balancing, segmentation, and augmentation.\n    \n\n\n          Results:\n        \n      \n      In the integrated diagnostic system, segmented lesions improve the classification performance of Inception-ResNet-v2 by 2.72% and 4.71% in terms of the F1-score for benign and malignant cases of the ISIC 2016 test dataset, respectively. The classifiers of Inception-v3, ResNet-50, Inception-ResNet-v2, and DenseNet-201 exhibit their capability with overall weighted prediction accuracies of 77.04%, 79.95%, 81.79%, and 81.27% for two classes of ISIC 2016, 81.29%, 81.57%, 81.34%, and 73.44% for three classes of ISIC 2017, and 88.05%, 89.28%, 87.74%, and 88.70% for seven classes of ISIC 2018, respectively, demonstrating the superior performance of ResNet-50.\n    \n\n\n          Conclusions:\n        \n      \n      The proposed integrated diagnostic networks could be used to support and aid dermatologists for further improvement in skin cancer diagnosis."
        },
        {
            "title": "Multidimensional indicators of scholarly impact in the skin oncology literature: is there a correlation between bibliometric and altmetric profiles?",
            "abstract": "Introduction: Bibliometric and altmetric analyses are used to identify landmark publications in their respective research field. We hypothesised that highly cited skin oncology articles correlate positively with the Oxford Evidence Based Medicine scoring level, altmetric score (AS) and rank within the top 100 manuscripts.Methods: Thomson Reuter's Web of Science citation indexing database was searched to identify all English-language skin oncology full-text articles in the last 75 years. The top 100 articles with the highest citation count were analysed by subject matter, publishing journal, author, year, institution, individual and five-year impact factor, AS and Oxford EBM level. Results: 180,132 articles were identified. The most cited article (Hodi et al.) demonstrated improved survival with ipilimumab in patients with metastatic melanoma (7894 citations). The article with the highest AS was Esteva et al. (AS = 576.7, 'dermatologist-level classification of skin cancer with deep neural networks'). No difference was found between evidence level and citation count (r = -0.1239, p = 0.2291), but a significant difference was seen for AS (r = -0.3024, p = 0.0028). AS scores increased over time, whereas bibliometrics did not. Conclusion: This work highlights the most influential work in the skin oncology field in the last 75 years. We have identified a differential relationship between commonly used metrics and evidence level in the field of skin oncology. As the digitalisation of research output and consumption increases, both bibliometric and altmetric analyses need to be considered when an article's impact is being assessed."
        },
        {
            "title": "Skin Lesion Classification on Imbalanced Data Using Deep Learning with Soft Attention.",
            "abstract": "Today, the rapid development of industrial zones leads to an increased incidence of skin diseases because of polluted air. According to a report by the American Cancer Society, it is estimated that in 2022 there will be about 100,000 people suffering from skin cancer and more than 7600 of these people will not survive. In the context that doctors at provincial hospitals and health facilities are overloaded, doctors at lower levels lack experience, and having a tool to support doctors in the process of diagnosing skin diseases quickly and accurately is essential. Along with the strong development of artificial intelligence technologies, many solutions to support the diagnosis of skin diseases have been researched and developed. In this paper, a combination of one Deep Learning model (DenseNet, InceptionNet, ResNet, etc) with Soft-Attention, which unsupervisedly extract a heat map of main skin lesions. Furthermore, personal information including age and gender are also used. It is worth noting that a new loss function that takes into account the data imbalance is also proposed. Experimental results on data set HAM10000 show that using InceptionResNetV2 with Soft-Attention and the new loss function gives 90 percent accuracy, mean of precision, F1-score, recall, and AUC of 0.81, 0.81, 0.82, and 0.99, respectively. Besides, using MobileNetV3Large combined with Soft-Attention and the new loss function, even though the number of parameters is 11 times less and the number of hidden layers is 4 times less, it achieves an accuracy of 0.86 and 30 times faster diagnosis than InceptionResNetV2."
        },
        {
            "title": "An Application for Skin Macules Characterization Based on a 3-Stage Image-Processing Algorithm for Patients with Diabetes.",
            "abstract": "Diabetic skin manifestations, previous to ulcers and wounds, are not highly accounted as part of diagnosis even when they represent the first symptom of vascular damage and are present in up to 70% of patients with diabetes mellitus type II. Here, an application for skin macules characterization based on a three-stage segmentation and characterization algorithm used to classify vascular, petechiae, trophic changes, and trauma macules from digital photographs of the lower limbs is presented. First, in order to find the skin region, a logical multiplication is performed on two skin masks obtained from color space transformations; dynamic thresholds are stabilised to self-adjust to a variety of skin tones. Then, in order to locate the lesion region, illumination enhancement is performed using a chromatic model color space, followed by a principal component analysis gray-scale transformation. Finally, characteristics of each type of macule are considered and classified; morphologic properties (area, axes, perimeter, and solidity), intensity properties, and a set of shade indices (red, green, blue, and brown) are proposed as a measure to obviate skin color differences among subjects. The values calculated show differences between macules with a statistical significance, which agree with the physician's diagnosis. Later, macule properties are fed to an artificial neural network classifier, which proved a 97.5% accuracy, to differentiate between them. Characterization is useful in order to track macule changes and development along time, provides meaningful information to provide early treatments, and offers support in the prevention of amputations due to diabetic feet. A graphical user interface was designed to show the properties of the macules; this application could be the background of a future Diagnosis Assistance Tool for educational (i.e., untrained physicians) and preventive assistance technology purposes."
        },
        {
            "title": "Performance of a deep neural network in teledermatology: a single-centre prospective diagnostic study.",
            "abstract": "Background:\n        \n      \n      The use of artificial intelligence (AI) algorithms for the diagnosis of skin diseases has shown promise in experimental settings but has not been yet tested in real-life conditions.\n    \n\n\n          Objective:\n        \n      \n      To assess the diagnostic performance and potential clinical utility of a 174-multiclass AI algorithm in a real-life telemedicine setting.\n    \n\n\n          Methods:\n        \n      \n      Prospective, diagnostic accuracy study including consecutive patients who submitted images for teledermatology evaluation. The treating dermatologist chose a single image to upload to a web application during teleconsultation. A follow-up reader study including nine healthcare providers (3 dermatologists, 3 dermatology residents and 3 general practitioners) was performed.\n    \n\n\n          Results:\n        \n      \n      A total of 340 cases from 281 patients met study inclusion criteria. The mean (SD) age of patients was 33.7 (17.5) years; 63% (n = 177) were female. Exposure to the AI algorithm results was considered useful in 11.8% of visits (n = 40) and the teledermatologist correctly modified the real-time diagnosis in 0.6% (n = 2) of cases. The overall top-1 accuracy of the algorithm (41.2%) was lower than that of the dermatologists (60.1%), residents (57.8%) and general practitioners (49.3%) (all comparisons P < 0.05, in the reader study). When the analysis was limited to the diagnoses on which the algorithm had been explicitly trained, the balanced top-1 accuracy of the algorithm (47.6%) was comparable to the dermatologists (49.7%) and residents (47.7%) but superior to the general practitioners (39.7%; P = 0.049). Algorithm performance was associated with patient skin type and image quality.\n    \n\n\n          Conclusions:\n        \n      \n      A 174-disease class AI algorithm appears to be a promising tool in the triage and evaluation of lesions with patient-taken photographs via telemedicine."
        },
        {
            "title": "Automatic identification of benign pigmented skin lesions from clinical images using deep convolutional neural network.",
            "abstract": "Objective:\n        \n      \n      We aimed to develop a computer-aided detection (CAD) system for accurate identification of benign pigmented skin lesions (PSLs) from images captured using a digital camera or a smart phone.\n    \n\n\n          Methods:\n        \n      \n      We collected a total of 12,836 clinical images which had been classified and location-labeled for training and validating. Four models were developed and validated; you only look once, v4 (YOLOv4), you only look once, v5 (YOLOv5), single shot multibox detector (SSD) and faster region-based convolutional neural networks (Faster R-CNN). The performance of the models was compared with three trained dermatologists, respectively. The accuracy of the best model was further tested and validated using smartphone-captured images.\n    \n\n\n          Results:\n        \n      \n      The accuracies of YOLOv4, YOLOv5, SSD and Faster R-CNN were 0.891, 0.929, 0.852 and 0.874, respectively. The precision, sensitivity and specificity of YOLOv5 (the best model) were 0.956, 0.962 and 0.952, respectively. The accuracy of YOLOv5 model for images captured using a smart-phone was 0.905. The CAD based YOLOv5 system can potentially be used in clinical identification of PSLs.\n    \n\n\n          Conclusion:\n        \n      \n      We developed and validated a CAD system for automatic identification of benign PSLs using digital images. This approach may be used by non-dermatologists to easily diagnose by taking a photo of skin lesion and guide on management of PSLs."
        },
        {
            "title": "An Improved CNN Architecture to Diagnose Skin Cancer in Dermoscopic Images Based on Wildebeest Herd Optimization Algorithm.",
            "abstract": "Skin cancer is one of the most common types of cancers that is sometimes difficult for doctors and experts to diagnose. The noninvasive dermatoscopic method is a popular method for observing and diagnosing skin cancer. Because this method is based on ocular inference, the skin cancer diagnosis by the dermatologists is difficult, especially in the early stages of the disease. Artificial intelligence is a proper complementary tool that can be used alongside the experts to increase the accuracy of the diagnosis. In the present study, a new computer-aided method has been introduced for the diagnosis of the skin cancer. The method is designed based on combination of deep learning and a newly introduced metaheuristic algorithm, namely, Wildebeest Herd Optimization (WHO) Algorithm. The method uses an Inception convolutional neural network for the initial features' extraction. Afterward, the WHO algorithm has been employed for selecting the useful features to decrease the analysis time complexity. The method is then performed to an ISIC-2008 skin cancer dataset. Final results of the feature selection based on the proposed WHO are compared with three other algorithms, and the results have indicated good results for the system. Finally, the total diagnosis system has been compared with five other methods to indicate its effectiveness against the studied methods. Final results showed that the proposed method has the best results than the comparative methods."
        },
        {
            "title": "Uncertainty-aware skin cancer detection: The element of doubt.",
            "abstract": "Artificial intelligence (AI)-based medical diagnosis has received huge attention due to its potential to improve and accelerate the decision-making process at the patient level in a range of healthcare settings. Despite the recent signs of progress in this field, reliable quantification and proper communication of predictive uncertainties have been fully or partially overlooked in the existing literature on AI applications for medical diagnosis. This paper studies the automatic diagnosis of skin cancer using dermatologist spot images. Three different uncertainty-aware training algorithms (MC dropout, Bayesian Ensembling, and Spectral Normalized Neural Gaussian Process) are utilized to detect skin cancer. The performances of the three above-mentioned algorithms are compared from different perspectives. In addition, some images from the Cifar10 dataset are applied as the out-of-domain data and the performances of the algorithms are evaluated and compared for images that are far from the training samples. The accuracy, uncertainty accuracy, uncertainty accuracy for out-of-domain distribution samples, and the uncertainties of the predictions are reported in all cases and compared."
        },
        {
            "title": "A Novel Fuzzy Multilayer Perceptron (F-MLP) for the Detection of Irregularity in Skin Lesion Border Using Dermoscopic Images.",
            "abstract": "Skin lesion border irregularity, which represents the B feature in the ABCD rule, is considered one of the most significant factors in melanoma diagnosis. Since signs that clinicians rely on in melanoma diagnosis involve subjective judgment including visual signs such as border irregularity, this deems it necessary to develop an objective approach to finding border irregularity. Increased research in neural networks has been carried out in recent years mainly driven by the advances of deep learning. Artificial neural networks (ANNs) or multilayer perceptrons have been shown to perform well in supervised learning tasks. However, such networks usually don't incorporate information pertaining the ambiguity of the inputs when training the network, which in turn could affect how the weights are being updated in the learning process and eventually degrading the performance of the network when applied on test data. In this paper, we propose a fuzzy multilayer perceptron (F-MLP) that takes the ambiguity of the inputs into consideration and subsequently reduces the effects of ambiguous inputs on the learning process. A new optimization function, the fuzzy gradient descent, has been proposed to reflect those changes. Moreover, a type-II fuzzy sigmoid activation function has also been proposed which enables finding the range of performance the fuzzy neural network is able to attain. The fuzzy neural network was used to predict the skin lesion border irregularity, where the lesion was firstly segmented from the skin, the lesion border extracted, border irregularity measured using a proposed measure vector, and using the extracted border irregularity measures to train the neural network. The proposed approach outperformed most of the state-of-the-art classification methods in general and its standard neural network counterpart in particular. However, the proposed fuzzy neural network was more time-consuming when training the network."
        },
        {
            "title": "A Low-Cost High-Performance Data Augmentation for Deep Learning-Based Skin Lesion Classification.",
            "abstract": "Objective and Impact Statement. There is a need to develop high-performance and low-cost data augmentation strategies for intelligent skin cancer screening devices that can be deployed in rural or underdeveloped communities. The proposed strategy can not only improve the classification performance of skin lesions but also highlight the potential regions of interest for clinicians' attention. This strategy can also be implemented in a broad range of clinical disciplines for early screening and automatic diagnosis of many other diseases in low resource settings. Methods. We propose a high-performance data augmentation strategy of search space 101, which can be combined with any model through a plug-and-play mode and search for the best argumentation method for a medical database with low resource cost. Results. With EfficientNets as a baseline, the best BACC of HAM10000 is 0.853, outperforming the other published models of \"single-model and no-external-database\" for ISIC 2018 Lesion Diagnosis Challenge (Task 3). The best average AUC performance on ISIC 2017 achieves 0.909 (Â±0.015), exceeding most of the ensembling models and those using external datasets. Performance on Derm7pt archives the best BACC of 0.735 (Â±0.018) ahead of all other related studies. Moreover, the model-based heatmaps generated by Grad-CAM++ verify the accurate selection of lesion features in model judgment, further proving the scientific rationality of model-based diagnosis. Conclusion. The proposed data augmentation strategy greatly reduces the computational cost for clinically intelligent diagnosis of skin lesions. It may also facilitate further research in low-cost, portable, and AI-based mobile devices for skin cancer screening and therapeutic guidance."
        },
        {
            "title": "Computer-aided classification of suspicious pigmented lesions using wide-field images.",
            "abstract": "Background and objective:\n        \n      \n      Early identification of melanoma is conducted through whole-body visual examinations to detect suspicious pigmented lesions, a situation that fluctuates in accuracy depending on the experience and time of the examiner. Computer-aided diagnosis tools for skin lesions are typically trained using pre-selected single-lesion images, taken under controlled conditions, which limits their use in wide-field scenes. Here, we propose a computer-aided classifier system with such input conditions to aid in the rapid identification of suspicious pigmented lesions at the primary care level.\n    \n\n\n          Methods:\n        \n      \n      133 patients with a multitude of skin lesions were recruited for this study. All lesions were examined by a board-certified dermatologist and classified into \"suspicious\" and \"non-suspicious\". A new clinical database was acquired and created by taking Wide-Field images of all major body parts with a consumer-grade camera under natural illumination condition and with a consistent source of image variability. 3-8 images were acquired per patient on different sites of the body, and a total of 1759 pigmented lesions were extracted. A machine learning classifier was optimized and build into a computer aided classification system to binary classify each lesion using a suspiciousness score.\n    \n\n\n          Results:\n        \n      \n      In a testing set, our computer-aided classification system achieved a sensitivity of 100% for suspicious pigmented lesions that were later confirmed by dermoscopy examination (\"SPL_A\") and 83.2% for suspicious pigmented lesions that were not confirmed after examination (\"SPL_B\"). Sensitivity for non-suspicious lesions was 72.1%, and accuracy was 75.9%. With these results we defined a suspiciousness score that is aligned with common macro-screening (naked eye) practices.\n    \n\n\n          Conclusions:\n        \n      \n      This work demonstrates that wide-field photography combined with computer-aided classification systems can distinguish suspicious from non-suspicious pigmented lesions, and might be effective to assess the severity of a suspicious pigmented lesions. We believe this approach could be useful to support skin screenings at a population-level."
        },
        {
            "title": "[The Rise of Artificial Intelligence - High Prediction Accuracy in Early Detection of Pigmented Melanoma].",
            "abstract": "The incidence of malignant melanoma is increasing worldwide. If detected early, melanoma is highly treatable, so early detection is vital.Skin cancer early detection has improved significantly in recent decades, for example by the introduction of screening in 2008 and dermoscopy. Nevertheless, in particular visual detection of early melanomas remains challenging because they show many morphological overlaps with nevi. Hence, there continues to be a high medical need to further develop methods for early skin cancer detection in order to be able to reliably diagnosemelanomas at a very early stage.Routine diagnostics for melanoma detection include visual whole body inspection, often supplemented by dermoscopy, which can significantly increase the diagnostic accuracy of experienced dermatologists. A procedure that is additionally offered in some practices and clinics is wholebody photography combined with digital dermoscopy for the early detection of malignant melanoma, especially for monitoring high-risk patients.In recent decades, numerous noninvasive adjunctive diagnostic techniques were developed for the examination of suspicious pigmented moles, that may have the potential to allow improved and, in some cases, automated evaluation of these lesions. First, confocal laser microscopy should be mentioned here, as well as electrical impedance spectroscopy, multiphoton laser tomography, multispectral analysis, Raman spectroscopy or optical coherence tomography. These diagnostic techniques usually focus on high sensitivity to avoid malignant melanoma being overlooked. However, this usually implies lower specificity, which may lead to unnecessary excision of benign lesions in screening. Also, some of the procedures are time-consuming and costly, which also limits their applicability in skin cancer screening. In the near future, the use of artificial intelligence might change skin cancer diagnostics in many ways. The most promising approach may be the analysis of routine macroscopic and dermoscopic images by artificial intelligence.For the classification of pigmented skin lesions based on macroscopic and dermoscopic images, artificial intelligence, especially in form of neural networks, has achieved comparable diagnostic accuracies to dermatologists under experimental conditions in numerous studies. In particular, it achieved high accuracies in the binary melanoma/nevus classification task, but it also performed comparably well to dermatologists in multiclass differentiation of various skin diseases. However, proof of the basic applicability and utility of such systems in clinical practice is still pending. Prerequisites that remain to be established to enable translation of such diagnostic systems into dermatological routine are means that allow users to comprehend the system's decisions as well as a uniformly high performance of the algorithms on image data from other hospitals and practices.At present, hints are accumulating that computer-aided diagnosis systems could provide their greatest benefit as assistance systems, since studies indicate that a combination of human and machine achieves the best results. Diagnostic systems based on artificial intelligence are capable of detecting morphological characteristics quickly, quantitatively, objectively and reproducibly, and could thus provide a more objective analytical basis - in addition to medical experience."
        },
        {
            "title": "Optical transfer diagnosis differentiating benign and malignant pigmented lesions in a simulated primary care practice.",
            "abstract": "Background:\n        \n      \n      The detection of melanoma poses a substantial challenge, particularly for primary care providers (PCPs) who may have limited training in discriminating between suspicious and benign melanocytic lesions. The noninvasive optical transfer diagnosis (OTD) method was designed to be used by PCPs in their decision-making process.\n    \n\n\n          Objectives:\n        \n      \n      To assess the potential of the OTD method by developing, training and validating an OTD indication algorithm for automated discrimination between benign melanocytic lesions and malignant lesions, based on a set of 712 lesions.\n    \n\n\n          Methods:\n        \n      \n      The authors performed in vivoOTD capture and subsequent analysis of 712 pigmented lesions. Of the lesions, 415 were clinically and dermoscopically benign and 297 were dermoscopically suspicious or equivocal. After image capture, all suspicious or equivocal lesions were biopsied and examined histopathologically.\n    \n\n\n          Results:\n        \n      \n      Of the 297 suspicious or equivocal lesions, histopathological findings revealed 80 to be malignant (64 melanomas, 13 basal cell carcinomas and 3 squamous cell carcinomas). OTD misdiagnosed one of the 80 malignant lesions as benign (sensitivity, 99%). OTD specificity was 93% for the dermoscopically benign lesions, 73% for all lesions included in the study and 36% for the clinically suspicious but histopathologically benign lesions.\n    \n\n\n          Conclusions:\n        \n      \n      High sensitivity and specificity, as provided by OTD in this preliminary study, would help PCPs reduce the number of referrals for dermatology consultation, excision or biopsy. Further studies are planned for screening patients in a primary care setting, with comparisons of OTD results with biopsy or dermoscopy results."
        },
        {
            "title": "A convolutional neural network trained with dermoscopic images of psoriasis performed on par with 230 dermatologists.",
            "abstract": "Background:\n        \n      \n      Psoriasis is a common chronic inflammatory skin disease that causes physical and psychological burden to patients. A Convolutional Neural Network (CNN) focused on dermoscopic images would substantially aid the classification and increase the accuracy of diagnosis of psoriasis.\n    \n\n\n          Objectives:\n        \n      \n      This study aimed to train an efficient deep-learning network to recognize dermoscopic images of psoriasis (and other papulosquamous diseases), improving the accuracy of the diagnosis of psoriasis.\n    \n\n\n          Methods:\n        \n      \n      EfficientNet-B4 architecture was trained with 7033 dermoscopic images from 1166 patients collected from the Department of Dermatology, Peking Union Medical College Hospital (China). We performed a five-fold cross-validation on the training set to compare the classification performance of EfficientNet-B4 over different networks commonly used in previous studies. From the test set, 90 images were used to compare the performance between our four-class model and that of board-certified dermatologists, whose diagnoses and information (e.g., age, titles) were obtained through an online questionnaire.\n    \n\n\n          Results:\n        \n      \n      The mean sensitivity and specificity of EfficientNet-B4 on the training set was 0.927Â± 0.028 and 0.827 Â± 0.043 for the two-class task, and 0.889 Â± 0.014 and 0.968 Â± 0.004 four-class task. The diagnostic sensitivity and specificity of the 230 dermatologists were 0.688 and 0.903 for psoriasis, 0.677 and 0.838 for eczema, 0.669 and 0.953 for lichen planus, and 0.832 and 0.932 for the \"others\" group, respectively; the diagnostic sensitivity and specificity of our four-class CNN was 0.929 and 0.952 for psoriasis, 0.773 and 0.926 for eczema, 0.933 and 0.960 for lichen planus, and 0.840 and 0.985 for the \"others\" group, respectively. Both the 230 dermatologists and CNN achieved at least moderate consistency with the reference standard, and there was no significant difference between them (P > 0.05).\n    \n\n\n          Conclusions:\n        \n      \n      The two-classification and four-classification models of psoriasis established in our study could accurately classify papulosquamous skin diseases. They showed generally comparable performances to the average level of dermatologists and would provide a strong support for the diagnosis of psoriasis."
        },
        {
            "title": "KIEGLFN: A unified acne grading framework on face images.",
            "abstract": "Background and objective:\n        \n      \n      Grading the severity level is an extremely important procedure for correct diagnoses and personalized treatment schemes for acne. However, the acne grading criteria are not unified in the medical field. This work aims to develop an acne diagnosis system that can be generalized to various criteria.\n    \n\n\n          Methods:\n        \n      \n      A unified acne grading framework that can be generalized to apply referring to different grading criteria is developed. It imitates the global estimation of the dermatologist diagnosis in two steps. First, an adaptive image preprocessing method effectively filters meaningless information and enhances key information. Next, an innovative network structure fuses global deep features with local features to simulate the dermatologists' comparison of local skin and global observation. In addition, a transfer fine-tuning strategy is proposed to transfer prior knowledge on one criterion to another criterion, which effectively improves the framework performance in case of insufficient data.\n    \n\n\n          Results:\n        \n      \n      The Preprocessing method effectively filters meaningless areas and improves the performance of downstream models.The framework reaches accuracies of 84.52% and 59.35% on two datasets separately.\n    \n\n\n          Conclusions:\n        \n      \n      The application of the framework on acne grading exceeds the state-of-the-art method by 1.71%, reaches the diagnostic level of a professional dermatologist and the transfer fine-tuning strategy improves the accuracy of 6.5% on the small data."
        },
        {
            "title": "The role of AI classifiers in skin cancer images.",
            "abstract": "Background:\n        \n      \n      The use of different imaging modalities to assist in skin cancer diagnosis is a common practice in clinical scenarios. Different features representative of the lesion under evaluation can be retrieved from image analysis and processing. However, the integration and understanding of these additional parameters can be a challenging task for physicians, so artificial intelligence (AI) methods can be implemented to assist in this process. This bibliographic research was performed with the goal of assessing the current applications of AI algorithms as an assistive tool in skin cancer diagnosis, based on information retrieved from different imaging modalities.\n    \n\n\n          Materials and methods:\n        \n      \n      The bibliography databases ISI Web of Science, PubMed and Scopus were used for the literature search, with the combination of keywords: skin cancer, skin neoplasm, imaging and classification methods.\n    \n\n\n          Results:\n        \n      \n      The search resulted in 526 publications, which underwent a screening process, considering the established eligibility criteria. After screening, only 65 were qualified for revision.\n    \n\n\n          Conclusion:\n        \n      \n      Different imaging modalities have already been coupled with AI methods, particularly dermoscopy for melanoma recognition. Learners based on support vector machines seem to be the preferred option. Future work should focus on image analysis, processing stages and image fusion assuring the best possible classification outcome."
        },
        {
            "title": "Comparison of the accuracy of human readers versus machine-learning algorithms for pigmented skin lesion classification: an open, web-based, international, diagnostic study.",
            "abstract": "Background:\n        \n      \n      Whether machine-learning algorithms can diagnose all pigmented skin lesions as accurately as human experts is unclear. The aim of this study was to compare the diagnostic accuracy of state-of-the-art machine-learning algorithms with human readers for all clinically relevant types of benign and malignant pigmented skin lesions.\n    \n\n\n          Methods:\n        \n      \n      For this open, web-based, international, diagnostic study, human readers were asked to diagnose dermatoscopic images selected randomly in 30-image batches from a test set of 1511 images. The diagnoses from human readers were compared with those of 139 algorithms created by 77 machine-learning labs, who participated in the International Skin Imaging Collaboration 2018 challenge and received a training set of 10 015 images in advance. The ground truth of each lesion fell into one of seven predefined disease categories: intraepithelial carcinoma including actinic keratoses and Bowen's disease; basal cell carcinoma; benign keratinocytic lesions including solar lentigo, seborrheic keratosis and lichen planus-like keratosis; dermatofibroma; melanoma; melanocytic nevus; and vascular lesions. The two main outcomes were the differences in the number of correct specific diagnoses per batch between all human readers and the top three algorithms, and between human experts and the top three algorithms.\n    \n\n\n          Findings:\n        \n      \n      Between Aug 4, 2018, and Sept 30, 2018, 511 human readers from 63 countries had at least one attempt in the reader study. 283 (55Â·4%) of 511 human readers were board-certified dermatologists, 118 (23Â·1%) were dermatology residents, and 83 (16Â·2%) were general practitioners. When comparing all human readers with all machine-learning algorithms, the algorithms achieved a mean of 2Â·01 (95% CI 1Â·97 to 2Â·04; p<0Â·0001) more correct diagnoses (17Â·91 [SD 3Â·42] vs 19Â·92 [4Â·27]). 27 human experts with more than 10 years of experience achieved a mean of 18Â·78 (SD 3Â·15) correct answers, compared with 25Â·43 (1Â·95) correct answers for the top three machine algorithms (mean difference 6Â·65, 95% CI 6Â·06-7Â·25; p<0Â·0001). The difference between human experts and the top three algorithms was significantly lower for images in the test set that were collected from sources not included in the training set (human underperformance of 11Â·4%, 95% CI 9Â·9-12Â·9 vs 3Â·6%, 0Â·8-6Â·3; p<0Â·0001).\n    \n\n\n          Interpretation:\n        \n      \n      State-of-the-art machine-learning classifiers outperformed human experts in the diagnosis of pigmented skin lesions and should have a more important role in clinical practice. However, a possible limitation of these algorithms is their decreased performance for out-of-distribution images, which should be addressed in future research.\n    \n\n\n          Funding:\n        \n      \n      None."
        },
        {
            "title": "Deep Neural Frameworks Improve the Accuracy of General Practitioners in the Classification of Pigmented Skin Lesions.",
            "abstract": "This study evaluated whether deep learning frameworks trained in large datasets can help non-dermatologist physicians improve their accuracy in categorizing the seven most common pigmented skin lesions. Open-source skin images were downloaded from the International Skin Imaging Collaboration (ISIC) archive. Different deep neural networks (DNNs) (n = 8) were trained based on a random dataset constituted of 8015 images. A test set of 2003 images was used to assess the classifiers' performance at low (300 Ã— 224 RGB) and high (600 Ã— 450 RGB) image resolution and aggregated data (age, sex and lesion localization). We also organized two different contests to compare the DNN performance to that of general practitioners by means of unassisted image observation. Both at low and high image resolution, the DNN framework differentiated dermatological images with appreciable performance. In all cases, the accuracy was improved when adding clinical data to the framework. Finally, the least accurate DNN outperformed general practitioners. The physician's accuracy was statistically improved when allowed to use the output of this algorithmic framework as guidance. DNNs are proven to be high performers as skin lesion classifiers and can improve general practitioner diagnosis accuracy in a routine clinical scenario."
        },
        {
            "title": "Skin cancer detection by deep learning and sound analysis algorithms: A prospective clinical study of an elementary dermoscope.",
            "abstract": "Background:\n        \n      \n      Skin cancer (SC), especially melanoma, is a growing public health burden. Experimental studies have indicated a potential diagnostic role for deep learning (DL) algorithms in identifying SC at varying sensitivities. Previously, it was demonstrated that diagnostics by dermoscopy are improved by applying an additional sonification (data to sound waves conversion) layer on DL algorithms. The aim of the study was to determine the impact of image quality on accuracy of diagnosis by sonification employing a rudimentary skin magnifier with polarized light (SMP).\n    \n\n\n          Methods:\n        \n      \n      Dermoscopy images acquired by SMP were processed by a first deep learning algorithm and sonified. Audio output was further analyzed by a different secondary DL. Study criteria outcomes of SMP were specificity and sensitivity, which were further processed by a F2-score, i.e. applying a twice extra weight to sensitivity over positive predictive values.\n    \n\n\n          Findings:\n        \n      \n      Patients (n = 73) fulfilling inclusion criteria were referred to biopsy. SMP analysis metrics resulted in a receiver operator characteristic curve AUC's of 0.814 (95% CI, 0.798-0.831). SMP achieved a F2-score sensitivity of 91.7%, specificity of 41.8% and positive predictive value of 57.3%. Diagnosing the same set of patients' lesions by an advanced dermoscope resulted in a F2-score sensitivity of 89.5%, specificity of 57.8% and a positive predictive value of 59.9% (P=NS).\n    \n\n\n          Interpretation:\n        \n      \n      DL processing of dermoscopic images followed by sonification results in an accurate diagnostic output for SMP, implying that the quality of the dermoscope is not the major factor influencing DL diagnosis of skin cancer. Present system might assist all healthcare providers as a feasible computer-assisted detection system. FUND: Bostel Technologies. Trial Registration clinicaltrials.gov Identifier: NCT03362138."
        },
        {
            "title": "Triage amalgamated dermoscopic algorithm (TADA) for skin cancer screening.",
            "abstract": "Importance:\n        \n      \n      Dermoscopic triage algorithms have been shown to improve beginners' abilities for identifying pigmented skin lesions requiring biopsy.\n    \n\n\n          Objective:\n        \n      \n      To estimate the diagnostic accuracy of the Triage Amalgamated Dermoscopic Algorithm (TADA) for pigmented and nonpigmented skin cancers. Secondarily, to compare TADAs performance to those of existing triage algorithms for the identification of pigmented skin cancers.\n    \n\n\n          Design:\n        \n      \n      Cross-sectional, observational, reader study that took place at a beginner and intermediate level dermoscopy course.\n    \n\n\n          Participants:\n        \n      \n      Two hundred medical professionals of various specialties attended the course and 120 voluntarily joined the study (60% participation rate).\n    \n\n\n          Exposures:\n        \n      \n      After receiving basic dermoscopy training, participants evaluated 50 polarized, dermoscopic images of pigmented (22 benign, 18 malignant) and nonpigmented (1 benign, 9 malignant) skin lesions using TADA. Pigmented lesions were also evaluated using the Three-Point Checklist and AC Rule. With TADA, participants first determined if a lesion was an unequivocal angioma, dermatofibroma, or seborrheic keratosis, which would exclude it from further evaluation. All other lesions were assessed for architectural disorder, starburst pattern, blue-black or gray color, shiny white structures, negative network, ulcer/erosion, or vessels. Any one feature indicated suspicion for malignancy.\n    \n\n\n          Results:\n        \n      \n      Most participants were dermatologists (n=64, 53.3%) or primary care physicians (n=41, 34.2%), and many lacked previous dermoscopy training (n=52, 43.3%). TADA's sensitivity and specificity for all skin cancers was 94.6% (95% CI=93.4-95.7%) and 72.5% (95% CI=70.1-74.7%), respectively. For pigmented skin cancers, the sensitivity and specificity were 94.0% (95% CI=92.9-95.0%) and 75.5% (95% CI=73.8-77.2%). This compared to 71.9% (95%CI=69.8-73.9%) and 81.4% (95%CI=79.7-83.0%) for the Three-Point Checklist and 88.6% (95%CI=87.1-89.9%) and 78.7% (95%CI=76.9-80.3%) for the AC Rule.\n    \n\n\n          Conclusions:\n        \n      \n      These results suggest that TADA compares favorably to existing triage algorithms and might be a useful triage tool with high sensitivity and specificity for pigmented and nonpigmented skin cancers. Further studies are needed to validate these preliminary observations."
        },
        {
            "title": "Differential Diagnosis of Rosacea Using Machine Learning and Dermoscopy.",
            "abstract": "Introduction:\n        \n      \n      Rosacea is a common chronic inflammatory disease occurring on the face, whose diagnosis is mainly based on symptoms and physical signs. Due to some overlap in symptoms and signs with other inflammatory skin diseases, young and inexperienced doctors often make misdiagnoses and missed diagnoses in clinical practices. We analyze the results of skin physiology and dermatoscopy using machine learning method and identify the characteristics of acne rosacea, which differentiate it from other common facial inflammatory skin diseases so as to improve the accuracy of clinical and differential diagnosis of rosacea.\n    \n\n\n          Methods:\n        \n      \n      A total of 495 patients who were jointly diagnosed by two experienced doctors were included. Basic data, clinical symptoms, physiological skin detection, and dermatoscopy results were collected, and the clinical characteristics of rosacea and other common facial inflammatory diseases were summarized according to the descriptive analysis results. The model was established using a machine learning method and compared with the judgment results of young and inexperienced doctors to verify whether the model can improve the accuracy of clinical diagnosis and differential diagnosis of rosacea.\n    \n\n\n          Results:\n        \n      \n      The proportion of yellow and red halos, vascular polygons, as well as follicular pustules, showed by dermatoscopy, and the melanin index in physiological skin detection revealed statistical significance in differentiating rosacea and other common facial inflammatory diseases (all P < 0.01). After adopting the machine learning, we found that GBM (Gradient Boosting Machine) algorithm was the best, and the error rate of this model in the validation set was 5.48%. In the final man-machine comparison, the accuracy of the GBM algorithm model for the classification of skin disease was significantly higher than that of young and inexperienced doctors.\n    \n\n\n          Conclusion:\n        \n      \n      Dermatoscopy combined with machine learning can effectively improve the diagnosis and differential diagnosis accuracy of rosacea and other facial inflammatory skin diseases."
        },
        {
            "title": "Early Melanoma Diagnosis With Sequential Dermoscopic Images.",
            "abstract": "Dermatologists often diagnose or rule out early melanoma by evaluating the follow-up dermoscopic images of skin lesions. However, existing algorithms for early melanoma diagnosis are developed using single time-point images of lesions. Ignoring the temporal, morphological changes of lesions can lead to misdiagnosis in borderline cases. In this study, we propose a framework for automated early melanoma diagnosis using sequential dermoscopic images. To this end, we construct our method in three steps. First, we align sequential dermoscopic images of skin lesions using estimated Euclidean transformations, extract the lesion growth region by computing image differences among the consecutive images, and then propose a spatio-temporal network to capture the dermoscopic changes from aligned lesion images and the corresponding difference images. Finally, we develop an early diagnosis module to compute probability scores of malignancy for lesion images over time. We collected 179 serial dermoscopic imaging data from 122 patients to verify our method. Extensive experiments show that the proposed model outperforms other commonly used sequence models. We also compared the diagnostic results of our model with those of seven experienced dermatologists and five registrars. Our model achieved higher diagnostic accuracy than clinicians (63.69% vs. 54.33%, respectively) and provided an earlier diagnosis of melanoma (60.7% vs. 32.7% of melanoma correctly diagnosed on the first follow-up images). These results demonstrate that our model can be used to identify melanocytic lesions that are at high-risk of malignant transformation earlier in the disease process and thereby redefine what is possible in the early detection of melanoma."
        },
        {
            "title": "Smart identification of psoriasis by images using convolutional neural networks: a case study in China.",
            "abstract": "Background:\n        \n      \n      Psoriasis is a chronic inflammatory skin disease, which holds a high incidence in China. However, professional dermatologists who can diagnose psoriasis early and correctly are insufficient in China, especially in the rural areas. A smart approach to identify psoriasis by pictures would be highly adaptable countrywide and could play a useful role in early diagnosis and regular treatment of psoriasis.\n    \n\n\n          Objectives:\n        \n      \n      Design and evaluation of a smart psoriasis identification system based on clinical images (without relying on a dermatoscope) that works effectively similar to a dermatologist.\n    \n\n\n          Methods:\n        \n      \n      A set of deep learning models using convolutional neural networks (CNNs) was explored and compared in the system for automatic identification of psoriasis. The work was carried out on a standardized dermatological dataset with 8021 clinical images of 9 common disorders including psoriasis along with full electronic medical records of patients built over the last 9 years in China. A two-stage deep neural network was designed and developed to identify psoriasis. In the first stage, a multilabel classifier was trained to learn the visual patterns for each individual skin disease. In the second stage, the output of the first stage was utilized to distinguish psoriasis from other skin diseases.\n    \n\n\n          Results:\n        \n      \n      The area under the curve (AUC) of the two-stage model reached 0.981 Â± 0.015, which outperforms a single-stage model. And, the classifier showed superior performance (missed diagnosis rate: 0.03, misdiagnosis rate: 0.04) than 25 Chinese dermatologists (missed diagnosis rate: 0.19, misdiagnosis rate: 0.10) in the diagnosis of psoriasis on 100 clinical images.\n    \n\n\n          Conclusions:\n        \n      \n      Using clinical images to identify psoriasis is feasible and effective based on CNNs, which also builds a solid technical base for smart care of skin diseases especially psoriasis using mobile/tablet applications for teledermatology in China."
        },
        {
            "title": "Occurrence of inflammatory bowel disease in patients with chronic inflammatory skin diseases: a cohort study: Classification: Epidemiology.",
            "abstract": "Background:\n        \n      \n      Several studies have linked various chronic inflammatory skin diseases (CISDs) with inflammatory bowel disease (IBD) in a range of data sources with mixed conclusions.\n    \n\n\n          Objectives:\n        \n      \n      We compared the incidence of IBD - ulcerative colitis (UC) and Crohn disease (CD) - in patients with a CISD vs. similar persons without a CISD.\n    \n\n\n          Methods:\n        \n      \n      In this cohort study using nationwide, longitudinal, commercial insurance claims data from the USA, we identified adults and children who were seen by a dermatologist between 2004 and 2020, and diagnosed with either psoriasis, atopic dermatitis, alopecia areata, vitiligo or hidradenitis suppurativa. Comparator patients were identified through risk-set sampling; they were eligible if they were seen by a dermatologist at least twice and not diagnosed with a CISD. Patient follow-up lasted until either IBD diagnosis, death, disenrolment or end of data stream, whichever came first. IBD events, UC or CD, were identified via validated algorithms: hospitalization or diagnosis with endoscopic confirmation. Incidence rates were computed before and after adjustment via propensity-score decile stratification to account for IBD risk factors. Hazard ratios (HR) and 95% confidence intervals (CIs) were estimated to compare the incidence of IBD in CISD vs. non-CISD.\n    \n\n\n          Results:\n        \n      \n      We identified patients with atopic dermatitis (n = 123 614), psoriasis (n = 83 049), alopecia areata (n = 18 135), vitiligo (n = 9003) or hidradenitis suppurativa (n = 6806), and comparator patients without a CISD (n = 2 376 120). During a median follow-up time of 718 days, and after applying propensity-score adjustment for IBD risk factors, we observed increased risk of both UC (HRUC 2Â·30, 95% CI 1Â·61-3Â·28) and CD (HRCD 2Â·70, 1Â·69-4Â·32) in patients with hidradenitis suppurativa, an increased risk of CD (HRCD 1Â·23, 1Â·03-1Â·46) but not UC (HRUC 1Â·01, 0Â·89-1Â·14) in psoriasis, and no increased risk of IBD in atopic dermatitis (HRUC 1Â·02, 0Â·92-1Â·12; HRCD 1Â·08, 0Â·94-1Â·23), alopecia areata (HRUC 1Â·18, 0Â·89-1Â·56; HRCD 1Â·26, 0Â·86-1Â·86) or vitiligo (HRUC 1Â·14, 0Â·77-1Â·68; HRCD 1Â·45, 0Â·87-2Â·41).\n    \n\n\n          Conclusions:\n        \n      \n      IBD was increased in patients with hidradenitis suppurativa. CD alone was increased in patients with psoriasis. Neither UC nor CD was increased in patients with atopic dermatitis, alopecia areata or vitiligo. What is already known about this topic? Several studies have linked various chronic inflammatory skin diseases (CISDs) with inflammatory bowel disease (IBD) utilizing a range of data sources, with mixed conclusions. What does this study add? This large-scale, claims-based cohort study expands current knowledge by providing background rates for IBD across multiple CISDs using consistent methods and within a single, nationally representative patient population. We observed a relative increased risk of IBD in patients with hidradenitis suppurativa, but the overall incidence rate difference of IBD was generally low. Crohn disease alone was significantly increased in patients with psoriasis, and neither ulcerative colitis nor Crohn disease was increased in patients with atopic dermatitis, vitiligo or alopecia areata."
        },
        {
            "title": "Automatic SCOring of Atopic Dermatitis Using Deep Learning: A Pilot Study.",
            "abstract": "Atopic dermatitis (AD) is a chronic, itchy skin condition that affects 15-20% of children but may occur at any age. It is estimated that 16.5 million US adults (7.3%) have AD that initially began at age >2 years, with nearly 40% affected by moderate or severe disease. Therefore, a quantitative measurement that tracks the evolution of AD severity could be extremely useful in assessing patient evolution and therapeutic efficacy. Currently, SCOring Atopic Dermatitis (SCORAD) is the most frequently used measurement tool in clinical practice. However, SCORAD has the following disadvantages: (i) time consuming-calculating SCORAD usually takes about 7-10 minutes per patient, which poses a heavy burden on dermatologists and (ii) inconsistency-owing to the complexity of SCORAD calculation, even well-trained dermatologists could give different scores for the same case. In this study, we introduce the Automatic SCORAD, an automatic version of the SCORAD that deploys state-of-the-art convolutional neural networks that measure AD severity by analyzing skin lesion images. Overall, we have shown that Automatic SCORAD may prove to be a rapid and objective alternative method for the automatic assessment of AD, achieving results comparable with those of human expert assessment while reducing interobserver variability."
        },
        {
            "title": "Digital skin imaging applications, part I: Assessment of image acquisition technique features.",
            "abstract": "Background:\n        \n      \n      The rapid adoption of digital skin imaging applications has increased the utilization of smartphone-acquired images in dermatology. While this has enormous potential for scaling the assessment of concerning skin lesions, the insufficient quality of many consumer/patient-taken images can undermine clinical accuracy and potentially harm patients due to lack of diagnostic interpretability. We aim to characterize the current state of digital skin imaging applications and comprehensively assess how image acquisition features address image quality.\n    \n\n\n          Materials and methods:\n        \n      \n      Publicly discoverable mobile, web, and desktop-based skin imaging applications, identified through keyword searches in mobile app stores, Google Search queries, previous teledermatology studies, and expert recommendations were independently assessed by three reviewers. Applications were categorized by primary audience (consumer-facing, nonhospital-based practice, or enterprise/health system), function (education, store-and-forward teledermatology, live-interactive teledermatology, electronic medical record adjunct/clinical imaging storage, or clinical triage), in-app connection to a healthcare provider (yes or no), and user type (patient, provider, or both).\n    \n\n\n          Results:\n        \n      \n      Just over half (57%) of 191 included skin imaging applications had at least one of 14 image acquisition technique features. Those that were consumer-facing, intended for educational use, and designed for both patient and physician users had significantly greater feature richness (p < 0.05). The most common feature was the inclusion of text-based imaging tips, followed by the requirement to submit multiple images and body area matching.\n    \n\n\n          Conclusion:\n        \n      \n      Very few skin imaging applications included more than one image acquisition technique feature. Feature richness varied significantly by audience, function, and user categories. Users of digital dermatology tools should consider which applications have standardized features that improve image quality."
        },
        {
            "title": "Dermatologist-level classification of skin cancer with deep neural networks.",
            "abstract": "Skin cancer, the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs) show potential for general and highly variable tasks across many fine-grained object categories. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images-two orders of magnitude larger than previous datasets-consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care."
        },
        {
            "title": "Nail apparatus melanoma: dermoscopic and histopathologic correlations on a series of 23 patients from a single centre.",
            "abstract": "Background:\n        \n      \n      Nail apparatus melanoma (NAM) is an uncommon tumour, and there are few studies focused on its dermoscopic features.\n    \n\n\n          Objective:\n        \n      \n      The aims of our study were to evaluate the diagnostic accuracy of dermoscopy in NAM. A diagnostic algorithm for adult patients with suspected NAM is proposed.\n    \n\n\n          Methods:\n        \n      \n      We collected NAM dermoscopic images of patients with a proven histopathology from 2008 until 2015. Clinical and dermoscopic images were blindly examined by two dermatologists, and correlations between histopathological aspects and dermoscopic features were investigated.\n    \n\n\n          Results:\n        \n      \n      We retrospectively collected NAM dermoscopic images associated with a proven histopathology of 23 Caucasian patients. Only cases with available both preoperative dermoscopic images and bioptic specimens were included. Seventeen women and six men were included. The mean age at diagnosis was 63 years (range 18-92).\n    \n\n\n          Conclusion:\n        \n      \n      We created an algorithm to indicate the correct way to follow an adult patient with suspected NAM. This algorithm may ameliorate management in case of suspected NAM and possibly facilitate an early diagnosis."
        },
        {
            "title": "Prediction of melanoma evolution in melanocytic nevi via artificial intelligence: A call for prospective data.",
            "abstract": "Recent research revealed the superiority of artificial intelligence over dermatologists to diagnose melanoma from images. However, 30-50% of all melanomas and more than half of those in young patients evolve from initially benign lesions. Despite its high relevance for melanoma screening, neither clinicians nor computers are yet able to reliably predict a nevus' oncologic transformation. The cause of this lies in the static nature of lesion presentation in the current standard of care, both for clinicians and algorithms. The status quo makes it difficult to train algorithms (and clinicians) to precisely assess the likelihood of a benign skin lesion to transform into melanoma. In addition, it inhibits the precision of current algorithms since 'evolution' image features may not be part of their decision. The current literature reveals certain types of melanocytic nevi (i.e. 'spitzoid' or 'dysplastic' nevi) and criteria (i.e. visible vasculature) that, in general, appear to have a higher chance to transform into melanoma. However, owing to the cumulative nature of oncogenic mutations in melanoma, a more fine-grained early morphologic footprint is likely to be detectable by an algorithm. In this perspective article, the concept of melanoma prediction is further explored by the discussion of the evolution of melanoma, the concept for training of such a nevi classifier and the implications of early melanoma prediction for clinical practice. In conclusion, the authors believe that artificial intelligence trained on prospective image data could be transformative for skin cancer diagnostics by (a) predicting melanoma before it occurs (i.e. pre-in situ) and (b) further enhancing the accuracy of current melanoma classifiers. Necessary prospective images for this research are obtained via free mole-monitoring mobile apps."
        },
        {
            "title": "Region Extraction and Classification of Skin Cancer: A Heterogeneous framework of Deep CNN Features Fusion and Reduction.",
            "abstract": "Cancer is one of the leading causes of deaths in the last two decades. It is either diagnosed malignant or benign - depending upon the severity of the infection and the current stage. The conventional methods require a detailed physical inspection by an expert dermatologist, which is time-consuming and imprecise. Therefore, several computer vision methods are introduced lately, which are cost-effective and somewhat accurate. In this work, we propose a new automated approach for skin lesion detection and recognition using a deep convolutional neural network (DCNN). The proposed cascaded design incorporates three fundamental steps including; a) contrast enhancement through fast local Laplacian filtering (FlLpF) along HSV color transformation; b) lesion boundary extraction using color CNN approach by following XOR operation; c) in-depth features extraction by applying transfer learning using Inception V3 model prior to feature fusion using hamming distance (HD) approach. An entropy controlled feature selection method is also introduced for the selection of the most discriminant features. The proposed method is tested on PH2 and ISIC 2017 datasets, whereas the recognition phase is validated on PH2, ISBI 2016, and ISBI 2017 datasets. From the results, it is concluded that the proposed method outperforms several existing methods and attained accuracy 98.4% on PH2 dataset, 95.1% on ISBI dataset and 94.8% on ISBI 2017 dataset."
        },
        {
            "title": "Patient Perspectives on the Use of Artificial Intelligence for Skin Cancer Screening: A Qualitative Study.",
            "abstract": "Importance:\n        \n      \n      The use of artificial intelligence (AI) is expanding throughout the field of medicine. In dermatology, researchers are evaluating the potential for direct-to-patient and clinician decision-support AI tools to classify skin lesions. Although AI is poised to change how patients engage in health care, patient perspectives remain poorly understood.\n    \n\n\n          Objective:\n        \n      \n      To explore how patients conceptualize AI and perceive the use of AI for skin cancer screening.\n    \n\n\n          Design, setting, and participants:\n        \n      \n      A qualitative study using a grounded theory approach to semistructured interview analysis was conducted in general dermatology clinics at the Brigham and Women's Hospital and melanoma clinics at the Dana-Farber Cancer Institute. Forty-eight patients were enrolled. Each interview was independently coded by 2 researchers with interrater reliability measurement; reconciled codes were used to assess code frequency. The study was conducted from May 6 to July 8, 2019.\n    \n\n\n          Main outcomes and measures:\n        \n      \n      Artificial intelligence concept, perceived benefits and risks of AI, strengths and weaknesses of AI, AI implementation, response to conflict between human and AI clinical decision-making, and recommendation for or against AI.\n    \n\n\n          Results:\n        \n      \n      Of 48 patients enrolled, 26 participants (54%) were women; mean (SD) age was 53.3 (21.7) years. Sixteen patients (33%) had a history of melanoma, 16 patients (33%) had a history of nonmelanoma skin cancer only, and 16 patients (33%) had no history of skin cancer. Twenty-four patients were interviewed about a direct-to-patient AI tool and 24 patients were interviewed about a clinician decision-support AI tool. Interrater reliability ratings for the 2 coding teams were Îº = 0.94 and Îº = 0.89. Patients primarily conceptualized AI in terms of cognition. Increased diagnostic speed (29 participants [60%]) and health care access (29 [60%]) were the most commonly perceived benefits of AI for skin cancer screening; increased patient anxiety was the most commonly perceived risk (19 [40%]). Patients perceived both more accurate diagnosis (33 [69%]) and less accurate diagnosis (41 [85%]) to be the greatest strength and weakness of AI, respectively. The dominant theme that emerged was the importance of symbiosis between humans and AI (45 [94%]). Seeking biopsy was the most common response to conflict between human and AI clinical decision-making (32 [67%]). Overall, 36 patients (75%) would recommend AI to family members and friends.\n    \n\n\n          Conclusions and relevance:\n        \n      \n      In this qualitative study, patients appeared to be receptive to the use of AI for skin cancer screening if implemented in a manner that preserves the integrity of the human physician-patient relationship."
        },
        {
            "title": "Improved patient satisfaction and diagnostic accuracy in skin diseases with a Visual Clinical Decision Support System-A feasibility study with general practitioners.",
            "abstract": "Patient satisfaction is an important indicator of health care quality, and it remains an important goal for optimal treatment outcomes to reduce the level of misdiagnoses and inappropriate or absent therapeutic actions. Digital support tools for differential diagnosis to assist clinicians in reaching the correct diagnosis may be helpful, but how the use of these affect patients is not clear. The primary objective of this feasibility study was to investigate patient experience and satisfaction in a primary care setting where general practitioners (GPs) used a visual clinical decision support system (CDSS) compared with standard consultations. Secondary objectives were diagnostic accuracy and length of consultation. Thirty-one patients with a dermatologist-confirmed skin diagnosis were allocated to consult GPs that had been randomized to conduct either standard consultations (SDR, n = 21) or CDSS (n = 16) on two separate study days one week apart. All patients were diagnosed independently by multiple GPs (n = 3-8) in both the SDR and CDSS study arms. Using the CDSS, more patients felt involved in the decision making (P = 0.05). In addition, more patients were exposed to images during the consultations (P = 6.8e-27), and 83% of those that were shown images replied they felt better supported in the consultation. The use of CDSS significantly improved the diagnostic accuracy (34%, P = 0.007), and did not increase the duration of the consultation (median 10 minutes in both arms). This study shows for the first time that compared with standard GP consultations, CDSS assist the GP on skin related diagnoses and improve patient satisfaction and diagnostic accuracy without impacting the duration of the consultations. This is likely to increase correct treatment choices, patient adherence, and overall result in better healthcare outcomes."
        },
        {
            "title": "Requirements and expectations of high-quality biomarkers for atopic dermatitis and psoriasis in 2021-a two-round Delphi survey among international experts.",
            "abstract": "Background:\n        \n      \n      Chronic inflammatory skin diseases such as atopic dermatitis (AD) and psoriasis (PSO) present major challenges in health care. Thus, biomarkers to identify disease trajectories and response to treatments to improve the lives of affected individuals warrant great research consideration. The requirements that these biomarkers must fulfil for use as practical clinical tools have not yet been adequately investigated.\n    \n\n\n          Aim:\n        \n      \n      To identify the core elements of high-quality AD and PSO biomarkers to prepare recommendations for current biomarker research.\n    \n\n\n          Method:\n        \n      \n      A cross-sectional two-round Delphi survey was conducted from August to October 2019 and October to November 2020. All participants were members of the BIOMAP project, an EU-funded consortium of clinicians, researchers, patient organizations and pharmaceutical industry partners. The first round consisted of three open-ended questions. Responses were qualitatively analysed, and 26 closed statements were developed. For the second round, 'agreement' was assumed when the responses of â‰¥70% of the participants were â‰¥5 points on a 7-point Likert scale for each statement. Priority classification was based on mean scores (<20th percentile = low, 20th to 60th percentile = medium, >60th percentile = high).\n    \n\n\n          Results:\n        \n      \n      Twenty-one and twenty-six individuals participated in rounds one and two, respectively. From 26 statements that were included in round 2, 18 achieved agreement (8 concerning the performance, 8 for the purpose and 2 on current obstacles). Seven statements were classified as high priority, e.g. those concerning reliability, clinical validity, a high positive predictive value, prediction of the therapeutic response and disease progression. Another seven statements were assigned medium priority, e.g. those about analytical validity, prediction of comorbidities and therapeutic algorithm. Low priority included four statements, like those concerning cost effectiveness and prediction of disease flares.\n    \n\n\n          Conclusion:\n        \n      \n      The core requirements that experts agreed on being essential for high-quality AD and PSO biomarkers require rapid validation. Biomarkers can therefore be assessed based on these prioritized requirements."
        },
        {
            "title": "Deep learning algorithms out-perform veterinary pathologists in detecting the mitotically most active tumor region.",
            "abstract": "Manual count of mitotic figures, which is determined in the tumor region with the highest mitotic activity, is a key parameter of most tumor grading schemes. It can be, however, strongly dependent on the area selection due to uneven mitotic figure distribution in the tumor section. We aimed to assess the question, how significantly the area selection could impact the mitotic count, which has a known high inter-rater disagreement. On a data set of 32 whole slide images of H&E-stained canine cutaneous mast cell tumor, fully annotated for mitotic figures, we asked eight veterinary pathologists (five board-certified, three in training) to select a field of interest for the mitotic count. To assess the potential difference on the mitotic count, we compared the mitotic count of the selected regions to the overall distribution on the slide. Additionally, we evaluated three deep learning-based methods for the assessment of highest mitotic density: In one approach, the model would directly try to predict the mitotic count for the presented image patches as a regression task. The second method aims at deriving a segmentation mask for mitotic figures, which is then used to obtain a mitotic density. Finally, we evaluated a two-stage object-detection pipeline based on state-of-the-art architectures to identify individual mitotic figures. We found that the predictions by all models were, on average, better than those of the experts. The two-stage object detector performed best and outperformed most of the human pathologists on the majority of tumor cases. The correlation between the predicted and the ground truth mitotic count was also best for this approach (0.963-0.979). Further, we found considerable differences in position selection between pathologists, which could partially explain the high variance that has been reported for the manual mitotic count. To achieve better inter-rater agreement, we propose to use a computer-based area selection for support of the pathologist in the manual mitotic count."
        },
        {
            "title": "An Analysis of Skin of Color Dermatology Related Content on Instagram.",
            "abstract": "Importance: Social media is making information about skin of color more readily available to those unfamiliar with ethnic skin and hair. Objectives: To answer: 1) what skin of color-related dermatology content is being posted on Instagram? And 2) who is producing this content? Design: Cross-sectional epidemiologic study analyzing the content of posts associated with 31 Instagram skin of color dermatology-related topics (hashtags). Setting: Population-based Participants: The Instagram accounts linked with the top 9 posts as generated by the Instagram algorithm associated with each search term. Exposures: Instagram account holders. Main Outcomes and Measures: [1] The number of posts associated with each skin of color dermatology hashtag search term. [2] Classification of posts as either educational or promotional. [3] Classification of posts as a photo or video. [4] Classification of Instagram accounts that produced the posts (American board-certified dermatologists, dermatology residents, foreign dermatologists, patients, medical interest groups, or other). [5] Quantification of the number of post likes and comments. [6] Comparison of number of educational and promotional posts between board-certified dermatologists and other Instagram users. Results: The 31 sampled hashtags were associated with a total of 9,087,589 posts as of January 16, 2020. 219 of the 288 top posts generated from these queries met inclusion criteria. Board-certified dermatologists (26 posts) only generated 12% of top posts, whereas individuals not certified in dermatology produced 88% of top content. Of this group, social media influencers were the largest subcategory (37 posts). A majority of the top posts were promotional (135 posts, 61.6%) and formatted as photos (181 posts, 82.6%). While there was a significant difference in the number of likes for content posted by board-certified dermatologists vs non-dermatologists (P=0.027), these differences became non-significant after stratifying by the intention of the post (promotional P=0.13, educational P=0.17). Conclusions and Relevance: Board-certified dermatologists are underrepresented among people generating top skin of color dermatology-related content on Instagram. Board-certified dermatologists should establish a more prominent presence on social media platforms so that patients have greater access to accurate, evidenced-based educational resources regarding dermatologic conditions, treatment options, and treatment risks from reliable sources. J Drugs Dermatol. 2020;19(7): doi:10.36849/JDD.2020.5142."
        },
        {
            "title": "A new deep learning approach integrated with clinical data for the dermoscopic differentiation of early melanomas from atypical nevi.",
            "abstract": "Background:\n        \n      \n      Timely recognition of malignant melanoma (MM) is challenging for dermatologists worldwide and represents the main determinant for mortality. Dermoscopic examination is influenced by dermatologists' experience and fails to achieve adequate accuracy and reproducibility in discriminating atypical nevi (AN) from early melanomas (EM).\n    \n\n\n          Objective:\n        \n      \n      We aimed to develop a Deep Convolutional Neural Network (DCNN) model able to support dermatologists in the classification and management of atypical melanocytic skin lesions (aMSL).\n    \n\n\n          Methods:\n        \n      \n      A training set (630 images), a validation set (135) and a testing set (214) were derived from the idScore dataset of 979 challenging aMSL cases in which the dermoscopic image is integrated with clinical data (age, sex, body site and diameter) and associated with histological data. A DCNN_aMSL architecture was designed and then trained on both dermoscopic images of aMSL and the clinical/anamnestic data, resulting in the integrated \"iDCNN_aMSL\" model. Responses of 111 dermatologists with different experience levels on both aMSL classification (intuitive diagnosis) and management decisions (no/long follow-up; short follow-up; excision/preventive excision) were compared with the DCNNs models.\n    \n\n\n          Results:\n        \n      \n      In the lesion classification study, the iDCNN_aMSL achieved the best accuracy, reaching an AUC = 90.3 %, SE = 86.5 % and SP = 73.6 %, compared to DCNN_aMSL (SE = 89.2 %, SP = 65.7 %) and intuitive diagnosis of dermatologists (SE = 77.0 %; SP = 61.4 %).\n    \n\n\n          Conclusions:\n        \n      \n      The iDCNN_aMSL proved to be the best support tool for management decisions reducing the ratio of inappropriate excision. The proposed iDCNN_aMSL model can represent a valid support for dermatologists in discriminating AN from EM with high accuracy and for medical decision making by reducing their rates of inappropriate excisions."
        },
        {
            "title": "A new dermoscopic algorithm for the differential diagnosis of facial lentigo maligna and pigmented actinic keratosis.",
            "abstract": "The clinical and dermoscopic diagnosis of facial lentigo maligna (LM) and pigmented actinic keratosis (PAK) remains challenging, particularly at the early disease stages. To identify dermoscopic criteria that might be useful to differentiate LM from PAK, and to elaborate and validate an automated diagnostic algorithm for facial LM/PAK. We performed a retrospective multicentre study to evaluate dermoscopic images of histologically-proven LM and PAK, and assess previously described dermoscopic criteria. In the first part of the study, 61 cases of LM and 74 PAK were examined and a parsimonious algorithm was elaborated using stepwise discriminant analysis. The following eight dermoscopic criteria achieved the greatest discriminative power: (1) light brown colour; (2) a structureless zone, varying in colour from brown to brown/tan, to black; (3) in-focus, discontinuous brown lines; (4) incomplete brown or grey circles; (5) a structureless brown or black zone, obscuring the hair follicles; (6) a brown (tan), eccentric, structureless zone; (7) a blue structureless zone; and (8) scales. The newly developed algorithm was subsequently validated using an additional series of 110 LM and 75 PAK cases. Diagnostic accuracy was 86.5% (Îº: 0.73, 95% CI: 0.63-0.83). For the diagnosis of LM vs PAK, sensitivity was 82.7% (95% CI: 75.7-89.8%), specificity was 92.0% (95% CI: 85.9-98.1%), positive predictive value was 93.8% (95% CI: 89.0-98.6%), and negative predictive value was 78.4% (95% CI: 68.4-86.5%). This algorithm may represent an additional tool for clinicians to distinguish between facial LM and PAK."
        },
        {
            "title": "The MOLES system to guide the management of melanocytic choroidal tumours: can optometrists apply it?",
            "abstract": "Clinical relevance:\n        \n      \n      Although melanocytic choroidal tumours of the choroid are a common eye pathology, no standardised protocol exists for their management in the community.\n    \n\n\n          Background:\n        \n      \n      Choroidal naevi are found in approximately 6% of the adult White population, whereas choroidal melanomas are rare, with an annual incidence of 5-10/million/year. Multimodal imaging has advanced the understanding of malignancy imaging biomarkers, but distinguishing between a small melanoma and naevus remains difficult and an algorithm for their management by community practitioners has not been uniformly adopted. One of the authors (BD) devised the MOLES scoring system, which indicates malignancy likelihood according to mushroom shape, orange pigment, large size, enlargement, and subretinal fluid. When applied by ocular oncologists, the system accurately distinguishes choroidal naevi from melanomas. The aim of this study was to evaluate whether community optometrists can appropriately manage patients with melanocytic choroidal tumours using this system.\n    \n\n\n          Methods:\n        \n      \n      Clinical images of 25 melanocytic choroidal tumours were presented in an online survey, including colour fundus photographs, fundus autofluorescence, optical coherence tomography, and B-scan ultrasound images. Using the MOLES system, 39 optometrists diagnosed tumours as naevus or probable melanoma and decided between community monitoring and ophthalmologist referral. Responses were compared to MOLES grading of the same clinical images by ocular oncologists.\n    \n\n\n          Results:\n        \n      \n      Using MOLES, optometrists correctly identified 389/406 probable melanomas (95.8% sensitivity) and 331/516 choroidal naevi (64.1% specificity); correctly referred 773/778 tumours to an ophthalmologist (99.4% sensitivity); and correctly managed 80/144 lesions (55.6% specificity) in the community.\n    \n\n\n          Conclusion:\n        \n      \n      Optometrists safely applied the MOLES scoring system in this survey. Further measures are indicated to reduce choroidal naevi over-referral and evaluate MOLES system usage in clinical optometric practice, where some imaging modalities may not be readily available."
        },
        {
            "title": "Computer-assisted diagnosis techniques (dermoscopy and spectroscopy-based) for diagnosing skin cancer in adults.",
            "abstract": "Background:\n        \n      \n      Early accurate detection of all skin cancer types is essential to guide appropriate management and to improve morbidity and survival. Melanoma and cutaneous squamous cell carcinoma (cSCC) are high-risk skin cancers which have the potential to metastasise and ultimately lead to death, whereas basal cell carcinoma (BCC) is usually localised with potential to infiltrate and damage surrounding tissue. Anxiety around missing early curable cases needs to be balanced against inappropriate referral and unnecessary excision of benign lesions. Computer-assisted diagnosis (CAD) systems use artificial intelligence to analyse lesion data and arrive at a diagnosis of skin cancer. When used in unreferred settings ('primary care'), CAD may assist general practitioners (GPs) or other clinicians to more appropriately triage high-risk lesions to secondary care. Used alongside clinical and dermoscopic suspicion of malignancy, CAD may reduce unnecessary excisions without missing melanoma cases.\n    \n\n\n          Objectives:\n        \n      \n      To determine the accuracy of CAD systems for diagnosing cutaneous invasive melanoma and atypical intraepidermal melanocytic variants, BCC or cSCC in adults, and to compare its accuracy with that of dermoscopy.\n    \n\n\n          Search methods:\n        \n      \n      We undertook a comprehensive search of the following databases from inception up to August 2016: Cochrane Central Register of Controlled Trials (CENTRAL); MEDLINE; Embase; CINAHL; CPCI; Zetoc; Science Citation Index; US National Institutes of Health Ongoing Trials Register; NIHR Clinical Research Network Portfolio Database; and the World Health Organization International Clinical Trials Registry Platform. We studied reference lists and published systematic review articles.\n    \n\n\n          Selection criteria:\n        \n      \n      Studies of any design that evaluated CAD alone, or in comparison with dermoscopy, in adults with lesions suspicious for melanoma or BCC or cSCC, and compared with a reference standard of either histological confirmation or clinical follow-up.\n    \n\n\n          Data collection and analysis:\n        \n      \n      Two review authors independently extracted all data using a standardised data extraction and quality assessment form (based on QUADAS-2). We contacted authors of included studies where information related to the target condition or diagnostic threshold were missing. We estimated summary sensitivities and specificities separately by type of CAD system, using the bivariate hierarchical model. We compared CAD with dermoscopy using (a) all available CAD data (indirect comparisons), and (b) studies providing paired data for both tests (direct comparisons). We tested the contribution of human decision-making to the accuracy of CAD diagnoses in a sensitivity analysis by removing studies that gave CAD results to clinicians to guide diagnostic decision-making.\n    \n\n\n          Main results:\n        \n      \n      We included 42 studies, 24 evaluating digital dermoscopy-based CAD systems (Derm-CAD) in 23 study cohorts with 9602 lesions (1220 melanomas, at least 83 BCCs, 9 cSCCs), providing 32 datasets for Derm-CAD and seven for dermoscopy. Eighteen studies evaluated spectroscopy-based CAD (Spectro-CAD) in 16 study cohorts with 6336 lesions (934 melanomas, 163 BCC, 49 cSCCs), providing 32 datasets for Spectro-CAD and six for dermoscopy. These consisted of 15 studies using multispectral imaging (MSI), two studies using electrical impedance spectroscopy (EIS) and one study using diffuse-reflectance spectroscopy. Studies were incompletely reported and at unclear to high risk of bias across all domains. Included studies inadequately address the review question, due to an abundance of low-quality studies, poor reporting, and recruitment of highly selected groups of participants.Across all CAD systems, we found considerable variation in the hardware and software technologies used, the types of classification algorithm employed, methods used to train the algorithms, and which lesion morphological features were extracted and analysed across all CAD systems, and even between studies evaluating CAD systems. Meta-analysis found CAD systems had high sensitivity for correct identification of cutaneous invasive melanoma and atypical intraepidermal melanocytic variants in highly selected populations, but with low and very variable specificity, particularly for Spectro-CAD systems. Pooled data from 22 studies estimated the sensitivity of Derm-CAD for the detection of melanoma as 90.1% (95% confidence interval (CI) 84.0% to 94.0%) and specificity as 74.3% (95% CI 63.6% to 82.7%). Pooled data from eight studies estimated the sensitivity of multispectral imaging CAD (MSI-CAD) as 92.9% (95% CI 83.7% to 97.1%) and specificity as 43.6% (95% CI 24.8% to 64.5%). When applied to a hypothetical population of 1000 lesions at the mean observed melanoma prevalence of 20%, Derm-CAD would miss 20 melanomas and would lead to 206 false-positive results for melanoma. MSI-CAD would miss 14 melanomas and would lead to 451 false diagnoses for melanoma. Preliminary findings suggest CAD systems are at least as sensitive as assessment of dermoscopic images for the diagnosis of invasive melanoma and atypical intraepidermal melanocytic variants. We are unable to make summary statements about the use of CAD in unreferred populations, or its accuracy in detecting keratinocyte cancers, or its use in any setting as a diagnostic aid, because of the paucity of studies.\n    \n\n\n          Authors' conclusions:\n        \n      \n      In highly selected patient populations all CAD types demonstrate high sensitivity, and could prove useful as a back-up for specialist diagnosis to assist in minimising the risk of missing melanomas. However, the evidence base is currently too poor to understand whether CAD system outputs translate to different clinical decision-making in practice. Insufficient data are available on the use of CAD in community settings, or for the detection of keratinocyte cancers. The evidence base for individual systems is too limited to draw conclusions on which might be preferred for practice. Prospective comparative studies are required that evaluate the use of already evaluated CAD systems as diagnostic aids, by comparison to face-to-face dermoscopy, and in participant populations that are representative of those in which the test would be used in practice."
        },
        {
            "title": "W-Net: Dense and diagnostic semantic segmentation of subcutaneous and breast tissue in ultrasound images by incorporating ultrasound RF waveform data.",
            "abstract": "We study the use of raw ultrasound waveforms, often referred to as the \"Radio Frequency\" (RF) data, for the semantic segmentation of ultrasound scans to carry out dense and diagnostic labeling. We present W-Net, a novel Convolution Neural Network (CNN) framework that employs the raw ultrasound waveforms in addition to the grey ultrasound image to semantically segment and label tissues for anatomical, pathological, or other diagnostic purposes. To the best of our knowledge, this is also the first deep-learning or CNN approach for segmentation that analyzes ultrasound raw RF data along with the grey image. We chose subcutaneous tissue (SubQ) segmentation as our initial clinical goal for dense segmentation since it has diverse intermixed tissues, is challenging to segment, and is an underrepresented research area. SubQ potential applications include plastic surgery, adipose stem-cell harvesting, lymphatic monitoring, and possibly detection/treatment of certain types of tumors. Unlike prior work, we seek to label every pixel in the image, without the use of a background class. A custom dataset consisting of hand-labeled images by an expert clinician and trainees are used for the experimentation, currently labeled into the following categories: skin, fat, fat fascia/stroma, muscle, and muscle fascia. We compared W-Net and attention variant of W-Net (AW-Net) with U-Net and Attention U-Net (AU-Net). Our novel W-Net's RF-Waveform encoding architecture outperformed regular U-Net and AU-Net, achieving the best mIoU accuracy (averaged across all tissue classes). We study the impact of RF data on dense labeling of the SubQ region, which is followed by the analyses of the generalization capability of the networks to patients and analysis on the SubQ tissue classes, determining that fascia tissues, especially muscle fascia in particular, are the most difficult anatomic class to recognize for both humans and AI algorithms. We present diagnostic semantic segmentation, which is semantic segmentation carried out for the purposes of direct diagnostic pixel labeling, and apply it to breast tumor detection task on a publicly available dataset to segment pixels into malignant tumor, benign tumor, and background tissue class. Using the segmented image we diagnose the patient by classifying the breast lesion as either benign or malignant. We demonstrate the diagnostic capability of RF data with the use of W-Net, which achieves the best segmentation scores across all classes."
        },
        {
            "title": "How I learned to stop worrying and love machine learning.",
            "abstract": "Artificial intelligence and its machine learning (ML) capabilities are very promising technologies for dermatology and other visually oriented fields due to their power in pattern recognition. Understandably, many physicians distrust replacing clinical finesse with unsupervised computer programs. We describe convolutional neural networks and discuss how this method of ML will impact the field of dermatology. ML is a form of artificial intelligence well suited for pattern recognition in visual applications. Many dermatologists are wary of such unsupervised algorithms and their future implications."
        },
        {
            "title": "A Comprehensive Evaluation and Benchmarking of Convolutional Neural Networks for Melanoma Diagnosis.",
            "abstract": "Melanoma is the most invasive skin cancer with the highest risk of death. While it is a serious skin cancer, it is highly curable if detected early. Melanoma diagnosis is difficult, even for experienced dermatologists, due to the wide range of morphologies in skin lesions. Given the rapid development of deep learning algorithms for melanoma diagnosis, it is crucial to validate and benchmark these models, which is the main challenge of this work. This research presents a new benchmarking and selection approach based on the multi-criteria analysis method (MCDM), which integrates entropy and the preference ranking organization method for enrichment of evaluations (PROMETHEE) methods. The experimental study is carried out in four phases. Firstly, 19 convolution neural networks (CNNs) are trained and evaluated on a public dataset of 991 dermoscopic images. Secondly, to obtain the decision matrix, 10 criteria, including accuracy, classification error, precision, sensitivity, specificity, F1-score, false-positive rate, false-negative rate, Matthews correlation coefficient (MCC), and the number of parameters are established. Third, entropy and PROMETHEE methods are integrated to determine the weights of criteria and rank the models. Fourth, the proposed benchmarking framework is validated using the VIKOR method. The obtained results reveal that the ResNet101 model is selected as the optimal diagnosis model for melanoma in our case study data. Thus, the presented benchmarking framework is proven to be useful at exposing the optimal melanoma diagnosis model targeting to ease the selection process of the proper convolutional neural network architecture."
        },
        {
            "title": "Detection of skin cancer with adaptive fuzzy classifier using improved whale optimization.",
            "abstract": "Skin cancer is considered as a well-known type of cancer globally, and its occurrence has been found to be raised in current days. Researchers state that the disease requires early prediction so that the identification of precise signs will make it simple for the dermatologists and clinicians. This disorder has been established to be unpredictable. Hence, this paper intends to develop an efficient skin cancer detection scheme, which classifies the nature of cancer, whether it is normal, benign or malignant. Accordingly, the skin image which is given as input is segmented using k-means clustering model and the features are extracted from segmented image using Local Vector Pattern (LVP). Moreover, the extracted features are subjected to fuzzy classifier for recognizing the cancer. In addition, the limits of membership functions are optimally selected by improved Whale Optimization Algorithm (WOA). Thus, the proposed scheme is termed as Improved Selection of Encircling and Spiral updating position of WO-based Fuzzy Classifier (ISESW-FC). From the optimized output, the type of skin cancer image can be determined, whether it is normal, benign or malignant. The performance of proposed model is compared over other conventional methods, and its efficiency is proved by means of Type I and Type II measures."
        },
        {
            "title": "Evaluation of Artificial Intelligence-Assisted Diagnosis of Skin Neoplasms: A Single-Center, Paralleled, Unmasked, Randomized Controlled Trial.",
            "abstract": "Trial design:\n        \n      \n      This was a single-center, unmasked, paralleled, randomized controlled trial.\n    \n\n\n          Methods:\n        \n      \n      A randomized trial was conducted in a tertiary care institute in South Korea to validate whether artificial intelligence (AI) could augment the accuracy of nonexpert physicians in the real-world settings, which included diverse out-of-distribution conditions. Consecutive patients aged >19 years, having one or more skin lesions suspicious for skin cancer detected by either the patient or physician, were randomly allocated to four nondermatology trainees and four dermatology residents. The attending dermatologists examined the randomly allocated patients with (AI-assisted group) or without (unaided group) the real-time assistance of AI algorithm (https://b2020.modelderm.com#world; convolutional neural networks; unmasked design) after simple randomization of the patients.\n    \n\n\n          Results:\n        \n      \n      Using 576 consecutive cases (Fitzpatrick skin phototypes III or IV) with suspicious lesions out of the initial 603 recruitments, the accuracy of the AI-assisted group (n = 295, 53.9%) was found to be significantly higher than those of the unaided group (n = 281, 43.8%; P = 0.019). Whereas the augmentation was more significant from 54.7% (n = 150) to 30.7% (n = 138; P < 0.0001) in the nondermatology trainees who had the least experience in dermatology, it was not significant in the dermatology residents. The algorithm could help trainees in the AI-assisted group include more differential diagnoses than the unaided group (2.09 vs. 1.95 diagnoses; P = 0.0005). However, a 12.2% drop in Top-1 accuracy of the trainees was observed in cases in which all Top-3 predictions given by the algorithm were incorrect.\n    \n\n\n          Conclusions:\n        \n      \n      The multiclass AI algorithm augmented the diagnostic accuracy of nonexpert physicians in dermatology."
        },
        {
            "title": "Dark corner artefact and diagnostic performance of a market-approved neural network for skin cancer classification.",
            "abstract": "Background and objectives:\n        \n      \n      Convolutional neural networks (CNN) have proven dermatologist-level performance in skin lesion classification. Prior to a broader clinical application, an assessment of limitations is crucial. Therefore, the influence of a dark tubular periphery in dermatoscopic images (also called dark corner artefact [DCA]) on the diagnostic performance of a market-approved CNN for skin lesion classification was investigated.\n    \n\n\n          Patients and methods:\n        \n      \n      A prospective image set of 233 skin lesions (60 malignant, 173 benign) without DCA (control-set) was modified to show small, medium or large DCA. All 932 images were analyzed by a market-approved CNN (Moleanalyzer-ProÂ® , FotoFinder Systems), providing malignancy scores (range 0-1) with the cut-off > 0.5 indicating malignancy.\n    \n\n\n          Results:\n        \n      \n      In the control-set the CNN achieved a sensitivity of 90.0 % (79.9 % - 95.3 %), a specificity of 96.5 % (92.6 % - 98.4 %), and an area under the curve (AUC) of receiver operating characteristics (ROC) of 0.961 (0.932 - 0.989). Comparable diagnostic performance was observed in the DCAsmall-set and DCAmedium-set. Conversely, in the DCAlarge-set significantly increased malignancy scores triggered a significantly decreased specificity (87.9 % [82.2 % - 91.9 %], P < 0.001), non-significantly increased sensitivity (96.7 % [88.6 % - 99.1 %]) and unchanged ROC-AUC of 0.962 (0.935 - 0.989).\n    \n\n\n          Conclusions:\n        \n      \n      Convolutional neural network classification was robust in images with small and medium DCA, but impaired in images with large DCA. Physicians should be aware of this limitation when submitting images to CNN classification."
        },
        {
            "title": "Facial skin cancer reconstructive and cosmetic outcomes: Analysis with algorithm for its management.",
            "abstract": "Background:\n        \n      \n      Management of facial skin cancer and its complications is important research topics needing continuous update to improve the outcome.\n    \n\n\n          Objective:\n        \n      \n      The study is to share our findings with surgeons and healthcare providers. The authors provide their efforts by pooling data from multiple institutions; as reporting surgical outcomes is significantly lacking and much needed in the Middle East and North Africa region in order to meaningfully improve quality of care. This study proposes an algorithm for management that could aid a surgical decision-making for reconstruction of defects after excision of facial skin cancer.\n    \n\n\n          Methods:\n        \n      \n      Retrograde simple descriptive analysis study is conducted for multicenter data about management of facial skin cancer and its cosmetic outcome. The analysis involves 159 male patients and 95 females.\n    \n\n\n          Results:\n        \n      \n      Nonmelanoma skin cancer was reported in 250 (98.4%) of 254 cases. Reconstructive procedures were complicated in 16 cases (~6.3% of the study). Skin cancer recurrence in head and neck has happened in five cases (~1.9% of the study). Flaps used survived without major complications; however, V-Y advancement flaps showed the best aesthetic outcome.\n    \n\n\n          Conclusion:\n        \n      \n      This study reports data in order to meaningfully improve the quality of care. Disease incidence, reconstructive complications, recurrences, and aesthetic outcome of facial skin cancer are included in the study. Based on the data pooling, the study proposes a simple treatment algorithm that could aid in surgical decision-making. V-Y advancement flaps showed the best aesthetic outcome."
        },
        {
            "title": "Validation of a Market-Approved Artificial Intelligence Mobile Health App for Skin Cancer Screening: A Prospective Multicenter Diagnostic Accuracy Study.",
            "abstract": "Background:\n        \n      \n      Mobile health (mHealth) consumer applications (apps) have been integrated with deep learning for skin cancer risk assessments. However, prospective validation of these apps is lacking.\n    \n\n\n          Objectives:\n        \n      \n      To identify the diagnostic accuracy of an app integrated with a convolutional neural network for the detection of premalignant and malignant skin lesions.\n    \n\n\n          Methods:\n        \n      \n      We performed a prospective multicenter diagnostic accuracy study of a CE-marked mHealth app from January 1 until August 31, 2020, among adult patients with at least one suspicious skin lesion. Skin lesions were assessed by the app on an iOS or Android device after clinical diagnosis and before obtaining histopathology. The app outcome was compared to the histopathological diagnosis, or if not available, the clinical diagnosis by a dermatologist. The primary outcome was the sensitivity and specificity of the app to detect premalignant and malignant skin lesions. Subgroup analyses were conducted for different smartphone types, the lesion's origin, indication for dermatological consultation, and lesion location.\n    \n\n\n          Results:\n        \n      \n      In total, 785 lesions, including 418 suspicious and 367 benign control lesions, among 372 patients (50.8% women) with a median age of 71 years were included. The app performed at an overall 86.9% (95% CI 82.3-90.7) sensitivity and 70.4% (95% CI 66.2-74.3) specificity. The sensitivity was significantly higher on the iOS device compared to the Android device (91.0 vs. 83.0%; p = 0.02). Specificity calculated on benign control lesions was significantly higher than suspicious skin lesions (80.1 vs. 45.5%; p < 0.001). Sensitivity was higher in skin fold areas compared to smooth skin areas (92.9 vs. 84.2%; p = 0.01), while the specificity was higher for lesions in smooth skin areas (72.0 vs. 56.6%; p = 0.02).\n    \n\n\n          Conclusion:\n        \n      \n      The diagnostic accuracy of the mHealth app is far from perfect, but is potentially promising to empower patients to self-assess skin lesions before consulting a health care professional. An additional prospective validation study, particularly for suspicious pigmented skin lesions, is warranted. Furthermore, studies investigating mHealth implementation in the lay population are needed to demonstrate the impact on health care systems."
        },
        {
            "title": "Skin Lesion Classification Based on Surface Fractal Dimensions and Statistical Color Cluster Features Using an Ensemble of Machine Learning Techniques.",
            "abstract": "(1) Background: An approach for skin cancer recognition and classification by implementation of a novel combination of features and two classifiers, as an auxiliary diagnostic method, is proposed. (2) Methods: The predictions are made by k-nearest neighbor with a 5-fold cross validation algorithm and a neural network model to assist dermatologists in the diagnosis of cancerous skin lesions. As a main contribution, this work proposes a descriptor that combines skin surface fractal dimension and relevant color area features for skin lesion classification purposes. The surface fractal dimension is computed using a 2D generalization of Higuchi's method. A clustering method allows for the selection of the relevant color distribution in skin lesion images by determining the average percentage of color areas within the nevi and melanoma lesion areas. In a classification stage, the Higuchi fractal dimensions (HFDs) and the color features are classified, separately, using a kNN-CV algorithm. In addition, these features are prototypes for a Radial basis function neural network (RBFNN) classifier. The efficiency of our algorithms was verified by utilizing images belonging to the 7-Point, Med-Node, and PH2 databases; (3) Results: Experimental results show that the accuracy of the proposed RBFNN model in skin cancer classification is 95.42% for 7-Point, 94.71% for Med-Node, and 94.88% for PH2, which are all significantly better than that of the kNN algorithm. (4) Conclusions: 2D Higuchi's surface fractal features have not been previously used for skin lesion classification purpose. We used fractal features further correlated to color features to create a RBFNN classifier that provides high accuracies of classification."
        },
        {
            "title": "Artificial Intelligence in Emergency Medicine: Benefits, Risks, and Recommendations.",
            "abstract": "Background:\n        \n      \n      Artificial intelligence (AI) can be described as the use of computers to perform tasks that formerly required human cognition. The American Medical Association prefers the term 'augmented intelligence' over 'artificial intelligence' to emphasize the assistive role of computers in enhancing physician skills as opposed to replacing them. The integration of AI into emergency medicine, and clinical practice at large, has increased in recent years, and that trend is likely to continue.\n    \n\n\n          Discussion:\n        \n      \n      AI has demonstrated substantial potential benefit for physicians and patients. These benefits are transforming the therapeutic relationship from the traditional physician-patient dyad into a triadic doctor-patient-machine relationship. New AI technologies, however, require careful vetting, legal standards, patient safeguards, and provider education. Emergency physicians (EPs) should recognize the limits and risks of AI as well as its potential benefits.\n    \n\n\n          Conclusions:\n        \n      \n      EPs must learn to partner with, not capitulate to, AI. AI has proven to be superior to, or on a par with, certain physician skills, such as interpreting radiographs and making diagnoses based on visual cues, such as skin cancer. AI can provide cognitive assistance, but EPs must interpret AI results within the clinical context of individual patients. They must also advocate for patient confidentiality, professional liability coverage, and the essential role of specialty-trained EPs."
        },
        {
            "title": "Assisting differential clinical diagnosis of cattle diseases using smartphone-based technology in low resource settings: a pilot study.",
            "abstract": "Background:\n        \n      \n      The recent rise in mobile phone use and increased signal coverage has created opportunities for growth of the mobile Health sector in many low resource settings. This pilot study explores the use of a smartphone-based application, VetAfrica-Ethiopia, in assisting diagnosis of cattle diseases. We used a modified Delphi protocol to select important diseases and Bayesian algorithms to estimate the related disease probabilities based on various clinical signs being present in Ethiopian cattle.\n    \n\n\n          Results:\n        \n      \n      A total of 928 cases were diagnosed during the study period across three regions of Ethiopia, around 70% of which were covered by diseases included in VetAfrica-Ethiopia. Parasitic Gastroenteritis (26%), Blackleg (8.5%), Fasciolosis (8.4%), Pasteurellosis (7.4%), Colibacillosis (6.4%), Lumpy skin disease (5.5%) and CBPP (5.0%) were the most commonly occurring diseases. The highest (84%) and lowest (30%) levels of matching between diagnoses made by student practitioners and VetAfrica-Ethiopia were for Babesiosis and Pasteurellosis, respectively. Multiple-variable logistic regression analysis indicated that the putative disease indicated, the practitioner involved, and the level of confidence associated with the prediction made by VetAfrica-Ethiopia were major determinants of the likelihood that a diagnostic match would be obtained.\n    \n\n\n          Conclusions:\n        \n      \n      This pilot study demonstrated that the use of such applications can be a valuable means of assisting less experienced animal health professionals in carrying out disease diagnosis which may lead to increased animal productivity through appropriate treatment."
        },
        {
            "title": "A machine learning-based, decision support, mobile phone application for diagnosis of common dermatological diseases.",
            "abstract": "Background:\n        \n      \n      The integration of machine learning algorithms in decision support tools for physicians is gaining popularity. These tools can tackle the disparities in healthcare access as the technology can be implemented on smartphones. We present the first, large-scale study on patients with skin of colour, in which the feasibility of a novel mobile health application (mHealth app) was investigated in actual clinical workflows.\n    \n\n\n          Objective:\n        \n      \n      To develop a mHealth app to diagnose 40 common skin diseases and test it in clinical settings.\n    \n\n\n          Methods:\n        \n      \n      A convolutional neural network-based algorithm was trained with clinical images of 40 skin diseases. A smartphone app was generated and validated on 5014 patients, attending rural and urban outpatient dermatology departments in India. The results of this mHealth app were compared against the dermatologists' diagnoses.\n    \n\n\n          Results:\n        \n      \n      The machine-learning model, in an in silico validation study, demonstrated an overall top-1 accuracy of 76.93 Â± 0.88% and mean area-under-curve of 0.95 Â± 0.02 on a set of clinical images. In the clinical study, on patients with skin of colour, the app achieved an overall top-1 accuracy of 75.07% (95% CI = 73.75-76.36), top-3 accuracy of 89.62% (95% CI = 88.67-90.52) and mean area-under-curve of 0.90 Â± 0.07.\n    \n\n\n          Conclusion:\n        \n      \n      This study underscores the utility of artificial intelligence-driven smartphone applications as a point-of-care, clinical decision support tool for dermatological diagnosis for a wide spectrum of skin diseases in patients of the skin of colour."
        },
        {
            "title": "Melanoma Detection by Non-Specialists: An Untapped Potential for Triage?",
            "abstract": "Introduction:\n        \n      \n      The incidence of melanoma increased considerably in recent decades, representing a significant public health problem. We aimed to evaluate the ability of non-specialists for the preliminary screening of skin lesions to identify melanoma-suspect lesions.\n    \n\n\n          Materials and methods:\n        \n      \n      A medical student and a dermatologist specialist examined the total body scans of 50 patients.\n    \n\n\n          Results:\n        \n      \n      The agreement between the expert and the non-specialist was 87.75% (Îº = 0.65) regarding the assessment of clinical significance. The four parameters of the ABCD rule were evaluated on the 129 lesions rated as clinically significant by both observers. Asymmetry was evaluated similarly in 79.9% (Îº = 0.59), irregular borders in 74.4% (Îº = 0.50), color in 81.4% (Îº = 0.57), and diameter in 89.9% (Îº = 0.77) of the cases. The concordance of the two groups was 96.9% (Îº = 0.83) in the case of the detection of the Ugly Duckling Sign.\n    \n\n\n          Conclusions:\n        \n      \n      Although the involvement of GPs is part of routine care worldwide, emphasizing the importance of educating medical students and general practitioners is crucial, as many European countries lack structured melanoma screening training programs targeting non-dermatologists."
        },
        {
            "title": "The Application of Deep Learning in the Risk Grading of Skin Tumors for Patients Using Clinical Images.",
            "abstract": "According to diagnostic criteria, skin tumors can be divided into three categories: benign, low degree and high degree malignancy. For high degree malignant skin tumors, if not detected in time, they can do serious harm to patients' health. However, in clinical practice, identifying malignant degree requires biopsy and pathological examination which is time costly. Furthermore, in many areas, due to the severe shortage of dermatologists, it's inconvenient for patients to go to hospital for examination. Therefore, an easy to access screening method of malignant skin tumors is needed urgently. Firstly, we spend 5 years to build a dataset which includes 4,500 images of 10 kinds of skin tumors. All instances are verified pathologically thus trustworthy; Secondly, we label each instance to be either low-risk, high-risk or dangerous in which Junctional nevus, Intradermal nevus, Dermatofibroma, Lipoma and Seborrheic keratosis are low-risk, Basal cell carcinoma, Bowen's disease and Actinic keratosis are high-risk, Squamous cell carcinoma and Malignant melanoma are dangerous; Thirdly, we apply the Xception architecture to build the risk degree classifier. The area under the curve (AUC) for three risk degrees reach 0.959, 0.919 and 0.947 respectively. To further evaluate the validity of the proposed risk degree classifier, we conduct a competition with 20 professional dermatologists. The results showed the proposed classifier outperforms dermatologists. Our system is helpful to patients in preliminary screening. It can identify the patients who are at risk and alert them to go to hospital for further examination."
        },
        {
            "title": "Use of convolutional neural networks in skin lesion analysis using real world image and non-image data.",
            "abstract": "Background:\n        \n      \n      Understanding performance of convolutional neural networks (CNNs) for binary (benign vs. malignant) lesion classification based on real world images is important for developing a meaningful clinical decision support (CDS) tool.\n    \n\n\n          Methods:\n        \n      \n      We developed a CNN based on real world smartphone images with histopathological ground truth and tested the utility of structured electronic health record (EHR) data on model performance. Model accuracy was compared against three board-certified dermatologists for clinical validity.\n    \n\n\n          Results:\n        \n      \n      At a classification threshold of 0.5, the sensitivity was 79 vs. 77 vs. 72%, and specificity was 64 vs. 65 vs. 57% for image-alone vs. combined image and clinical data vs. clinical data-alone models, respectively. The PPV was 68 vs. 69 vs. 62%, AUC was 0.79 vs. 0.79 vs. 0.69, and AP was 0.78 vs. 0.79 vs. 0.64 for image-alone vs. combined data vs. clinical data-alone models. Older age, male sex, and number of prior dermatology visits were important positive predictors for malignancy in the clinical data-alone model.\n    \n\n\n          Conclusion:\n        \n      \n      Additional clinical data did not significantly improve CNN image model performance. Model accuracy for predicting malignant lesions was comparable to dermatologists (model: 71.31% vs. 3 dermatologists: 77.87, 69.88, and 71.93%), validating clinical utility. Prospective validation of the model in primary care setting will enhance understanding of the model's clinical utility."
        },
        {
            "title": "Computer Aided Diagnosis of Melanoma Using Deep Neural Networks and Game Theory: Application on Dermoscopic Images of Skin Lesions.",
            "abstract": "Early detection of melanoma remains a daily challenge due to the increasing number of cases and the lack of dermatologists. Thus, AI-assisted diagnosis is considered as a possible solution for this issue. Despite the great advances brought by deep learning and especially convolutional neural networks (CNNs), computer-aided diagnosis (CAD) systems are still not used in clinical practice. This may be explained by the dermatologist's fear of being misled by a false negative and the assimilation of CNNs to a \"black box\", making their decision process difficult to understand by a non-expert. Decision theory, especially game theory, is a potential solution as it focuses on identifying the best decision option that maximizes the decision-maker's expected utility. This study presents a new framework for automated melanoma diagnosis. Pursuing the goal of improving the performance of existing systems, our approach also attempts to bring more transparency in the decision process. The proposed framework includes a multi-class CNN and six binary CNNs assimilated to players. The players' strategies is to first cluster the pigmented lesions (melanoma, nevus, and benign keratosis), using the introduced method of evaluating the confidence of the predictions, into confidence level (confident, medium, uncertain). Then, a subset of players has the strategy to refine the diagnosis for difficult lesions with medium and uncertain prediction. We used EfficientNetB5 as the backbone of our networks and evaluated our approach on the public ISIC dataset consisting of 8917 lesions: melanoma (1113), nevi (6705) and benign keratosis (1099). The proposed framework achieved an area under the receiver operating curve (AUROC) of 0.93 for melanoma, 0.96 for nevus and 0.97 for benign keratosis. Furthermore, our approach outperformed existing methods in this task, improving the balanced accuracy (BACC) of the best compared method from 77% to 86%. These results suggest that our framework provides an effective and explainable decision-making strategy. This approach could help dermatologists in their clinical practice for patients with atypical and difficult-to-diagnose pigmented lesions. We also believe that our system could serve as a didactic tool for less experienced dermatologists."
        },
        {
            "title": "Identification and Validation of Immune- and Stemness-Related Prognostic Signature of Melanoma.",
            "abstract": "Purpose: Our aim was to construct a signature that accurately predicted the prognostic and immune response of melanoma. Methods: First, the weighted co-expression network analysis (WGCNA) algorithm was used to identify the hub genes related to clinical phenotypes of melanoma in the cancer genome atlas (TCGA) database. Nest, the least absolute shrinkage and selection operator (LASSO) analysis was used to dimensionality reduction of these hub genes and constructed a prognostic signature to predict the prognosis and immunosuppressive response of melanoma. Result: Through in-depth analysis, we constructed a 5-mRNA prognostic signature and verified its prognostic value in internal (TCGA-SKCM, n = 452) and external independent datasets (GSE53118, n = 79). Based on this signature, the tumor immune microenvironment (TME) of melanoma was characterized, and the result was found that patients in the high-risk group had lower CD8 T cell infiltration and immune checkpoint expression (PD-1, PD-L1, CTLA4), as well as higher M0/M2 macrophage infiltration. Our results also found the risk score based on a 5-mRNA signature was significantly associated with tumor mutational burden (TMB) and tumor stem cell markers (CD20, CD38, ABCB5, CD44, etc.). Lastly, we built a nomogram for clinician prediction for the prognosis of patients with melanoma. Conclusion: Our findings indicated that the 5-mRNA signature has an important predictive value for the overall survival of melanoma. By analyzing the tumor immune microenvironment and tumor stem cell marker between different groups, a new method is provided for the stratified diagnosis and treatment of melanoma."
        },
        {
            "title": "Towards Accurate Diagnosis of Skin Lesions Using Feedforward Back Propagation Neural Networks.",
            "abstract": "In the automatic detection framework, there have been many attempts to develop models for real-time melanoma detection. To effectively discriminate benign and malign skin lesions, this work investigates sixty different architectures of the Feedforward Back Propagation Network (FFBPN), based on shape asymmetry for an optimal structural design that includes both the hidden neuron number and the input data selection. The reason for the choice of shape asymmetry was based on the 5-10% disagreement between dermatologists regarding the efficacy of asymmetry in the diagnosis of malignant melanoma. Asymmetry is quantified based on lesion shape (contour), moment of inertia of the lesion shape and histograms. The FFBPN has a high architecture flexibility, which indicates it as a favorable tool to avoid the over-parameterization of the ANN and, equally, to discard those redundant input datasets that usually result in poor test performance. The FFBPN was tested on four public image datasets containing melanoma, dysplastic nevus and nevus images. Experimental results on multiple benchmark data sets demonstrate that asymmetry A2 is a meaningful feature for skin lesion classification, and FFBPN with 16 neurons in the hidden layer can model the data without compromising prediction accuracy."
        },
        {
            "title": "Deep learning-based, computer-aided classifier developed with dermoscopic images shows comparable performance to 164 dermatologists in cutaneous disease diagnosis in the Chinese population.",
            "abstract": "Background:\n        \n      \n      Diagnoses of Skin diseases are frequently delayed in China due to lack of dermatologists. A deep learning-based diagnosis supporting system can facilitate pre-screening patients to prioritize dermatologists' efforts. We aimed to evaluate the classification sensitivity and specificity of deep learning models to classify skin tumors and psoriasis for Chinese population with a modest number of dermoscopic images.\n    \n\n\n          Methods:\n        \n      \n      We developed a convolutional neural network (CNN) based on two datasets from a consecutive series of patients who underwent the dermoscopy in the clinic of the Department of Dermatology, Peking Union Medical College Hospital, between 2016 and 2018, prospectively. In order to evaluate the feasibility of the algorithm, we used two datasets. Dataset I consisted of 7192 dermoscopic images for a multi-class model to differentiate three most common skin tumors and other diseases. Dataset II consisted of 3115 dermoscopic images for a two-class model to classify psoriasis from other inflammatory diseases. We compared the performance of CNN with 164 dermatologists in a reader study with 130 dermoscopic images. The experts' consensus was used as the reference standard except for the cases of basal cell carcinoma (BCC), which were all confirmed by histopathology.\n    \n\n\n          Results:\n        \n      \n      The accuracies of multi-class and two-class models were 81.49% Â± 0.88% and 77.02% Â± 1.81%, respectively. In the reader study, for the multi-class tasks, the diagnosis sensitivity and specificity of 164 dermatologists were 0.770 and 0.962 for BCC, 0.807 and 0.897 for melanocytic nevus, 0.624 and 0.976 for seborrheic keratosis, 0.939 and 0.875 for the \"others\" group, respectively; the diagnosis sensitivity and specificity of multi-class CNN were 0.800 and 1.000 for BCC, 0.800 and 0.840 for melanocytic nevus, 0.850 and 0.940 for seborrheic keratosis, 0.750 and 0.940 for the \"others\" group, respectively. For the two-class tasks, the sensitivity and specificity of dermatologists and CNN for classifying psoriasis were 0.872 and 0.838, 1.000 and 0.605, respectively. Both the dermatologists and CNN achieved at least moderate consistency with the reference standard, and there was no significant difference in Kappa coefficients between them (P > 0.05).\n    \n\n\n          Conclusions:\n        \n      \n      The performance of CNN developed with relatively modest number of dermoscopic images of skin tumors and psoriasis for Chinese population is comparable with 164 dermatologists. These two models could be used for screening in patients suspected with skin tumors and psoriasis respectively in primary care hospital."
        },
        {
            "title": "The Role in Teledermoscopy of an Inexpensive and Easy-to-Use Smartphone Device for the Classification of Three Types of Skin Lesions Using Convolutional Neural Networks.",
            "abstract": "Background:\n        \n      \n      The use of teledermatology has spread over the last years, especially during the recent SARS-Cov-2 pandemic. Teledermoscopy, an extension of teledermatology, consists of consulting dermoscopic images, also transmitted through smartphones, to remotely diagnose skin tumors or other dermatological diseases. The purpose of this work was to verify the diagnostic validity of images acquired with an inexpensive smartphone microscope (NurugoTM), employing convolutional neural networks (CNN) to classify malignant melanoma (MM), melanocytic nevus (MN), and seborrheic keratosis (SK).\n    \n\n\n          Methods:\n        \n      \n      The CNN, trained with 600 dermatoscopic images from the ISIC (International Skin Imaging Collaboration) archive, was tested on three test sets: ISIC images, images acquired with the NurugoTM, and images acquired with a conventional dermatoscope.\n    \n\n\n          Results:\n        \n      \n      The results obtained, although with some limitations due to the smartphone device and small data set, were encouraging, showing comparable results to the clinical dermatoscope and up to 80% accuracy (out of 10 images, two were misclassified) using the NurugoTM demonstrating how an amateur device can be used with reasonable levels of diagnostic accuracy.\n    \n\n\n          Conclusion:\n        \n      \n      Considering the low cost and the ease of use, the NurugoTM device could be a useful tool for general practitioners (GPs) to perform the first triage of skin lesions, aiding the selection of lesions that require a face-to-face consultation with dermatologists."
        },
        {
            "title": "Automated multi-class classification of skin lesions through deep convolutional neural network with dermoscopic images.",
            "abstract": "As an analytic tool in medicine, deep learning has gained great attention and opened new ways for disease diagnosis. Recent studies validate the effectiveness of deep learning algorithms for binary classification of skin lesions (i.e., melanomas and nevi classes) with dermoscopic images. Nonetheless, those binary classification methods cannot be applied to the general clinical situation of skin cancer screening in which multi-class classification must be taken into account. The main objective of this research is to develop, implement, and calibrate an advanced deep learning model in the context of automated multi-class classification of skin lesions. The proposed Deep Convolutional Neural Network (DCNN) model is carefully designed with several layers, and multiple filter sizes, but fewer filters and parameters to improve efficacy and performance. Dermoscopic images are acquired from the International Skin Imaging Collaboration databases (ISIC-17, ISIC-18, and ISIC-19) for experiments. The experimental results of the proposed DCNN approach are presented in terms of precision, sensitivity, specificity, and other metrics. Specifically, it attains 94 % precision, 93 % sensitivity, and 91 % specificity in ISIC-17. It is demonstrated by the experimental results that this proposed DCNN approach outperforms state-of-the-art algorithms, exhibiting 0.964 area under the receiver operating characteristics (AUROC) in ISIC-17 for the classification of skin lesions and can be used to assist dermatologists in classifying skin lesions. As a result, this proposed approach provides a novel and feasible way for automating and expediting the skin lesion classification task as well as saving effort, time, and human life."
        },
        {
            "title": "Discrimination Between Invasive and In Situ Melanomas Using Clinical Close-Up Images and a De Novo Convolutional Neural Network.",
            "abstract": "Background: Melanomas are often easy to recognize clinically but determining whether a melanoma is in situ (MIS) or invasive is often more challenging even with the aid of dermoscopy. Recently, convolutional neural networks (CNNs) have made significant and rapid advances within dermatology image analysis. The aims of this investigation were to create a de novo CNN for differentiating between MIS and invasive melanomas based on clinical close-up images and to compare its performance on a test set to seven dermatologists. Methods: A retrospective study including clinical images of MIS and invasive melanomas obtained from our department during a five-year time period (2016-2020) was conducted. Overall, 1,551 images [819 MIS (52.8%) and 732 invasive melanomas (47.2%)] were available. The images were randomized into three groups: training set (n = 1,051), validation set (n = 200), and test set (n = 300). A de novo CNN model with seven convolutional layers and a single dense layer was developed. Results: The area under the curve was 0.72 for the CNN (95% CI 0.66-0.78) and 0.81 for dermatologists (95% CI 0.76-0.86) (P < 0.001). The CNN correctly classified 208 out of 300 lesions (69.3%) whereas the corresponding number for dermatologists was 216 (72.0%). When comparing the CNN performance to each individual reader, three dermatologists significantly outperformed the CNN. Conclusions: For this classification problem, the CNN was outperformed by the dermatologist. However, since the algorithm was only trained and validated on 1,251 images, future refinement and development could make it useful for dermatologists in a real-world setting."
        },
        {
            "title": "The degradation of performance of a state-of-the-art skin image classifier when applied to patient-driven internet search.",
            "abstract": "Model Dermatology ( https://modelderm.com ; Build2021) is a publicly testable neural network that can classify 184 skin disorders. We aimed to investigate whether our algorithm can classify clinical images of an Internet community along with tertiary care center datasets. Consecutive images from an Internet skin cancer community ('RD' dataset, 1,282 images posted between 25 January 2020 to 30 July 2021; https://reddit.com/r/melanoma ) were analyzed retrospectively, along with hospital datasets (Edinburgh dataset, 1,300 images; SNU dataset, 2,101 images; TeleDerm dataset, 340 consecutive images). The algorithm's performance was equivalent to that of dermatologists in the curated clinical datasets (Edinburgh and SNU datasets). However, its performance deteriorated in the RD and TeleDerm datasets because of insufficient image quality and the presence of out-of-distribution disorders, respectively. For the RD dataset, the algorithm's Top-1/3 accuracy (39.2%/67.2%) and AUC (0.800) were equivalent to that of general physicians (36.8%/52.9%). It was more accurate than that of the laypersons using random Internet searches (19.2%/24.4%). The Top-1/3 accuracy was affected by inadequate image quality (adequate = 43.2%/71.3% versus inadequate = 32.9%/60.8%), whereas participant performance did not deteriorate (adequate = 35.8%/52.7% vs. inadequate = 38.4%/53.3%). In this report, the algorithm performance was significantly affected by the change of the intended settings, which implies that AI algorithms at dermatologist-level, in-distribution setting, may not be able to show the same level of performance in with out-of-distribution settings."
        },
        {
            "title": "An introduction to the Cyrcadia Breast Monitor: A wearable breast health monitoring device.",
            "abstract": "Background:\n        \n      \n      The most common breast cancer detection modalities are generally limited by radiation exposure, discomfort, high costs, inter-observer variabilities in image interpretation, and low sensitivity in detecting cancer in dense breast tissue. Therefore, there is a clear need for an affordable and effective adjunct modality that can address these limitations. The Cyrcadia Breast Monitor (CBM) is a non-invasive, non-compressive, and non-radiogenic wearable device developed as an adjunct to current modalities to assist in the detection of breast tissue abnormalities in any type of breast tissue.\n    \n\n\n          Methods:\n        \n      \n      The CBM records thermodynamic metabolic data from the breast skin surface over a period of time using two wearable biometric patches consisting of eight sensors each and a data recording device. The acquired multi-dimensional temperature time series data are analyzed to determine the presence of breast tissue abnormalities. The objective of this paper is to present the scientific background of CBM and also to describe the history around the design and development of the technology.\n    \n\n\n          Results:\n        \n      \n      The results of using the CBM device in the initial clinical studies are also presented. Twenty four-hour long breast skin temperature circadian rhythm data was collected from 93 benign and 108 malignant female study subjects in the initial clinical studies. The predictive model developed using these datasets could differentiate benign and malignant lesions with 78% accuracy, 83.6% sensitivity and 71.5% specificity. A pilot study of 173 female study subjects is underway, in order to validate this predictive model in an independent test population.\n    \n\n\n          Conclusions:\n        \n      \n      The results from the initial studies indicate that the CBM may be valuable for breast health monitoring under physician supervision for confirmation of any abnormal changes, potentially prior to other methods, such as, biopsies. Studies are being conducted and planned to validate the technology and also to evaluate its ability as an adjunct breast health monitoring device for identifying abnormalities in difficult-to-diagnose dense breast tissue."
        },
        {
            "title": "Content-Based Medical Image Retrieval System for Skin Melanoma Diagnosis Based on Optimized Pair-Wise Comparison Approach.",
            "abstract": "Medical image analysis for perfect diagnosis of disease has become a very challenging task. Due to improper diagnosis, required medical treatment may be skipped. Proper diagnosis is needed as suspected lesions could be missed by the physician's eye. Hence, this problem can be settled up by better means with the investigation of similar case studies present in the healthcare database. In this context, this paper substantiates an assistive system that would help dermatologists for accurate identification of 23 different kinds of melanoma. For this, 2300 dermoscopic images were used to train the skin-melanoma similar image search system. The proposed system uses feature extraction by assigning dynamic weights to the low-level features based on the individual characteristics of the searched images. Optimal weights are obtained by the newly proposed optimized pair-wise comparison (OPWC) approach. The uniqueness of the proposed approach is that it provides the dynamic weights to the features of the searched image instead of applying static weights. The proposed approach is supported by analytic hierarchy process (AHP) and meta-heuristic optimization algorithms such as particle swarm optimization (PSO), JAYA, genetic algorithm (GA), and gray wolf optimization (GWO). The proposed approach has been tested with images of 23 classes of melanoma and achieved significant precision and recall. Thus, this approach of skin melanoma image search can be used as an expert assistive system to help dermatologists/physicians for accurate identification of different types of melanomas."
        },
        {
            "title": "Clinically Inspired Skin Lesion Classification through the Detection of Dermoscopic Criteria for Basal Cell Carcinoma.",
            "abstract": "Background and Objective. Skin cancer is the most common cancer worldwide. One of the most common non-melanoma tumors is basal cell carcinoma (BCC), which accounts for 75% of all skin cancers. There are many benign lesions that can be confused with these types of cancers, leading to unnecessary biopsies. In this paper, a new method to identify the different BCC dermoscopic patterns present in a skin lesion is presented. In addition, this information is applied to classify skin lesions into BCC and non-BCC. Methods. The proposed method combines the information provided by the original dermoscopic image, introduced in a convolutional neural network (CNN), with deep and handcrafted features extracted from color and texture analysis of the image. This color analysis is performed by transforming the image into a uniform color space and into a color appearance model. To demonstrate the validity of the method, a comparison between the classification obtained employing exclusively a CNN with the original image as input and the classification with additional color and texture features is presented. Furthermore, an exhaustive comparison of classification employing different color and texture measures derived from different color spaces is presented. Results. Results show that the classifier with additional color and texture features outperforms a CNN whose input is only the original image. Another important achievement is that a new color cooccurrence matrix, proposed in this paper, improves the results obtained with other texture measures. Finally, sensitivity of 0.99, specificity of 0.94 and accuracy of 0.97 are achieved when lesions are classified into BCC or non-BCC. Conclusions. To the best of our knowledge, this is the first time that a methodology to detect all the possible patterns that can be present in a BCC lesion is proposed. This detection leads to a clinically explainable classification into BCC and non-BCC lesions. In this sense, the classification of the proposed tool is based on the detection of the dermoscopic features that dermatologists employ for their diagnosis."
        },
        {
            "title": "AI-based detection of erythema migrans and disambiguation against other skin lesions.",
            "abstract": "This study examines the use of AI methods and deep learning (DL) for prescreening skin lesions and detecting the characteristic erythema migrans rash of acute Lyme disease. Accurate identification of erythema migrans allows for early diagnosis and treatment, which avoids the potential for later neurologic, rheumatologic, and cardiac complications of Lyme disease. We develop and test several deep learning models for detecting erythema migrans versus several other clinically relevant skin conditions, including cellulitis, tinea corporis, herpes zoster, erythema multiforme, lesions due to tick bites and insect bites, as well as non-pathogenic normal skin. We consider a set of clinically-relevant binary and multiclass classification problems of increasing complexity. We train the DL models on a combination of publicly available images and test on public images as well as images obtained in the clinical setting. We report performance metrics that measure agreement with a gold standard, as well as a receiver operating characteristic curve and associated area under the curve. On public images, we find that the DL system has an accuracy ranging from 71.58% (and 95% error margin equal to 3.77%) for an 8-class problem of EM versus 7 other classes including other skin pathologies, insect bites and normal skin, to 94.23% (3.66%) for a binary problem of EM vs. non-pathological skin. On clinical images of affected individuals, the DL system has a sensitivity of 88.55% (2.39%). These results suggest that a DL system can help in prescreening and referring individuals to physicians for earlier diagnosis and treatment, in the presence of clinically relevant confusers, thereby reducing further complications and morbidity."
        },
        {
            "title": "Adapting Microarray Gene Expression Signatures for Early Melioidosis Diagnosis.",
            "abstract": "Melioidosis is caused by Burkholderia pseudomallei and is predominantly seen in tropical regions. The clinical signs and symptoms of the disease are nonspecific and often result in misdiagnosis, failure of treatment, and poor clinical outcome. Septicemia with septic shock is the most common cause of death, with mortality rates above 40%. Bacterial culture is the gold standard for diagnosis, but it has low sensitivity and takes days to produce definitive results. Early laboratory diagnosis can help guide physicians to provide treatment specific to B. pseudomallei In our study, we adapted host gene expression signatures obtained from microarray data of B. pseudomallei-infected cases to develop a real-time PCR diagnostic test using two differentially expressed genes, AIM2 (absent in melanoma 2) and FAM26F (family with sequence similarity 26, member F). We tested blood from 33 patients with B. pseudomallei infections and 29 patients with other bacterial infections to validate the test and determine cutoff values for use in a cascading diagnostic algorithm. Differentiation of septicemic melioidosis from other sepsis cases had a sensitivity of 82%, specificity of 93%, and negative and positive predictive values (NPV and PPV) of 82% and 93%, respectively. Separation of cases likely to be melioidosis from those unlikely to be melioidosis in nonbacteremic situations showed a sensitivity of 40%, specificity of 54%, and NPV and PPV of 44% and 50%, respectively. We suggest that our AIM2 and FAM26F expression combination algorithm could be beneficial for early melioidosis diagnosis, offering a result within 24 h of admission."
        },
        {
            "title": "An Image Processing and Genetic Algorithm-based Approach for the Detection of Melanoma in Patients.",
            "abstract": "Melanoma skin cancer is the most aggressive type of skin cancer. It is most commonly caused by excessive exposure to Ultraviolet radiation which triggers uncontrollable proliferation of melanocytes. Early detection makes melanoma relatively easily curable. Diagnosis is usually done using traditional methods such as dermoscopy which consists of a manual examination performed by the physician. However, these methods are not always well founded because they depend heavily on the physician's experience. Hence, there is a great need for a new automated approach in order to make diagnosis more reliable. In this paper, we present a twophase technique to classify images of lesions into benign or malignant. The first phase consists of an image processing-based method that extracts the Asymmetry, Border Irregularity, Color Variation and Diameter of a given mole. The second phase classifies lesions using a Genetic Algorithm. Our technique shows a significant improvement over other well-known algorithms and proves to be more stable on both training and testing data."
        },
        {
            "title": "Identification of metastatic primary cutaneous squamous cell carcinoma utilizing artificial intelligence analysis of whole slide images.",
            "abstract": "Cutaneous squamous cell carcinoma (cSCC) harbors metastatic potential and causes mortality. However, clinical assessment of metastasis risk is challenging. We approached this challenge by harnessing artificial intelligence (AI) algorithm to identify metastatic primary cSCCs. Residual neural network-architectures were trained with cross-validation to identify metastatic tumors on clinician annotated, hematoxylin and eosin-stained whole slide images representing primary non-metastatic and metastatic cSCCs (n = 104). Metastatic primary tumors were divided into two subgroups, which metastasize rapidly (â‰¤ 180 days) (n = 22) or slowly (> 180 days) (n = 23) after primary tumor detection. Final model was able to predict whether primary tumor was non-metastatic or rapidly metastatic with slide-level area under the receiver operating characteristic curve (AUROC) of 0.747. Furthermore, risk factor (RF) model including prediction by AI, Clark's level and tumor diameter provided higher AUROC (0.917) than other RF models and predicted high 5-year disease specific survival (DSS) for patients with cSCC with 0 or 1 RFs (100% and 95.7%) and poor DSS for patients with cSCCs with 2 or 3 RFs (41.7% and 40.0%). These results indicate, that AI recognizes unknown morphological features associated with metastasis and may provide added value to clinical assessment of metastasis risk and prognosis of primary cSCC."
        },
        {
            "title": "System for the Recognizing of Pigmented Skin Lesions with Fusion and Analysis of Heterogeneous Data Based on a Multimodal Neural Network.",
            "abstract": "Today, skin cancer is one of the most common malignant neoplasms in the human body. Diagnosis of pigmented lesions is challenging even for experienced dermatologists due to the wide range of morphological manifestations. Artificial intelligence technologies are capable of equaling and even surpassing the capabilities of a dermatologist in terms of efficiency. The main problem of implementing intellectual analysis systems is low accuracy. One of the possible ways to increase this indicator is using stages of preliminary processing of visual data and the use of heterogeneous data. The article proposes a multimodal neural network system for identifying pigmented skin lesions with a preliminary identification, and removing hair from dermatoscopic images. The novelty of the proposed system lies in the joint use of the stage of preliminary cleaning of hair structures and a multimodal neural network system for the analysis of heterogeneous data. The accuracy of pigmented skin lesions recognition in 10 diagnostically significant categories in the proposed system was 83.6%. The use of the proposed system by dermatologists as an auxiliary diagnostic method will minimize the impact of the human factor, assist in making medical decisions, and expand the possibilities of early detection of skin cancer."
        },
        {
            "title": "Deep learning outperformed 11 pathologists in the classification of histopathological melanoma images.",
            "abstract": "Background:\n        \n      \n      The diagnosis of most cancers is made by a board-certified pathologist based on a tissue biopsy under the microscope. Recent research reveals a high discordance between individual pathologists. For melanoma, the literature reports on 25-26% of discordance for classifying a benign nevus versus malignant melanoma. A recent study indicated the potential of deep learning to lower these discordances. However, the performance of deep learning in classifying histopathologic melanoma images was never compared directly to human experts. The aim of this study is to perform such a first direct comparison.\n    \n\n\n          Methods:\n        \n      \n      A total of 695 lesions were classified by an expert histopathologist in accordance with current guidelines (350 nevi/345 melanoma). Only the haematoxylin & eosin (H&E) slides of these lesions were digitalised via a slide scanner and then randomly cropped. A total of 595 of the resulting images were used to train a convolutional neural network (CNN). The additional 100 H&E image sections were used to test the results of the CNN in comparison to 11 histopathologists. Three combined McNemar tests comparing the results of the CNNs test runs in terms of sensitivity, specificity and accuracy were predefined to test for significance (p < 0.05).\n    \n\n\n          Findings:\n        \n      \n      The CNN achieved a mean sensitivity/specificity/accuracy of 76%/60%/68% over 11 test runs. In comparison, the 11 pathologists achieved a mean sensitivity/specificity/accuracy of 51.8%/66.5%/59.2%. Thus, the CNN was significantly (p = 0.016) superior in classifying the cropped images.\n    \n\n\n          Interpretation:\n        \n      \n      With limited image information available, a CNN was able to outperform 11 histopathologists in the classification of histopathological melanoma images and thus shows promise to assist human melanoma diagnoses."
        },
        {
            "title": "Application of ultrasound artificial intelligence in the differential diagnosis between benign and malignant breast lesions of BI-RADS 4A.",
            "abstract": "Background:\n        \n      \n      The classification of Breast Imaging Reporting and Data System 4A (BI-RADS 4A) lesions is mostly based on the personal experience of doctors and lacks specific and clear classification standards. The development of artificial intelligence (AI) provides a new method for BI-RADS categorisation. We analysed the ultrasonic morphological and texture characteristics of BI-RADS 4A benign and malignant lesions using AI, and these ultrasonic characteristics of BI-RADS 4A benign and malignant lesions were compared to examine the value of AI in the differential diagnosis of BI-RADS 4A benign and malignant lesions.\n    \n\n\n          Methods:\n        \n      \n      A total of 206 lesions of BI-RADS 4A examined using ultrasonography were analysed retrospectively, including 174 benign lesions and 32 malignant lesions. All of the lesions were contoured manually, and the ultrasonic morphological and texture features of the lesions, such as circularity, height-to-width ratio, margin spicules, margin coarseness, margin indistinctness, margin lobulation, energy, entropy, grey mean, internal calcification and angle between the long axis of the lesion and skin, were calculated using grey level gradient co-occurrence matrix analysis. Differences between benign and malignant lesions of BI-RADS 4A were analysed.\n    \n\n\n          Results:\n        \n      \n      Significant differences in margin lobulation, entropy, internal calcification and ALS were noted between the benign group and malignant group (P = 0.013, 0.045, 0.045, and 0.002, respectively). The malignant group had more margin lobulations and lower entropy compared with the benign group, and the benign group had more internal calcifications and a greater angle between the long axis of the lesion and skin compared with the malignant group. No significant differences in circularity, height-to-width ratio, margin spicules, margin coarseness, margin indistinctness, energy, and grey mean were noted between benign and malignant lesions.\n    \n\n\n          Conclusions:\n        \n      \n      Compared with the naked eye, AI can reveal more subtle differences between benign and malignant BI-RADS 4A lesions. These results remind us carefully observation of the margin and the internal echo is of great significance. With the help of morphological and texture information provided by AI, doctors can make a more accurate judgment on such atypical benign and malignant lesions."
        },
        {
            "title": "Viscoelasticity assessment of tumoral skin with the use of a novel contact-free palpation methodology based upon surface waves.",
            "abstract": "The ensuing pilot investigation sheds new light on characterizing tumoral and non-tumoral human skin mechanical properties that will not only assist the dermatologist's diagnosis but also could constitute the creation of an Artificial Intelligence database for upcoming research. A modern, non-invasive, and contact-free methodology-UNDERSKIN-was developed, and hinges upon Fourier transform computations that permit the analysis of surface wave dispersion with a specific skin inversion model and viscoelastic model. It yields a detailed look at how particle movements of the medium propagate throughout its near sub-surface, hence a novel knowledge of the mechanical responses of skin tumors. The research results display the tumors' viscoelastic responses alongside their respective healthy skin outcomes for each skin layer as well as the dermatologist's touch analysis. Although dermatologists are capable of sensing and having a fair overall assessment of what they are palpating, they are unable heretofore to quantify it and inform where the firmness or softness derives from, which it is necessary to be acquainted with so as to perform an accurate diagnosis, prognosis, treatment, future surgery, and teledermatology."
        },
        {
            "title": "Classification of Skin Disease Using Deep Learning Neural Networks with MobileNet V2 and LSTM.",
            "abstract": "Deep learning models are efficient in learning the features that assist in understanding complex patterns precisely. This study proposed a computerized process of classifying skin disease through deep learning based MobileNet V2 and Long Short Term Memory (LSTM). The MobileNet V2 model proved to be efficient with a better accuracy that can work on lightweight computational devices. The proposed model is efficient in maintaining stateful information for precise predictions. A grey-level co-occurrence matrix is used for assessing the progress of diseased growth. The performance has been compared against other state-of-the-art models such as Fine-Tuned Neural Networks (FTNN), Convolutional Neural Network (CNN), Very Deep Convolutional Networks for Large-Scale Image Recognition developed by Visual Geometry Group (VGG), and convolutional neural network architecture that expanded with few changes. The HAM10000 dataset is used and the proposed method has outperformed other methods with more than 85% accuracy. Its robustness in recognizing the affected region much faster with almost 2Ã— lesser computations than the conventional MobileNet model results in minimal computational efforts. Furthermore, a mobile application is designed for instant and proper action. It helps the patient and dermatologists identify the type of disease from the affected region's image at the initial stage of the skin disease. These findings suggest that the proposed system can help general practitioners efficiently and effectively diagnose skin conditions, thereby reducing further complications and morbidity."
        },
        {
            "title": "Assessment of Accuracy of an Artificial Intelligence Algorithm to Detect Melanoma in Images of Skin Lesions.",
            "abstract": "Importance:\n        \n      \n      A high proportion of suspicious pigmented skin lesions referred for investigation are benign. Techniques to improve the accuracy of melanoma diagnoses throughout the patient pathway are needed to reduce the pressure on secondary care and pathology services.\n    \n\n\n          Objective:\n        \n      \n      To determine the accuracy of an artificial intelligence algorithm in identifying melanoma in dermoscopic images of lesions taken with smartphone and digital single-lens reflex (DSLR) cameras.\n    \n\n\n          Design, setting, and participants:\n        \n      \n      This prospective, multicenter, single-arm, masked diagnostic trial took place in dermatology and plastic surgery clinics in 7 UK hospitals. Dermoscopic images of suspicious and control skin lesions from 514 patients with at least 1 suspicious pigmented skin lesion scheduled for biopsy were captured on 3 different cameras. Data were collected from January 2017 to July 2018. Clinicians and the Deep Ensemble for Recognition of Malignancy, a deterministic artificial intelligence algorithm trained to identify melanoma in dermoscopic images of pigmented skin lesions using deep learning techniques, assessed the likelihood of melanoma. Initial data analysis was conducted in September 2018; further analysis was conducted from February 2019 to August 2019.\n    \n\n\n          Interventions:\n        \n      \n      Clinician and algorithmic assessment of melanoma.\n    \n\n\n          Main outcomes and measures:\n        \n      \n      Area under the receiver operating characteristic curve (AUROC), sensitivity, and specificity of the algorithmic and specialist assessment, determined using histopathology diagnosis as the criterion standard.\n    \n\n\n          Results:\n        \n      \n      The study population of 514 patients included 279 women (55.7%) and 484 white patients (96.8%), with a mean (SD) age of 52.1 (18.6) years. A total of 1550 images of skin lesions were included in the analysis (551 [35.6%] biopsied lesions; 999 [64.4%] control lesions); 286 images (18.6%) were used to train the algorithm, and a further 849 (54.8%) images were missing or unsuitable for analysis. Of the biopsied lesions that were assessed by the algorithm and specialists, 125 (22.7%) were diagnosed as melanoma. Of these, 77 (16.7%) were used for the primary analysis. The algorithm achieved an AUROC of 90.1% (95% CI, 86.3%-94.0%) for biopsied lesions and 95.8% (95% CI, 94.1%-97.6%) for all lesions using iPhone 6s images; an AUROC of 85.8% (95% CI, 81.0%-90.7%) for biopsied lesions and 93.8% (95% CI, 91.4%-96.2%) for all lesions using Galaxy S6 images; and an AUROC of 86.9% (95% CI, 80.8%-93.0%) for biopsied lesions and 91.8% (95% CI, 87.5%-96.1%) for all lesions using DSLR camera images. At 100% sensitivity, the algorithm achieved a specificity of 64.8% with iPhone 6s images. Specialists achieved an AUROC of 77.8% (95% CI, 72.5%-81.9%) and a specificity of 69.9%.\n    \n\n\n          Conclusions and relevance:\n        \n      \n      In this study, the algorithm demonstrated an ability to identify melanoma from dermoscopic images of selected lesions with an accuracy similar to that of specialists."
        },
        {
            "title": "Man against machine reloaded: performance of a market-approved convolutional neural network in classifying a broad spectrum of skin lesions in comparison with 96 dermatologists working under less artificial conditions.",
            "abstract": "Background:\n        \n      \n      Convolutional neural networks (CNNs) efficiently differentiate skin lesions by image analysis. Studies comparing a market-approved CNN in a broad range of diagnoses to dermatologists working under less artificial conditions are lacking.\n    \n\n\n          Materials and methods:\n        \n      \n      One hundred cases of pigmented/non-pigmented skin cancers and benign lesions were used for a two-level reader study in 96 dermatologists (level I: dermoscopy only; level II: clinical close-up images, dermoscopy, and textual information). Additionally, dermoscopic images were classified by a CNN approved for the European market as a medical device (Moleanalyzer Pro, FotoFinder Systems, Bad Birnbach, Germany). Primary endpoints were the sensitivity and specificity of the CNN's dichotomous classification in comparison with the dermatologists' management decisions. Secondary endpoints included the dermatologists' diagnostic decisions, their performance according to their level of experience, and the CNN's area under the curve (AUC) of receiver operating characteristics (ROC).\n    \n\n\n          Results:\n        \n      \n      The CNN revealed a sensitivity, specificity, and ROC AUC with corresponding 95% confidence intervals (CI) of 95.0% (95% CI 83.5% to 98.6%), 76.7% (95% CI 64.6% to 85.6%), and 0.918 (95% CI 0.866-0.970), respectively. In level I, the dermatologists' management decisions showed a mean sensitivity and specificity of 89.0% (95% CI 87.4% to 90.6%) and 80.7% (95% CI 78.8% to 82.6%). With level II information, the sensitivity significantly improved to 94.1% (95% CI 93.1% to 95.1%; P < 0.001), while the specificity remained unchanged at 80.4% (95% CI 78.4% to 82.4%; P = 0.97). When fixing the CNN's specificity at the mean specificity of the dermatologists' management decision in level II (80.4%), the CNN's sensitivity was almost equal to that of human raters, at 95% (95% CI 83.5% to 98.6%) versus 94.1% (95% CI 93.1% to 95.1%); P = 0.1. In contrast, dermatologists were outperformed by the CNN in their level I management decisions and level I and II diagnostic decisions. More experienced dermatologists frequently surpassed the CNN's performance.\n    \n\n\n          Conclusions:\n        \n      \n      Under less artificial conditions and in a broader spectrum of diagnoses, the CNN and most dermatologists performed on the same level. Dermatologists are trained to integrate information from a range of sources rendering comparative studies that are solely based on one single case image inadequate."
        },
        {
            "title": "DermoCC-GAN: A new approach for standardizing dermatological images using generative adversarial networks.",
            "abstract": "Background and objective:\n        \n      \n      Dermatological images are typically diagnosed based on visual analysis of the skin lesion acquired using a dermoscope. However, the final quality of the acquired image is highly dependent on the illumination conditions during the acquisition phase. This variability in the light source can affect the dermatologist's diagnosis and decrease the accuracy of computer-aided diagnosis systems. Color constancy algorithms have proven to be a powerful tool to address this issue by allowing the standardization of the image illumination source, but the most commonly used algorithms still present some inherent limitations due to assumptions made on the original image. In this work, we propose a novel Dermatological Color Constancy Generative Adversarial Network (DermoCC-GAN) algorithm to overcome the current limitations by formulating the color constancy task as an image-to-image translation problem.\n    \n\n\n          Methods:\n        \n      \n      A generative adversarial network was trained with a custom heuristic algorithm that performs well on the training set. The model hence learns the domain transfer task (from original to color standardized image) and is then able to accurately apply the color constancy on test images characterized by different illumination conditions.\n    \n\n\n          Results:\n        \n      \n      The proposed algorithm outperforms state-of-the-art color constancy algorithms for dermatological images in terms of normalized median intensity and when using the color-normalized images in a deep learning framework for lesion classification (accuracy of the seven-class classifier: 79.2%) and segmentation (dice score: 90.9%). In addition, we validated the proposed approach on two different external datasets with highly satisfactory results.\n    \n\n\n          Conclusions:\n        \n      \n      The novel strategy presented here shows how it is possible to generalize a heuristic method for color constancy for dermatological image analysis by training a GAN. The overall approach presented here can be easily extended to numerous other applications."
        },
        {
            "title": "Quantitative Comparison of Color Asymmetry Features for Automatic Melanoma Detection.",
            "abstract": "Asymmetry assessment is an important step towards melanoma detection. This paper compares some of the color asymmetry features proposed in the literature which have been used to automatically detect melanoma from color images. A total of nine features were evaluated based on their accuracy in predicting lesion asymmetry on a dataset of 277 images. In addition, the accuracies of these features in differentiating melanoma from benign lesions were compared. Results show that simple features based on the brightness difference between the two halves of the lesion performed the best in predicting asymmetry and subsequently melanoma.Clinical relevance- The proposed work will assist researchers in choosing better performing color asymmetry features thereby improving the accuracy of automatic melanoma detection. The resulting system will reduce the workload of clinicians by screening out obviously benign cases and referring only the suspicious cases to them."
        },
        {
            "title": "Distributed Skin Lesion Analysis Across Decentralised Data Sources.",
            "abstract": "Skin cancer has become the most common cancer type. Research has applied image processing and analysis tools to support and improve the diagnose process. Conventional procedures usually centralise data from various data sources to a single location and execute the analysis tasks on central servers. However, centralisation of medical data does not often comply with local data protection regulations due to its sensitive nature and the loss of sovereignty if data providers allow unlimited access to the data. The Personal Health Train (PHT) is a Distributed Analytics (DA) infrastructure bringing the algorithms to the data instead of vice versa. By following this paradigm shift, it proposes a solution for persistent privacy- related challenges. In this work, we present a feasibility study, which demonstrates the capability of the PHT to perform statistical analyses and Machine Learning on skin lesion data distributed among three Germany-wide data providers."
        },
        {
            "title": "Segmenting Vitiligo on Clinical Face Images Using CNN Trained on Synthetic and Internet Images.",
            "abstract": "Accurately diagnosing and describing the severity of vitiligo is crucial for prognostication, treatment selection and comparison. Currently, disease severity scores require dermatologists to estimate percentage area of involvement, which is subjected to inter and intra-assessor variability. Previous studies focus on pure skin but vitiligo on the face, which has a more serious impact on patients' quality of life, was completely neglected. Convolutional neural networks (CNNs) have good performance on many segmentation tasks. However, due to data privacy, it is hard to have a large clinical vitiligo face image dataset to train a CNN. To address this challenge, images from two different sources, the Internet and the proposed vitiligo face synthesis algorithm, are employed in training. 843 vitiligo images taken from different viewpoints were collected from the Internet. These images are hugely different from the target clinical images collected according to a newly established international standard. To have more vitiligo face images similar to the target clinical images to enhance segmentation performance, an image synthesis algorithm is proposed. Both synthetic and Internet images are used to train a CNN which is modified from the fully convolutional network (FCN) to segment face vitiligo lesions. The results show that 1) the synthetic images effectively improve segmentation performance; 2) the proposed algorithm achieves 1.06 % error for the face vitiligo area estimation and 3) it is more accurate than two dermatologists and all the previous automated vitiligo segmentation methods, which were designed for segmentation vitiligo on pure skin."
        },
        {
            "title": "Artificial Intelligence analysis of over half a million European and Chinese women reveals striking differences in the facial skin ageing process.",
            "abstract": "Background:\n        \n      \n      Artificial Intelligence (A.I) and deep learning-based algorithms are increasingly being used in dermatology following the emergence of powerful smartphones with high-resolution cameras.\n    \n\n\n          Objectives:\n        \n      \n      To use an A.I-based algorithm, validated by dermatologists, to compare the evolution of the skin ageing process among Chinese and European women.\n    \n\n\n          Methods:\n        \n      \n      Selfie images were taken by 465 587 European and 79 016 Chinese women ranging from 18 to 85 and 18 to 69 years old, respectively, without facial skin diseases and who had access to a smartphone with a high-resolution camera (â‰¥4 Megapixels). The selfies were analysed by facial skin diagnostic using a smartphone application to grade the severity of 9 facial signs (including wrinkles, sagging, vascular, pigmentation signs, pores).\n    \n\n\n          Results:\n        \n      \n      Wrinkles/texture, ptosis and sagging increased linearly with age in European women compared to lower scores and more gradual increase in the younger age-classes in Chinese women. In Chinese women, pigmentation signs increased regularly between 18 and 40 years, plateaued between 40 and 60 years, then increased in the over 60s compared to lower scores and a slower more regular increase with age in European women. Vascularization signs increased steadily with age in European women compared to no significant change in Chinese women.\n    \n\n\n          Conclusions:\n        \n      \n      Marked differences were observed in the skin ageing process between European and Chinese populations, both in the prevalence of each facial ageing sign and their kinetics. Automatic grading performed on selfies and analysed by A.I is a fast and confidential method for quantifying signs of facial ageing and identifying the main issues for each population and age-class, which is of practical interest, as it will allow the development of tailored prevention and therapeutic measures."
        },
        {
            "title": "Detection of Malignant Melanoma Using Artificial Intelligence: An Observational Study of Diagnostic Accuracy.",
            "abstract": "Background:\n        \n      \n      Malignant melanoma can most successfully be cured when diagnosed at an early stage in the natural history. However, there is controversy over screening programs and many advocate screening only for high-risk individuals.\n    \n\n\n          Objectives:\n        \n      \n      This study aimed to evaluate the accuracy of an artificial intelligence neural network (Deep Ensemble for Recognition of Melanoma [DERM]) to identify malignant melanoma from dermoscopic images of pigmented skin lesions and to show how this compared to doctors' performance assessed by meta-analysis.\n    \n\n\n          Methods:\n        \n      \n      DERM was trained and tested using 7,102 dermoscopic images of both histologically confirmed melanoma (24%) and benign pigmented lesions (76%). A meta-analysis was conducted of studies examining the accuracy of naked-eye examination, with or without dermoscopy, by specialist and general physicians whose clinical diagnosis was compared to histopathology. The meta-analysis was based on evaluation of 32,226 pigmented lesions including 3,277 histopathology-confirmed malignant melanoma cases. The receiver operating characteristic (ROC) curve was used to examine and compare the diagnostic accuracy.\n    \n\n\n          Results:\n        \n      \n      DERM achieved a ROC area under the curve (AUC) of 0.93 (95% confidence interval: 0.92-0.94), and sensitivity and specificity of 85.0% and 85.3%, respectively. Avoidance of false-negative results is essential, so different decision thresholds were examined. At 95% sensitivity DERM achieved a specificity of 64.1% and at 95% specificity the sensitivity was 67%. The meta-analysis showed primary care physicians (10 studies) achieve an AUC of 0.83 (95% confidence interval: 0.79-0.86), with sensitivity and specificity of 79.9% and 70.9%; and dermatologists (92 studies) 0.91 (0.88-0.93), 87.5%, and 81.4%, respectively.\n    \n\n\n          Conclusions:\n        \n      \n      DERM has the potential to be used as a decision support tool in primary care, by providing dermatologist-grade recommendation on the likelihood of malignant melanoma."
        },
        {
            "title": "AcneGrader: An ensemble pruning of the deep learning base models to grade acne.",
            "abstract": "Background:\n        \n      \n      Acne is one of the most common skin lesions in adolescents. Some severe or inflammatory acne leads to scars, which may have major impacts on patients' quality of life or even job prospects. Grading acne plays an important role in diagnosis, and the diagnosis is made by counting the number of acne. It is a labor-intensive job and it is easy for dermatologists to make mistakes, so it is very important to develop automatic diagnosis methods. Ensemble learning may improve the prediction results of the base models, but its time complexity is relatively high. The ensemble pruning strategy may solve this computational challenge by removing the redundant base models.\n    \n\n\n          Materials and methods:\n        \n      \n      This study proposed a novel ensemble pruning framework of deep learning models to accurately detect and grade acne using images. First, we train multi-base models and prune the redundancy models according to the performance and diversity of the models. Then, we construct the new features of the training data by the base models we select in the previous step. Next, we remove the redundancy models further by a feature selection algorithm. Finally, we integrate all the base models by classifiers. The ensemble pruning algorithm was proposed to prune the deep learning base models.\n    \n\n\n          Results:\n        \n      \n      The experimental data showed that the ensemble pruned framework achieved a prediction accuracy of 85.82% on the acne dataset, better than the existing studies. To verify our method's effectiveness, we test our method in a skin cancer dataset and greatly outperform the state-of-the-art methods.\n    \n\n\n          Conclusion:\n        \n      \n      The method we proposed is used to grade acne. Our method's performance outperforms state-of-the-art methods on two datasets, and it can also remove redundancy models to reduce computational complexity."
        },
        {
            "title": "Classification Models for Skin Tumor Detection Using Texture Analysis in Medical Images.",
            "abstract": "Medical images have made a great contribution to early diagnosis. In this study, a new strategy is presented for analyzing medical images of skin with melanoma and nevus to model, classify and identify lesions on the skin. Machine learning applied to the data generated by first and second order statistics features, Gray Level Co-occurrence Matrix (GLCM), keypoints and color channel information-Red, Green, Blue and grayscale images of the skin were used to characterize decisive information for the classification of the images. This work proposes a strategy for the analysis of skin images, aiming to choose the best mathematical classifier model, for the identification of melanoma, with the objective of assisting the dermatologist in the identification of melanomas, especially towards an early diagnosis."
        },
        {
            "title": "Precision Diagnosis Of Melanoma And Other Skin Lesions From Digital Images.",
            "abstract": "Melanoma will affect an estimated 73,000 new cases this year and result in 9,000 deaths, yet precise diagnosis remains a serious problem. Without early detection and preventative care, melanoma can quickly spread to become fatal (Stage IV 5-year survival rate is 20-10%) from a once localized skin lesion (Stage IA 5- year survival rate is 97%). There is no biomarker for melanoma in clinical use, and the current diagnostic criteria for skin lesions remains subjective and imprecise. Accurate diagnosis of melanoma relies on a histopathologic gold standard; thus, aggressive excision of melanocytic skin lesions has been the mainstay of treatment. It is estimated that 36 biopsies are performed for every melanoma confirmed by pathology among excised lesions. There is significant morbidity in misdiagnosing melanoma such as progression of the disease for a false negative prediction vs the risks of unnecessary surgery for a false positive prediction. Every year, poor diagnostic precision adds an estimated $673 million in overall cost to manage the disease. Currently, manual dermatoscopic imaging is the standard of care in selecting atypical skin lesions for biopsy, and at best it achieves 90% sensitivity but only 59% specificity when performed by an expert dermatologist. Many computer vision (CV) algorithms perform better than dermatologists in classifying skin lesions although not significantly so in clinical practice. Meanwhile, open source deep learning (DL) techniques in CV have been gaining dominance since 2012 for image classification, and today DL can outperform humans in classifying millions of digital images with less than 5% error rates. Moreover, DL algorithms are readily run on commoditized hardware and have a strong online community of developers supporting their rapid adoption. In this work, we performed a successful pilot study to show proof of concept to DL skin pathology from images. However, DL algorithms must be trained on very large labelled datasets of images to achieve high accuracy. Here, we begin to assemble a large imageset of skin lesions from the UCSF and the San Francisco Veterans Affairs Medical Center (VAMC) dermatology clinics that are well characterized by their underlying pathology, on which to train DL algorithms. If trained on sufficient data, we hypothesize that our approach will significantly outperform general dermatologists in predicting skin lesion pathology. We posit that our work will allow for precision diagnosis of melanoma from widely available digital photography, which may optimize the management of the disease by decreasing unnecessary office visits and the significant morbidity and cost of melanoma misdiagnosis."
        },
        {
            "title": "Teledermoscopy for Skin Cancer Prevention: a Comparative Study of Clinical and Teledermoscopic Diagnosis.",
            "abstract": "Introduction:\n        \n      \n      The number of newly diagnosed skin cancers per year is greater than the sum of the four most common cancers: breast, prostate, lung, and colon. The implementation of primary and secondary prevention measures, over the last 2 to 3 decades, has made a major contribution to successful treatment.\n    \n\n\n          Aim:\n        \n      \n      Evaluate the accuracy and reliability of teledermoscopic versus clinical diagnosis for skin cancers when diagnostic algorithms are used, and when GPs and surgical specialties are involved in the clinical procedure.\n    \n\n\n          Methods:\n        \n      \n      Digital dermoscope (TS-DD, by Teleskin company) was used for the acquisition of teledermoscopic photographs and specialized teledermoscopic software was used for clinical examination and teledermoscopic consultation. The teledermoscopic procedure itself was performed in two steps. The first step was a clinical examination using the ABCDE rule with digital dermoscopic photography of the suspected lesion. The second step was a 2-step dermoscopic evaluation using the second step ABCD algorithm for the second step. Accuracy and diagnostic reliability were calculated for: teledermoscopic diagnosis versus histopathological diagnosis; clinical diagnosis versus histopathological diagnosis and teledermoscopic diagnosis versus clinical diagnosis.\n    \n\n\n          Results:\n        \n      \n      The study included 120 patients with 121 Pigmented Skin Lesions, of which 75 (62%) were benign and 46 (38%) were malignant lesions (6 melanomas and 40 NonMelanoma Skin Cancers). Diagnostic accuracy between teledermoscopic and histopathologic diagnosis was 90.91% and reliability k=0.81; between clinical and histopathological diagnosis the diagnostic accuracy was 82.64% and the reliability k=0.64 and between the clinical and teledermoscopic diagnosis the diagnostic accuracy was 81.82% and the reliability k=0.62.\n    \n\n\n          Conclusion:\n        \n      \n      The achieved diagnostic accuracy between clinical and teledermoscopic diagnosis, when using diagnostic algorithms, establishes a feasible screening path for skin cancers and indicates that general practitioners and specialized surgeons may equally be involved in prevention."
        },
        {
            "title": "Evaluation of High-Efficiency Image Coding algorithm for dermatology images in teledermatology.",
            "abstract": "Background:\n        \n      \n      Currently, teledermatology assumes a progressively greater role in the modern healthcare system, especially in consultation, diagnosis, or examining lesions and skin cancers. One of the major challenges facing teledermatology systems is determining the optimal image compression method to efficiently reduce the space needed for electronic storage and data transmission.\n    \n\n\n          Objective:\n        \n      \n      To the objective and subjective assessment of HEIC compression method on dermatological color images and benchmarking the performance of High-Efficiency Image Coding (HEIC) with different algorithms to a feasibility study of the method for teledermatology.\n    \n\n\n          Methods:\n        \n      \n      Twenty-five clinical and five skin histopathology images were taken in department of dermatology, Imam Reza Hospital, Mashhad, Iran. For each image, a set of 24 compressed images with different compression rates, which is composed of eight JPEG, eight JPEG2000, and eight HEIC images, has been prepared. Compressed and original images were shown simultaneously to three dermatologists and one dermatopathologist with different experiences. Each dermatologist scored quality and suitability of compressed images for diagnostic, as well as educational/scientific purposes. An objective evaluation was performed by calculating the mean \"distance\" of pixel colors and peak signal-to-noise ratio (PSNR).\n    \n\n\n          Results:\n        \n      \n      All compression rates for HEIC were objectively better than JPEG and JPEG2000, particularly at PSNR. Moreover, mean \"color distance\" per pixel for compressed images using HEIC was lower than others. The subjective image quality assessment also confirms the results of objective evaluation. In both educational and clinical diagnostic applications, HEIC compressed images have the highest score.\n    \n\n\n          Conclusion:\n        \n      \n      In consideration of objective and subjective evaluation, the HEIC algorithm represents an optimal performance in dermatology images compression compared with JPEG and JPEG2000."
        },
        {
            "title": "Cancer-Net SCa: tailored deep neural network designs for detection of skin cancer from dermoscopy images.",
            "abstract": "Background:\n        \n      \n      Skin cancer continues to be the most frequently diagnosed form of cancer in the U.S., with not only significant effects on health and well-being but also significant economic costs associated with treatment. A crucial step to the treatment and management of skin cancer is effective early detection with key screening approaches such as dermoscopy examinations, leading to stronger recovery prognoses. Motivated by the advances of deep learning and inspired by the open source initiatives in the research community, in this study we introduce Cancer-Net SCa, a suite of deep neural network designs tailored for the detection of skin cancer from dermoscopy images that is open source and available to the general public. To the best of the authors' knowledge, Cancer-Net SCa comprises the first machine-driven design of deep neural network architectures tailored specifically for skin cancer detection, one of which leverages attention condensers for an efficient self-attention design.\n    \n\n\n          Results:\n        \n      \n      We investigate and audit the behaviour of Cancer-Net SCa in a responsible and transparent manner through explainability-driven performance validation. All the proposed designs achieved improved accuracy when compared to the ResNet-50 architecture while also achieving significantly reduced architectural and computational complexity. In addition, when evaluating the decision making process of the networks, it can be seen that diagnostically relevant critical factors are leveraged rather than irrelevant visual indicators and imaging artifacts.\n    \n\n\n          Conclusion:\n        \n      \n      The proposed Cancer-Net SCa designs achieve strong skin cancer detection performance on the International Skin Imaging Collaboration (ISIC) dataset, while providing a strong balance between computation and architectural efficiency and accuracy. While Cancer-Net SCa is not a production-ready screening solution, the hope is that the release of Cancer-Net SCa in open source, open access form will encourage researchers, clinicians, and citizen data scientists alike to leverage and build upon them."
        },
        {
            "title": "Evaluation of the Diagnostic Accuracy of an Online Artificial Intelligence Application for Skin Disease Diagnosis.",
            "abstract": "Artificial intelligence (AI) algorithms for automated classification of skin diseases are available to the consumer market. Studies of their diagnostic accuracy are rare. We assessed the diagnostic accuracy of an open-access AI application (Skin Image Searchâ„¢) for recognition of skin diseases. Clinical images including tumours, infective and inflammatory skin diseases were collected at the Department of Dermatology at the Sahlgrenska University Hospital and uploaded for classification by the online application. The AI algorithm classified the images giving 5 differential diagnoses, which were then compared to the diagnoses made clinically by the dermatologists and/or histologically. We included 521 images portraying 26 diagnoses. The diagnostic accuracy was 56.4% for the top 5 suggested diagnoses and 22.8% when only considering the most probable diagnosis. The level of diagnostic accuracy varied considerably for diagnostic groups. The online application demonstrated low diagnostic accuracy compared to a dermatologist evaluation and needs further development."
        },
        {
            "title": "Interest in artificial intelligence for the diagnosis of non-melanoma skin cancer: a survey among French general practitioners.",
            "abstract": "General practitioners (GPs) are playing a key role in skin cancer screening. Non-melanoma skin cancer is frequent and difficult to diagnose. We aimed to assess whether GPs are facing difficulties in diagnosing non-pigmented skin tumours (NPSTs) and whether they would be interested in artificial intelligence (AI) software that could help them with this task. A questionnaire addressing the difficulties in diagnosing NPST and the potential interest in AI as a tool to help diagnose these tumours was emailed to GPs working in two French regions. In total, 147 respondents (98%) had faced difficulties diagnosing NPSTs; 86% agreed that an AI diagnostic tool could be useful in a GP's office and 83% agreed that it could change their practice. Nevertheless, 68% would not be willing to pay for this kind of software. GPs are facing difficulties in diagnosing NPSTs and would be interested in an AI tool that could help them achieve this. As referral to dermatology practices can be trying, AI diagnostic aids should be developed to help GPs in their gatekeeping task, however at limited cost to the GP."
        },
        {
            "title": "Estimation error of the body surface area in psoriasis: a comparative study of physician and computer-assisted image analysis (ImageJ).",
            "abstract": "Background:\n        \n      \n      Assessing the area involved in a skin disease, i.e. the body surface area (BSA), is essential in diagnosing disease severity, including in psoriasis. However, in psoriasis, BSA tends to be overestimated by physicians and has shown high inter-rater and intrarater variability. Furthermore, there are no reports suggesting the cause and clinical significance of overestimating BSA in psoriasiss.\n    \n\n\n          Aim:\n        \n      \n      To investigate the errors in estimating BSA in psoriasis by comparing physicians' results with those of computer-assisted image analysis (CAIA) and to provide suggestions regarding the clinical implications of such errors.\n    \n\n\n          Methods:\n        \n      \n      Using 43 images, 36 physicians visually estimated BSA in psoriasis, and subsequently, the images were evaluated using a CAIA program (ImageJ); the BSA values determined by the physicians and CAIA were then compared and matched. The BSA percentage was also graded on a scale from 0 to 6, as follows: Grade 0 = no lesion, Grade 1 = 1%-9%, Grade 2 = 10%-29%, Grade 3 = 30%-49%, Grade 4 = 50%-69%, Grade 5 = 70%-89% and Grade 6 = 90%-100%. Each grade range was divided, with the bottom and top 50% defined as the 'first half' and 'second half,' respectively.\n    \n\n\n          Results:\n        \n      \n      The mean proportion of correct assessments by physicians was 49.4%. Physicians tended to overestimate the BSA of psoriatic lesions by 8.76% Â± 8.82% compared with CAIA. The largest estimation error (proportion incorrect 75.7%) was observed in Grade 3 (30%-49% involvement). Estimates in the second half of the range demonstrated a higher proportion of inaccuracies compared with those in the first half. An overestimating error occurred in certain morphological characteristics of the psoriatic lesions.\n    \n\n\n          Conclusions:\n        \n      \n      The inaccuracy of BSA estimation by physicians may be related to the fact that information from the human eye is perceived to be exaggerated compared with the actual size. Further research into using artificial intelligence technology is needed to reduce quantification error and develop an ideal BSA assessment system. Additionally, education and training are needed for physicians to measure BSA accurately."
        },
        {
            "title": "Augmented decision-making for acral lentiginous melanoma detection using deep convolutional neural networks.",
            "abstract": "Background:\n        \n      \n      Several studies have achieved high-level performance of melanoma detection using convolutional neural networks (CNNs). However, few have described the extent to which the implementation of CNNs improves the diagnostic performance of the physicians.\n    \n\n\n          Objective:\n        \n      \n      This study is aimed at developing a CNN for detecting acral lentiginous melanoma (ALM) and investigating whether its implementation can improve the initial decision for ALM detection made by the physicians.\n    \n\n\n          Methods:\n        \n      \n      A CNN was trained using 1072 dermoscopic images of acral benign nevi, ALM and intermediate tumours. To investigate whether the implementation of CNN can improve the initial decision for ALM detection, 60 physicians completed a three-stage survey. In Stage I, they were asked for their decisions solely on the basis of dermoscopic images provided to them. In Stage II, they were also provided with clinical information. In Stage III, they were provided with the additional diagnosis and probability predicted by the CNN.\n    \n\n\n          Results:\n        \n      \n      The accuracy of ALM detection in the participants was 74.7% (95% confidence interval [CI], 72.6-76.8%) in Stage I and 79.0% (95% CI, 76.7-81.2%) in Stage II. In Stage III, it was 86.9% (95% CI, 85.3-88.4%), which exceeds the accuracy delivered in Stage I by 12.2%p (95% CI, 10.1-14.3%p) and Stage II by 7.9%p (95% CI, 6.0-9.9%p). Moreover, the concordance between the participants considerably increased (Fleiss-Îº of 0.436 [95% CI, 0.437-0.573] in Stage I, 0.506 [95% CI, 0.621-0.749] in Stage II and 0.684 [95% CI, 0.621-0.749] in Stage III).\n    \n\n\n          Conclusions:\n        \n      \n      Augmented decision-making improved the performance of and concordance between the clinical decisions of a diverse group of experts. This study demonstrates the potential use of CNNs as an adjoining, decision-supporting system for physicians' decisions."
        },
        {
            "title": "Validation of mitotic cell quantification via microscopy and multiple whole-slide scanners.",
            "abstract": "Background:\n        \n      \n      The establishment of whole-slide imaging (WSI) as a medical diagnostic device allows that pathologists may evaluate mitotic activity with this new technology. Furthermore, the image digitalization provides an opportunity to develop algorithms for automatic quantifications, ideally leading to improved reproducibility as compared to the naked eye examination by pathologists. In order to implement them effectively, accuracy of mitotic figure detection using WSI should be investigated. In this study, we aimed to measure pathologist performance in detecting mitotic figures (MFs) using multiple platforms (multiple scanners) and compare the results with those obtained using a brightfield microscope.\n    \n\n\n          Methods:\n        \n      \n      Four slides of canine oral melanoma were prepared and digitized using 4 WSI scanners. In these slides, 40 regions of interest (ROIs) were demarcated, and five observers identified the MFs using different viewing modes: microscopy and WSI. We evaluated the inter- and intra-observer agreements between modes with Cohen's Kappa and determined \"true\" MFs with a consensus panel. We then assessed the accuracy (agreement with truth) using the average of sensitivity and specificity.\n    \n\n\n          Results:\n        \n      \n      In the 40 ROIs, 155 candidate MFs were detected by five pathologists; 74 of them were determined to be true MFs. Inter- and intra-observer agreement was mostly \"substantial\" or greater (Kappa = 0.594-0.939). Accuracy was between 0.632 and 0.843 across all readers and modes. After averaging over readers for each modality, we found that mitosis detection accuracy for 3 of the 4 WSI scanners was significantly less than that of the microscope (p = 0.002, 0.012, and 0.001).\n    \n\n\n          Conclusions:\n        \n      \n      This study is the first to compare WSIs and microscopy in detecting MFs at the level of individual cells. Our results suggest that WSI can be used for mitotic cell detection and offers similar reproducibility to the microscope, with slightly less accuracy."
        },
        {
            "title": "Physicians' level of hindrance by body hair in dermatoscopy and clinical benefit of an automated hair removal algorithm.",
            "abstract": "Background and objectives:\n        \n      \n      Dermatoscopy may be hindered by body hair, and the development of an automated hair removal algorithm (AuHRA) might improve the diagnostic accuracy. However, the physicians' exact level of hindrance and the clinical benefit attained by AuHRA has not been assessed. The objectives of this study are to quantify the physicians' level of hindrance by body hair and the level of improvement in the visibility of underlying dermatoscopic patterns after application of AuHRA to digital images of hair-covered nevi.\n    \n\n\n          Patients and methods:\n        \n      \n      A cross-sectional reader study including 59 sets of dermatoscopic images of benign nevi that were presented to six dermatologists. Each set included three images of one individual nevus (unshaved/physically shaved/digitally shaved with AuHRA), which were compared to each other within each set to assess the level of improvement caused by hair removal.\n    \n\n\n          Results:\n        \n      \n      In comparison to unshaved lesions, dermatologists attributed the highest mean level of improvement to a physical shave (+1.36, p < 0.001) followed by AuHRA's digital shave (+0.79, p < 0.001). The majority of dermatologists considered the application of AuHRA as helpful and confirmed a medical need.\n    \n\n\n          Conclusions:\n        \n      \n      The dermatologists in our study confirmed a substantial impairment of the dermatoscopic examination by body hair. We demonstrated a clinical benefit attained by AuHRA in comparison to unshaved or physically shaved lesions."
        },
        {
            "title": "Man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists.",
            "abstract": "Background:\n        \n      \n      Deep learning convolutional neural networks (CNN) may facilitate melanoma detection, but data comparing a CNN's diagnostic performance to larger groups of dermatologists are lacking.\n    \n\n\n          Methods:\n        \n      \n      Google's Inception v4 CNN architecture was trained and validated using dermoscopic images and corresponding diagnoses. In a comparative cross-sectional reader study a 100-image test-set was used (level-I: dermoscopy only; level-II: dermoscopy plus clinical information and images). Main outcome measures were sensitivity, specificity and area under the curve (AUC) of receiver operating characteristics (ROC) for diagnostic classification (dichotomous) of lesions by the CNN versus an international group of 58 dermatologists during level-I or -II of the reader study. Secondary end points included the dermatologists' diagnostic performance in their management decisions and differences in the diagnostic performance of dermatologists during level-I and -II of the reader study. Additionally, the CNN's performance was compared with the top-five algorithms of the 2016 International Symposium on Biomedical Imaging (ISBI) challenge.\n    \n\n\n          Results:\n        \n      \n      In level-I dermatologists achieved a mean (Â±standard deviation) sensitivity and specificity for lesion classification of 86.6% (Â±9.3%) and 71.3% (Â±11.2%), respectively. More clinical information (level-II) improved the sensitivity to 88.9% (Â±9.6%, P = 0.19) and specificity to 75.7% (Â±11.7%, P < 0.05). The CNN ROC curve revealed a higher specificity of 82.5% when compared with dermatologists in level-I (71.3%, P < 0.01) and level-II (75.7%, P < 0.01) at their sensitivities of 86.6% and 88.9%, respectively. The CNN ROC AUC was greater than the mean ROC area of dermatologists (0.86 versus 0.79, P < 0.01). The CNN scored results close to the top three algorithms of the ISBI 2016 challenge.\n    \n\n\n          Conclusions:\n        \n      \n      For the first time we compared a CNN's diagnostic performance with a large international group of 58 dermatologists, including 30 experts. Most dermatologists were outperformed by the CNN. Irrespective of any physicians' experience, they may benefit from assistance by a CNN's image classification.\n    \n\n\n          Clinical trial number:\n        \n      \n      This study was registered at the German Clinical Trial Register (DRKS-Study-ID: DRKS00013570; https://www.drks.de/drks_web/)."
        },
        {
            "title": "Development and validation of an automated basal cell carcinoma histopathology information extraction system using natural language processing.",
            "abstract": "Introduction:\n        \n      \n      Routinely collected healthcare data are a powerful research resource, but often lack detailed disease-specific information that is collected in clinical free text such as histopathology reports. We aim to use natural Language Processing (NLP) techniques to extract detailed clinical and pathological information from histopathology reports to enrich routinely collected data.\n    \n\n\n          Methods:\n        \n      \n      We used the general architecture for text engineering (GATE) framework to build an NLP information extraction system using rule-based techniques. During validation, we deployed our rule-based NLP pipeline on 200 previously unseen, de-identified and pseudonymised basal cell carcinoma (BCC) histopathological reports from Swansea Bay University Health Board, Wales, UK. The results of our algorithm were compared with gold standard human annotation by two independent and blinded expert clinicians involved in skin cancer care.\n    \n\n\n          Results:\n        \n      \n      We identified 11,224 items of information with a mean precision, recall, and F1 score of 86.0% (95% CI: 75.1-96.9), 84.2% (95% CI: 72.8-96.1), and 84.5% (95% CI: 73.0-95.1), respectively. The difference between clinician annotator F1 scores was 7.9% in comparison with 15.5% between the NLP pipeline and the gold standard corpus. Cohen's Kappa score on annotated tokens was 0.85.\n    \n\n\n          Conclusion:\n        \n      \n      Using an NLP rule-based approach for named entity recognition in BCC, we have been able to develop and validate a pipeline with a potential application in improving the quality of cancer registry data, supporting service planning, and enhancing the quality of routinely collected data for research."
        },
        {
            "title": "Corrigendum: Dermatologist-level classification of skin cancer with deep neural networks.",
            "abstract": "This corrects the article DOI: 10.1038/nature21056."
        },
        {
            "title": "Assessment of Tibot Artificial Intelligence Application in Prediction of Diagnosis in Dermatological Conditions: Results of a Single Centre Study.",
            "abstract": "Objective:\n        \n      \n      To analyze the accuracy of Tibot artificial intelligence (AI) application tool in predicting the diagnosis of dermatological conditions.\n    \n\n\n          Material and methods:\n        \n      \n      In this prospective, observational study photographs of dermatological lesions with other details of patients having different skin conditions were fed in the AI application for the diagnosis. Predictions given by the Tibot AI application were compared with diagnosis done by the dermatologist. The performance of AI application was evaluated using accuracy, precision, and recall.\n    \n\n\n          Results:\n        \n      \n      Data of 398 patients were included in the application of whom 159 (39.9%) had fungal infections. Other conditions included eczema 36 (9%), alopecia 28 (7%), infestations 27 (6.8%), acne 25 (6.3%), psoriasis 19 (4.8%), benign tumors 7 (1.8%), bacterial infection 19 (4.8%), viral infection 15 (3.8%), and pigmentary disorders 20 (5%). The prediction accuracy (ability to get diagnosis in top three conditions) for alopecia, fungal infections, and eczema was 100%, 95.6%, and 91.7%, respectively. Mean prediction accuracy for correct diagnosis in the predicted top three diagnoses was 85.2%, and for correct diagnosis was 60.7%. Sensitivity and specificity of the application were approximately 86% and 98%, respectively. The sensitivity and positive predictive value of the application to diagnose alopecia was 100% and for fungal infections it was 96.85% and 90.05%, respectively.\n    \n\n\n          Conclusion:\n        \n      \n      In the preliminary stages, AI application tool showed promising results in diagnosing skin conditions. The accuracy and predictive value of the test may improve with the expansion of the database."
        },
        {
            "title": "Collective human intelligence outperforms artificial intelligence in a skin lesion classification task.",
            "abstract": "Background and objectives:\n        \n      \n      Convolutional neural networks (CNN) enable accurate diagnosis of medical images and perform on or above the level of individual physicians. Recently, collective human intelligence (CoHI) was shown to exceed the diagnostic accuracy of individuals. Thus, diagnostic performance of CoHI (120 dermatologists) versus individual dermatologists versus two state-of-the-art CNN was investigated.\n    \n\n\n          Patients and methods:\n        \n      \n      Cross-sectional reader study with presentation of 30 clinical cases to 120 dermatologists. Six diagnoses were offered and votes collected via remote voting devices (quizzboxÂ®, Quizzbox Solutions GmbH, Stuttgart, Germany). Dermatoscopic images were classified by a binary and multiclass CNN (FotoFinder Systems GmbH, Bad Birnbach, Germany). Three sets of diagnostic classifications were scored against ground truth: (1) CoHI, (2) individual dermatologists, and (3) CNN.\n    \n\n\n          Results:\n        \n      \n      CoHI attained a significantly higher accuracy [95 % confidence interval] (80.0 % [62.7 %-90.5 %]) than individual dermatologists (75.7 % [73.8 %-77.5 %]) and CNN (70.0 % [52.1 %-83.3 %]; all P < 0.001) in binary classifications. Moreover, CoHI achieved a higher sensitivity (82.4 % [59.0 %-93.8 %]) and specificity (76.9 % [49.7 %-91.8 %]) than individual dermatologists (sensitivity 77.8 % [75.3 %-80.2 %], specificity 73.0 % [70.6 %-75.4 %]) and CNN (sensitivity 70.6 % [46.9 %-86.7 %], specificity 69.2 % [42.4 %-87.3 %]). The diagnostic accuracy of CoHI was superior to that of individual dermatologists (P < 0.001) in multiclass evaluation, with the accuracy of the latter comparable to multiclass CNN.\n    \n\n\n          Conclusions:\n        \n      \n      Our analysis revealed that the majority vote of an interconnected group of dermatologists (CoHI) outperformed individuals and CNN in a demanding skin lesion classification task."
        },
        {
            "title": "Skin lesion computational diagnosis of dermoscopic images: Ensemble models based on input feature manipulation.",
            "abstract": "Background and objectives:\n        \n      \n      The number of deaths worldwide due to melanoma has risen in recent times, in part because melanoma is the most aggressive type of skin cancer. Computational systems have been developed to assist dermatologists in early diagnosis of skin cancer, or even to monitor skin lesions. However, there still remains a challenge to improve classifiers for the diagnosis of such skin lesions. The main objective of this article is to evaluate different ensemble classification models based on input feature manipulation to diagnose skin lesions.\n    \n\n\n          Methods:\n        \n      \n      Input feature manipulation processes are based on feature subset selections from shape properties, colour variation and texture analysis to generate diversity for the ensemble models. Three subset selection models are presented here: (1) a subset selection model based on specific feature groups, (2) a correlation-based subset selection model, and (3) a subset selection model based on feature selection algorithms. Each ensemble classification model is generated using an optimum-path forest classifier and integrated with a majority voting strategy. The proposed models were applied on a set of 1104 dermoscopic images using a cross-validation procedure.\n    \n\n\n          Results:\n        \n      \n      The best results were obtained by the first ensemble classification model that generates a feature subset ensemble based on specific feature groups. The skin lesion diagnosis computational system achieved 94.3% accuracy, 91.8% sensitivity and 96.7% specificity.\n    \n\n\n          Conclusions:\n        \n      \n      The input feature manipulation process based on specific feature subsets generated the greatest diversity for the ensemble classification model with very promising results."
        },
        {
            "title": "Cost-effectiveness of Artificial Intelligence as a Decision-Support System Applied to the Detection and Grading of Melanoma, Dental Caries, and Diabetic Retinopathy.",
            "abstract": "Objective:\n        \n      \n      To assess the cost-effectiveness of artificial intelligence (AI) for supporting clinicians in detecting and grading diseases in dermatology, dentistry, and ophthalmology.\n    \n\n\n          Importance:\n        \n      \n      AI has been referred to as a facilitator for more precise, personalized, and safer health care, and AI algorithms have been reported to have diagnostic accuracies at or above the average physician in dermatology, dentistry, and ophthalmology.\n    \n\n\n          Design, setting, and participants:\n        \n      \n      This economic evaluation analyzed data from 3 Markov models used in previous cost-effectiveness studies that were adapted to compare AI vs standard of care to detect melanoma on skin photographs, dental caries on radiographs, and diabetic retinopathy on retina fundus imaging. The general US and German population aged 50 and 12 years, respectively, as well as individuals with diabetes in Brazil aged 40 years were modeled over their lifetime. Monte Carlo microsimulations and sensitivity analyses were used to capture lifetime efficacy and costs. An annual cycle length was chosen. Data were analyzed between February 2021 and August 2021.\n    \n\n\n          Exposure:\n        \n      \n      AI vs standard of care.\n    \n\n\n          Main outcomes and measures:\n        \n      \n      Association of AI with tooth retention-years for dentistry and quality-adjusted life-years (QALYs) for individuals in dermatology and ophthalmology; diagnostic costs.\n    \n\n\n          Results:\n        \n      \n      In 1000 microsimulations with 1000 random samples, AI as a diagnostic-support system showed limited cost-savings and gains in tooth retention-years and QALYs. In dermatology, AI showed mean costs of $750 (95% CI, $608-$970) and was associated with 86.5 QALYs (95% CI, 84.9-87.9 QALYs), while the control showed higher costs $759 (95% CI, $618-$970) with similar QALY outcome. In dentistry, AI accumulated costs of â‚¬320 (95% CI, â‚¬299-â‚¬341) (purchasing power parity [PPP] conversion, $429 [95% CI, $400-$458]) with 62.4 years per tooth retention (95% CI, 60.7-65.1 years). The control was associated with higher cost, â‚¬342 (95% CI, â‚¬318-â‚¬368) (PPP, $458; 95% CI, $426-$493) and fewer tooth retention-years (60.9 years; 95% CI, 60.5-63.1 years). In ophthalmology, AI accrued costs of R $1321 (95% CI, R $1283-R $1364) (PPP, $559; 95% CI, $543-$577) at 8.4 QALYs (95% CI, 8.0-8.7 QALYs), while the control was less expensive (R $1260; 95% CI, R $1222-R $1303) (PPP, $533; 95% CI, $517-$551) and associated with similar QALYs. Dominance in favor of AI was dependent on small differences in the fee paid for the service and the treatment assumed after diagnosis. The fee paid for AI was a factor in patient preferences in cost-effectiveness between strategies.\n    \n\n\n          Conclusions and relevance:\n        \n      \n      The findings of this study suggest that marginal improvements in diagnostic accuracy when using AI may translate into a marginal improvement in outcomes. The current evidence supporting AI as decision support from a cost-effectiveness perspective is limited; AI should be evaluated on a case-specific basis to capture not only differences in costs and payment mechanisms but also treatment after diagnosis."
        },
        {
            "title": "A deep learning-based approach toward differentiating scalp psoriasis and seborrheic dermatitis from dermoscopic images.",
            "abstract": "Objectives:\n        \n      \n      This study aims to develop a new diagnostic method for discriminating scalp psoriasis and seborrheic dermatitis based on a deep learning (DL) model, which uses the dermatoscopic image as input and achieved higher accuracy than dermatologists trained with dermoscopy.\n    \n\n\n          Methods:\n        \n      \n      A total of 1,358 pictures (obtained from 617 patients) with pathological and diagnostic confirmed skin diseases (508 psoriases, 850 seborrheic dermatitides) were randomly allocated into the training, validation, and testing datasets (1,088/134/136) in this study. A DL model concerning dermatoscopic images was established using the transfer learning technique and trained for diagnosing two diseases.\n    \n\n\n          Results:\n        \n      \n      The developed DL model exhibits good sensitivity, specificity, and Area Under Curve (AUC) (96.1, 88.2, and 0.922%, respectively), it outperformed all dermatologists in the diagnosis of scalp psoriasis and seborrheic dermatitis when compared to five dermatologists with various levels of experience. Furthermore, non-proficient doctors with the assistance of the DL model can achieve comparable diagnostic performance to dermatologists proficient in dermoscopy. One dermatology graduate student and two general practitioners significantly improved their diagnostic performance, where their AUC values increased from 0.600, 0.537, and 0.575 to 0.849, 0.778, and 0.788, respectively, and their diagnosis consistency was also improved as the kappa values went from 0.191, 0.071, and 0.143 to 0.679, 0.550, and 0.568, respectively. DL enjoys favorable computational efficiency and requires few computational resources, making it easy to deploy in hospitals.\n    \n\n\n          Conclusions:\n        \n      \n      The developed DL model has favorable performance in discriminating two skin diseases and can improve the diagnosis, clinical decision-making, and treatment of dermatologists in primary hospitals."
        },
        {
            "title": "Dermoscopy Training Effect on Diagnostic Accuracy of Skin Lesions in Canadian Family Medicine Physicians Using the Triage Amalgamated Dermoscopic Algorithm.",
            "abstract": "Background:\n        \n      \n      Accurate identification of cutaneous lesions is an essential skill for family medicine physicians (FMPs). Studies show significant improvement in skin cancer detection with dermoscopy use. Frontline FMPs are an ideal target group for dermoscopy training. The 3-step Triage Amalgamated Dermoscopic Algorithm (TADA) facilitates high sensitivity and specificity for pigmented and nonpigmented skin lesions. Step I requires unequivocal identification of dermoscopic features for 1 of 3 benign skin lesions: angioma, dermatofibroma, or seborrheic keratosis. If absent, steps II and III are applied assessing for features of architectural disorder and malignancies with organized, symmetric patterns, respectively.\n    \n\n\n          Objective:\n        \n      \n      To assess FMPs' diagnostic accuracy of benign and malignant skin lesions before and after training in TADA step I.\n    \n\n\n          Methods:\n        \n      \n      In this repeated-measures observational study, 33 dermoscopy-naive FMPs attending an introductory dermoscopy workshop each assessed gross and corresponding dermoscopic photographic images of 50 pigmented and nonpigmented skin lesions (23 benign, 27 malignant) for features of TADA step I lesions before and after training. Analyses compared diagnostic accuracy in relation to training and baseline physician characteristics.\n    \n\n\n          Results:\n        \n      \n      Diagnostic accuracy improved from 76.4% to 90.8% (P < 0.001) and from 85.0% to 90.0% (P = 0.01), respectively, for all lesions and for all TADA I lesions. Female sex was significant as a predictor of individual posttraining performance (all lesions combined, P = 0.02).\n    \n\n\n          Conclusions:\n        \n      \n      Results show significant improvement in diagnostic accuracies for benign and malignant skin lesions with introductory dermoscopy training using TADA step I. This will reduce unnecessary benign lesion excision and enhance referral sensitivity, conserving specialist resources."
        },
        {
            "title": "ZooME: Efficient Melanoma Detection Using Zoom-in Attention and Metadata Embedding Deep Neural Network.",
            "abstract": "Melanoma detection is a crucial yet hard task for both dermatologists and computer-aided diagnosis (CAD). Many traditional machine learning algorithms including deep learning-based methods are employed for melanoma classification. However, more and more complex network architectures do not harvest a leap in model performance. In this paper, we aim to enhance the credibility of CAD approach for melanoma by paying more attention to clinically important information. We propose a Zoom-in Attention and Metadata Embedding (ZooME) melanoma detection network by: 1) introducing a Zoom-in Attention model to better extract and utilize unique pathological information of dermoscopy images; 2) embedding patients' demographic information including age, gender, and anatomic body site, to provide well-rounded information for better prediction. We apply a ten-fold cross-validation on the latest ISIC-2020 dataset with 33,126 dermoscopy images. The proposed ZooME achieved state-of-the-art results with 92.23% in AUC score, 84.59% in accuracy, 85.95% in sensitivity, and 84.63% in specialty, respectively."
        },
        {
            "title": "Automated Segmentation of Abnormal Tissues in Medical Images.",
            "abstract": "Nowadays, medical image modalities are almost available everywhere. These modalities are bases of diagnosis of various diseases sensitive to specific tissue type. Usually physicians look for abnormalities in these modalities in diagnostic procedures. Count and volume of abnormalities are very important for optimal treatment of patients. Segmentation is a preliminary step for these measurements and also further analysis. Manual segmentation of abnormalities is cumbersome, error prone, and subjective. As a result, automated segmentation of abnormal tissue is a need. In this study, representative techniques for segmentation of abnormal tissues are reviewed. Main focus is on the segmentation of multiple sclerosis lesions, breast cancer masses, lung nodules, and skin lesions. As experimental results demonstrate, the methods based on deep learning techniques perform better than other methods that are usually based on handy feature engineering techniques. Finally, the most common measures to evaluate automated abnormal tissue segmentation methods are reported."
        },
        {
            "title": "Hidden Variables in Deep Learning Digital Pathology and Their Potential to Cause Batch Effects: Prediction Model Study.",
            "abstract": "Background:\n        \n      \n      An increasing number of studies within digital pathology show the potential of artificial intelligence (AI) to diagnose cancer using histological whole slide images, which requires large and diverse data sets. While diversification may result in more generalizable AI-based systems, it can also introduce hidden variables. If neural networks are able to distinguish/learn hidden variables, these variables can introduce batch effects that compromise the accuracy of classification systems.\n    \n\n\n          Objective:\n        \n      \n      The objective of the study was to analyze the learnability of an exemplary selection of hidden variables (patient age, slide preparation date, slide origin, and scanner type) that are commonly found in whole slide image data sets in digital pathology and could create batch effects.\n    \n\n\n          Methods:\n        \n      \n      We trained four separate convolutional neural networks (CNNs) to learn four variables using a data set of digitized whole slide melanoma images from five different institutes. For robustness, each CNN training and evaluation run was repeated multiple times, and a variable was only considered learnable if the lower bound of the 95% confidence interval of its mean balanced accuracy was above 50.0%.\n    \n\n\n          Results:\n        \n      \n      A mean balanced accuracy above 50.0% was achieved for all four tasks, even when considering the lower bound of the 95% confidence interval. Performance between tasks showed wide variation, ranging from 56.1% (slide preparation date) to 100% (slide origin).\n    \n\n\n          Conclusions:\n        \n      \n      Because all of the analyzed hidden variables are learnable, they have the potential to create batch effects in dermatopathology data sets, which negatively affect AI-based classification systems. Practitioners should be aware of these and similar pitfalls when developing and evaluating such systems and address these and potentially other batch effect variables in their data sets through sufficient data set stratification."
        },
        {
            "title": "Model soups improve performance of dermoscopic skin cancer classifiers.",
            "abstract": "Background:\n        \n      \n      Image-based cancer classifiers suffer from a variety of problems which negatively affect their performance. For example, variation in image brightness or different cameras can already suffice to diminish performance. Ensemble solutions, where multiple model predictions are combined into one, can improve these problems. However, ensembles are computationally intensive and less transparent to practitioners than single model solutions. Constructing model soups, by averaging the weights of multiple models into a single model, could circumvent these limitations while still improving performance.\n    \n\n\n          Objective:\n        \n      \n      To investigate the performance of model soups for a dermoscopic melanoma-nevus skin cancer classification task with respect to (1) generalisation to images from other clinics, (2) robustness against small image changes and (3) calibration such that the confidences correspond closely to the actual predictive uncertainties.\n    \n\n\n          Methods:\n        \n      \n      We construct model soups by fine-tuning pre-trained models on seven different image resolutions and subsequently averaging their weights. Performance is evaluated on a multi-source dataset including holdout and external components.\n    \n\n\n          Results:\n        \n      \n      We find that model soups improve generalisation and calibration on the external component while maintaining performance on the holdout component. For robustness, we observe performance improvements for pertubated test images, while the performance on corrupted test images remains on par.\n    \n\n\n          Conclusions:\n        \n      \n      Overall, souping for skin cancer classifiers has a positive effect on generalisation, robustness and calibration. It is easy for practitioners to implement and by combining multiple models into a single model, complexity is reduced. This could be an important factor in achieving clinical applicability, as less complexity generally means more transparency."
        },
        {
            "title": "Assessing the impact of color blindness on the ability of identifying benign and malignant skin lesions by naked-eye examination.",
            "abstract": "Background:\n        \n      \n      Color vision deficiency describes the inability to distinguish certain shades of color. The aim of this study was to assess the impact of having color vision deficiency on the accuracy of distinguishing benign and malignant skin lesions by naked-eye examination.\n    \n\n\n          Methods:\n        \n      \n      This was a cross-sectional study conducted during the period August 2020 to February 2021. We randomly selected a total of 20 nevi and 20 melanoma images from an open access image database. The 40 images were divided into four sets of images, each set contained 5 benign and 5 malignant skin lesion images simulated as if they were seen by a protanope physician, deuteranope physician, tritanope physician, and a set of images presented without simulation. In an online survey, students who were in their final year of medical school or had newly graduated were asked to diagnose each image as benign or malignant.\n    \n\n\n          Results:\n        \n      \n      A total of 140 participants were included with a mean (SD) age of 24.88 (1.51). We found a significantly higher mean accuracy for non-simulated images compared to deuteranope simulated images (p< 0.001, mean difference = 11.07, 95% CI 8.40 to 13.74). We did not find a significant difference in accuracy classification for protanope simulated images (p = 0.066), nor for tritanope simulated images (p = 0.315). Classification accuracy for malignant lesions was higher than classification accuracy for benign lesions, with the highest difference belonging to deuteranope simulated images, with a difference in mean accuracy of classifying malignant lesions by 32.2 (95% CI 27.0 to 37.6).\n    \n\n\n          Conclusion:\n        \n      \n      Deuteranope participants (i.e., green color deficiency) had a significantly lower accuracy of distinguishing pigmented skin lesions as benign or malignant, an impact not found for other color vision deficiencies, which was mainly for misdiagnosing benign lesions as malignant."
        },
        {
            "title": "Optimized Identification of High-Grade Prostate Cancer by Combining Different PSA Molecular Forms and PSA Density in a Deep Learning Model.",
            "abstract": "After skin cancer, prostate cancer (PC) is the most common cancer among men. The gold standard for PC diagnosis is based on the PSA (prostate-specific antigen) test. Based on this preliminary screening, the physician decides whether to proceed with further tests, typically prostate biopsy, to confirm cancer and evaluate its aggressiveness. Nevertheless, the specificity of the PSA test is suboptimal and, as a result, about 75% of men who undergo a prostate biopsy do not have cancer even if they have elevated PSA levels. Overdiagnosis leads to unnecessary overtreatment of prostate cancer with undesirable side effects, such as incontinence, erectile dysfunction, infections, and pain. Here, we used artificial neuronal networks to develop models that can diagnose PC efficiently. The model receives as an input a panel of 4 clinical variables (total PSA, free PSA, p2PSA, and PSA density) plus age. The output of the model is an estimate of the Gleason score of the patient. After training on a dataset of 190 samples and optimization of the variables, the model achieved values of sensitivity as high as 86% and 89% specificity. The efficiency of the method can be improved even further by training the model on larger datasets."
        },
        {
            "title": "Augmented Intelligence Dermatology: Deep Neural Networks Empower Medical Professionals in Diagnosing Skin Cancer and Predicting Treatment Options for 134 Skin Disorders.",
            "abstract": "Although deep learning algorithms have demonstrated expert-level performance, previous efforts were mostly binary classifications of limited disorders. We trained an algorithm with 220,680 images of 174 disorders and validated it using Edinburgh (1,300 images; 10 disorders) and SNU datasets (2,201 images; 134 disorders). The algorithm could accurately predict malignancy, suggest primary treatment options, render multi-class classification among 134 disorders, and improve the performance of medical professionals. The area under the curves for malignancy detection were 0.928 Â± 0.002 (Edinburgh) and 0.937 Â± 0.004 (SNU). The area under the curves of primary treatment suggestion (SNU) were 0.828 Â± 0.012, 0.885 Â± 0.006, 0.885 Â± 0.006, and 0.918 Â± 0.006 for steroids, antibiotics, antivirals, and antifungals, respectively. For multi-class classification, the mean top-1 and top-5 accuracies were 56.7 Â± 1.6% and 92.0 Â± 1.1% (Edinburgh) and 44.8 Â± 1.2% and 78.1 Â± 0.3% (SNU), respectively. With the assistance of our algorithm, the sensitivity and specificity of 47 clinicians (21 dermatologists and 26 dermatology residents) for malignancy prediction (SNU; 240 images) were improved by 12.1% (P < 0.0001) and 1.1% (P < 0.0001), respectively. The malignancy prediction sensitivity of 23 non-medical professionals was significantly increased by 83.8% (P < 0.0001). The top-1 and top-3 accuracies of four doctors in the multi-class classification of 134 diseases (SNU; 2,201 images) were increased by 7.0% (P = 0.045) and 10.1% (P = 0.0020), respectively. The results suggest that our algorithm may serve as augmented intelligence that can empower medical professionals in diagnostic dermatology."
        },
        {
            "title": "The dermoscopic inverse approach significantly improves the accuracy of human readers for lentigo maligna diagnosis.",
            "abstract": "Background:\n        \n      \n      A recently introduced dermoscopic method for the diagnosis of early lentigo maligna (LM) is based on the absence of prevalent patterns of pigmented actinic keratosis and solar lentigo/flat seborrheic keratosis. We term this the inverse approach.\n    \n\n\n          Objective:\n        \n      \n      To determine whether training on the inverse approach increases the diagnostic accuracy of readers compared to classic pattern analysis.\n    \n\n\n          Methods:\n        \n      \n      We used clinical and dermoscopic images of histopathologically diagnosed LMs, pigmented actinic keratoses, and solar lentigo/flat seborrheic keratoses. Participants in a dermoscopy masterclass classified the lesions at baseline and after training on pattern analysis and the inverse approach. We compared their diagnostic performance among the 3 timepoints and to that of a trained convolutional neural network.\n    \n\n\n          Results:\n        \n      \n      The mean sensitivity for LM without training was 51.5%; after training on pattern analysis, it increased to 56.7%; and after learning the inverse approach, it increased to 83.6%. The mean proportions of correct answers at the 3 timepoints were 62.1%, 65.5, and 78.5%. The percentages of readers outperforming the convolutional neural network were 6.4%, 15.4%, and 53.9%, respectively.\n    \n\n\n          Limitations:\n        \n      \n      The experimental setting and the inclusion of histopathologically diagnosed lesions only.\n    \n\n\n          Conclusions:\n        \n      \n      The inverse approach, added to the classic pattern analysis, significantly improves the sensitivity of human readers for early LM diagnosis."
        },
        {
            "title": "Improving Skin cancer Management with ARTificial Intelligence (SMARTI): protocol for a preintervention/postintervention trial of an artificial intelligence system used as a diagnostic aid for skin cancer management in a specialist dermatology setting.",
            "abstract": "Introduction:\n        \n      \n      Convolutional neural networks (CNNs) can diagnose skin cancers with impressive accuracy in experimental settings, however, their performance in the real-world clinical setting, including comparison to teledermatology services, has not been validated in prospective clinical studies.\n    \n\n\n          Methods and analysis:\n        \n      \n      Participants will be recruited from dermatology clinics at the Alfred Hospital and Skin Health Institute, Melbourne. Skin lesions will be imaged using a proprietary dermoscopic camera. The artificial intelligence (AI) algorithm, a CNN developed by MoleMap Ltd and Monash eResearch, classifies lesions as benign, malignant or uncertain. This is a preintervention/postintervention study. In the preintervention period, treating doctors are blinded to AI lesion assessment. In the postintervention period, treating doctors review the AI lesion assessment in real time, and have the opportunity to then change their diagnosis and management. Any skin lesions of concern and at least two benign lesions will be selected for imaging. Each participant's lesions will be examined by a registrar, the treating consultant dermatologist and later by a teledermatologist. At the conclusion of the preintervention period, the safety of the AI algorithm will be evaluated in a primary analysis by measuring its sensitivity, specificity and agreement with histopathology where available, or the treating consultant dermatologists' classification. At trial completion, AI classifications will be compared with those of the teledermatologist, registrar, treating dermatologist and histopathology. The impact of the AI algorithm on diagnostic and management decisions will be evaluated by: (1) comparing the initial management decision of the registrar with their AI-assisted decision and (2) comparing the benign to malignant ratio (for lesions biopsied) between the preintervention and postintervention periods.\n    \n\n\n          Ethics and dissemination:\n        \n      \n      Human Research Ethics Committee (HREC) approval received from the Alfred Hospital Ethics Committee on 14 February 2019 (HREC/48865/Alfred-2018). Findings from this study will be disseminated through peer-reviewed publications, non-peer reviewed media and conferences.\n    \n\n\n          Trial registration number:\n        \nNCT04040114."
        },
        {
            "title": "Computer algorithms show potential for improving dermatologists' accuracy to diagnose cutaneous melanoma: Results of the International Skin Imaging Collaboration 2017.",
            "abstract": "Background:\n        \n      \n      Computer vision has promise in image-based cutaneous melanoma diagnosis but clinical utility is uncertain.\n    \n\n\n          Objective:\n        \n      \n      To determine if computer algorithms from an international melanoma detection challenge can improve dermatologists' accuracy in diagnosing melanoma.\n    \n\n\n          Methods:\n        \n      \n      In this cross-sectional study, we used 150 dermoscopy images (50 melanomas, 50 nevi, 50 seborrheic keratoses) from the test dataset of a melanoma detection challenge, along with algorithm results from 23 teams. Eight dermatologists and 9 dermatology residents classified dermoscopic lesion images in an online reader study and provided their confidence level.\n    \n\n\n          Results:\n        \n      \n      The top-ranked computer algorithm had an area under the receiver operating characteristic curve of 0.87, which was higher than that of the dermatologists (0.74) and residents (0.66) (P < .001 for all comparisons). At the dermatologists' overall sensitivity in classification of 76.0%, the algorithm had a superior specificity (85.0% vs. 72.6%, P = .001). Imputation of computer algorithm classifications into dermatologist evaluations with low confidence ratings (26.6% of evaluations) increased dermatologist sensitivity from 76.0% to 80.8% and specificity from 72.6% to 72.8%.\n    \n\n\n          Limitations:\n        \n      \n      Artificial study setting lacking the full spectrum of skin lesions as well as clinical metadata.\n    \n\n\n          Conclusion:\n        \n      \n      Accumulating evidence suggests that deep neural networks can classify skin images of melanoma and its benign mimickers with high accuracy and potentially improve human performance."
        },
        {
            "title": "Retracted: Diagnosis and Treatment of Intestinal Melanoma Metastases in the Era of Effective Systemic Treatment.",
            "abstract": "Objective:\n        \n      \n      The aim of the present study was to describe different presentations, diagnostic tools, and available treatments for melanoma metastasized to the intestines.\n    \n\n\n          Background:\n        \n      \n      The intestine is a frequent site of metastases in melanoma patients. In the current era, with long-term survival after systemic treatment, there is a need for a timely diagnosis and optimal treatment of intestinal metastases.\n    \n\n\n          Methods:\n        \n      \n      Patients diagnosed between 2011 and 2015 with intestinal metastases of melanoma were included. Diagnostic procedures, treatment strategies, and their outcome were analyzed for all patients.\n    \n\n\n          Results:\n        \n      \n      A total of 22 patients were included. Twenty patients received systemic therapy for widely disseminated disease. Fourteen of these twenty patients received local treatment for symptomatic intestinal metastases. Median overall survival after detection of intestinal metastasis in patients receiving systemic treatment was 22 months. On the basis of this cohort, a treatment algorithm for treatment of patients with symptomatic intestinal melanoma metastases was constructed.\n    \n\n\n          Conclusions:\n        \n      \n      The treatment of intestinal melanoma metastases has changed due to the introduction of novel systemic treatments that can result in long-term survival of patients with widely metastatic melanoma. Surgeons and other clinicians should be aware of these changes in clinical practice as well as the diverse presentation of intestinal melanoma metastases and the diagnostic and therapeutic dilemmas involved."
        },
        {
            "title": "The use of noninvasive imaging techniques in the diagnosis of melanoma: a prospective diagnostic accuracy study.",
            "abstract": "Background:\n        \n      \n      Early detection of melanoma is crucial to improving the detection of thin curable melanomas. Noninvasive, computer-assisted methods have been developed to use at the bedside to aid in diagnoses but have not been compared directly in a clinical setting.\n    \n\n\n          Objective:\n        \n      \n      We conducted a prospective diagnostic accuracy study comparing a dermatologist's clinical examination at the bedside, teledermatology, and noninvasive imaging techniques (FotoFinder, MelaFind, and Verisante Aura).\n    \n\n\n          Methods:\n        \n      \n      A total of 184 patients were recruited prospectively from an outpatient dermatology clinic, with lesions imaged, assessed, and excised. Skin specimens were assessed by 2 blinded pathologists, providing the gold standard comparison.\n    \n\n\n          Results:\n        \n      \n      Fifty-nine lesions from 56 patients had a histopathologic diagnosis of melanoma, whereas 150 lesions from 128 patients were diagnosed as benign. Sensitivities and specificities were, respectively, MelaFind (82.5%, 52.4%), Verisante Aura (21.4%, 86.2%), and FotoFinder Moleanalyzer Pro (88.1%, 78.8%). The sensitivity and specificity of the teledermoscopist (84.5% and 82.6%, respectively) and local dermatologist (96.6% and 32.2%, respectively) were also compared.\n    \n\n\n          Limitations:\n        \n      \n      There are inherent limitations in using pathology as the gold standard to compare sensitivities and specificities.\n    \n\n\n          Conclusion:\n        \n      \n      This study demonstrates that the highest sensitivity and specificity of the instruments were established with the FotoFinder Moleanalyzer Pro, which could be a valuable tool to assist with, but not replace, clinical decision making."
        },
        {
            "title": "Melanoma recognition by a deep learning convolutional neural network-Performance in different melanoma subtypes and localisations.",
            "abstract": "Background:\n        \n      \n      Deep learning convolutional neural networks (CNNs) show great potential for melanoma diagnosis. Melanoma thickness at diagnosis among others depends on melanoma localisation and subtype (e.g. advanced thickness in acrolentiginous or nodular melanomas). The question whether CNN may counterbalance physicians' diagnostic difficulties in these melanomas has not been addressed. We aimed to investigate the diagnostic performance of a CNN with approval for the European market across different melanoma localisations and subtypes.\n    \n\n\n          Methods:\n        \n      \n      The current market version of a CNN (Moleanalyzer-ProÂ®, FotoFinder Systems GmbH, Bad Birnbach, Germany) was used for classifications (malignant/benign) in six dermoscopic image sets. Each set included 30 melanomas and 100 benign lesions of related localisations and morphology (set-SSM: superficial spreading melanomas and macular nevi; set-LMM: lentigo maligna melanomas and facial solar lentigines/seborrhoeic keratoses/nevi; set-NM: nodular melanomas and papillomatous/dermal/blue nevi; set-Mucosa: mucosal melanomas and mucosal melanoses/macules/nevi; set-AMskin: acrolentiginous melanomas and acral (congenital) nevi; set-AMnail: subungual melanomas and subungual (congenital) nevi/lentigines/ethnical type pigmentations).\n    \n\n\n          Results:\n        \n      \n      The CNN showed a high-level performance in set-SSM, set-NM and set-LMM (sensitivities >93.3%, specificities >65%, receiver operating characteristics-area under the curve [ROC-AUC] >0.926). In set-AMskin, the sensitivity was lower (83.3%) at a high specificity (91.0%) and ROC-AUC (0.928). A limited performance was found in set-mucosa (sensitivity 93.3%, specificity 38.0%, ROC-AUC 0.754) and set-AMnail (sensitivity 53.3%, specificity 68.0%, ROC-AUC 0.621).\n    \n\n\n          Conclusions:\n        \n      \n      The CNN may help to partly counterbalance reduced human accuracies. However, physicians need to be aware of the CNN's limited diagnostic performance in mucosal and subungual lesions. Improvements may be expected from additional training images of mucosal and subungual sites."
        },
        {
            "title": "Artificial Intelligence in the Evaluation of Telemedicine Dermatology Patients.",
            "abstract": "Background:\n        \n      \n      Background: Early detection of malignant skin lesions reduces morbidity. There is increased need for a telemedicine triage tool to prioritize patients who require in-person evaluation for potential malignancy.\n    \n\n\n          Objective:\n        \n      \n      To evaluate the utility of artificial intelligence (AI) in telemedicine triage and diagnosis of cutaneous lesions.\n    \n\n\n          Methods:\n        \n      \n      Clinical photographs of unbiopsied skin lesions were presented to AI software and three board-certified dermatologists with 18 years average clinical experience. Diagnoses were compared with biopsy reports of the same lesions.\n    \n\n\n          Results:\n        \n      \n      Results from 100 images revealed no significant diagnostic difference between AI and a panel of three dermatologists when using the AI top three differential diagnoses. The AI correctly identified 63% of the cases whereas the dermatology group correctly identified 64.3% of the cases (P&lt;.05). In summary, there was no statistically significant difference when evaluating lesions.\n    \n\n\n          Conclusion:\n        \n      \n      The use of artificial intelligence as a method of triaging patients with potential skin cancer is a very useful option in telemedicine, as AI identification of BCC, SCC, and melanoma did not significantly differ from board-certified dermatologists. Both dermatologists and non-dermatologists will benefit from an AI triage system, prioritizing lesions that the software deems malignant. J Drugs Dermatol. 2022;21(2):191-194. doi:10.36849/JDD.6277."
        },
        {
            "title": "Combining CNN-based histologic whole slide image analysis and patient data to improve skin cancer classification.",
            "abstract": "Background:\n        \n      \n      Clinicians and pathologists traditionally use patient data in addition to clinical examination to support their diagnoses.\n    \n\n\n          Objectives:\n        \n      \n      We investigated whether a combination of histologic whole slides image (WSI) analysis based on convolutional neural networks (CNNs) and commonly available patient data (age, sex and anatomical site of the lesion) in a binary melanoma/nevus classification task could increase the performance compared with CNNs alone.\n    \n\n\n          Methods:\n        \n      \n      We used 431 WSIs from two different laboratories and analysed the performance of classifiers that used the image or patient data individually or three common fusion techniques. Furthermore, we tested a naive combination of patient data and an image classifier: for cases interpreted as 'uncertain' (CNN output score <0.7), the decision of the CNN was replaced by the decision of the patient data classifier.\n    \n\n\n          Results:\n        \n      \n      The CNN on its own achieved the best performance (mean Â± standard deviation of five individual runs) with AUROC of 92.30% Â± 0.23% and balanced accuracy of 83.17% Â± 0.38%. While the classification performance was not significantly improved in general by any of the tested fusions, naive strategy of replacing the image classifier with the patient data classifier on slides with low output scores improved balanced accuracy to 86.72% Â± 0.36%.\n    \n\n\n          Conclusion:\n        \n      \n      In most cases, the CNN on its own was so accurate that patient data integration did not provide any benefit. However, incorporating patient data for lesions that were classified by the CNN with low 'confidence' improved balanced accuracy."
        },
        {
            "title": "Management of urticarial vasculitis: A worldwide physician perspective.",
            "abstract": "Background:\n        \n      \n      Urticarial vasculitis (UV) is a rare type of leukocytoclastic vasculitis characterized by long lasting urticarial skin lesions and poor response to treatment. As of yet, no clinical guidelines, diagnostic criteria, or treatment algorithms exist, and the approaches to the diagnostic workup and treatment of UV patients may differ globally. We conducted an online survey to examine how UV patients are diagnosed and treated by international specialists and to reveal the greatest challenges in managing UV patients worldwide.\n    \n\n\n          Methods:\n        \n      \n      Distribution of the questionnaire included an email to individuals in the World Allergy Organization (WAO) database, with no restrictions applied to the specialty, affiliation, or nationality of the participants (November 2018). The email contained a link (Internet address) to the online questionnaire. Responses were anonymous. The link to the questionnaire was further sent to the network of Urticaria Centers of Reference and Excellence (UCARE) in the Global Allergy and Asthma European Network (GA2LEN) as well as to the Turkish Dermatology Society and the Japanese Society of Allergology, who distributed the link to their members. In addition, the survey link was posted online in the group of the Russian Society of Allergologists and Immunologists.\n    \n\n\n          Results:\n        \n      \n      We received 883 completed surveys from physicians in 92 countries. UV was reported to be rare in clinical practice, with an average of 5 patients per physician per year. More than two-thirds of physicians reported wheals, burning of the skin, and residual hyperpigmentation in 60-100% of UV patients. The most frequently reported reason for receiving referrals of patients with UV was to establish the diagnosis. The most important features for establishing the diagnosis of UV were wheals of longer than 24 hours duration (72%), the results of skin biopsy (63%), and post-inflammatory hyperpigmentation (46%). The most common tests ordered in UV patients were complete blood count, erythrocyte sedimentation rate, C-reactive protein, complement components, antinuclear antibodies, and skin biopsy. Physicians considered UV to be of unknown cause in most patients, and drugs and systemic lupus erythematosus to be the most common identifiable causes. Two of 3 physicians reported that they use second-generation antihistamines in standard dose as the first-line therapy in patients with UV. The greatest perceived challenges in the management of UV were the limited efficacy of drugs and the absence of clinical guidelines and treatment algorithms.\n    \n\n\n          Conclusions:\n        \n      \n      UV is a challenging disease. Skin biopsy, a gold standard for UV diagnosis, is not performed by many physicians. This may lead to misdiagnosis of UV, for example, as chronic spontaneous urticaria, and to inadequate treatment. International consensus-based recommendations for the classification of UV and the diagnostic workup and treatment, as well as prospective studies evaluating potentially safe and effective drugs for the treatment of UV, are necessary."
        },
        {
            "title": "Intelligent Dermatologist Tool for Classifying Multiple Skin Cancer Subtypes by Incorporating Manifold Radiomics Features Categories.",
            "abstract": "The rates of skin cancer (SC) are rising every year and becoming a critical health issue worldwide. SC's early and accurate diagnosis is the key procedure to reduce these rates and improve survivability. However, the manual diagnosis is exhausting, complicated, expensive, prone to diagnostic error, and highly dependent on the dermatologist's experience and abilities. Thus, there is a vital need to create automated dermatologist tools that are capable of accurately classifying SC subclasses. Recently, artificial intelligence (AI) techniques including machine learning (ML) and deep learning (DL) have verified the success of computer-assisted dermatologist tools in the automatic diagnosis and detection of SC diseases. Previous AI-based dermatologist tools are based on features which are either high-level features based on DL methods or low-level features based on handcrafted operations. Most of them were constructed for binary classification of SC. This study proposes an intelligent dermatologist tool to accurately diagnose multiple skin lesions automatically. This tool incorporates manifold radiomics features categories involving high-level features such as ResNet-50, DenseNet-201, and DarkNet-53 and low-level features including discrete wavelet transform (DWT) and local binary pattern (LBP). The results of the proposed intelligent tool prove that merging manifold features of different categories has a high influence on the classification accuracy. Moreover, these results are superior to those obtained by other related AI-based dermatologist tools. Therefore, the proposed intelligent tool can be used by dermatologists to help them in the accurate diagnosis of the SC subcategory. It can also overcome manual diagnosis limitations, reduce the rates of infection, and enhance survival rates."
        },
        {
            "title": "Skin Cancer Detection Based on Deep Learning.",
            "abstract": "Background:\n        \n      \n      The conventional procedure of skin-related disease detection is a visual inspection by a dermatologist or a primary care clinician, using a dermatoscope. The suspected patients with early signs of skin cancer are referred for biopsy and histopathological examination to ensure the correct diagnosis and the best treatment. Recent advancements in deep convolutional neural networks (CNNs) have achieved excellent performance in automated skin cancer classification with accuracy similar to that of dermatologists. However, such improvements are yet to bring about a clinically trusted and popular system for skin cancer detection.\n    \n\n\n          Objective:\n        \n      \n      This study aimed to propose viable deep learning (DL) based method for the detection of skin cancer in lesion images, to help physicians in diagnosis.\n    \n\n\n          Material and methods:\n        \n      \n      In this analytical study, a novel DL based model was proposed, in which other than the lesion image, the patient's data, including the anatomical site of the lesion, age, and gender were used as the model input to predict the type of the lesion. An Inception-ResNet-v2 CNN pretrained for object recognition was employed in the proposed model.\n    \n\n\n          Results:\n        \n      \n      Based on the results, the proposed method achieved promising performance for various skin conditions, and also using the patient's metadata in addition to the lesion image for classification improved the classification accuracy by at least 5% in all cases investigated. On a dataset of 57536 dermoscopic images, the proposed approach achieved an accuracy of 89.3%Â±1.1% in the discrimination of 4 major skin conditions and 94.5%Â±0.9% in the classification of benign vs. malignant lesions.\n    \n\n\n          Conclusion:\n        \n      \n      The promising results highlight the efficacy of the proposed approach and indicate that the inclusion of the patient's metadata with the lesion image can enhance the skin cancer detection performance."
        },
        {
            "title": "Comparing artificial intelligence algorithms to 157 German dermatologists: the melanoma classification benchmark.",
            "abstract": "Background:\n        \n      \n      Several recent publications have demonstrated the use of convolutional neural networks to classify images of melanoma at par with board-certified dermatologists. However, the non-availability of a public human benchmark restricts the comparability of the performance of these algorithms and thereby the technical progress in this field.\n    \n\n\n          Methods:\n        \n      \n      An electronic questionnaire was sent to dermatologists at 12 German university hospitals. Each questionnaire comprised 100 dermoscopic and 100 clinical images (80 nevi images and 20 biopsy-verified melanoma images, each), all open-source. The questionnaire recorded factors such as the years of experience in dermatology, performed skin checks, age, sex and the rank within the university hospital or the status as resident physician. For each image, the dermatologists were asked to provide a management decision (treat/biopsy lesion or reassure the patient). Main outcome measures were sensitivity, specificity and the receiver operating characteristics (ROC).\n    \n\n\n          Results:\n        \n      \n      Total 157 dermatologists assessed all 100 dermoscopic images with an overall sensitivity of 74.1%, specificity of 60.0% and an ROC of 0.67 (range = 0.538-0.769); 145 dermatologists assessed all 100 clinical images with an overall sensitivity of 89.4%, specificity of 64.4% and an ROC of 0.769 (range = 0.613-0.9). Results between test-sets were significantly different (P < 0.05) confirming the need for a standardised benchmark.\n    \n\n\n          Conclusions:\n        \n      \n      We present the first public melanoma classification benchmark for both non-dermoscopic and dermoscopic images for comparing artificial intelligence algorithms with diagnostic performance of 145 or 157 dermatologists. Melanoma Classification Benchmark should be considered as a reference standard for white-skinned Western populations in the field of binary algorithmic melanoma classification."
        },
        {
            "title": "Over-Detection of Melanoma-Suspect Lesions by a CE-Certified Smartphone App: Performance in Comparison to Dermatologists, 2D and 3D Convolutional Neural Networks in a Prospective Data Set of 1204 Pigmented Skin Lesions Involving Patients' Perception.",
            "abstract": "The exponential increase in algorithm-based mobile health (mHealth) applications (apps) for melanoma screening is a reaction to a growing market. However, the performance of available apps remains to be investigated. In this prospective study, we investigated the diagnostic accuracy of a class 1 CE-certified smartphone app in melanoma risk stratification and its patient and dermatologist satisfaction. Pigmented skin lesions â‰¥ 3 mm and any suspicious smaller lesions were assessed by the smartphone app SkinVisionÂ® (SkinVisionÂ® B.V., Amsterdam, the Netherlands, App-Version 6.8.1), 2D FotoFinder ATBMÂ® master (FotoFinder ATBMÂ® Systems GmbH, Bad Birnbach, Germany, Version 3.3.1.0), 3D VectraÂ® WB360 (Canfield Scientific, Parsippany, NJ, USA, Version 4.7.1) total body photography (TBP) devices, and dermatologists. The high-risk score of the smartphone app was compared with the two gold standards: histological diagnosis, or if not available, the combination of dermatologists', 2D and 3D risk assessments. A total of 1204 lesions among 114 patients (mean age 59 years; 51% females (55 patients at high-risk for developing a melanoma, 59 melanoma patients)) were included. The smartphone app's sensitivity, specificity, and area under the receiver operating characteristics (AUROC) varied between 41.3-83.3%, 60.0-82.9%, and 0.62-0.72% according to two study-defined reference standards. Additionally, all patients and dermatologists completed a newly created questionnaire for preference and trust of screening type. The smartphone app was rated as trustworthy by 36% (20/55) of patients at high-risk for melanoma, 49% (29/59) of melanoma patients, and 8.8% (10/114) of dermatologists. Most of the patients rated the 2D TBP imaging (93% (51/55) resp. 88% (52/59)) and the 3D TBP imaging (91% (50/55) resp. 90% (53/59)) as trustworthy. A skin cancer screening by combination of dermatologist and smartphone app was favored by only 1.8% (1/55) resp. 3.4% (2/59) of the patients; no patient preferred an assessment by a smartphone app alone. The diagnostic accuracy in clinical practice was not as reliable as previously advertised and the satisfaction with smartphone apps for melanoma risk stratification was scarce. MHealth apps might be a potential medium to increase awareness for melanoma screening in the lay population, but healthcare professionals and users should be alerted to the potential harm of over-detection and poor performance. In conclusion, we suggest further robust evidence-based evaluation before including market-approved apps in self-examination for public health benefits."
        },
        {
            "title": "Differentiation of combined nevi and melanomas: Case-control study with comparative analysis of dermoscopic features.",
            "abstract": "Background and objectives:\n        \n      \n      Combined nevi (CN) show two or more components of major nevus subtypes and simulate melanomas. We investigated a panel of dermoscopic features and three dermoscopic algorithms for differentiating CN from melanomas.\n    \n\n\n          Patients and methods:\n        \n      \n      Retrospective, blinded case-control study using dermoscopic images of 36 CN and 36 melanoma controls. Twenty-one dermoscopic features validated for the diagnosis of melanocytic lesions, the number of colors, and three dermoscopic algorithms were investigated (ABCD rule of dermoscopy, Menzies scoring method, 7-point checklist).\n    \n\n\n          Results:\n        \n      \n      Five of seven features indicative of nevi were observed significantly more frequently in CN than in melanomas (all p < 0.05) and two were exclusively found in CN. Eleven out of 14 features indicative of melanomas were observed significantly more frequently in melanomas than in CN (all p < 0.03) and five were exclusively found in melanomas. The mean (Â± SD) number of colors in CN was lower than in melanomas (2.1 Â± 0.6 versus 3.4 Â± 0.7; p < 0.001). Among tested algorithms the ABCD rule of dermoscopy performed best (sensitivity 91.7 %, specificity 77.8 %).\n    \n\n\n          Conclusions:\n        \n      \n      The ABCD rule of dermoscopy differentiated CN from melanomas most efficiently. Additional knowledge of dermoscopic features to be expected exclusively in either CN or melanomas should help dermatologists to make a correct clinical diagnosis."
        },
        {
            "title": "Convolutional neural network assistance significantly improves dermatologists' diagnosis of cutaneous tumours using clinical images.",
            "abstract": "Background:\n        \n      \n      Convolutional neural networks (CNNs) have demonstrated expert-level performance in cutaneous tumour classification using clinical images, but most previous studies have focused on dermatologist-versus-CNN comparisons rather than their combination. The objective of our study was to evaluate the potential impact of CNN assistance on dermatologists for clinical image interpretation.\n    \n\n\n          Methods:\n        \n      \n      A multi-class CNN was trained and validated using a dataset of 25,773 clinical images comprising 10 categories of cutaneous tumours. The CNN's performance was tested on an independent dataset of 2107 images. A total of 400 images (40 per category) were randomly selected from the test dataset. A fully crossed, self-control, multi-reader multi-case (MRMC) study was conducted to compare the performance of 18 board-certified dermatologists (experience: 13/18 â‰¤ 10 years; 5/18ï¼ž10 years) in interpreting the 400 clinical images with or without CNN assistance.\n    \n\n\n          Results:\n        \n      \n      The CNN achieved an overall accuracy of 78.45% and kappa of 0.73 in the classification of 10 types of cutaneous tumours on 2107 images. CNN-assisted dermatologists achieved a higher accuracy (76.60% vs. 62.78%, P < 0.001) and kappa (0.74 vs. 0.59, P < 0.001) than unassisted dermatologists in interpreting the 400 clinical images. Dermatologists with less experience benefited more from CNN assistance. At the binary classification level (malignant or benign), the sensitivity (89.56% vs. 83.21%, P < 0.001) and specificity (87.90% vs. 80.92%, P < 0.001) of dermatologists with CNN assistance were also significantly improved than those without.\n    \n\n\n          Conclusions:\n        \n      \n      CNN assistance improved dermatologist accuracy in interpreting cutaneous tumours and could further boost the acceptance of this new technique."
        },
        {
            "title": "Survivorship care planning in skin cancer: An unbiased statistical approach to identifying patterns of care-plan use.",
            "abstract": "Background:\n        \n      \n      Nearly 1 in 5 Americans will develop skin cancer, and as a result, survivors of skin cancer compose one of the largest groups of cancer survivors. Survivorship care plans (SCPs) are an important tool for improving patient outcomes and provide critical information to both survivors and health care professionals. Recent efforts have been made to expand SCP utilization; however, which patients currently receive SCPs is poorly understood.\n    \n\n\n          Methods:\n        \n      \n      This study used 596 individuals with a diagnosis of melanoma (n = 391) or nonmelanoma skin cancer (n = 205) who had used an Internet-based SCP tool from May 2010 to December 2016 to model the patient and provider characteristics that determine SCP utilization.\n    \n\n\n          Results:\n        \n      \n      Survivors were predominantly white (95.3%) and female (56.5%). Survivors who received a treatment summary were more likely to also receive an SCP. University and nonuniversity cancer centers used SCPs at a higher rate than other care settings. Survivors whose care was managed by a team rather than just an individual physician were also more likely to receive an SCP. Survivors older than 70 years at diagnosis were almost twice as likely to receive a plan as survivors who were diagnosed at a younger age.\n    \n\n\n          Conclusions:\n        \n      \n      With a convenience sample of skin cancer survivors, it is possible to model factors that predict the receipt of SCPs. Important variables include the diagnosis age, treatment setting, physician type, and treatment-summary utilization. A closer examination of these variables identified several disparities in care-plan use and, therefore, opportunities to improve the distribution of SCPs. Further validation in additional cohorts of survivors is necessary to confirm these conclusions. Cancer 2018;124:183-91. Â© 2017 American Cancer Society."
        },
        {
            "title": "Treatment patterns and outcomes for patients with locally advanced basal cell carcinoma before availability of Hedgehog pathway inhibitors: a retrospective chart review.",
            "abstract": "Understanding the molecular basis of basal cell carcinoma (BCC) has led to development of Hedgehog pathway inhibitors (HPIs) for patients with advanced forms of BCC (aBCC). A practical definition of aBCC as a distinct disease entity is unavailable, and epidemiological information is limited. To conduct the RONNIE study to describe characteristics, treatment patterns, and outcomes of patients with aBCC during the period preceding HPI introduction, as well as results from patients with locally advanced BCC (laBCC). A retrospective chart review was conducted using data from adult patients with a new diagnosis of laBCC between 1st January 2005 and 31st December 2010. The study period was 1st January 2005 to 31st December 2011 to allow for inclusion of at least 12 months of follow-up information for all patients.\n    \n\n\n          Results:\n        \n      \n      Treatment data were available for 106/117 patients. Radiation and excisional surgery were the most common first-line treatment options (43.4% and 23.5% of patients, respectively). Patients typically received multiple subsequent treatments; no apparent trend or pattern was observed. Complete visual response, partial visual response, and stable disease were obtained in 51.9%, 25.9%, and 11.1% of patients, respectively, after first-line surgery, and in 53.7%, 22.0%, and 9.8%, respectively, after first-line radiation. Median progression-free survival after first-line treatment was 32.1 months. Median overall survival was 78.8 months. These data represent a baseline for laBCC before HPIs became part of the treatment algorithm. The observed heterogeneity of treatment patterns highlights the lack of an established standard treatment for laBCC before HPIs were available."
        },
        {
            "title": "A deep learning-based hybrid artificial intelligence model for the detection and severity assessment of vitiligo lesions.",
            "abstract": "Background:\n        \n      \n      We aimed to establish and validate a deep learning-based hybrid artificial intelligence (AI) model for the objective morphometric and colorimetric assessment of vitiligo lesions.\n    \n\n\n          Methods:\n        \n      \n      Two main datasets containing curated images of vitiligo lesions from Chinese patients (Fitzpatrick skin types III or IV) were established, including one with 2,720 images for lesion localization study and the other with 1,262 images for lesion segmentation study. Besides, an additional test set containing 145 images of vitiligo lesions from other Fitzpatrick skin types (I, II, or V) was also generated. A 3-stage hybrid model was constructed. YOLO v3 (You Only Look Once, v3) architecture was trained and validated to classify and localize vitiligo lesions, with sensitivity and error rate as primary performance outcomes. Then a segmentation study comparing 3 deep convolutional neural networks (DCNNs), Pyramid Scene Parsing Network (PSPNet), UNet, and UNet++, was carried out based on the Jaccard index (JI). The architecture with the best performance was integrated into the model. Three add-on metrics, namely VAreaA, VAreaR, and VColor were finally developed to measure absolute, relative size changes and pigmentation, respectively. Agreement between the AI model and dermatologist evaluators were assessed.\n    \n\n\n          Results:\n        \n      \n      The sensitivity of the YOLO v3 architecture to detect vitiligo lesions was 92.91% with an error rate of 14.98%. The UNet++ architecture outperformed the others in the segmentation study (JI, 0.79) and was integrated into the model. On the additional test set, however, the model achieved a lower detection sensitivity (72.41%) and a lower segmentation score (JI, 0.69). With respect to size changes, no difference was observed between the AI model, trained dermatologists (W=0.812, P<0.05), and Photoshop analysis (P=0.075, P=0.212 respectively), which all displayed good concordance.\n    \n\n\n          Conclusions:\n        \n      \n      We developed a novel, convenient, objective, and quantitative deep learning-based hybrid model which simultaneously evaluated both morphometric and colorimetric vitiligo lesions from patients with Fitzpatrick skin types III or IV, rendering it suitable for the assessment of severity of vitiligo lesions in Asians in both clinic and research scenarios. More work is also warranted for its use in other ethnic skin groups."
        },
        {
            "title": "Skin Lesion Classification Using Additional Patient Information.",
            "abstract": "In this paper, we describe our method for skin lesion classification. The goal is to classify skin lesions based on dermoscopic images to several diagnoses' classes presented in the HAM (Human Against Machine) dataset: melanoma (MEL), melanocytic nevus (NV), basal cell carcinoma (BCC), actinic keratosis (AK), benign keratosis (BKL), dermatofibroma (DF), and vascular lesion (VASC). We propose a simplified solution which has a better accuracy than previous methods, but only predicted on a single model that is practical for a real-world scenario. Our results show that using a network with additional metadata as input achieves a better classification performance. This metadata includes both the patient information and the extra information during the data augmentation process. On the international skin imaging collaboration (ISIC) 2018 skin lesion classification challenge test set, our algorithm yields a balanced multiclass accuracy of 88.7% on a single model and 89.5% for the embedding solution, which makes it the currently first ranked algorithm on the live leaderboard. To improve the inference accuracy. Test time augmentation (TTA) is applied. We also demonstrate how Grad-CAM is applied in TTA. Therefore, TTA and Grad-CAM can be integrated in heat map generation, which can be very helpful to assist the clinician for diagnosis."
        },
        {
            "title": "The Classification of Six Common Skin Diseases Based on Xiangya-Derm: Development of a Chinese Database for Artificial Intelligence.",
            "abstract": "Background:\n        \n      \n      Skin and subcutaneous disease is the fourth-leading cause of the nonfatal disease burden worldwide and constitutes one of the most common burdens in primary care. However, there is a severe lack of dermatologists, particularly in rural Chinese areas. Furthermore, although artificial intelligence (AI) tools can assist in diagnosing skin disorders from images, the database for the Chinese population is limited.\n    \n\n\n          Objective:\n        \n      \n      This study aims to establish a database for AI based on the Chinese population and presents an initial study on six common skin diseases.\n    \n\n\n          Methods:\n        \n      \n      Each image was captured with either a digital camera or a smartphone, verified by at least three experienced dermatologists and corresponding pathology information, and finally added to the Xiangya-Derm database. Based on this database, we conducted AI-assisted classification research on six common skin diseases and then proposed a network called Xy-SkinNet. Xy-SkinNet applies a two-step strategy to identify skin diseases. First, given an input image, we segmented the regions of the skin lesion. Second, we introduced an information fusion block to combine the output of all segmented regions. We compared the performance with 31 dermatologists of varied experiences.\n    \n\n\n          Results:\n        \n      \n      Xiangya-Derm, as a new database that consists of over 150,000 clinical images of 571 different skin diseases in the Chinese population, is the largest and most diverse dermatological data set of the Chinese population. The AI-based six-category classification achieved a top 3 accuracy of 84.77%, which exceeded the average accuracy of dermatologists (78.15%).\n    \n\n\n          Conclusions:\n        \n      \n      Xiangya-Derm, the largest database for the Chinese population, was created. The classification of six common skin conditions was conducted based on Xiangya-Derm to lay a foundation for product research."
        },
        {
            "title": "Psoriasis image representation using patch-based dictionary learning for erythema severity scoring.",
            "abstract": "Psoriasis is a chronic skin disease which can be life-threatening. Accurate severity scoring helps dermatologists to decide on the treatment. In this paper, we present a semi-supervised computer-aided system for automatic erythema severity scoring in psoriasis images. Firstly, the unsupervised stage includes a novel image representation method. We construct a dictionary, which is then used in the sparse representation for local feature extraction. To acquire the final image representation vector, an aggregation method is exploited over the local features. Secondly, the supervised phase is where various multi-class machine learning (ML) classifiers are trained for erythema severity scoring. Finally, we compare the proposed system with two popular unsupervised feature extractor methods, namely: bag of visual words model (BoVWs) and AlexNet pretrained model. Root mean square error (RMSE) and F1 score are used as performance measures for the learned dictionaries and the trained ML models, respectively. A psoriasis image set consisting of 676 images, is used in this study. Experimental results demonstrate that the use of the proposed procedure can provide a setup where erythema scoring is accurate and consistent. Also, it is revealed that dictionaries with large number of atoms and small patch sizes yield the best representative erythema severity features. Further, random forest (RF) outperforms other classifiers with F1 score 0.71, followed by support vector machine (SVM) and boosting with 0.66 and 0.64 scores, respectively. Furthermore, the conducted comparative studies confirm the effectiveness of the proposed approach with improvement of 9% and 12% over BoVWs and AlexNet based features, respectively."
        },
        {
            "title": "Saliva may predict quality of life in psoriasis as measured by Fourier transform infrared spectroscopy (FTIR) and chemometrics.",
            "abstract": "Background:\n        \n      \n      Psoriasis is a chronic skin disease, with several comorbidities, such as psoriatic arthritis, inflammatory bowel disease, metabolic syndrome, and impaired quality of life and work activity. The Dermatology Life Quality Index (DLQI) is the most commonly used quality of life index in psoriatic patients, as it is a marker of severe disease. This study evaluated the association between salivary Fourier transform Infrared Spectroscopy (FTIR) metabolic fingerprints and severity of psoriasis as measured by DLQI, using chemometric algorithms.\n    \n\n\n          Materials and methods:\n        \n      \n      Saliva was collected from 56 (27 with DLQI â‰¤ 10 [GI]; 29 with DLQI > 10 [GII]) psoriatic patients diagnosed and assessed by DLQI for disease severity by a dermatologist and analyzed by the transflectance technique in mid-infrared. Hierarchic cluster analysis (HCA), principal component analysis (PCA), orthogonal partial least squares discriminant analysis (OPLS-DA) and orthogonal partial least squares (OPLS) algorithms were used to associate salivary FTIR spectra with the respective DLQI scores.\n    \n\n\n          Results:\n        \n      \n      Second derivative (2D) discriminated GI and GII at 2522 cm-1 (p < 0.0001). HCA and PCA partially discriminated GI from GII at 4000-450 cm-1 (p = 0.042 and 0.00821, respectively). Data processing with 1st derivative (1D), 3 latent variables (LV) and 1 orthogonal signal correction (OSC) component at 2550-1801 cm-1 generated an FTIR/OPLS-DA model with 100% accuracy to classify the severity of psoriasis, and an FTIR/OPLS model to quantify DLQI (range 0-28) with high performance: root mean square error of prediction (RMSEP) < 0.01 and coefficient of determination (R2) > 0.9999.\n    \n\n\n          Conclusions:\n        \n      \n      Salivary FTIR combined with chemometric algorithms such as OPLS-DA and OPLS can be used as a clinical tool to classify or predict the severity of psoriasis according to DLQI in patients with confirmed psoriasis."
        },
        {
            "title": "The Comparative Use of Multiple Electronic Devices in the Teledermoscopic Diagnosis of Early Melanoma.",
            "abstract": "Background: The use of mobile electronic devices as support to medical activity was largely implemented in the past decade. Introduction: Our first aim was to evaluate the frequency of use of different electronic devices, that is, personal computer (PC), notebook, tablet, smartphone, in a pool of dermatologists recruited to perform multiple online testing session on difficult melanocytic skin lesions (MSLs) cases. The second aim was to evaluate the feasibility of each device in terms of teledermatologic diagnostic performance; the use of four different diagnostic methods, that is, intuitive diagnosis and three dermoscopic algorithms, was also investigated. Materials and Methods: A total of 111 dermatologists with 4 different levels of experience in dermoscopy, performed 4 tests (intuitive diagnosis and iDScore, ABCD rule, 7-point-checklist-based diagnosis) on 979 MSLs blinded cases. Each testing session was performed with a preferred device. Results: The overall highest areas under the receiver operating characteristic (AUROC) (82%) was obtained by young generation dermoscopists 1-4 years experience) when using an integrated clinical dermoscopic algorithm (iDScore) on a notebook. The average dermatologist using the iDScore obtained AUROC 77.40% with large screen devices (PC and notebook) 77.6% with small screen (tablet, smartphone) and 78.2% by combining the two. Discussion: Young generation of dermoscopists alternately use different devices, whereas elderly generation still prefer to use the PC. The diagnostic performances obtained with small/large screen were not statistically different from those obtained with fixed/mobile devices. Conclusions: Mobile devices were feasible tools to achieve adequate diagnostic accuracy in difficult MSLs, on a teledermatology setting, independently from participant skill level/age."
        },
        {
            "title": "Immune-related adverse events during anticancer immunotherapy: Pathogenesis and management.",
            "abstract": "Immunotherapy is one of the most recent systemic treatments to emerge for use in oncology, and is based on the blocking of inhibitory immune checkpoints to potentiate the immune response to cancer. The anti-cytotoxic T lymphocyte-associated antigen-4 antibody ipilimumab and anti-programmed cell death protein 1 antibodies, including nivolumab and pembrolizumab, are currently available and widely used, and other immune-inhibiting antibodies are now under intensive investigation. These antibodies have shown efficacy in a growing number of tumor types, following initial observations of their notable effects in melanoma treatment. Despite the efficacy of these antibodies, their novel mechanisms of action are also associated with a new class of side effects called immune-related adverse events (IRAEs). These side effects do not share a common pathophysiology with other anticancer treatments and, therefore, they often require specific therapies. When detected early and correctly treated, IRAEs are reversible; however, they can become severe and life-threatening if underestimated or inappropriately treated. This review aims to revisit the pathogenesis of IRAEs, with attention to gastrointestinal manifestations, since these are common and potentially dangerous complications of immunotherapy and represent a major cause of treatment discontinuation. Recommendations and guidelines for the management of IRAEs are also presented, in order to provide a clear and applicable algorithm for use by clinicians."
        },
        {
            "title": "An Adaptive Deep Learning Framework for Dynamic Image Classification in the Internet of Things Environment.",
            "abstract": "In the modern era of digitization, the analysis in the Internet of Things (IoT) environment demands a brisk amalgamation of domains such as high-dimension (images) data sensing technologies, robust internet connection (4 G or 5 G) and dynamic (adaptive) deep learning approaches. This is required for a broad range of indispensable intelligent applications, like intelligent healthcare systems. Dynamic image classification is one of the major areas of concern for researchers, which may take place during analysis under the IoT environment. Dynamic image classification is associated with several temporal data perturbations (such as novel class arrival and class evolution issue) which cause a massive classification deterioration in the deployed classification models and make them in-effective. Therefore, this study addresses such temporal inconsistencies (novel class arrival and class evolution issue) and proposes an adapted deep learning framework (ameliorated adaptive convolutional neural network (CNN) ensemble framework), which handles novel class arrival and class evaluation issue during dynamic image classification. The proposed framework is an improved version of previous adaptive CNN ensemble with an additional online training (OT) and online classifier update (OCU) modules. An OT module is a clustering-based approach which uses the Euclidean distance and silhouette method to determine the potential new classes, whereas, the OCU updates the weights of the existing instances of the ensemble with newly arrived samples. The proposed framework showed the desirable classification improvement under non-stationary scenarios for the benchmark (CIFAR10) and real (ISIC 2019: Skin disease) data streams. Also, the proposed framework outperformed against state-of-art shallow learning and deep learning models. The results have shown the effectiveness and proven the diversity of the proposed framework to adapt the new concept changes during dynamic image classification. In future work, the authors of this study aim to develop an IoT-enabled adaptive intelligent dermoscopy device (for dermatologists). Therefore, further improvements in classification accuracy (for real dataset) is the future concern of this study."
        },
        {
            "title": "Multi-type skin diseases classification using OP-DNN based feature extraction approach.",
            "abstract": "In the current world, the disorders occurring in dermatological images are among the foremost widespread diseases. Despite being common, its identification is tremendously hard because of the complexities like skin tone and color variation due to the presence of hair regions. Therefore the type of skin disease prediction is not accurately achieved in many pieces of research. To deal with mentioned concerns, a novel optimal probability-based deep neural network is proposed to assist medical professionals in appropriately diagnosing the type of skin disease. Initially, the input dataset is fed into the pre-processing stage, which helps to remove unwanted contents in the image. Afterward, features extracted for all the pre-processed images are subjected to the proposed Optimal Probability-Based Deep Neural Network (OP-DNN) for the training process. This classification algorithm classifies incoming clinical images as different skin diseases with the help of probability values. While learning OP-DNN, it is essential to determine the optimal weight values for reducing the training error. For optimizing weight in OP-DNN structure, an optimization approach is implemented in this research. For that, whale optimization is utilized because it works faster than other methods. The proposed multi-type skin disease prediction model is implemented in MatLab software and achieved 95% of accuracy, 0.97 of specificity, and 0.91 of sensitivity. This exposes the superiority of the proposed multi-type skin disease prediction model using an effective OP-DNN based feature extraction approach to attain a high accuracy rate and also it predict several kinds of skin disease than the previous models, which can protect the patients survives as well as can assist the physicians in making a decision certainly."
        },
        {
            "title": "Skin strata delineation in reflectance confocal microscopy images using recurrent convolutional networks with attention.",
            "abstract": "Reflectance confocal microscopy (RCM) is an effective non-invasive tool for cancer diagnosis. However, acquiring and reading RCM images requires extensive training and experience, and novice clinicians exhibit high discordance in diagnostic accuracy. Quantitative tools to standardize image acquisition could reduce both required training and diagnostic variability. To perform diagnostic analysis, clinicians collect a set of RCM mosaics (RCM images concatenated in a raster fashion to extend the field view) at 4-5 specific layers in skin, all localized in the junction between the epidermal and dermal layers (dermal-epidermal junction, DEJ), necessitating locating that junction before mosaic acquisition. In this study, we automate DEJ localization using deep recurrent convolutional neural networks to delineate skin strata in stacks of RCM images collected at consecutive depths. Success will guide to automated and quantitative mosaic acquisition thus reducing inter operator variability and bring standardization in imaging. Testing our model against an expert labeled dataset of 504 RCM stacks, we achieved [Formula: see text] classification accuracy and nine-fold reduction in the number of anatomically impossible errors compared to the previous state-of-the-art."
        },
        {
            "title": "Partnering with a senior living community to optimise teledermatology via full body skin screening during the COVID-19 pandemic: A pilot programme.",
            "abstract": "Background:\n        \n      \n      Elderly patients in senior communities faced high barriers to care during the COVID-19 pandemic, including increased vulnerability to COVID-19, long quarantines for clinic visits, and difficulties with telemedicine adoption.\n    \n\n\n          Objective:\n        \n      \n      To pilot a new model of dermatologic care to overcome barriers for senior living communities during the COVID-19 pandemic and assess patient satisfaction.\n    \n\n\n          Methods:\n        \n      \n      From 16 November 2020 to 9 July 2021, this quality improvement programme combined in-residence full body imaging with real-time outlier lesion identification and virtual teledermatology. Residents from the Sequoias Portola Valley Senior Living Retirement Community (Portola Valley, California) voluntarily enroled in the Stanford Skin Scan Programme. Non-physician clinical staff with a recent negative COVID-19 test travelled on-site to obtain in-residence full body photographs using a mobile app-based system on an iPad called SkinIO that leverages deep learning to analyse patient images and suggest suspicious, outlier lesions for dermoscopic photos. A single dermatologist reviewed photographs with the patient and provided recommendations via a video visit. Objective measures included follow-up course and number of skin cancers detected. Subjective findings were obtained through patient experience surveys.\n    \n\n\n          Results:\n        \n      \n      Twenty-seven individuals participated, three skin cancers were identified, with 11 individuals scheduled for a follow up in-person visit and four individuals starting home treatment. Overall, 88% of patients were satisfied with the Skin Scan programme, with 77% likely to recommend the programme to others. 92% of patients agreed that the Skin Scan photographs were representative of their skin. In the context of the COVID-19 pandemic, 100% of patients felt the process was safer or comparable to an in-person visit. Despite overall appreciation for the programme, 31% of patients reported that they would prefer to see dermatologist in-person after the pandemic.\n    \n\n\n          Conclusions:\n        \n      \n      This programme offers a framework for how a hybrid skin scan programme may provide high utility for individuals with barriers to accessing in-person clinics."
        },
        {
            "title": "A Non-Invasive Interpretable Diagnosis of Melanoma Skin Cancer Using Deep Learning and Ensemble Stacking of Machine Learning Models.",
            "abstract": "A skin lesion is a portion of skin that observes abnormal growth compared to other areas of the skin. The ISIC 2018 lesion dataset has seven classes. A miniature dataset version of it is also available with only two classes: malignant and benign. Malignant tumors are tumors that are cancerous, and benign tumors are non-cancerous. Malignant tumors have the ability to multiply and spread throughout the body at a much faster rate. The early detection of the cancerous skin lesion is crucial for the survival of the patient. Deep learning models and machine learning models play an essential role in the detection of skin lesions. Still, due to image occlusions and imbalanced datasets, the accuracies have been compromised so far. In this paper, we introduce an interpretable method for the non-invasive diagnosis of melanoma skin cancer using deep learning and ensemble stacking of machine learning models. The dataset used to train the classifier models contains balanced images of benign and malignant skin moles. Hand-crafted features are used to train the base models (logistic regression, SVM, random forest, KNN, and gradient boosting machine) of machine learning. The prediction of these base models was used to train level one model stacking using cross-validation on the training set. Deep learning models (MobileNet, Xception, ResNet50, ResNet50V2, and DenseNet121) were used for transfer learning, and were already pre-trained on ImageNet data. The classifier was evaluated for each model. The deep learning models were then ensembled with different combinations of models and assessed. Furthermore, shapely adaptive explanations are used to construct an interpretability approach that generates heatmaps to identify the parts of an image that are most suggestive of the illness. This allows dermatologists to understand the results of our model in a way that makes sense to them. For evaluation, we calculated the accuracy, F1-score, Cohen's kappa, confusion matrix, and ROC curves and identified the best model for classifying skin lesions."
        },
        {
            "title": "Twenty-five practical recommendations in primary care dermoscopy.",
            "abstract": "Dermoscopy in primary care enhances clinical diagnoses and allows for risk stratifications. We have compiled 25 recommendations from our experience of dermoscopy in a wide range of clinical settings. The aim of this study is to enhance the application of dermoscopy by primary care clinicians. For primary care physicians commencing dermoscopy, we recommend understanding the aims of dermoscopy, having adequate training, purchasing dermoscopes with polarised and unpolarised views, performing regular maintenance on the equipment, seeking consent, applying contact and close non-contact dermoscopy, maintaining sterility, knowing one algorithm well and learning the rules for special regions such as the face, acral regions and nails. For clinicians already applying dermoscopy, we recommend establishing a platform for storing and retrieving clinical and dermoscopic images; shooting as uncompressed files; applying high magnifications and in-camera improvisations; explaining dermoscopic images to patients and their families; applying toggling; applying scopes with small probes for obscured lesions and lesions in body creases; applying far, non-contact dermoscopy; performing skin manipulations before and during dermoscopy; practising selective dermoscopy if experienced enough; and being aware of compound lesions. For clinicians in academic practice for whom dermatology and dermoscopy are special interests, we recommend acquiring the best hardware available with separate setups for clinical photography and dermoscopy; obtaining oral or written consent from patients for taking and publishing recognisable images; applying extremely high magnifications in search of novel dermoscopic features that are clinically important; applying dermoscopy immediately after local anaesthesia; and further augmenting images to incorporate messages beyond words to readers."
        },
        {
            "title": "Skin lesions of face and scalp - Classification by a market-approved convolutional neural network in comparison with 64 dermatologists.",
            "abstract": "Background:\n        \n      \n      The clinical differentiation of face and scalp lesions (FSLs) is challenging even for trained dermatologists. Studies comparing the diagnostic performance of a convolutional neural network (CNN) with dermatologists in FSL are lacking.\n    \n\n\n          Methods:\n        \n      \n      A market-approved CNN (Moleanalyzer-Pro, FotoFinder Systems) was used for binary classifications of 100 dermoscopic images of FSL. The same lesions were used in a two-level reader study including 64 dermatologists (level I: dermoscopy only; level II: dermoscopy, clinical close-up images, textual information). Primary endpoints were the CNN's sensitivity and specificity in comparison with the dermatologists' management decisions in level II. Generalizability of the CNN results was tested by using four additional external data sets.\n    \n\n\n          Results:\n        \n      \n      The CNN's sensitivity, specificity and ROC AUC were 96.2% [87.0%-98.9%], 68.8% [54.7%-80.1%] and 0.929 [0.880-0.978], respectively. In level II, the dermatologists' management decisions showed a mean sensitivity of 84.2% [82.2%-86.2%] and specificity of 69.4% [66.0%-72.8%]. When fixing the CNN's specificity at the dermatologists' mean specificity (69.4%), the CNN's sensitivity (96.2% [87.0%-98.9%]) was significantly higher than that of dermatologists (84.2% [82.2%-86.2%]; p < 0.001). Dermatologists of all training levels were outperformed by the CNN (all p < 0.001). In confirmation, the CNN's accuracy (83.0%) was significantly higher than dermatologists' accuracies in level II management decisions (all p < 0.001). The CNN's performance was largely confirmed in three additional external data sets but particularly showed a reduced specificity in one Australian data set including FSL on severely sun-damaged skin.\n    \n\n\n          Conclusions:\n        \n      \n      When applied as an assistant system, the CNN's higher sensitivity at an equivalent specificity may result in an improved early detection of face and scalp skin cancers."
        },
        {
            "title": "[Artificial intelligence and dermatology.].",
            "abstract": "The approach of artificial intelligence (AI) systems can especially support doctors who base their work on the interpretation of digital images. Despite undoubted favorable results, the validation of diagnostic algorithms in clinical practice has not yet been demonstrated. In the dermatological field, a study found the poor performance of AI systems in diagnosing skin lesions that better reflect clinical practice, that is characterized by the presence of \"artifacts\" such as crusts or ulcerations above the lesion, hair or pen marks, pigmentation. The algorithms also correctly classified the category of images not present in the training dataset in only 11% of cases. In almost half of the cases the images were assigned to the category of neoplasms. In clinical reality, such false positivity predictions would lead to an increase in unnecessary biopsies with a related burden of worry and anxiety for patients and their families. This confirms that the value of the data is not in their breadth but in the validity of the path that led to their use, in order not to arrive at erroneous causal inferences that could lead to poor generalizability of the results and potentially serious diagnostic errors."
        },
        {
            "title": "Biologically Inspired QuadTree Color Detection in Dermoscopy Images of Melanoma.",
            "abstract": "This paper presents a QuadTree-based melanoma detection system inspired by dermatologists' color perception. Clinical color assessment in dermoscopy images is challenging because of subtle differences in shades, location-dependent color information, poor color contrast, and wide variation among images of the same class. To overcome these challenges, color enhancement and automatic color identification techniques, based on QuadTree segmentation and modeled after expert color assessments, are developed. The approach presented in this paper is shown to provide an accurate model of expert color assessment. Specifically, the proposed model is shown to: 1) identify significantly more colors in melanomas than in benign skin lesions; 2) identify a higher frequency in melanomas of three colors: blue-gray, black, and pink; and 3) delineate locations of melanoma colors by quintiles, specifically predilection for blue-gray and pink in the periphery and a trend for white and black in the lesion center. Performance of the proposed method is evaluated using four classifiers. The kernel support vector machine classifier is found to achieve the best results, with an area under the receiver operating characteristic (ROC) curve of 0.93, compared to average area under the ROC curve of 0.82 achieved by the dermatologists in this study. The results indicate that the biologically inspired method of automatic color detection proposed in this paper has the potential to play an important role in melanoma diagnosis in the clinic."
        },
        {
            "title": "Design publicity of black box algorithms: a support to the epistemic and ethical justifications of medical AI systems.",
            "abstract": "In their article 'Who is afraid of black box algorithms? On the epistemological and ethical basis of trust in medical AI', DurÃ¡n and Jongsma discuss the epistemic and ethical challenges raised by black box algorithms in medical practice. The opacity of black box algorithms is an obstacle to the trustworthiness of their outcomes. Moreover, the use of opaque algorithms is not normatively justified in medical practice. The authors introduce a formalism, called computational reliabilism, which allows generating justified beliefs on the algorithm reliability and trustworthy outcomes of artificial intelligence (AI) systems by means of epistemic warrants, called reliability indicators. However, they remark the need for reliability indicators specific to black box algorithms and that justified knowledge is not sufficient to justify normatively the actions of the physicians using medical AI systems. Therefore, DurÃ¡n and Jongsma advocate for a more transparent design and implementation of black box algorithms, providing a series of recommendations to mitigate the epistemic and ethical challenges behind their use in medical practice. In this response, I argue that a peculiar form of black box algorithm transparency, called design publicity, may efficiently implement these recommendations. Design publicity encodes epistemic, that is, reliability indicators, and ethical recommendations for black box algorithms by means of four subtypes of transparency. These target the values and goals, their translation into design requirements, the performance and consistency of the algorithm altogether. I discuss design publicity applying it to a use case focused on the automated classification of skin lesions from medical images."
        },
        {
            "title": "Background selection schema on deep learning-based classification of dermatological disease.",
            "abstract": "Skin diseases are one of the most common ailments affecting humans. Artificial intelligence based on deep learning can significantly improve the efficiency of identifying skin disorders and alleviate the scarcity of medical resources. However, the distribution of background information in dermatological datasets is imbalanced, causing generalized deep learning models to perform poorly in skin disease classification. We propose a deep learning schema that combines data preprocessing, data augmentation, and residual networks to study the influence of color-based background selection on a deep model's capacity to learn foreground lesion subject attributes in a skin disease classification problem. First, clinical photographs are annotated by dermatologists, and then the original background information is masked with unique colors to generate several subsets with distinct background colors. Sample-balanced training and test sets are generated using random over/undersampling and data augmentation techniques. Finally, the deep learning networks are independently trained on diverse subsets of backdrop colors to compare the performance of classifiers based on different background information. Extensive experiments demonstrate that color-based background information significantly affects the classification of skin diseases and that classifiers trained on the green subset achieve state-of-the-art performance for classifying black and red skin lesions."
        },
        {
            "title": "Using Artificial Intelligence as a Diagnostic Decision Support Tool in Skin Disease: Protocol for an Observational Prospective Cohort Study.",
            "abstract": "Background:\n        \n      \n      Dermatological conditions are a relevant health problem. Each person has an average of 1.6 skin diseases per year, and consultations for skin pathology represent 20% of the total annual visits to primary care and around 35% are referred to a dermatology specialist. Machine learning (ML) models can be a good tool to help primary care professionals, as it can analyze and optimize complex sets of data. In addition, ML models are increasingly being applied to dermatology as a diagnostic decision support tool using image analysis, especially for skin cancer detection and classification.\n    \n\n\n          Objective:\n        \n      \n      This study aims to perform a prospective validation of an image analysis ML model as a diagnostic decision support tool for the diagnosis of dermatological conditions.\n    \n\n\n          Methods:\n        \n      \n      In this prospective study, 100 consecutive patients who visit a participant general practitioner (GP) with a skin problem in central Catalonia were recruited. Data collection was planned to last 7 months. Anonymized pictures of skin diseases were taken and introduced to the ML model interface (capable of screening for 44 different skin diseases), which returned the top 5 diagnoses by probability. The same image was also sent as a teledermatology consultation following the current stablished workflow. The GP, ML model, and dermatologist's assessments will be compared to calculate the precision, sensitivity, specificity, and accuracy of the ML model. The results will be represented globally and individually for each skin disease class using a confusion matrix and one-versus-all methodology. The time taken to make the diagnosis will also be taken into consideration.\n    \n\n\n          Results:\n        \n      \n      Patient recruitment began in June 2021 and lasted for 5 months. Currently, all patients have been recruited and the images have been shown to the GPs and dermatologists. The analysis of the results has already started.\n    \n\n\n          Conclusions:\n        \n      \n      This study will provide information about ML models' effectiveness and limitations. External testing is essential for regulating these diagnostic systems to deploy ML models in a primary care practice setting."
        },
        {
            "title": "Management of dupilumab-associated ocular surface diseases in atopic dermatitis patients.",
            "abstract": "Atopic dermatitis is a chronic inflammatory skin disease characterised by eczematous skin lesions and intense pruritus. It is often associated with other atopic diseases such as allergic rhinitis and conjunctivitis, bronchial asthma and eosinophilic oesophagitis. Dupilumab is the first biologic approved for the treatment of moderate-to-severe atopic dermatitis in Switzerland. Dupilumab targets the interleukin (IL)-4/IL-13 receptor and thus inhibits the signalling of IL-4 and IL-13, two key mediators of type 2 inflammation, resulting in an improvement of clinical signs and symptoms of atopic dermatitis. Patients with atopic dermatitis present more often with ocular surface diseases (OSDs), such as allergic conjunctivitis, blepharitis and keratitis as well as infectious conjunctivitis and keratoconus compared with the general population. Upon dupilumab therapy, increased rates of ocular surface diseases have been reported in clinical trials. Interestingly, dupilumab-associated (da) OSD is restricted to atopic dermatitis patients and has not been observed in asthma and chronic rhinosinusitis trials. Fortunately, most cases of dupilumab-associated OSD are mild-to-moderate and transient. Thus, ocular surface disease presents a particular adverse event of treatment with dupilumab in dermatology. This article aims at providing a practical guide for physicians, with a special focus on dermatologists, allergists and ophthalmologists in Switzerland, to the diagnosis and management of dupilumab-associated OSD in atopic dermatitis patients.For this purpose, an expert group of dermatologists and ophthalmologists from university and cantonal hospitals in Switzerland reviewed data on ocular surface diseases published in clinical trial and real-life reports of dupilumab therapy, published case reports and case series on the management of dupilumab-associated OSD, as well as recent recommendations provided by experts of national and international boards. Based on the observations of dupilumab-associated OSD and practical experiences in identifying and treating OSD, an algorithm has been developed that is specific to the needs in Switzerland. Considering concomitant ocular diseases and differential diagnoses, the clinical presentation of dupilumab-associated OSD and its response to therapeutic measures, a stepwise approach is recommended. Mild dupilumab-associated OSD can be managed by dermatologists and allergists, whereas patients with moderate-to-severe OSD requiring corticosteroid or calcineurin inhibitor therapy should necessarily be referred to an ophthalmologist. The effects of preventive measures, such as artificial tears, are uncertain. The recommendations provided here should guarantee a prompt and effective treatment of OSD for patients under dupilumab therapy in order to prevent that an otherwise potent therapy has to be ceased because of ocular adverse events."
        },
        {
            "title": "Association Between Surgical Skin Markings in Dermoscopic Images and Diagnostic Performance of a Deep Learning Convolutional Neural Network for Melanoma Recognition.",
            "abstract": "Importance:\n        \n      \n      Deep learning convolutional neural networks (CNNs) have shown a performance at the level of dermatologists in the diagnosis of melanoma. Accordingly, further exploring the potential limitations of CNN technology before broadly applying it is of special interest.\n    \n\n\n          Objective:\n        \n      \n      To investigate the association between gentian violet surgical skin markings in dermoscopic images and the diagnostic performance of a CNN approved for use as a medical device in the European market.\n    \n\n\n          Design and setting:\n        \n      \n      A cross-sectional analysis was conducted from August 1, 2018, to November 30, 2018, using a CNN architecture trained with more than 120 000 dermoscopic images of skin neoplasms and corresponding diagnoses. The association of gentian violet skin markings in dermoscopic images with the performance of the CNN was investigated in 3 image sets of 130 melanocytic lesions each (107 benign nevi, 23 melanomas).\n    \n\n\n          Exposures:\n        \n      \n      The same lesions were sequentially imaged with and without the application of a gentian violet surgical skin marker and then evaluated by the CNN for their probability of being a melanoma. In addition, the markings were removed by manually cropping the dermoscopic images to focus on the melanocytic lesion.\n    \n\n\n          Main outcomes and measures:\n        \n      \n      Sensitivity, specificity, and area under the curve (AUC) of the receiver operating characteristic (ROC) curve for the CNN's diagnostic classification in unmarked, marked, and cropped images.\n    \n\n\n          Results:\n        \n      \n      In all, 130 melanocytic lesions (107 benign nevi and 23 melanomas) were imaged. In unmarked lesions, the CNN achieved a sensitivity of 95.7% (95% CI, 79%-99.2%) and a specificity of 84.1% (95% CI, 76.0%-89.8%). The ROC AUC was 0.969. In marked lesions, an increase in melanoma probability scores was observed that resulted in a sensitivity of 100% (95% CI, 85.7%-100%) and a significantly reduced specificity of 45.8% (95% CI, 36.7%-55.2%, P < .001). The ROC AUC was 0.922. Cropping images led to the highest sensitivity of 100% (95% CI, 85.7%-100%), specificity of 97.2% (95% CI, 92.1%-99.0%), and ROC AUC of 0.993. Heat maps created by vanilla gradient descent backpropagation indicated that the blue markings were associated with the increased false-positive rate.\n    \n\n\n          Conclusions and relevance:\n        \n      \n      This study's findings suggest that skin markings significantly interfered with the CNN's correct diagnosis of nevi by increasing the melanoma probability scores and consequently the false-positive rate. A predominance of skin markings in melanoma training images may have induced the CNN's association of markings with a melanoma diagnosis. Accordingly, these findings suggest that skin markings should be avoided in dermoscopic images intended for analysis by a CNN.\n    \n\n\n          Trial registration:\n        \n      \n      German Clinical Trial Register (DRKS) Identifier: DRKS00013570."
        },
        {
            "title": "Stress testing reveals gaps in clinic readiness of image-based diagnostic artificial intelligence models.",
            "abstract": "Artificial intelligence models match or exceed dermatologists in melanoma image classification. Less is known about their robustness against real-world variations, and clinicians may incorrectly assume that a model with an acceptable area under the receiver operating characteristic curve or related performance metric is ready for clinical use. Here, we systematically assessed the performance of dermatologist-level convolutional neural networks (CNNs) on real-world non-curated images by applying computational \"stress tests\". Our goal was to create a proxy environment in which to comprehensively test the generalizability of off-the-shelf CNNs developed without training or evaluation protocols specific to individual clinics. We found inconsistent predictions on images captured repeatedly in the same setting or subjected to simple transformations (e.g., rotation). Such transformations resulted in false positive or negative predictions for 6.5-22% of skin lesions across test datasets. Our findings indicate that models meeting conventionally reported metrics need further validation with computational stress tests to assess clinic readiness."
        },
        {
            "title": "Ensemble Method of Convolutional Neural Networks with Directed Acyclic Graph Using Dermoscopic Images: Melanoma Detection Application.",
            "abstract": "The early detection of melanoma is the most efficient way to reduce its mortality rate. Dermatologists achieve this task with the help of dermoscopy, a non-invasive tool allowing the visualization of patterns of skin lesions. Computer-aided diagnosis (CAD) systems developed on dermoscopic images are needed to assist dermatologists. These systems rely mainly on multiclass classification approaches. However, the multiclass classification of skin lesions by an automated system remains a challenging task. Decomposing a multiclass problem into a binary problem can reduce the complexity of the initial problem and increase the overall performance. This paper proposes a CAD system to classify dermoscopic images into three diagnosis classes: melanoma, nevi, and seborrheic keratosis. We introduce a novel ensemble scheme of convolutional neural networks (CNNs), inspired by decomposition and ensemble methods, to improve the performance of the CAD system. Unlike conventional ensemble methods, we use a directed acyclic graph to aggregate binary CNNs for the melanoma detection task. On the ISIC 2018 public dataset, our method achieves the best balanced accuracy (76.6%) among multiclass CNNs, an ensemble of multiclass CNNs with classical aggregation methods, and other related works. Our results reveal that the directed acyclic graph is a meaningful approach to develop a reliable and robust automated diagnosis system for the multiclass classification of dermoscopic images."
        },
        {
            "title": "Japan Society of Gynecologic Oncology guidelines 2015 for the treatment of vulvar cancer and vaginal cancer.",
            "abstract": "Background:\n        \n      \n      Vulvar cancer and vaginal cancer are relatively rare tumors, and there had been no established treatment principles or guidelines to treat these rare tumors in Japan. The first version of the Japan Society of Gynecologic Oncology (JSGO) guidelines for the treatment of vulvar cancer and vaginal cancer was published in 2015 in Japanese.\n    \n\n\n          Objective:\n        \n      \n      The JSGO committee decided to publish the English version of the JSGO guidelines worldwide, and hope it will be a useful guide to physicians in a similar situation as in Japan.\n    \n\n\n          Methods:\n        \n      \n      The guideline was created according to the basic principles in creating the guidelines of JSGO.\n    \n\n\n          Results:\n        \n      \n      The guidelines consist of five chapters and five algorithms. Prior to the first chapter, basic items are described including staging classification and history, classification of histology, and definition of the methods of surgery, radiation, and chemotherapy to give the reader a better understanding of the contents of the guidelines for these rare tumors. The first chapter gives an overview of the guidelines, including the basic policy of the guidelines. The second chapter discusses vulvar cancer, the third chapter discusses vaginal cancer, and the fourth chapter discusses vulvar Paget's disease and malignant melanoma. Each chapter includes clinical questions, recommendations, backgrounds, objectives, explanations, and references. The fifth chapter provides supplemental data for the drugs that are mentioned in the explanation of clinical questions.\n    \n\n\n          Conclusion:\n        \n      \n      Overall, the objective of these guidelines is to clearly delineate the standard of care for vulvar and vaginal cancer with the goal of ensuring a high standard of care for all women diagnosed with these rare diseases."
        },
        {
            "title": "Perceptions of the use of artificial intelligence in the diagnosis of skin cancer: an outpatient survey.",
            "abstract": "Background:\n        \n      \n      Convolutional neural networks (artificial intelligence, AI) are rapidly appearing within the field of dermatology, with diagnostic accuracy matching that of dermatologists. As technologies become available for use by both the health professionals and the general public, their uptake in healthcare will become more acceptable. National Health Service England recognizes the potential of AI for healthcare but emphasizes that patient-centred care should be at the forefront of these technological advancements.\n    \n\n\n          Aim:\n        \n      \n      To obtain opinions of patients on the use of AI in a dermatology setting, when aiding the diagnosis of skin cancers.\n    \n\n\n          Methods:\n        \n      \n      A cross-sectional 14-point questionnaire was handed out to patients attending dermatology outpatient skin cancer clinics in two UK hospitals, between March and August 2018.\n    \n\n\n          Results:\n        \n      \n      In total, 603 patient questionnaires were completed. Nearly half (47%; n = 282) of respondents were not concerned if AI technology was used by a skin specialist to aid skin cancer diagnosis. However, the majority (81%; n = 491) of respondents, considered it important for a dermatologist to examine and confirm a diagnosis and to be present for discussion of a cancer diagnosis.\n    \n\n\n          Conclusion:\n        \n      \n      Although the majority of respondents were not reluctant about the use of AI for skin cancer diagnosis, respondents still considered it important that dermatologists are involved in the diagnosis and/or confirmation of skin cancer. Furthermore, the study results demonstrate that personal interaction with a clinician is important. This is in keeping with proposals that AI be used as an adjunctive technology to increase accuracy of skin cancer diagnoses, but not as a substitute for a dermatologist."
        },
        {
            "title": "An Enhancement on Convolutional Artificial Intelligent Based Diagnosis for Skin Disease Using Nanotechnology Sensors.",
            "abstract": "Skin disease is the major health problem around the world. The diagnosis of skin disease remains a challenge to dermatologist profession particularly in the detection, evaluation, and management. Health data are very large and complex due to this processing of data using traditional data processing techniques is very difficult. In this paper, to ease the complexity while processing the inputs, we use multilayered perceptron with backpropagation neural networks (MLP-BPNN). The image is collected from the devices that contain nanotechnology sensors, which is the state-of-art in the proposed model. The nanotechnology sensors sense the skin for its chemical, physical, and biological conditions with better detection specificity, sensitivity, and multiplexing ability to acquire the image for optimal classification. The MLP-BPNN technique is used to envisage the future result of disease type effectively. By using the above MLP-BPNN technique, it is easy to predict the skin diseases such as melanoma, nevus, psoriasis, and seborrheic keratosis."
        },
        {
            "title": "Superpixel-Oriented Label Distribution Learning for Skin Lesion Segmentation.",
            "abstract": "Lesion segmentation is a critical task in skin cancer analysis and detection. When developing deep learning-based segmentation methods, we need a large number of human-annotated labels to serve as ground truth for model-supervised learning. Due to the complexity of dermatological images and the subjective differences of different dermatologists in decision-making, the labels in the segmentation target boundary region are prone to produce uncertain labels or error labels. These labels may lead to unsatisfactory performance of dermoscopy segmentation. In addition, the model trained by the errored one-hot label may be overconfident, which can lead to arbitrary prediction and model overfitting. In this paper, a superpixel-oriented label distribution learning method is proposed. The superpixels formed by the simple linear iterative cluster (SLIC) algorithm combine one-hot labels constraint and define a distance function to convert it into a soft probability distribution. Referring to the model structure of knowledge distillation, after Superpixel-oriented label distribution learning, we get soft labels with structural prior information. Then the soft labels are transferred as new knowledge to the lesion segmentation network for training. Ours method on ISIC 2018 datasets achieves an Dice coefficient reaching 84%, sensitivity 79.6%, precision 80.4%, improved by 19.3%, 8.6% and 2.5% respectively in comparison with the results of U-Net. We also evaluate our method on the tasks of skin lesion segmentation via several general neural network architectures. The experiments show that ours method improves the performance of network image segmentation and can be easily integrated into most existing deep learning architectures."
        },
        {
            "title": "Deep learning outperformed 136 of 157 dermatologists in a head-to-head dermoscopic melanoma image classification task.",
            "abstract": "Background:\n        \n      \n      Recent studies have successfully demonstrated the use of deep-learning algorithms for dermatologist-level classification of suspicious lesions by the use of excessive proprietary image databases and limited numbers of dermatologists. For the first time, the performance of a deep-learning algorithm trained by open-source images exclusively is compared to a large number of dermatologists covering all levels within the clinical hierarchy.\n    \n\n\n          Methods:\n        \n      \n      We used methods from enhanced deep learning to train a convolutional neural network (CNN) with 12,378 open-source dermoscopic images. We used 100 images to compare the performance of the CNN to that of the 157 dermatologists from 12 university hospitals in Germany. Outperformance of dermatologists by the deep neural network was measured in terms of sensitivity, specificity and receiver operating characteristics.\n    \n\n\n          Findings:\n        \n      \n      The mean sensitivity and specificity achieved by the dermatologists with dermoscopic images was 74.1% (range 40.0%-100%) and 60% (range 21.3%-91.3%), respectively. At a mean sensitivity of 74.1%, the CNN exhibited a mean specificity of 86.5% (range 70.8%-91.3%). At a mean specificity of 60%, a mean sensitivity of 87.5% (range 80%-95%) was achieved by our algorithm. Among the dermatologists, the chief physicians showed the highest mean specificity of 69.2% at a mean sensitivity of 73.3%. With the same high specificity of 69.2%, the CNN had a mean sensitivity of 84.5%.\n    \n\n\n          Interpretation:\n        \n      \n      A CNN trained by open-source images exclusively outperformed 136 of the 157 dermatologists and all the different levels of experience (from junior to chief physicians) in terms of average specificity and sensitivity."
        },
        {
            "title": "Teaching Skin Cancer Detection to Medical Students Using a Dermoscopic Algorithm.",
            "abstract": "Introduction:\n        \n      \n      Early detection of melanoma skin cancer improves survival rates. Training family physicians in dermoscopy with the triage amalgamated dermoscopic algorithm (TADA) has high sensitivity and specificity for identifying malignant skin neoplasms. In this study we evaluated the effectiveness of TADA training among medical students, compared with practicing clinicians.\n    \n\n\n          Methods:\n        \n      \n      We incorporated the TADA framework into 90-minute workshops that taught dermoscopy to family physicians, primary care residents, and first- and second-year medical students. The workshop reviewed the clinical and dermoscopic features of benign and malignant skin lesions and included a hands-on interactive session using a dermatoscope. All participants took a 30-image pretest and a different 30-image posttest.\n    \n\n\n          Results:\n        \n      \n      Forty-six attending physicians, 25 residents, and 48 medical students participated in the workshop. Mean pretest scores were 20.1, 20.3, and 15.8 for attending physicians, resident physicians and students, respectively (P<.001); mean posttest scores were 24.5, 25.9, and 24.1, respectively (P=.11). Pre/posttest score differences were significant ( P<.001) for all groups. The medical students showed the most gain in their pretest and posttest scores.\n    \n\n\n          Conclusion:\n        \n      \n      After short dermoscopy workshop, medical students perform as well as trained physicians in identifying images of malignant skin lesions. Dermoscopy training may be a valuable addition to the medical school curriculum as this skill can be used by primary care physicians as well as multiple specialists including dermatologists, gynecologists, otolaryngologists, plastic surgeons, and ophthalmologists, who often encounter patients with concerning skin lesions."
        },
        {
            "title": "Automated Lesion Segmentation and Quantitative Analysis of Nevus in Whole-Face Images.",
            "abstract": "Background:\n        \n      \n      Nevus is very common; however, melanoma is slightly related to the deterioration of nevus because of its vulnerability to solarization, friction, aging, heredity, and other factors. Early diagnosis is essential for melanoma treatment, since patients have a high survival rate with early detection and treatment. Computer-aided diagnosis has been applied in the differential diagnosis of melanoma and benign nevi and achieved high accuracy, but it does not suit the screening of nevi because most studies are based on dermoscopy with a narrow field of vision and performed by professional doctors. Therefore, this study aimed to present the accuracy and effectiveness of our algorithm.\n    \n\n\n          Methods:\n        \n      \n      Based on whole-face images of patients, the authors used logistic regression and the Newton method to detect the nevus region. Then, Python and OpenCV were employed to detect the lesion edge and compute the area of the regions. A multicenter clinical trial with a sample size of 600 was then conducted to evaluate the effectiveness of the algorithm.\n    \n\n\n          Results:\n        \n      \n      The algorithm detected 2672 nevi from 600 patients, in which there were 195 patients of missed diagnosis and 310 patients of misdiagnosis. The Kappa value between 2 groups was 0.860 (>0.8). Paired t-test showed no significant difference between 2 groups' area results (P = 0.265, P > 0.05).\n    \n\n\n          Conclusion:\n        \n      \n      Within the limitations of this study, the authors demonstrated a high agreement between algorithm's detection and doctor's diagnosis. Our new algorithm has great effectiveness in nevus detection, edge segmentation, and area measurement."
        },
        {
            "title": "Quantitative evaluation of binary digital region asymmetry with application to skin lesion detection.",
            "abstract": "Background:\n        \n      \n      The performance of Computer Aided Diagnosis Systems for early melanoma detection relies mainly on quantitative evaluation of the geometric features corresponding to skin lesions. In these systems, diagnosis is carried out by analyzing four geometric characteristics: asymmetry (A), border (B), color (C) and dimension (D). The main objective of this study is to establish an algorithm for the measurement of asymmetry in biological entities.\n    \n\n\n          Methods:\n        \n      \n      Binary digital images corresponding to lesions are divided into 8 segments from their centroid. For each segment, the discrete compactness value is calculated using Normalized E-Factor (NEF). The asymmetry value is obtained from the sum of the square difference of each NEF value and corresponding value of its opposite by the vertex. Two public skin cancer databases were used. 1) Lee's database with 40 digital regions evaluated by fourteen dermatologists. 2) The PH2 database which consists of 200 images in an 8-bit RGB format. This database provides a pre-classification of asymmetry carried out by experts, and it also indicates if the lesion is a melanoma.\n    \n\n\n          Results:\n        \n      \n      The measure was applied using two skin lesion image databases. 1) In Lee's database, Spearman test provided a value of 0.82 between diagnosis of dermatologists and asymmetry values. For the 12 binary images most likely to be melanoma, the correlation between the measurement and dermatologists was 0.98. 2) In the PH2 database a label is provided for each binary image where the type of asymmetry is indicated. Class 0-1 corresponds to symmetry and one axis of symmetry shapes, the completely asymmetrical were assigned to Class 2, the values of sensitivity and specificity were 59.62 and 85.8% respectively between the asymmetry measured by a group of dermatologists and the proposed algorithm.\n    \n\n\n          Conclusions:\n        \n      \n      Simple image digital features such as compactness can be used to quantify the asymmetry of a skin lesion using its digital binary image representation. This measure is stable taking into account translations, rotations, scale changes and can be applied to non-convex regions, including areas with holes."
        },
        {
            "title": "The impact of anatomical location and sun exposure on the dermoscopic recognition of atypical nevi and early melanomas: usefulness of an integrated clinical-dermoscopic method (iDScore).",
            "abstract": "Background:\n        \n      \n      The anatomical location of atypical melanocytic skin lesion (aMSL) was never combined into an algorithm for discriminating early melanomas (EM) from atypical nevi (AN).\n    \n\n\n          Aims:\n        \n      \n      To investigate the impact of body location on the intuitive diagnosis performed in teledermoscopy by dermatologists of different skill levels. A further aim was to evaluate how the integration of the body location could improve an algorithm-aided diagnosis.\n    \n\n\n          Methods:\n        \n      \n      We retrospectively collected 980 standardized dermoscopic images of aMSL cases (663 AN, 317 EM): data on the anatomical location were collected according to 15 body sites classified into 4 macro-areas of chronically/frequently/seldom/rarely exposure. Through a teledermatology web platform, 111 variously skilled dermoscopists performed either the intuitive diagnosis and 3 algorithm-assisted diagnostic tests (i.e. iDScore, 7-point checklist, ABCD rule) on each case, for a total of 3330 examinations.\n    \n\n\n          Results:\n        \n      \n      In the rarely photoexposed area (side, bottom, abdomen), AN were the most tricky (i.e. highest quote of false positives), due to a frequent recognition of dermoscopic features usually considered as suggestive for melanoma in these lesions; the EM at these sites received the highest quote of false negatives, being generally interpreted as 'featureless' according to these traditional parameters, that were more frequently displayed on the chronically photoexposed area. In rarely and seldom photoexposed area, intuitive diagnosis fails to achieve adequate accuracy for all aMSLs, as the ABCD rule and the 7-point checklist; by applying the iDScore algorithm the diagnostic performance was increased by 15% in young and 17% in experts.\n    \n\n\n          Conclusions:\n        \n      \n      The body location of an aMSL can affect the quality of intuitive dermoscopic diagnosis, especially in sun-protected areas. Accuracy can be improved by using the iDScore algorithm that assigns a different partial score of each body site."
        },
        {
            "title": "An interpretable CNN-based CAD system for skin lesion diagnosis.",
            "abstract": "Recently, convolutional neural networks have greatly outperformed previous systems based on handcrafted features once the size of public databases has increased. However, these algorithms learn feature representations that are difficult to interpret and analyse. On the other hand, experts require automatic systems to explain their decisions according to clinical criteria which, in the field of melanoma diagnosis, are related to the analysis of dermoscopic features found in the lesions. In recent years, the interpretability of deep networks has been explored using methods that obtain visual features highlighted by neurones or analyse activations to extract more useful information. Following the latter approach, this study proposes a system for melanoma diagnosis that explicitly incorporates dermoscopic feature segmentations into a diagnosis network through a channel modulation scheme. Modulation weights control the influence of the detected visual patterns based on the lesion content. As shown in the experimental section, our design not only improves the system performance on the ISIC 2016 (average AUC of 86.6% vs. 85.8%) and 2017 (average AUC of 94.0% vs. 93.8%) datasets, but also notably enhances the interpretability of the diagnosis, providing useful and intuitive cues to clinicians."
        },
        {
            "title": "Using deep learning for dermatologist-level detection of suspicious pigmented skin lesions from wide-field images.",
            "abstract": "A reported 96,480 people were diagnosed with melanoma in the United States in 2019, leading to 7230 reported deaths. Early-stage identification of suspicious pigmented lesions (SPLs) in primary care settings can lead to improved melanoma prognosis and a possible 20-fold reduction in treatment cost. Despite this clinical and economic value, efficient tools for SPL detection are mostly absent. To bridge this gap, we developed an SPL analysis system for wide-field images using deep convolutional neural networks (DCNNs) and applied it to a 38,283 dermatological dataset collected from 133 patients and publicly available images. These images were obtained from a variety of consumer-grade cameras (15,244 nondermoscopy) and classified by three board-certified dermatologists. Our system achieved more than 90.3% sensitivity (95% confidence interval, 90 to 90.6) and 89.9% specificity (89.6 to 90.2%) in distinguishing SPLs from nonsuspicious lesions, skin, and complex backgrounds, avoiding the need for cumbersome individual lesion imaging. We also present a new method to extract intrapatient lesion saliency (ugly duckling criteria) on the basis of DCNN features from detected lesions. This saliency ranking was validated against three board-certified dermatologists using a set of 135 individual wide-field images from 68 dermatological patients not included in the DCNN training set, exhibiting 82.96% (67.88 to 88.26%) agreement with at least one of the top three lesions in the dermatological consensus ranking. This method could allow for rapid and accurate assessments of pigmented lesion suspiciousness within a primary care visit and could enable improved patient triaging, utilization of resources, and earlier treatment of melanoma."
        },
        {
            "title": "Image Processing for mHealth-Based Approach to Detect the Local Tissue Inflammation in Cutaneous Leishmaniasis: A Proof of Concept Study.",
            "abstract": "Skin lesions are a feature of many diseases including cutaneous leishmaniasis (CL). Ulcerative lesions are a common manifestation of CL. Response to treatment in such lesions is judged through the assessment of the healing process by regular clinical observations, which remains a challenge for the clinician, health system, and the patient in leishmaniasis endemic countries. In this study, image processing was initially done using 40 CL lesion color images that were captured using a mobile phone camera, to establish a technique to extract features from the image which could be related to the clinical status of the lesion. The identified techniques were further developed, and ten ulcer images were analyzed to detect the extent of inflammatory response and/or signs of healing using pattern recognition of inflammatory tissue captured in the image. The images were preprocessed at the outset, and the quality was improved using the CIE Lâˆ—aâˆ—b color space technique. Furthermore, features were extracted using the principal component analysis and profiled using the signal spectrogram technique. This study has established an adaptive thresholding technique ranging between 35 and 200 to profile the skin lesion images using signal spectrogram plotted using Signal Analyzer in MATLAB. The outcome indicates its potential utility in visualizing and assessing inflammatory tissue response in a CL ulcer. This approach is expected to be developed further to a mHealth-based prediction algorithm to enable remote monitoring of treatment response of cutaneous leishmaniasis."
        },
        {
            "title": "Distance Learning and Spaced Review to Complement Dermoscopy Training for Primary Care.",
            "abstract": "Background:\n        \n      \n      Dermoscopy aids in skin cancer identification. For family physicians who use dermoscopy, there is higher sensitivity for melanoma detection than naked-eye examination. There is a shortage of dermoscopy training for primary care providers. The triage amalgamated dermoscopic algorithm (TADA) is designed for novice dermoscopists. While TADA can be taught in a short dermoscopy workshop, spaced review and blended learning strategies improve knowledge retention.\n    \n\n\n          Objectives:\n        \n      \n      This study determined the impact that the addition of a distance learning platform has on clinical dermoscopy use. Moreover, it evaluated dermoscopic image identification (knowledge retention) following the addition of distance learning via Extension for Community Health Outcomes (ECHO) to a traditional TADA dermoscopy workshop.\n    \n\n\n          Methods:\n        \n      \n      Primary care providers voluntarily attended a 120-minute TADA dermoscopy workshop. Participants completed pre-intervention, post-TADA, and post-ECHO tests of 30 dermoscopic images of benign and malignant skin lesions. A survey was also administered to analyze clinical dermoscopy use and prior dermoscopy training.\n    \n\n\n          Results:\n        \n      \n      Twenty-seven residents, faculty, and advanced practice providers participated in this longitudinal observational cohort study. Mean test scores (out of 30) for images of benign and malignant lesions improved from 20.29 pre-intervention to 24.62 post-TADA and 27.63 post-ECHO (P < .001). On average, participants attended 4 ECHO sessions (out of 7 total) and there was a positive correlation (r = 0.77) between the number of ECHOs attended and post-ECHO scores. Dermoscope use increased from 37.0% to 96.3% (P < .001).\n    \n\n\n          Conclusion:\n        \n      \n      Distance learning and spaced review complement dermoscopy workshop training for primary care."
        },
        {
            "title": "Efficient skin lesion segmentation using separable-Unet with stochastic weight averaging.",
            "abstract": "Background and objective:\n        \n      \n      Efficient segmentation of skin lesion in dermoscopy images can improve the classification accuracy of skin diseases, which provides a powerful approach for the dermatologists in examining pigmented skin lesions. However, the segmentation is challenging due to the low contrast of skin lesions from a captured image, fuzzy and indistinct lesion boundaries, huge variety of interclass variation of melanomas, the existence of artifacts, etc. In this work, an efficient and accurate melanoma region segmentation method is proposed for computer-aided diagnostic systems.\n    \n\n\n          Method:\n        \n      \n      A skin lesion segmentation (SLS) method based on the separable-Unet with stochastic weight averaging is proposed in this work. Specifically, the proposed Separable-Unet framework takes advantage of the separable convolutional block and U-Net architectures, which can extremely capture the context feature channel correlation and higher semantic feature information to enhance the pixel-level discriminative representation capability of fully convolutional networks (FCN). Further, considering that the over-fitting is a local optimum (or sub-optimum) problem, a scheme based on stochastic weight averaging is introduced, which can obtain much broader optimum and better generalization.\n    \n\n\n          Results:\n        \n      \n      The proposed method is evaluated in three publicly available datasets. The experimental results showed that the proposed approach segmented the skin lesions with an average Dice coefficient of 93.03% and Jaccard index of 89.25% for the International Skin Imaging Collaboration (ISIC) 2016 Skin Lesion Challenge (SLC) dataset, 86.93% and 79.26% for the ISIC 2017 SLC, and 94.13% and 89.40% for the PH2 dataset, respectively. The proposed approach is compared with other state-of-the-art methods, and the results demonstrate that the proposed approach outperforms them for SLS on both melanoma and non-melanoma cases. Segmentation of a potential lesion with the proposed approach in a dermoscopy image requires less than 0.05 s of processing time, which is roughly 30 times faster than the second best method (regarding the value of Jaccard index) for the ISIC 2017 dataset with the same hardware configuration.\n    \n\n\n          Conclusions:\n        \n      \n      We concluded that using the separable convolutional block and U-Net architectures with stochastic weight averaging strategy could enable to obtain better pixel-level discriminative representation capability. Moreover, the considerably decreased computation time suggests that the proposed approach has potential for practical computer-aided diagnose systems, besides provides a segmentation for the specific analysis with improved segmentation performance."
        },
        {
            "title": "Dermatoscopy.",
            "abstract": "The dermatoscope has gained tremendous popularity among dermatologists as an adjunctive tool to better visualize subsurface structures and identify patterns that may improve the diagnosis of a wide range of skin diseases. Initially, the pigmented lesion experts who were the early adopters promoted the use of the dermatoscope to increase diagnostic accuracy of early melanomas and decrease the harvesting of benign lesions. With current near universal adoption of the diagnostic technique by dermatologists, the dermatoscope is now employed to help identify a wide variety of inflammatory, infectious, and vascular conditions of the skin, hair, and nails, resulting in the emergence of several branches of dermatoscopy-inflammoscopy, trichoscopy, onychoscopy, and entodermoscopy. The future of dermatoscopy will involve incorporation of artificial intelligence that will make the assessment process increasingly objective, more accurate, and universally available. Despite the wide acceptance and adoption of dermatoscopy, the overall impact of its widespread use still remains unclear, whether it has decreased biopsy rates of benign lesions, reduced health care costs, or improved patient outcomes."
        },
        {
            "title": "Burden and treatment patterns of advanced basal cell carcinoma among commercially insured patients in a United States database from 2010 to 2014.",
            "abstract": "Background:\n        \n      \n      The burden of advanced basal cell carcinoma (aBCC) is not fully understood.\n    \n\n\n          Objective:\n        \n      \n      To compare BCC disease burden and treatment patterns for aBCC with those for non-aBCC.\n    \n\n\n          Methods:\n        \n      \n      A retrospective, insurance claims-based study design was used. Adults with â‰¥2 claims associated with a BCC diagnosis (ICD-9-CM 173.x1) separated by â‰¥30 days on or after October 1, 2011, were classified as aBCC or non-aBCC by using an algorithm based on metastasis diagnosis, radiation therapy use, and medical oncologist/other specialist use. Non-aBCC and aBCC patients were matched 1:1 on the basis of age, sex, and region, and assigned the same index date (date of first qualifying diagnosis or event). Comparisons were made using Wilcoxon signed-rank (continuous variables) and McNemar's (categorical variables) tests.\n    \n\n\n          Results:\n        \n      \n      In total, 847 matched aBCC/non-aBCC patient pairs were selected (mean age 75 years; 57% men; locally advanced BCC, n = 826; metastatic BCC, n = 21). During the 12-month study period following the index date, aBCC patients had a significantly higher mean Charlson Comorbidity Index (P = .0023), significantly higher mean numbers of outpatient/dermatologist/medical oncologist visits (all P < .0001), and significantly higher mean total/medical/inpatient/outpatient/BCC treatment costs (all P < .05).\n    \n\n\n          Limitations:\n        \n      \n      This study only included information from a database on commercial insurance and Medicare claims. The algorithm criteria might have restricted patient numbers; data were not fully reflective of targeted therapy era.\n    \n\n\n          Conclusions:\n        \n      \n      aBCC patients had a higher disease burden than non-aBCC patients. Cost differences were largely driven by higher BCC treatment costs, specifically radiation therapy."
        },
        {
            "title": "Evaluation of Melanoma Thickness with Clinical Close-up and Dermoscopic Images Using a Convolutional Neural Network.",
            "abstract": "Convolutional neural networks (CNNs) have shown promise in discriminating between invasive and in situ melanomas. The aim of this study was to analyse how a CNN model, integrating both clinical close-up and dermoscopic images, performed compared with 6 independent dermatologists. The secondary aim was to address which clinical and dermoscopic features dermatologists found to be suggestive of invasive and in situ melanomas, respectively. A retrospective investigation was conducted including 1,578 cases of paired images of invasive (n = 728, 46.1%) and in situ melanomas (n = 850, 53.9%). All images were obtained from the Department of Dermatology and Venereology at Sahlgrenska University Hospital and were randomized to a training set (n = 1,078), a validation set (n = 200) and a test set (n = 300). The area under the receiver operating characteristics curve (AUC) among the dermatologists ranged from 0.75 (95% confidence interval 0.70-0.81) to 0.80 (95% confidence interval 0.75-0.85). The combined dermatologists' AUC was 0.80 (95% confidence interval 0.77-0.86), which was significantly higher than the CNN model (0.73, 95% confidence interval 0.67-0.78, p = 0.001). Three of the dermatologists significantly outperformed the CNN. Shiny white lines, atypical blue-white structures and polymorphous vessels displayed a moderate interobserver agreement, and these features also correlated with invasive melanoma. Prospective trials are needed to address the clinical usefulness of CNN models in this setting."
        },
        {
            "title": "Diagnostic performance of the MelaFind device in a real-life clinical setting.",
            "abstract": "Background:\n        \n      \n      MelaFind is a multispectral computer vision system intended to -provide additional information on melanocytic lesions suspected of being melanoma by -objectively assessing their three-dimensional morphology.\n    \n\n\n          Objectives:\n        \n      \n      Analysis of the diagnostic performance of MelaFind in a real-life clinical setting.\n    \n\n\n          Patients and methods:\n        \n      \n      In this observational study, 360 pigmented skin lesions (PSL) in 111 patients were assessed by office-based dermatologists using MelaFind. Scores â‰¥ 2 were considered to be suspicious of malignancy. The decision for surgical excision was left to the discretion of the examining dermatologists.\n    \n\n\n          Results:\n        \n      \n      MelaFind scores â‰¥ 2 were observed in 147 of 360 PSL (40.8 %). Of the 107 excised lesions with a MelaFind-score â‰¥ 2, the diagnosis of melanoma was made in three cases; 53 (49.5 %) lesions proved to be dysplastic nevi. Among all lesions biopsied (n = 113), the sensitivity and specificity of MelaFind was 100 % and 5.5 %, respectively. While a higher specificity of 68.5 % may be assumed with respect to the overall data set (n = 360), this assumption is limited by incomplete follow-up data required to confirm that all non-excised lesions with a score < 2 were actually benign.\n    \n\n\n          Conclusion:\n        \n      \n      The high sensitivity of MelaFind facilitated the detection of melanoma. The overall specificity and benign-to-malignant ratio of excised lesions were acceptable. These parameters may be improved by using higher cutoff scores for excisional biopsies, and by more vigorously selecting PSL for MelaFind examination."
        },
        {
            "title": "An overview of methods to mitigate artifacts in optical coherence tomography imaging of the skin.",
            "abstract": "Background:\n        \n      \n      Optical coherence tomography (OCT) of skin delivers three-dimensional images of tissue microstructures. Although OCT imaging offers a promising high-resolution modality, OCT images suffer from some artifacts that lead to misinterpretation of tissue structures. Therefore, an overview of methods to mitigate artifacts in OCT imaging of the skin is of paramount importance. Speckle, intensity decay, and blurring are three major artifacts in OCT images. Speckle is due to the low coherent light source used in the configuration of OCT. Intensity decay is a deterioration of light with respect to depth, and blurring is the consequence of deficiencies of optical components.\n    \n\n\n          Method:\n        \n      \n      Two speckle reduction methods (one based on artificial neural network and one based on spatial compounding), an attenuation compensation algorithm (based on Beer-Lambert law) and a deblurring procedure (using deconvolution), are described. Moreover, optical properties extraction algorithm based on extended Huygens-Fresnel (EHF) principle to obtain some additional information from OCT images are discussed.\n    \n\n\n          Results:\n        \n      \n      In this short overview, we summarize some of the image enhancement algorithms for OCT images which address the abovementioned artifacts. The results showed a significant improvement in the visibility of the clinically relevant features in the images. The quality improvement was evaluated using several numerical assessment measures.\n    \n\n\n          Conclusion:\n        \n      \n      Clinical dermatologists benefit from using these image enhancement algorithms to improve OCT diagnosis and essentially function as a noninvasive optical biopsy."
        },
        {
            "title": "Suspicious Skin Lesion Detection in Wide-Field Body Images using Deep Learning Outlier Detection.",
            "abstract": "During consultation dermatologists have to address hundreds of lesions in a limited amount of time. They will not only evaluate the single lesion of interest but more importantly the context of it. Visually comparing the similarity of the majority of lesions within the same patient provides a strong indication for lesions with significantly differing aspects. Deep learning algorithms are capable to identify such outliers, i.e. images that differ considerably from the expected appearance on a larger cohort, and highlight the main differences in those cases. In the present study we evaluate the use of autoencoders as unsupervised tools to detect suspicious skin lesions based on evaluation of real world data acquired during consultation at the USZ Dermatology Clinic. Clinical Relevance- Deep learning algorithms are showing many promising results in dermatology lesion classification. However the context of the lesion is normally not considered in the analysis which prevents these tools to transition into routine practice. An outlier detector based on real world data would allow a dermatologist or general practitioner to detect the suspicious lesions for further examination. The algorithm would additionally provide useful insights by highlighting the feature differences between the original outlier (malignant lesion) and the lesion reconstructed by the autoencoder."
        }
    ]
}