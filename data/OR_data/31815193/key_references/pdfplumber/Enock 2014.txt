CognTherRes(2014)38:200–216
DOI10.1007/s10608-014-9606-z
ORIGINAL ARTICLE
Attention Bias Modification Training Via Smartphone
to Reduce Social Anxiety: A Randomized, Controlled
Multi-Session Experiment
Philip M. Enock • Stefan G. Hofmann •
Richard J. McNally
Publishedonline:4March2014
(cid:2)SpringerScience+BusinessMediaNewYork2014
Abstract Testing feasibility and efficacy of psychologi- social anxiety, intention-to-treat analyses (n = 326)
cal treatment via mobile devices is important, given its revealed significant pre–post treatment declines with
potential benefits for high-dosage treatment delivery, medium to large effect sizes in both training groups,
widespread and inexpensive dissemination, and efficient whereas small declines in a waitlist group were nonsig-
research methods. We conducted the first randomized nificant.Bothtraininggroupsshowedgreaterreductionsin
controlled trial of attention bias modification training socialanxietythandidwaitlist;however,thebenefitsunder
delivered via smartphones, comparing this training to these two training conditions were statistically indistin-
control training in a double-blind design, also including a guishable. Improvements in the two training conditions
waitlist condition. All participants performed a variant of beyondthoseofwaitlistcouldbeattributabletoanyfactors
dot-probetraining involvingfaceswithneutralanddisgust common to them, but not to the contingency training spe-
(representative of social threat) expressions in brief ses- cific to active attention bias modification training.
sions three times daily over 4 weeks on their own smart-
phones, at home or anywhere they chose. Attention bias Keywords Cognitive bias modification (cid:2) Attentional
modification, also known as cognitive bias modification of bias (cid:2) Attention training (cid:2) Social anxiety (cid:2) Mobile app
attention, training included a contingency to induce atten- treatment
tional deployment away from disgust faces, whereas the
control training included no contingency. Participants
completed weekly Internet-based self-report symptom Introduction
assessments as well as smartphone-delivered dot-probe
attention bias assessments, whose reliability findings sup- Anxious people, especially those suffering from anxiety
ported the viability of using smartphones for reaction-time disorders, often exhibit an attention bias for threat (Bar-
based assessments. The between-groups training effect on Haimetal.2007).Althoughdetectionofthreatisessential
attention bias scores was small, showing statistical signif- forsurvival,aproclivityforattendingtominorthreatsmay
icance insomeanalyses and notin others. On measuresof needlessly heighten one’s anxiety in everyday life. Labo-
ratory studies documenting this bias usually involve vari-
ants of the dot-probe paradigm (MacLeod et al. 1986) to
Electronicsupplementarymaterial Theonlineversionofthis
article(doi:10.1007/s10608-014-9606-z)containssupplementary measureattentionaldeploymentwithinpairsofneutraland
material,whichisavailabletoauthorizedusers. threatening stimuli.
Ifattentionbiasplaysacausalroleintheirdevelopment
P.M.Enock(&)(cid:2)R.J.McNally
and maintenance of anxiety disorders, then reducing it
DepartmentofPsychology,HarvardUniversity,Cambridge,
MA,USA should diminish a person’s vulnerability to experience
e-mail:p.enock@gmail.com episodes of anxiety (MacLeod et al. 2002). MacLeod
(1995) proposed modifying the dot-probe task by having
S.G.Hofmann
visual probes consistently appear in the location of non-
DepartmentofPsychology,BostonUniversity,Boston,MA,
USA threatening words (or faces), thereby directing subjects’
123
CognTherRes(2014)38:200–216 201
attention away from threatening stimuli. He reasoned that Fifth, establishing CBM-A’s efficacy on the small screens
such an attention bias modification (CBM-A, also known of smartphones would confirm its robustness across vary-
as ABM) training procedure could alter anxious individu- ing sizes of stimulus presentation. Sixth, establishing
als’ attention bias for threat, potentially reducing anxiety smartphones’ viability for reaction-time based tasks would
proneness. Inspired by MacLeod, researchers have modi- open the platform to this category of psychological
fied experimental paradigms, creating other cognitive bias assessment methods.
modification (CBM) interventions, such that CBM-A rep- In the first study of CBM-A on mobile devices, we
resents the cognitive bias modification of attention, tested the feasibility of reducing social anxiety and worry
whereas other CBM interventions attempt to modify other via iPhone, iPod Touch, and Android-based smartphones
forms of cognitive bias, such as interpretation bias. (Enock and McNally 2010, summarized in Enock and
Researchers have conducted randomized controlled tri- McNally 2013). Using a multiple baseline across subjects
als (RCTs) to test the efficacy of multisession CBM-A single-casedesign(Barlow etal.2009),weadministered1
training for reducing anxiety, reporting mixed results (for or2 weeksofCONfollowedby3 weeksoffrequentCBM-
meta-analytic findings, see Beard et al. 2012; Hakamata A training to 16 anxious individuals. Participants, mostly
et al. 2010, 2012; Hallion and Ruscio 2011). CBM-A Harvard University students, generally found treatment to
treatment has also reduced symptoms in people with gen- be acceptable. They reported training on their mobile
eralized anxiety disorder (Amir et al. 2009a), pediatric devices primarily at home (67 % of sessions), but also in
anxiety (Eldar et al. 2012), and depressive symptoms libraries(9 %),bathrooms(6 %),andothersites.Although
(Wells and Beevers 2010). RCTs appearing prior to the symptoms declined significantly, improvements did not
onset of our study showed strong support for CBM-A’s differ between the CON and CBM-A phases.
superiority to control training (CON) for treating general- In the present RCT, we tested the efficacy of smart-
ized social anxiety disorder (Amir et al. 2009b; Schmidt phone-delivered CBM-A. We randomly assigned partici-
et al. 2009). One study also showed large effectsof CBM- pantstooneofthreeconditions:CBM-A,CON,orwaitlist.
A versus CON for reducing social anxiety (Li et al. 2008) Our study tested the following hypotheses: (1) that social
ontheSocialInteractionAnxietyScale(SIAS;Mattickand anxiety would decrease more in the CBM-A group than in
Clarke 1998), but not on the Social Phobia Scale (Mattick the CON group; (2) that social anxiety would decrease
andClarke1998)ortheFearofNegativeEvaluationScale more inboth CBM-A andCON groups than inthe waitlist
(Watson and Friend 1969). More recently, although one group; and (3) that attention bias scores would diverge at
study indicated superior efficacy of CBM-A versus CON the start of training and grow further apartduring training,
(Heeren et al. 2012) for social anxiety disorder, six others with lower scores in the CBM-A group than in the CON
have not (Boettcher et al. 2012, 2013; Bunnell et al. 2013; training group. If CBM-A causes greater decreases in
Carlbring et al. 2012; Neubauer et al. 2013; Sawyer et al. social anxiety than does CON, then this would imply that
2012). Although researchers have usually administered the putative active ingredient of CBM-A, the contingency
training in research laboratories, delivery through a web- linking probes to locations opposite to threat stimuli, pro-
basedplatformcouldincreaseitsaccessibility,asMacLeod duces these differential decreases. If, however, CBM-A
et al. (2007) demonstrated. Additionally, four RCTs of andCONyieldsimilarsymptomdeclines,bothgreaterthan
CBM-A delivered training via Internet to participants’ those of waitlist, this would imply that performing either
home PCs (Boettcher et al. 2012, 2013; Carlbring et al. training has anxiolytic effects that are not specific to the
2012; Neubauer et al. 2013). theoretically active ingredient. We included measures of
For several reasons, we investigated the feasibility of worry and depression as secondary measures to charac-
delivering CBM-A on smartphone mobile devices rather terize the breadth of clinical benefit.
than PCs. First, the approach could augment CBM-A’s
effects by facilitating a higher dosage via ease of frequent
training, perhaps enabling enduring changes in attentional Method
habits more likely. Increasing the frequency of sessions is
easywithsmartphones,asparticipantscanperformtraining Participants
anywhere throughout the day. Second, training in diverse
locations could foster generalization of clinical benefits. Onthestudywebsite,826individualssignedup,indicating
Third, higher frequency enables brevity of sessions, per- their desire to participate in the study. There were 429
haps increasing tolerability of this repetitive task. Fourth, participants (52.2 % male) randomized in the study, rang-
mobile devices have great dissemination potential, and the inginagefrom18to68 yearsold(M = 34.8,SD = 11.4).
popularity and convenience of mobile apps suggest that The racial/ethnic composition of the sample was 81.2 %
people will welcome psychological help via this venue. white, 11.7 % Asian, 4.9 % Hispanic or Latino, 1.4 %
123
202 CognTherRes(2014)38:200–216
Fig.1 Participant
randomization,inclusioninITT
analyses,anddropouts
Black or African American, 0.9 % American Indian or opportunity to receive CBM-A after the 2-month follow-
AlaskanNative,0.2 %NativeHawaiianorPacificIslander, up. We encouraged participation from individuals with
and 2.3 % other. The mean years of education was 17.0 highlevelsofsocialanxiety,generalizedanxietyorworry,
(SD = 3.0). Participants used these handheld devices orboth,buttherewasnoexclusioncriterionduringsignup
during the study: 52.1 % iPhone (Apple Computer, Inc., based on symptoms.
Cupertino, CA, USA), 22.4 % iPod Touch (Apple Com- To participate, individuals were required only to: (1)
puter), and 24.1 % any Android-based (Google, Mountain have access to an iPhone, iPod Touch, or Android-based
View, CA, USA) smartphone.1 phone with Wi-Fi or other Internet access during the
Data collection occurred between September 12, 2010 4 weeks of training, (2) be aged 18 or older, and (3) be
and January 6, 2012. Prior to June 18, 2011, we randomly sufficientlyproficientinEnglishtoreadandunderstandthe
assigned participants to either the active (CBM-A) or instructions and consent form. For data analyses, we
control (CON) conditions with a .5 probability of assign- applied cutoff scores to examine socially anxious individ-
ment to each condition. From June 18, 2011 to January 6, uals.Aflowchartofparticipantassignment anddropoutis
2012,werandomlyassignedparticipantstoCBM-A,CON, included (see Fig. 1).
or waitlist (WL) conditions with a .33 probability for each
condition. Materials
We recruited from a range of sources, mostly word of
mouth stemming from a news article in the Economist Face Stimuli
magazine (Gee 2011), but also online messageboards,
Craigslist, the Harvard Study Pool, flyers posted locally, We used the same face stimuli (Matsumoto and Ekman
and Google search and AdWords. Harvard students who 1988) as other studies (Amir et al. 2008, 2009b; Schmidt
sought course credit for their participation received it, et al. 2009), balanced across the factors of sex (male vs.
whereas others received no compensation other than the female) and ethnicity (Caucasian vs. Japanese). Each
model portrayed disgust and neutral expressions.
Smartphone Attention Bias Modification Training Task
1 Data from study signup was missing for one participant, and the Participantstrainedontheirownhandhelddevices,whichhad
answer on handheld device type was missing for 1.4% of
ascreenwidthofapproximately5 cm(horizontal) 9 7.5 cm
participants.
123
CognTherRes(2014)38:200–216 203
Fig.2 Trialscreensequence
fordot-probeattentionbias
assessmentandtraining.Images
aretoscale,astheyappearedon
aniPhonemodel3GS
(vertical).ScreenshotsfromaniPhone3GSillustrate,toscale, quickly as possible indicating whether an E or F was
thesequenceofscreensandtimingsforonetrialofdot-probe present. In the control version of the task (given to the
training/assessment(Fig. 2).WeimplementedCBM-Aona CON group), the probe replaced each type of face equally
website by using JavaScript and HTML code for task pre- often. In the active training version (given to the CBM-A
sentationandresponsecollectionwithMySQLandPHPcode group),theprobereplacedtheneutral(nonthreatening)face
forserver-sideprogramming.Instructionswalkedparticipants every time a neutral-threat face pair appeared. Thus, the
throughcreatingahomescreenshortcuticon.Hence,theuser goal was for participants to learn implicitly to attend to
experienceofaccessingthetrainingpageresembledthatofa neutralratherthantothreatfaces,andtodisengagequickly
mobile app, but it lacked an app’s typical user-friendly iftheirattentionwascapturedfirstbythethreatfaces.Each
interface.Inselectingabrowserwebappinsteadofanative training session comprised 80 trials. The median session
app,weconsideredtimingprecisionissues.Largedifferences duration was 2.24 min, and most sessions (86.6 %) took
in precision have little impact on reaction time task scores 2–2.5 min to complete.
(Damian2010;UlrichandGiray1989),minimizingconcerns
aboutusingawebapp. Smartphone Attention Bias Assessment Task
In this paradigm, a fixation cross appeared for 500 ms,
followedbythesimultaneouspresentationoftwofacesfor Participants used the same device for assessment as for
500 ms. One face appeared on top, and the other appeared training. Also, the stimuli were the same. In using the
on the bottom of the screen. On any given trial, both faces training stimuli in assessment, we intended to maximize
were of the same model.2 In 20 % of the trials, the model the chance of detecting a change in attention bias during
displayed the identical neutral expression, whereas in the the experiment. Indeed, our previous study’s data failed to
remaining80 % of the trials the modeldisplayed a neutral show attention bias reduction for new stimuli (Enock and
expressionandathreateningexpressionconveyingdisgust. McNally 2010, summarized in Enock and McNally 2013).
Immediately thereafter, a probe replaced one of the two The assessment task differed from training in that each
faces.TheprobewaseitheranEoranF.Theparticipants’ session comprised 160 trials, and that all trials involved
task was to push one of two buttons on the screen as threat-neutral facial pairs.
2 Duetoaprogrammingerror,intwooftheeightpairs,thefaceof
Modified Posner Cueing Task
onemodel(IDYY2)waspairedwiththefaceofanothermodel(ID
ES2) who shared similar features. Because many participants had
already completed training when we discovered this problem, we Local participants able to visit our laboratory (n = 62)
maintainedthesamestimulithroughoutthestudywithoutmentioning performed a modified Posner cueing task on a desktop
it to participants. Two participants reported noticing the mismatch.
computerwiththeGoogleChromebrowser,a19’’monitor
However,theerrordidnotviolatetherequirementforattentionbias
modificationthateachpairconsistofaneutralandathreatstimulus. with a 5:4 aspect ratio. The task was programmed via
123
204 CognTherRes(2014)38:200–216
JavaScriptand HTML.Thedistancefrom the participants’ Table1 Reliability coefficients for internal consistency and test–
eyes to the screen was 50–70 cm. We used the method of retestreliability
Amir et al. (2003), including their positive, neutral, and r,CBM-A r,CON
social threat words. In this paradigm, a black screen
Smartphone-delivereddot-probe
appeared with two white box outlines on either side (left
and right) of a fixation cross (‘‘?’’) for 500 ms. A word Internalconsistency
then appeared in one of the boxes for 250 ms, after which Preassessment/practice -.05 .00
anasteriskappearedineitherthesamebox(avalidcue)or Day2 .07 -.23
the other box (an invalid cue). On some trials, no word Week1 .18 .14
appeared (no cue). Holding the mouse in both hands, with Week2 .35 .04
theirthumbsonthemousebuttons,participantspressedthe Week3 .50 .39
left or right button to indicate on what side the asterisk Week4(postassessment) .53 .31
appeared. Response latencies typically show a cue depen- Test–retestreliability
dency effect; that is, mean latencies are lower for validly Preassessment-day2 -.25 .05
cuedtrialsthanforinvalidlycuedtrials,withuncuedtrials’ Day2–week1 .08 -.13
mean latency falling midway between that of validly and Week1–week2 .45** .26*
invalidly cued trials. Participants performed 24 practice Week2–week3 .70* .49**
trials and 288 training trials per session, including three Week3–week4 .61** .63**
rest breaks. Participants were orally instructed that the PC-deliveredmodifiedPosnertask
asterisk would usually, but not always, appear in the same Internalconsistency
locationasthewordandtoldtoperformthetaskasquickly Preassessment -.22
and as accurately as possible. The session took about Week4(postassessment) -.04
10 min. Test–retestreliability
Pre–postassessment .07
Social Interaction Anxiety Scale (SIAS)
Values have been augmented by the Spearman–Brown formula for
estimating full-length reliability from split halves. The Monte Carlo
The SIAS (Mattick and Clarke 1998) is a self-report reliability estimation method used precludes significance testing;
measure of social anxiety, psychometrically strong in hence, p values were not calculated. Modified Posner cueing task
reliabilityestimateswereperformedwithgroupscombined
online administration (Hedman et al. 2010). The SIAS-17
excludes the three reverse-scored items, reducing its Significancekey:*p\.01;**p\.001
overlap with extraversion (Rodebaugh et al. 2007). We
used the full version for screening and the SIAS-17 as an
version (Zlomke 2009). In our data, internal consistency
outcome measure. In our data, internal consistency was
was acceptable (a = .93–.95).
acceptable (SIAS at preassessment, a = .85; SIAS-17
across assessment points a = .85–.95).
Depression Anxiety Stress Scales, 21-Item Version (DASS)
LiebowitzSocialAnxietyScale,Self-ReportVersion(LSAS-
The DASS (Lovibond and Lovibond 1995) measures
SR)
depression,anxiety,andstress.Weincludeditprimarilyto
assess depression. We employed the 21-item version (An-
TheLSAS-SR(Bakeretal.2002;Coxetal.1998)assesses
tony et al. 1998) and report results from the DASS
fear and avoidance in social and performance situations.
depression subscale. In our data, internal consistency was
Theself-reportversionhassimilarproperties(Frescoetal.
acceptable (DASS-Depression, a = .90–.95).
2001) to the clinician-administered version of the scale
(Liebowitz1987),asdoestheInternet-administeredLSAS-
SR (Hedman et al. 2010). In our data, internal consistency Reliability of Smartphone-Delivered Attention Bias
was acceptable (Fear subscale, a = .91–.96; Avoidance Assessments
subscale, a = .91–.95).
To estimate the internal consistency of the smartphone-
Penn State Worry Questionnaire (PSWQ) deliveredattentionbiasassessments,weemployedaMonte
Carlo simulation process that repeats the steps (2,000
The PSWQ (Meyer et al. 1990) measures worry. The times)ofrandomlyreselectinghalvesandcalculatingsplit-
Internet-administered version shares the strong internal half reliability of bias scores of the halves (Enock et al.
consistencyandconcurrentvalidityofthepaper-and-pencil 2012). We used this method because other ones yield
123
CognTherRes(2014)38:200–216 205
unstableestimatesofbiasscorereliability(e.g.,Cronbach’s Participantscreatedaniconforeasyaccess,alongsidetheir
alpha or standard split-half reliability). home screen apps, and scheduled daily calendar reminders
For test–retest reliability, we calculated a Pearson-r for their training. Those who did not attend the laboratory
correlation of scores at each adjacent time point. In all sessions commenced training on their own, after an initial
reliabilityanalyses,weuseddatafromprotocolcompleters, email from us.
rather than the fullintention-to-treat (ITT) sample, and we Forthoseattendingthelaboratorysessions,intheinitial
excluded missing data, rather than employing last obser- meeting,theexperimenterexplainedtotheparticipanthow
vation carried forward (LOCF). Reliabilities were low or tousethedot-probetaskonhisorherhandhelddeviceand
nonsignificant for the first two time points (preassessment administered the modified Posner cueing task on a labo-
and Day 2) and significant in the later weeks. The results ratory computer. This took approximately 25 min.
appearinTable 1. We instructed participants to perform three training
sessions per day during the 4-week training period. We
Reliability of PC-Delivered Modified Posner Cueing Task askedthemtoperformonesessioninthemorning(4a.m.–
Assessments 12p.m.),onesessionintheafternoon(12p.m.–8p.m.),and
one session in the evening (8 p.m.–4 a.m.). Participants
Employing the Monte Carlo method described above, we could make up for missed sessions that evening, and they
analyzed CBM-A and CON together, due to the small werelimitedtothreesessionsperday.Dailyemailssentto
number of observations (41 preassessment and 37 postas- participantsremindedthemtocontinuetraining.Attheend
sessment sessions). Results showed no reliability in the of any session, participants could view the number and
attention bias scores (see Table 1). percentage of sessions they had completed. Participants
To ensure that our implementation of the task was completing fewer than 80 % of sessions in the previous
effectively measuring reaction times and that unreliability 5 daysorsincethestartsawthenotice,‘‘Agoodtargetisto
wasnotduetofactorssuchasparticipantdistractionorlack complete 80 %.’’
of effort during the task, we created scores for the cue Participants received emails containing links to the fol-
validity effect, collapsing across all word types. These lowingonlineassessmentbatteryofmeasuresonDay1,Day
scores do not measure attention bias and are not expected 8,Day15,Day22,Day29(thedayaftertheendoftraining),
torelate toother variables ofinterest in thisstudy. Rather, 1-month follow-up (Day 58), and 2-month follow-up (Day
they index the relative cost of a participant responding to 88):LSAS-SR,SIAS,PSWQ,andDASS.Duringthetrain-
an invalid cue compared with a valid cue. Reliability ing period, instructions asked participants to consider only
estimates for these cue validity scores were r = .83 at thepastweekfortheirresponses.Thetimingofsmartphone-
preassessment and r = .89 at postassessment, with a test– deliveredattentionbiasassessmentswasasfollows:OnDay
retest reliability of r(35) = .62, p\.001, suggesting that 1, participants completed a practice session with 80 trials
the task did measure reaction times suitably for reliable (including 16 trials where both faces showed neutral
assessment. expressions, in addition to 64 critical trials), which also
servedaspreassessment.Ourprimaryattentionbiasassess-
Procedure mentsalloccurredaftertraininghadbegunandparticipants
hadpracticedonthedot-probetask,withsessionsconsisting
Participants began by completing the consent form and of160trialsonDay2,Day8(henceforthWeek1),Day15
answeringquestions online as they signed up for the study (Week 2),Day22(Week3),andDay 28(Week 4orpost-
via KeySurvey, a web survey platform. They answered assessment). They completed these assessment sessions
demographic questions before completing the SIAS and upon visiting the training web page, before doing any
PSWQ. We asked participants with a high score on either training on that day. Participants who did not visit the
measure (35 or higher on the SIAS or 56 or higher on the trainingpageonthescheduleddaycompletedthesessionthe
PSWQ) whether they were able to attend two laboratory nexttimetheyvisitedthetrainingwebpage.
sessions(pre-trainingandpost-training).Wedidnotscreen For participants who attended laboratory sessions, the
for other psychopathology, and nor did we inquire about second visit took place at approximately the end of the
current treatment at sign-up. Those who did not meet the trainingperiod.Theycompletedthefinalassessmentofthe
symptom cutoff scores or who declined to attend the lab- Posner task.
oratory sessions completed the procedure with online and All participants in training conditions were told their
email instructions only. condition and debriefed only after they had completed the
Eligible individuals visited a website that outlined the 2-month follow-up questionnaire. Those who withdrew
training protocol and provided instructions for accessing from the study were debriefed and told their condition if
the training web page on their handheld devices. they explicitly requested this information.
123
206 CognTherRes(2014)38:200–216
Participants in the WL condition completed the same moderate range (14–20 points; Lovibond and Lovibond
onlineassessmentbatteryofmeasuresatthesameintervals 1995) of depression symptom severity.
as participants in the training conditions, but they did not
use their handheld device for the study during the main Clinical Outcome Analyses
periodof4 weeks.Afterthisperiod,theybegan4 weeksof
the active training either immediately or at a convenient We report results from four measures separately: LSAS-
time for them. SR, SIAS-17, PSWQ,andDASS-Depression subscale.For
each measure, we first conducted a one-way ANOVA to
Data Analyses ensurethatpreassessmentscoresdidnotsignificantlydiffer
among the groups. Second, we conducted a 3 Group
We used SPSS software (SPSS Inc. 2009) for mixed (between-subjects factor: CBM-A, CON, WL) 9 5 Time
ANOVA analyses and R (R Development Core Team (within-subjects factor: preassessment, Week 1, Week 2,
2012) for all other analyses. Week 3, and postassessment) mixed ANOVA. In all clin-
ical outcome ANOVAs, Mauchly’s Test of Sphericity
Inclusion Criteria for Intention-to-Treat (ITT) Analyses indicated a lack of sphericity; hence, we employed the
Greenhouse-Geisser correction for all main effects of time
Our primary analyses involved an ITT approach on par- andtheGroup 9 Timeinteractioneffects.Weselectedthe
ticipantswithhighsocialanxiety,definedasanSIASofat ANOVAandLOCFmethodsfortheseanalyses,ratherthan
least 35 at preassessment. Heimberg et al. (1992) used an multilevel linear modeling, due to their customary use in
SIAScutoffof34,whichwasonestandarddeviationabove treatment research including CBM-A RCTs.
the mean of their community sample. In that study, the To further explore the main effects of time and inter-
cutoffclassified82 %ofthesocialanxietydisordersample action effects, we calculated pre–post change scores from
correctly as cases and 18 % of the community sample the postassessment (end of training) score minus the pre-
incorrectly as cases. assessment (prior to training) score. We then conducted
For inclusion in analyses, participants also needed to two-tailed Welch’s t tests on these scores. To assess whe-
havecompletedthepreassessmentself-reportmeasuresand ther scores declined significantly in each group, from
tohavebeenrandomized.ForthoseassignedtoCBM-Aor preassessmenttopostassessment,weemployedone-sample
CON, completing at least one training session signified t tests. To assess whether the degree of declines in scores
randomization, and for those in WL, there was no such differed between individual groups, we conducted inde-
requirement. Although 826 people completed screening pendentsamplesttestsforeachpair.Totestthehypothesis
measures, we were often unable to run participants thatchangescoresofbothtraininggroupstogetherdiffered
immediately following their signup, and some had waited fromthoseoftheWLgroup,weconductedacontrastwith
4 monthstobegin.Unsurprisingly,60.5 %ofthosesigning weights coded as 1 (CBM-A), 1 (CON), and -2 (WL).
up never began the study. Finally, we conducted two-tailed independent samples
The ITT analysis sample comprised 326 participants. t tests comparing the groups’ scores at postassessment and
Thegroupsizesweren = 158(CBM-A),n = 141(CON), at 2-month follow-up. We include Cohen’s d effect sizes
and n = 27 (WL). The lag between signup and preassess- for each t test.3
ment varied (M = 34.1 days, Mdn = 11, SD = 41.4). The size of the WL group (n = 27) in the ITT sample
Given the absence of a diagnostic interview in this study, was much smaller than that of the CBM-A (n = 158) and
clinical cutoff scores thatare both sensitive andspecific to CON (n = 141) groups. These unequal sample sizes
diagnostic status are useful. They provide metrics for between WL and the other groups would be problematic
estimating the proportion of individuals who might have forttestsifunequalvarianceswerepresent.Therefore,we
received a diagnosis of social anxiety disorder (SAD) or used Welch’s method in t tests, which does not assume
generalizedanxietydisorder(GAD)byclinicalinterviewat
preassessment if we had conducted interviews. In the ITT
sample,96.6 %ofparticipants’LSAS-SRscores exceeded
3 Allpvaluesaretwo-tailed.TtestsemployWelch’smethod(equal
30, signifying likely SAD (Rytwinski et al. 2009); 69.3 %
variancesarenotassumed).Thoseappearinginthesecondparagraph
of LSAS-SR scores exceeded 60, signifying likely gen-
under each symptom heading (e.g., under LSAS above) apply to
eralized SAD (Rytwinski et al. 2009); and 50.3 % of comparisons of change scores, whereas those in the third paragraph
PSWQ scoresexceeded 65,signifying likely GAD (Fresco apply to scores at one time, either postassessment or two-month
follow-up.Forpre–postCohen’sdeffectsizeswithineachgroup,we
et al. 2003). Although diagnostic cutoffs for the DASS-
usedtheformula(M -M )/SD .Forbetween-groupsCohen’s
Depression are unavailable, to our knowledge, the mean post pre pre
d effect sizes, we employed the standard Cohen’s d formula using
(M = 19.0) and median (Mdn = 16.0) fell within the pooledstandarddeviation,(M -M )/SD .
Group1 Group2 pooled
123
CognTherRes(2014)38:200–216 207
equal variances, and we also report Levene’s tests for analyses,focusingontheGroup 9 Timeinteractioneffect,
unequal variances. as well as t tests, all using LOCF for missing data.
Dot-Probe Attention Bias Score Analyses Modified Posner Cueing Task Attention Bias Score
Analyses
We calculated a bias score for each session by subtracting
themeanresponsetimeforthreat-locationprobesfromthe To focus on the most theoretically relevant tests and save
meanresponseforneutral-locationprobes.Hence,positive space, we calculated one bias score per session. As the
biasscoresrepresentattentionbiastowardthreatfaces,and difference between participants’ responses to social threat
negative bias scores represent bias away from threat, or, words and nonthreat words has the most theoretical inter-
equivalently, bias toward neutral faces. est, we first collapsed neutral and positive words into one
We analyzed bias scores in two ways: (1) a multilevel category, nonthreat. For each session, we then calculated
linear modeling approach tailored to the specific circum- cuevalidityeffectscoresforthreatandnonthreatwordsby
stances of the present data and missing data, and (2) a subtracting the mean response time for validly cued trials
traditional approach comprising ANOVA and t tests with from the mean response time for invalidly cued trials,
LOCF for missing data, often used in the CBM-A withintrialsofeachwordtype.Increatingabiasscorefor
literature. a session, we followed the logic of Fox et al. (2001) such
For the tailored analyses, we excluded preassessment/ thatthecue validityeffectshouldbelargerforthreattrials
practice sessions due to poor data quality (see Procedure than for nonthreat trials in socially anxious individuals.
andDataReductionsections).Duelargelytodropoutfrom Hence, we calculated the attention bias score by subtract-
the study, a sizable amount of dot-probe assessment data ing the cue validity effect score for nonthreat words from
points were missing, especially at later time points (e.g., the cue validity effect score for threat words. A bias score
26.8 %ofsessionsmissingatWeek4versus2.7 %atDay greater than zero signifies an attention bias toward threat.
2, 15.7 % at Week 2). The LOCF policy presupposes that We conducted statistical tests similar to those of the clin-
scores of any dropouts would have remained constant. In ical outcome pre–post analyses.
contrast, multilevel linear modeling does not make this
assumption, and it uses observed data to estimate missing
scores. Results
Multilevel linear modeling (a.k.a., linear mixed effects
modeling) is a form of regression appropriate for mixed Protocol Compliance
designs with between-groups conditions and repeated
measures assessments (Gelman and Hill 2007). Accord- Participant Dropout
ingly, we used model comparison methods to test the
hypothesis that CBM-A group bias scores would be lower We defined protocol completers as participants who met
thanthoseoftheCONgroupduringandaftertraining.This inclusion criteria for the ITT sample, completed postas-
is a test of the main effect of group, collapsed across sessment self-report measures at the end of Week 4, and
assessments, following the start of training, not an inter- completed at least 20 of the 83 training sessions in the
action effect. As to the Group 9 Time interaction effect, protocol for CBM-A or CON (not applicable for WL),
the hypothesis tested is that the difference between the which amounted to 1,280 critical training trials. Dropouts,
groups’ scores would change during the training. We defined as participants in the ITT sample who were not
employed the R package ‘‘nlme’’ (Pinheiro et al. 2010) completers, were n = 38 (24.1 %, CBM-A), n = 37
withmaximumlikelihoodestimationandanautoregressive (26.2 %,CON),andn = 0(WL).Inmostcases,wedidnot
correlation structure to model the presumptive pattern of obtain a reason from participants for their dropout; hence,
closer time points having closer scores than distant ones. we do not attempt to report reasons for dropout.
Bias score was the dependent variable. Participants were
modeled as a random effect, with intercepts allowed to Training Session Completion
vary. Time was entered as a continuous predictor.
For our traditional analyses, we included the preas- Out of the 83 training sessions in the 4-week protocol,
sessment/practice sessions. We also calculated one score participants(includingdropouts)performedameanof53.9
per participant, termed the Post Mean, to serve as post- sessions (64.9 %). Among protocol completers, a mean of
assessment, a mean of the five assessments that occurred 64.8(78.1 %)sessionswereperformed,andthenumberof
after training commenced. We employed mixed ANOVA sessionswasnotsignificantlycorrelated(allps[.11)with
123
208 CognTherRes(2014)38:200–216
Table2 Symptom measure means and standard deviations for changeonanyclinicaloutcomemeasure,ineithertraining
intention-to-treatanalysis condition.
CBM-A CON WL
(n=158)a (n=141)b (n=27)c
Symptom Assessment Completion
LSAS
Of the five weekly online self-report assessments, partici-
Pre 74.2(23.5) 72.8(24.3) 80.1(29.9)
pants completed 83.5 % (CBM-A), 83.3 % (CON), and
Post 57.6(30.7) 58.2(31.3) 75.0(34.7)
98.5 % (WL).
One-monthfollow- 57.5(29.3) 57.9(30.6) NAd
up
Two-monthfollow- 58.1(28.2) 57.3(31.4) NA Clinical Outcome Measures
up
Pre–postchange -16.6(22.9) -14.6(19.2) -5.1(22.4) Descriptivestatisticsfortheclinicaloutcomemeasuresare
Pre–postCohen’s -0.71 -0.60 -0.17 presented in Table 2.
de
SIAS-17 Tests for Unequal Variance Between Groups
Pre 43.2(8.8) 42.1(9.7) 47.1(11.7)
Post 33.9(13.9) 33.4(13.9) 44.4(14.2) Levene’s tests for unequal variances comparing CON and
One-monthfollow- 34.1(13.3) 32.7(13.8) NA WL scores were nonsignificant for all measures at preas-
up sessment, postassessment, and for pre–post change scores
Two-monthfollow- 34.7(13.5) 32.8(13.5) NA (all ps[.09).Forcomparing CBM-AandWLscores,Le-
up
vene’s testswere nonsignificant forallmeasuresatpostas-
Pre–postchange -9.3(10.5) -8.7(10.4) -2.7(8.2)
sessmentandforpre–postchangescores(allps[.15),but
Pre–postCohen’sd -1.06 -0.90 -0.23
significant for the preassessment SIAS-17 (p = .033) and
PSWQ
DASS-Depression (p = .025), suggesting unequal vari-
Pre 63.7(11.7) 62.2(13.7) 64(12.5)
ances.OnthepreassessmentSIAS-17,SD = 8.8forCBM-
Post 57.7(12.4) 57.6(14.2) 62.1(12.4)
A and SD = 11.7 for WL. On the preassessment DASS-
One-monthfollow- 57.5(12) 56.8(14.5) NA
Depression,SD = 10.2forCBM-AandSD = 13.0forWL.
up
Thus, the results of testing for unequal variance show no
Two-monthfollow- 57.1(12.8) 57(14.6) NA
significant differences between WL and either of the other
up
groups except for two instances where the preassessment
Pre–postchange -6.0(9.6) -4.6(7.5) -1.9(8.7)
varianceintheWLgroupwashigher.
Pre–postCohen’sd -0.51 -0.34 -0.15
DASS-depression
LSAS-SR
Pre 19.2(10.2) 18.1(10.9) 22.4(13)
Post 14.6(11.6) 14.1(12) 21.8(12.9)
On the LSAS-SR, scores at preassessment did not signifi-
One-monthfollow- 14.9(10.8) 14.7(11.6) NA
up cantly differ among the groups (F(2, 69.8) = 0.74,
Two-monthfollow- 14.6(11.5) 14.0(11.7) NA p = .48).The3Group 9 5TimemixedANOVAyieldeda
up main effect of time (F(2.7, 308) = 31.12, p\.001,
Pre–postchange -4.6(9) -4.0(8.3) -0.7(8.5) g2 = .088) and a trend of a main effect of group (F(2,
p
Pre–postCohen’sd -0.45 -0.37 -0.05 323) = 2.59, p = .077, g2 = .016). The Group 9 Time
p
interaction was significant (F(5.3, 308) = 2.67, p = .018,
ThesedataarefromITTanalyses.Missingdata,mainlyattributableto
studydropout,werefilledinviaLOCF.Valuesaremeanscoresonthe g p2 = .016).
givenscale,withstandarddeviationsinparentheses Scores decreased from pre to postassessment in the two
a Number of observations missing and filled via LOCF in CBM-A training groups (CBM-A, t(157) = -9.13, p\.001,
group, cumulatively: 0 (pre), 37 (post), 42 (1-month follow-up), 46 d = -0.71; CON, t(140) = -9.04, p\.001, d = -0.60)
(2-monthfollow-up)
but not significantly in WL (t(26) = -1.18, p = .25,
b Number of observations missing and filled via LOCF in CON
d = -0.17). Declines in CBM-A and CON did not differ
group, cumulatively: 0 (pre), 35 (post), 36 (1-month follow-up), 39
(2-monthfollow-up) (t(295.8) = -0.83,p = .41,d = -0.10)butdeclineswere
c Noobservationsmissing greaterinCBM-AversusWL(t(36.0) = -2.47,p = .018,
d WLparticipantswereofferedactivetrainingimmediatelyfollowing d = -0.51) and in CON versus WL (t(33.7) = -2.07,
theWLperiod;therefore,wedidnotcollectfollow-updatafromthem p = .046, d = -0.60). A contrast on pre–post change
e Cohen’sdwithineachgroupis(M -M )/SD scores with weights coded as 1 (CBM-A), 1 (CON), and
post pre pre
123
groups showed greater declines than the WL group
90
(t(34.3) = -3.74, p\.001). From postassessment to
85 2-month follow-up, scores did not change significantly
within CBM-A or CON (ps[.16).
80
SIAS-17 scores for CBM-A and CON did not differ at
75 postassessment (t(292.8) = 0.28, p = .78, d = 0.03) or at
2-month follow-up (t(292.8) = 1.20, p = .23, d = 0.14).
70
However,CBM-AandWLscoresdifferedatpostassessment
(t(35.0) = -3.57, p = .001, d = -0.76), as did CON and
65
WLscores(t(36.2) = -3.69,p\.001,d = -.79).
60
PSWQ
55
Pre Week 1 Week 2 Week 3 Post 1−month 2−month
(Week 4) follow−up follow−up OnthePSWQ,scoresatpreassessmentdidnotsignificantly
Time
differamongthegroups(F(2,73) = 0.55,p = .58).The3
Group 9 5 Time mixed ANOVA yielded a main effect of
time (F(2.9, 308) = 19.75, p\.001, g2 = .058) but no
p
main effect of group (F(2, 323) = 1.15, p = .32,
g2 = .0071).TheGroup 9 Timeinteractionwassignificant
p
-2 (WL) confirmed that the two training groups showed (F(5.7,308) = 2.27,p = .038,g2 = .014).
p
greaterdeclinesthandidWL(t(30.3) = -2.36,p = .025). Scores decreased from pre to postassessment in the two
From postassessment to 2-month follow-up, scores did not training groups (CBM-A, t(157) = -7.84, p\.001,
change significantly within CBM-A or CON (ps[.48). d = -0.51; CON, t(140) = -7.32, p\.001, d = -0.34)
LSAS-SR scores for CBM-A and CON did not differ at but not significantly in the WL group (t(26) = -1.14,
postassessment (t(291.9) = -0.17, p = .87, d = -0.02) p = .26, d = -0.15). Declines in CBM-A and CON did
or at 2-month follow-up (t(283.3) = 0.21, p = .83, not differ (t(292.3) = -1.36, p = .17, d = -0.16), but
d = 0.02). However, CBM-A and WL scores differed at declines were greater in CBM-A versus WL (t(37.5) =
postassessment (t(33.3) = -2.45, p = .020, d = -0.56), -2.19, p = .034, d = -0.43). Declines were not signifi-
as did CON and WL scores (t(34.6) = -2.35, p = .025, cantly greater in CON versus WL (t(33.7) = -1.50,
d = -0.53). p = .14,d = -0.35).Acontrastonpre–postchangescores
For a comparison of LSAS-SR scores across all time withweightscodedas1(CBM-A),1(CON),and-2(WL)
points and conditions, see Fig. 3. suggested that the two training groups showed a trend
toward greater declines versus WL (t(30.7) = -1.93,
SIAS-17 p = .063). From postassessment to 2-month follow-up,
scoresdidnotchangesignificantlywithinCBM-AorCON
On the SIAS-17, scores at preassessment did not signifi- (ps[.29).
cantly differ among the groups (F(2, 69.4) = 2.22, PSWQ scores for CBM-A and CON did not differ at
p = .12).The3Group 9 5TimemixedANOVAyieldeda postassessment (t(279.6) = -0.08, p = .94, d = -0.01)
main effect of time (F(2.4, 308) = 42.54, p\.001, or at 2-month follow-up (t(280.1) = 0.02, p = .99,
g2 = .12) and a main effect of group (F(2, 323) = 6.54, d = 0.002). Likewise, WL scores did not significantly
p
p = .002, g2 = .039). The Group 9 Time interaction was differ, at postassessment, from CBM-A scores
p
significant (F(4.9, 308) = 5.05, p\.001, g2 = .030). (t(35.5) = -1.69, p = .10, d = -0.35) or from CON
p
Scores decreased from pre to postassessment in the two scores (t(33.7) = -1.50, p = .14, d = -0.35).
training groups (CBM-A, t(157) = -11.11, p\.001,
d = -1.06;CON,t(140) = -10.02,p\.001,d = -0.90) DASS-Depression
but not significantly in the WL group (t(26) = -1.75,
p = .092, d = -0.23). Declines in CBM-A and CON did On the DASS-Depression, scores at preassessment did not
not differ (t(294.2) = -0.47, p = .64, d = -0.06), but significantly differ among the groups (F(2, 69.9) = 1.43,
declines were greater in CBM-A versus WL (t(42.4) = p = .25).The3Group 9 5TimemixedANOVAyieldeda
-3.70, p\.001, d = -0.64) and in CON versus WL main effect of time (F(3.3, 308) = 9.84, p\.001,
(t(43.8) = -3.34, p = .0017, d = -0.60). A contrast on g2 = .030) and a main effect of group (F(2, 323) = 3.85,
p
pre–postchangescoreswithweightscodedas1(CBM-A), p = .022, g2 = .023). The Group 9 Time interaction was
p
1 (CON), and -2 (WL), confirmed that the two training not significant (F(6.6, 308) = 1.28, p = .26, g2 = .008).
p
RS−SASL
CognTherRes(2014)38:200–216 209
Condition
CBM−A
CON
WL
Fig.3 LSAS-SR scores during main protocol and follow-up. This
figuredepictsthemeansandstandarderrors,withmissingdatafilled
viaLOCF
123
210 CognTherRes(2014)38:200–216
Because we had a priori hypotheses requiring group practicetrialsandthenoveltyofthetask),andtheelimina-
comparisons, we analyzed pre–post change scores despite tionof2.3 %oflatersessions.Withintheremaining301,287
thenonsignificantGroup 9 Timeinteractioneffect.Scores trials considered together, the descriptive statistics were
decreased from pre to postassessment in both training M = 706.9 (SD = 173.1) across all trials, M = 701.5
groups (CBM-A, t(157) = -6.45, p\.001, d = -0.45; (SD = 171.2) for neutral trials, and M = 706.1
CON, t(140) = -5.82, p\.001, d = -0.37), but not (SD = 170.7)forthreattrials.
significantly in the WL group (t(26) = -0.41, p = .69,
d = -0.05). Declines in CBM-A and CON did not differ Effects of Training Group on Bias Scores
(t(296.7) = -0.57, p = .57, d = -0.065), but declines
were greater in CBM-A versus WL (t(36.6) = -2.21, In the multilevel linear modeling analyses tailored to the
p = .034, d = -0.44). There was a trend of a greater present study’s data, we used three models to test our
decline in CON versus WL (t(36.0) = -1.90, p = .066, hypotheses.InModel1,timewasthesolepredictor,andit
d = -0.41). A contrast on pre–post change scores with showedasignificantdecreaseinscoresovertime,inCBM-
weights coded as 1 (CBM-A), 1 (CON), and -2 (WL) A and CON combined (b = -1.50, t(980) = -3.11,
showed that the two training groups showed greater p = .0019). To explore this effect, we constructed Model
declines than did WL (t(31.0) = -2.14, p = .040). From 1-CBM-AandModel 1-CON, usingonly datafrom CBM-
postassessment to 2-month follow-up, scores did not AandCONgroups,respectively.Thepredictorcoefficients
change significantly within CBM-A or CON (ps[.88). fromthesemodelsshowedasignificantdecreaseovertime
DASS-Depression scores for CBM-A and CON did not within CBM-A (b = -1.82, t(516) = -2.59, p = .0098),
differ at postassessment (t(290.7) = 0.36, p = .72, and a similar, nonsignificant trend within CON (b =
d = 0.04) or at 2-month follow-up (t(291.7) = 0.46, -1.12, t(463) = -1.72, p = .087).
p = .64, d = 0.05). However, CBM-A and WL scores To assess whether training group (CBM-A vs. CON)
differed at postassessment (t(33.6) = -2.72, p = .010, affected bias scores, we then created Model 2, identical to
d = -0.61),asdidCONandWLscores(t(34.6) = -2.35, the first, but with the group main effect included as a
p = .025, d = -0.53). predictor.Basedonalikelihoodratiotest,Model2showed
a significantly better fit to the data than Model 1
Smartphone-Delivered Dot-Probe Attention Bias (v2(1) = 4.42, p = .036), with group as a significant pre-
Assessments dictor (b = 4.21, t(294) = 2.11, p = .036), showing the
group main effect, that scores significantly differed
Data Reduction between groups, considering all time points during and at
the end of training. To test the direction of the effect, we
We performed data reduction on all dot-probe attention examinedthe coefficient for thegroup effectinthesecond
bias assessments collected, including participants whose model. Its value (b = 4.21, with CBM-A as the reference
SIASpreassessmentscoresfellbelowthecutoffneededfor group) reflected a model-estimated mean 4.21 ms higher
inclusion in the ITT sample. The 429 participants who for the CON group compared to CBM-A, thus confirming
began the study completed M = 5.37 assessments out of that training acted in the intended direction.
the six possible. The days of assessment varied, as partic- To test the interaction effect, addressing the hypothesis
ipantscompletedassessmentsthefirsttimetheyvisitedthe thatscoreswouldincreasinglydivergebetweengroupsover
training website after a given assessment day. time,wecreatedModel3,identicaltoModel2,butwiththe
We eliminated outlier reaction times through several Group 9 Timeinteractionincludedasapredictor.Basedon
steps,definedaprioribeforeweexaminedtheresults.From alikelihoodratiotest,Model3didnotshowasignificantly
334,480 trials, we removed inaccurate responses (3.51 %), better fit than Model 2 (v2(1) = 0.53, p = .47), indicating
then responses under 200 ms (0.6 % of accurate trials) or thattherewasnosignificantinteractioneffect.Takentoge-
above 1,500 ms (2.4 % of accurate trials), and, finally, ther,thenonsignificantinteractionandthesignificantgroup
responsesmorethantwostandarddeviationsbelow(0.16 % maineffectsuggestthatscoresdiverged(withasmalleffect)
oftheremainder)orabove(4.3 %oftheremainder)themean very soon after training commenced, but did not diverge
responsetime(calculatedideographicallywithinindividual furtherthroughouttheremainderoftraining.
sessions).Afterthesesteps,90.1 %ofresponsesremained. For traditional analyses, we used the preassessment/
We also eliminated and treated as missing any sessions in practicescore,thePostMeanscore,andLOCFformissing
which fewer than 75 % of trials remained after outlier data.WeconductedatwoGroup(between-subjectsfactor;
removal,resultingintheeliminationof11.2 %ofpractice/ CBM-A, CON) 9 2 Time (within-subjects factor; Preas-
preassessment sessions, for which responses tended to be sessment, Post Mean) mixed ANOVA. The main effect of
more variable (likely due to this session’s instructions as time was significant (F(1, 266) = 6.65, p = .010,
123
g2 = .024), indicating that scores decreased over time
p 5
(collapsing across groups). The Group 9 Time interaction
was nonsignificant (F(1, 266) = 0.27, p = .60,
g2 = .001), indicating that the degree of change in scores p
over time did not depend on group. 0
In between-groups t tests, at preassessment, scores for
CBM-A and CON did not differ in the ITT sample
(t(239.6) = -0.11, p = .91, d = -0.013). The Post Mean −5
scores comparison fell short of significance (t(294.0) =
-1.77, p = .078, d = -0.20), although a one-tailed ver-
sion of the test indicated lower scores in CBM-A than in
−10
CON (p = .039). Additionally, a two-tailed test on proto-
col completers (thus obviating LOCF) was significant
(t(211.0) = -2.86, p = .0046, d = -0.37).
−15
In within-groups t tests, preassessment scores did not
Pre Day 2 Week 1 Week 2 Week 3 Post
differ from zero in either CBM-A (t(142) = -0.51, (Week 4)
Time
p = .61, d = -0.042) or CON (t(125) = -0.52, p = .61,
d = -0.046), but Post Mean scores were significantly
lower than zero in both CBM-A (t(155) = -4.58,
p\.001, d = -0.37) and CON (t(139) = -2.24,
p = .026, d = -0.19). Change scores (Post Mean minus
preassessment)revealedsignificantdecreasesinbiasscores
from pre to post within the CBM-A group (t(141) = Withintheremaining30,787trialsconsideredtogether,the
-2.31,p = .022,d = -0.19)butnotCON(t(125) = -1.38, mean and standard deviation across all trials were
p = .17, d = -0.12). M = 391.3 (SD = 98.5).
SeeFig. 4foraplotofmeansandstandarderrorsofbias
scores. Effects of Training Group on Bias Scores
PC-Delivered Modified Posner Cueing Task Attention First,weperformedanalysesofsessiondatatoconfirmthat
Bias Assessments spatial cueing had the intended effect on response times,
namely, that validly cued trials prompted faster responses
Data Reduction than invalidly cued trials. Collapsing across all three word
types,wecalculatedeachsession’smeanresponsetimefor
Weeliminatedoutlierreactiontimesthroughseveralsteps, validlycuedtrials,forinvalidlycuedtrials,andforuncued
using a similar trimming process as for data from the trials. A one-way ANOVA on the three trial types was
smartphone-delivered dot-probe task, adjusted for the fas- significant for pre (F(2, 83.5) = 12.32, p\.001) and
terresponsesobservedonthistask.Ofthe429participants postassessment (F(2,71.3) = 16.68, p\.001). As expec-
who began the study (disregarding the SIAS cutoff crite- ted, mean responses to invalidly cued trials were slower
rionneededforinclusionintheITTsample),62visitedthe thantovalidlycuedtrials atpre(t(82.8) = 3.67,p\.001,
laboratory to complete a modified Posner cueing task d = 0.79) and postassessment (t(70.1) = 4.31, p\.001,
assessment on the computer. There were n = 62 preas- d = 1.00). Mean responses to uncued trials were slower
sessment sessions, from Day 1 of training, and n = 53 than to valid trials at pre (t(81.6) = 4.62, p\.001,
postassessment sessions from Week 4 of training. From d = 1.00) and postassessment (t(68.9) = 5.30, p\.001,
33,298 trials, we removed inaccurate responses (1.49 %), d = 1.23), but their mean response times did not signifi-
thenresponsesunder 100 ms(0.80 %ofaccurate trials)or cantly differ from invalidly cued trials at pre
above 1,200 ms (0.28 % of accurate trials), and, finally, (t(83.7) = 1.00, p = .32, d = 0.22) or postassessment
responses more than two standard deviations below (t(71.8) = 1.04, p = .30, d = 0.24), though they were
(1.03 % of the remainder) or above (4.1 % of the nominally slower (by 17.1 ms at preassessment and
remainder) the mean response time (calculated ideo- 15.3 ms at postassessment).
graphically within individual sessions). After these steps, Forty-three participants included in our ITT analyses
94.88 % of responses remained. No session had less than visited our laboratory and completed the modified Posner
82 % of trials remaining after trimming, thus we did not cueing task. None of these individuals dropped out of the
eliminate any sessions due to the quality of responses. study. At preassessment, scores did not significantly differ
)sm(
erocs
saiB
CognTherRes(2014)38:200–216 211
Condition
CBM−A
CON
Fig.4 Smartphone-delivered dot-probe attention bias assessment
scores.Thisfiguredepictsthemeansandstandarderrors.Formissing
data,weusedamultilevellinearmodel(describedasModel3inthe
‘‘Results’’section)forposthocpredictionofeachvalue
123
212 CognTherRes(2014)38:200–216
from zero in either group (CBM-A: t(20) = -0.72, behavioral, and physiological measures of anxiety in par-
p = .48, d = -0.16); CON: t(21) = 1.07, p = .30, ticipantswhofearedpublicspeaking(McNallyetal.2013).
d = 0.23), nor did they significantly differ between CBM- However, we did find that both CBM-A and CON
A and CON (t(40.1) = -1.28, p = .21, d = -0.39). A training reduced social anxiety more than did WL. Fur-
comparison of pre–post change scores between groups thermore, the decreased symptom levels for CBM-A and
revealednosignificantdifferencesinchangeinbiasscores CON were stable from postassessment through follow-up.
over time (CBM-A vs. CON: t(33.2) = 1.40, p = .17, What caused these reductions? Perhaps the data permit
d = 0.46).Thenominaldifferenceinchangescoreswasin onlyonefirmconclusion:Theactiveingredientwasnotthe
the opposite direction than the intended effect of training, contingency of probe placement, as the no-contingency
as CBM-A group scores nominally increased, whereas CON was as helpful as CBM-A. Medication treatments
CON group scores nominally decreased. involve placebo effects, and researchers label some bene-
ficial aspects of psychotherapy as ‘‘nonspecific factors.’’
The present study’s CBM-A and CON participants pre-
Discussion sumably benefitted from some nonspecific effects; how-
ever, such effects are not easily demarcated from specific
In a double-blind RCT, we tested the effects of CBM-A ones. For example, if, hypothetically, one’s use of any
training, CON training, and waitlist on participants’ distracting mobile app when feeling anxious were benefi-
symptoms of social anxiety, worry, and depression, while cial,thenwecoulddefineittobeeitheraspecificfactorfor
also assessing attention bias with a remote smartphone- mobile app treatments or a nonspecific factor for CBM-A
delivered dot-probe task and an in-laboratory PC-deliv- or CON training compared with other mobile app treat-
ered modified Posner cueing task. We demonstrated the ments. Perhaps active use of any computerized treatment
feasibility of delivering CBM-A via smartphones in short, tool, such as a mobile app treatment, could instill partici-
frequent sessions, as well as the feasibility of conducting pants with confidence that their social anxiety will
a relatively large, low-cost, minimal contact, web-based improve. Bolstered confidence, in turn, may foster greater
RCT. The internal consistency and test–retest reliability comfort in social interaction, thereby attenuating social
findings for the dot-probe assessments demonstrated that anxiety.Ontheotherhand,previouslaboratorystudiesdid
smartphones are viable for reaction time task assessments. find superiority for CBM-A over CON training. By
We found no greater symptom declines in CBM-A than in employing several comparison conditions to isolate treat-
CON on measures of social anxiety, worry, and depres- ment factors, future investigations may clarify which spe-
sion, although both CBM-A and CON training groups cific aspects are clinically useful and, importantly,
showed significantly greater symptom declines than did replicable in studies of computerized cognitive training.
WL on measures of social anxiety. The effects of CBM-A In this study, the effects of training on CBM-A com-
versus CON training on attention yielded only small pared to CON dot-probe attention bias scores were sig-
differences in dot-probe attention bias scores and no nificant when we employed data analytic methods tailored
significant differences in modified Posner cueing task to the study’s five assessments during and after training,
scores. addressing missing data via multilevel linear modeling.
Our primary test was of whether CBM-A would reduce Yet, the effects of training on dot-probe bias scores were
socialanxietymorethanwouldCON.Itdidnot:Symptom small, and some traditional statistical analyses revealed a
change in the two groups showed a very similar pattern nonsignificant group by time interaction. The modified
across all time points. Several RCTs testing similar CBM- Posner cueing task detected no attentional effects of
A and control protocols with individuals diagnosed with training.Thus,thetrainingconditionsmaynothavehadthe
social anxiety disorder have likewise found no significant intendedimpactonattentionbias.Itispossiblethatweekly
differences in symptom change between conditions. Four dot-probeassessmentcouldhaveinterferedwithtrainingin
studiesemployedhome-basedPCtraining(Boettcheretal. the CBM-A group, though the training sessions were far
2012, 2013; Carlbring et al. 2012; Neubauer et al. 2013), more frequent than assessment sessions.
and two used laboratory-based PC training (Bunnell et al. Pragmatically, any factors that confer symptom reduc-
2013;Sawyeretal.2012).Giventhenumberofstudiesand tion are important. Hence, elements common to CBM-A
their larger sample sizes finding no significant differences, and CON may warrant further investigation. They may
theevidencenowsuggeststhatthebenefitsofCBM-Aover reduce anxiety, but not necessarily through reducing
control training for treating social anxiety are very limited attention bias for threat. The magnitude of the LSAS-SR
or highly inconsistent. Indeed, another multi-session, lab- decline in the CON group was substantial, alongside the
based study revealed indistinguishably significant reduc- declineintheCBM-Agroup.DeclinesinLSASandLSAS-
tions for CBM-A and CON groups on self-report, SR scores have varied widely across CBM-A RCTs, and
123
CognTherRes(2014)38:200–216 213
Table3 LSAS/LSAS-SRscoresinCBM-Atrialstargetingsocialanxietysymptoms(ordisorder)
CBM-A CON Differenceinchange
n Pre Post Change n Pre Post Change
Amiretal.(2009b) 22 74.5 46.1 -28.4 22 68.1 60.0 -8.1 -20.3
Schmidtetal.(2009) 18 80.8 68.5 -12.3 18 80.7 78.0 -2.6 -9.6
Boettcheretal.(2012) 33 83.1 64.7 -18.4 35 80.5 64.6 -15.9 -2.5
Carlbringetal.(2012) 40 73.8 66.0 -7.8 39 73.0 60.5 -12.5 4.7
Heerenetal.(2012)a 20 82.1 61.0 -21.1 18 79.5 62.9 -16.6 -4.5
Neubaueretal.(2013) 30 69.9 65.8 -4.0 29 63.4 65.6 2.2 -6.2
Sawyeretal.(2012) 15 72.8 61.9 -10.9 16 79.6 65.0 -14.6 3.7
Boettcheretal.(2013) 43 74.7 62.1 -12.6 43 73.2 57.6 -15.6 3.0
Bunnelletal.(2013) 15 86.7 59.9 -26.7 16 76.8 66.4 -10.4 -16.3
Enock&McNally(2010) 16 47.6 35.4 -12.2 NA NA NA NA NA
Presentstudy,ITTanalysis 158 74.2 57.6 -16.6 141 72.8 58.2 -14.6 -2.0
Presentstudy,protocolcompletersonly 120 73.4 53.9 -19.5 104 73.0 56.1 -16.9 -2.6
ScoresarefromtheLSAS-clinicianadministeredversion(Amiretal.2009b;Sawyeretal.2012;Schmidtetal.2009)orLSAS-SR(allother
studies) in trials employing dot-probe CBM-A tasks with socially anxious individuals. Scores reflect group means at preassessment and
postassessment,aswellasthepre–postchange.Thecolumnlabeled‘‘differenceinchange’’showsthedifferencebetweenLSASchangeinCBM-
AversusinCON.Therearevariousdifferencesacrossstudiesintheirproceduresandhandlingofmissingdata
a InHeerenetal.(2012),duetothebrieftrainingperiod,thefollow-upscores(CBM-A,51.1;CON,71.2;differenceinchange,-22.7),are
highlyrelevant,aswellasthepostassessmentscoresshownbelowforconsistencywiththetablecolumns
the means from other trials and the present one are shown (e.g., Wald et al. 2011). Several reliability estimates had
in Table 3, for comparison. Our study alone has a waitlist negativevalues.Explorationofthisphenomenonisbeyond
group, essential for evaluating symptom decline without the scope of this article, but this issue has seemingly sur-
treatment. Future reviews, meta-analyses, and experiments faced in past studies of reliability (e.g., Schmukle 2005;
shouldprobewhethertherearemoderatorsofthetreatment Staugaard 2009) where some negative reliability estimates
effects of CBM-A, control training, and waitlist. For emerged, and the problem exists for Cronbach’s alpha as
example, participants may harbor differing expectations. well as split-half reliability.
They may commence training with the belief that the Thefindingofsubstantialdot-probeattentionbiasscore
procedure is merely experimental and unproven as effec- reliabilityinlaterweeksdemonstratesthatsmartphonesare
tive, or they may commence training with the perspective capable of delivering reliable reaction-time based assess-
that the procedure is a high-tech, powerful new treatment. mentsthatareatleastasgoodasthoseadministeredviaPC
Howclinicalresearchersrecruitparticipantsmayshapethe (Ataya et al. 2012; Browning et al. 2011; Schmukle 2005;
perceptions of those enrolled in the study. In our study, Staugaard2009;Waechteretal.2013).Unfortunately,few
participantsweretreatment-seekers,motivatedtoattempta dot-probe studies have reported reliability estimates. The
novel treatment to better their condition, receiving no smalldifferencesinbiasscoresbetweentraininggroups,in
financial compensation, as in some other CBM-A studies. the context ofhigh test–retest reliabilityfrom Week 3 to4
As another contextual issue, perhaps in-laboratory situa- (r(215) = .63, p\.001, missing data excluded), suggests
tions affect participants’ anxiety and attentional bias in thatparticipantsmaynotrespondtotrainingaspredictably
contrasttoremote-deliverysituations.Anyofthesefactors as researchers might expect. The reliability suggests con-
may mobilize beneficial nonspecific effects. sistencyacrossthetwosessions:Participantswerelikelyto
The reliability data for the attention bias assessment maintain similar scores at these two times. Hence, their
taskswereinformative.Wefoundthatattentionbiasscores differential responses to the task’s threat and neutral trials
fromthemodifiedPosnercueingtaskwereunreliableeven maintained a similar pattern. However, for Week 4 alone,
though the cue validity scores across all word types were CBM-A group scores showed only a small, nonsignificant
highlyreliable.Thishighlightsthechallengesofmeasuring difference compared to CON. Despite having performed
attention bias. It is unclear what factors may cause indi- approximately 4,000 trials with probes appearing in the
vidual differences in attention bias to emerge and then to location of the same eight neutral face stimuli, CBM-A
bedetectable ornotindifferent studies, butoneissue may participants’responsesdidnotreflectoptimaldetectionand
be the tendency of attention bias scores to shift towards rapid response to probes in their predictable locations.
threat-avoidance when a sample is exposed to acute stress Peoplemaynotbehavesouniformlyandconvenientlyasto
123
214 CognTherRes(2014)38:200–216
optimize their reaction time task performance based on Thedot-probetaskfortrainingandassessmentappeared
contingencies within long bouts of repetitive training. on smartphones’ small screens, and we did not attempt to
Our study leveraged advantages of web-based research control participants’ viewing distance. Distance from eyes
andtreatment.IncontrasttotraditionalRCTswithin-clinic to screen, stimulus size, and visual angles have varied
treatment and clinician assessments, requiring extensive widely in computer-based studies, so this concern is not
resources and staff, our trial needed only one doctoral unique to the present study. One potential concern intro-
student and two research assistants to run hundreds of duced by the smartphone adaptation of the task is the
volunteers. The resulting sample size exceeded that of any appearanceoftheEandFresponsebuttonsonthesidesof
published trial concerning cognitive bias modification. In the screen, simultaneously appearing with the letter probe.
total, participants performed over 20,000 training sessions This arrangement could affect participants’ attention in
andtappedontheirscreensapproximately2milliontimes, unknown ways. Based on the instructions, participants’
as we recorded their reaction times remotely. The training thumbs may have partially covered the on-screen response
sessions were more evenly distributed over time than in buttons.
previous studies, and the amount of training overall was Dropout rates from the ITT sample were substantial in
high. Participants who completed the study performed an bothCBM-AandCONtraininggroups,whereastherewere
average of 3,450 critical training trials, a greater number no dropouts from WL. There could be many reasons for
than other 4-week RCTs of CBM-A to reduce social anx- this, but this difference suggests the need for increased
iety: 1,024 critical trials across eight sessions were in tolerability of training. Our attempt to increase tolerability
training protocols for Amir et al. (2009b), Boettcher et al. for this study consistent of making sessions shorter and
(2012), Bunnell et al. (2013), Carlbring et al. (2012), more accessible, to allow participants to work the training
Neubauer et al. (2013), Sawyer et al. (2012), and Schmidt into their daily lives less obtrusively than long blocks of
et al. (2009). The amount in the present study was com- training. Future efforts to increase the tolerability, or even
parable to more concentrated training designs (Li et al. the pleasure, of training methods could reduce dropout.
2008, used 3,360 critical trials across seven sessions; He- In conclusion, smartphones can deliver frequent cogni-
eren et al. 2012, used 2,976 across four sessions) but the tive training sessions. Since CBM-A and control training
smartphone-delivered sessions were spread across numer- may reduce symptoms equally more than waitlist partici-
oussessions(54,onaverage,inprotocolcompleters).Web- pation, these methods warrant further experimental testing
based research methods hold great potential for large, to isolate active ingredients and evaluate their merit for
inexpensive trials, with frequent treatment sessions. Such clinical use by the public.
methods facilitate high statistical power and fidelity of
treatment delivery, which may lead to an advantageous Acknowledgments The authors thank Imke Vonk, Linh Vu, and
JenniferYufortheirassistance,primarilyindatacollection.
cycle of treatment development, testing, and clinical use
(Enock and McNally 2013).
Conflict of Interest Philip M. Enock, Stefan G. Hofmann and
Our study has limitations. We did not conduct formal RichardJ.McNallydeclarethattheyhavenoconflictofinterest.
psychiatricdiagnosticassessmentsofanymentaldisorders,
InformedConsent Allparticipantssignedupthroughthewebsite,
andassessmentswereconfinedtoquestionnaires.Symptom
which described the study in an easy-to-read format (Online Sup-
scores based on participants’ responses suggest that most
plement1).Theyelectronicallyprovidedconsentaftergoingthrough
would be diagnosable with social anxiety disorder, given these pages and a detailed consent form. All procedures were
the proportion exceeding diagnostic screening cutoffs on approvedbyHarvard’sCommitteeontheUseofHumanSubjectsin
Research.
the LSAS-SR. Also, participants had no incentive to
exaggerate symptoms, as there was no financial compen-
Animal Rights No animal studies were carried out by the authors
sation, and we informed recruits that symptoms were not forthisarticle.
required for enrollment. Still, the lack of diagnostic inter-
viewisanimportantlimitationofthisexperimentaldesign,
a choice driven chiefly by feasibility concerns. The fact
References
that participants were seekers of self-directed treatment
makes the study clinically relevant with respect to this
Amir, N., Beard, C., Burns, M., & Bomyea, J. (2009a). Attention
population, as many people seek such treatment irrespec- modification program in individuals with generalized anxiety
tive of any diagnosis. The waitlist group was small as we disorder. Journal of Abnormal Psychology, 118(1), 28–33.
doi:10.1037/a0012589.
added9 monthsafterlaunchingthestudy,butitsinclusion
Amir,N.,Beard,C.,Taylor,C.T.,Klumpp,H.,Elias,J.,Burns,M.,
provided a vital baseline for assessing change in the two
etal.(2009b).Attentiontraininginindividualswithgeneralized
training groups. social phobia: A randomized controlled trial. Journal of
123
CognTherRes(2014)38:200–216 215
Consulting and Clinical Psychology, 77(5), 961–973. doi:10. Damian, M. F. (2010). Does variability in human performance
1037/a0016685. outweigh imprecision in response devices such as computer
Amir, N., Elias, J., Klumpp, H., & Przeworski, A. (2003). keyboards?BehaviorResearchMethods,42(1),205–211.doi:10.
Attentional bias to threat in social phobia: Facilitated 3758/BRM.42.1.205.
processing of threat or difficulty disengaging attention from Eldar,S.,Apter,A.,Lotan,D.,Edgar,K.P.,Fox,N.A.,Pine,D.S.,
threat?BehaviourResearchandTherapy,41(11),1325–1335. etal.(2012).Attentionbiasmodificationtreatmentforpediatric
doi:10.1016/S0005-7967(03)00039-1. anxietydisorders:Arandomizedcontrolledtrial.TheAmerican
Amir,N.,Weber,G.,Beard,C.,Bomyea,J.,&Taylor,C.T.(2008). JournalofPsychiatry,15,213–220.Retrievedfromhttp://www.
Theeffectofasingle-sessionattentionmodificationprogramon ncbi.nlm.nih.gov/pmc/articles/PMC3491316/.
response to a public-speaking challenge in socially anxious Enock, P. M., & McNally, R. J. (2010). Feasibility and efficacy of
individuals.JournalofAbnormalPsychology,117(4),860–868. attentionbiasmodificationviaiPhoneandotherhandhelddevices
doi:10.1037/a0013445. to reduce social anxiety and worry. Unpublished manuscript.
Antony,M.M.,Bieling,P.J.,Cox,B.J.,Enns,M.W.,&Swinson,R. DepartmentofPsychology,HarvardUniversity,Cambridge,MA.
P. (1998). Psychometric properties of the 42-item and 21-item Enock,P.M.,&McNally,R.J.(2013).Howmobileappsandother
versions of the Depression Anxiety Stress Scales in clinical web-based interventions can transform psychological treatment
groups and a community sample. Psychological Assessment, and the treatment development cycle. The Behavior Therapist,
10(2),176–181.doi:10.1037/1040-3590.10.2.176. 36(3), 56, 58, 60, 62–66. Retrieved from http://www.abct.org/
Ataya,A.F.,Adams,S.,Mullings,E.,Cooper,R.M.,Attwood,A.S., docs/PastIssue/36n3.pdf.
& Munafo`, M. R. (2012). Internal reliability of measures of Enock, P. M., Robinaugh, D. J., Reese, H. E., & McNally, R. J.
substance-relatedcognitivebias.DrugandAlcoholDependence, (2012).Improvedreliabilityestimationandpsychometricsofthe
121(1–2),148–151.doi:10.1016/j.drugalcdep.2011.08.023. dot-probe paradigm on smartphones and PC. Poster session
Baker,S.L.,Heinrichs,N.,Kim,H.-J.,&Hofmann,S.G.(2002).The presented at the meeting of The Association of Behavioral and
Liebowitz social anxiety scale as a self-report instrument: A CognitiveTherapies,NationalHarbor,MD.
preliminary psychometric analysis. Behaviour Research and Fox,E.,Russo,R.,Bowles,R.,&Dutton,K.(2001).Dothreatening
Therapy,40(6),701–715.doi:10.1016/S0005-7967(01)00060-2. stimuli draw or hold visual attention in subclinical anxiety?
Bar-Haim, Y., Lamy, D., Pergamin, L., Bakermans-Kranenburg, M. Journal of Experimental Psychology: General, 130(4), 681.
J., & van IJzendoorn, M. H. (2007). Threat-related attentional doi:10.1037//0096-3445.130.4.681.
bias in anxious and nonanxious individuals: A meta-analytic Fresco, D. M., Coles, M. E., Heimberg, R. G., Leibowitz, M. R.,
study. Psychological Bulletin, 133(1), 1–24. doi:10.1037/0033- Hami, S., Stein, M. B., et al. (2001). The Liebowitz Social
2909.133.1.1. AnxietyScale:Acomparisonofthepsychometricpropertiesof
Barlow, D. H., Nock, M. K., & Hersen, M. (2009). Single case self-report and clinician-administered formats. Psychological
experimental designs: Strategies for studying behavior change Medicine,31(6),1025–1035.doi:10.1017/S0033291701004056.
(3rded.).Boston,MA:AllynandBacon. Fresco,D.M.,Mennin,D.S.,Heimberg,R.G.,&Turk,C.L.(2003).
Beard, C., Sawyer, A. T., & Hofmann, S. G. (2012). Efficacy of UsingthePennStateWorryQuestionnairetoidentifyindividuals
attentionbiasmodificationusingthreatandappetitivestimuli:A with generalized anxietydisorder: Areceiveroperating charac-
meta-analyticreview.BehaviorTherapy,43(4),724–740.doi:10. teristicanalysis.JournalofBehaviorTherapyandExperimental
1016/j.beth.2012.01.002. Psychiatry,34(3–4),283–291.doi:10.1016/j.jbtep.2003.09.001.
Boettcher, J., Berger, T., & Renneberg, B. (2012). Internet-based Gee, A. (2011). Therapist-free therapy: Cognitive-bias modification
attention training for social anxiety: A randomized controlled mayputthepsychiatrist’scouchoutofbusiness.TheEconomist.
trial. Cognitive Therapy and Research, 36(5), 522–536. doi:10. Retrievedfromhttp://www.economist.com/node/18276234.
1007/s10608-011-9374-y. Gelman, A., & Hill, J. (2007). Data analysis using regression and
Boettcher, J., Leek, L., Matson, L., Holmes, E., Browning, M., multilevel/hierarchical models (p. 648). New York: Cambridge
MacLeod, C., et al. (2013). Internet-based attention bias UniversityPress.Retrievedfromhttp://www.amazon.com/Analysis-
modification for social anxiety: A randomised controlled com- Regression-Multilevel-Hierarchical-Models/dp/052168689X.
parison of training towards negative and training towards Hakamata, Y., Lissek, S., Bar-Haim, Y., Britton, J. C., Fox, N. A.,
positive cues. PLoS ONE, 8(9), e71760. doi:10.1371/journal. Leibenluft, E., et al. (2010). Attention bias modification
pone.0071760. treatment: A meta-analysis toward the establishment of novel
Browning,M.,Grol,M.,Ly,V.,Goodwin,G.M.,Holmes,E.A.,& treatment for anxiety. Biological Psychiatry. doi:10.1016/j.
Harmer,C.J.(2011).Usinganexperimentalmedicinemodelto biopsych.2010.07.021.
explore combination effects of pharmacological and cognitive Hakamata, Y., Lissek, S., Bar-Haim, Y., Britton, J. C., Fox, N. A.,
interventions for depression and anxiety. Neuropsychopharma- Leibenluft,E.,etal.(2012).Erratum:Attentionbiasmodification
cology,36(13),2689–2697.doi:10.1038/npp.2011.159. treatment: A meta-analysis toward the establishment of novel
Bunnell,B.E.,Beidel,D.C.,&Mesa,F.(2013).Arandomizedtrial treatmentforanxiety.BiologicalPsychiatry,72(5),429.doi:10.
ofattentiontrainingforgeneralizedsocialphobia:Doesattention 1016/j.biopsych.2012.07.015.
trainingchangesocialbehavior?BehaviorTherapy.doi:10.1016/ Hallion,L.S.,&Ruscio,A.M.(2011).Ameta-analysisoftheeffect
j.beth.2013.04.010. of cognitive bias modification on anxiety and depression.
Carlbring, P., Apelstrand, M., Sehlin, H., Amir, N., Rousseau, A., PsychologicalBulletin,137(6),940–958.doi:10.1037/a0024355.
Hofmann, S., et al. (2012). Internet-delivered attention bias Hedman, E., Ljo´tsson, B., Ru¨ck, C., Furmark, T., Carlbring, P.,
modification training in individuals with social anxiety disor- Lindefors,N.,etal.(2010).Internetadministrationofself-report
der—a double blind randomized controlled trial. BMC Psychi- measurescommonlyusedinresearchonsocialanxietydisorder:
atry,12(1),66.doi:10.1186/1471-244X-12-66. A psychometric evaluation. Computers in Human Behavior,
Cox, B. J., Ross, L., Swinson, R. P., & Direnfeld, D. M. (1998). A 26(4),736–740.doi:10.1016/j.chb.2010.01.010.
comparison of social phobia outcome measures in cognitive- Heeren, A., Reese, H. E., McNally, R. J., & Philippot, P. (2012).
behavioral group therapy. Behavior Modification, 22(3), Attentiontrainingtowardandawayfromthreatinsocialphobia:
285–297.doi:10.1177/01454455980223004. Effectsonsubjective,behavioral,andphysiologicalmeasuresof
123
216 CognTherRes(2014)38:200–216
anxiety.BehaviourResearchandTherapy,50(1),30–39.doi:10. Statistical Computing. Retrieved from http://cran.r-project.org/
1016/j.brat.2011.10.005. web/packages/nlme.
Heimberg, R. G., Mueller, G. P., Holt, C. S., Hope, D. A., & RDevelopmentCoreTeam.(2012).R:Alanguageandenvironment
Liebowitz, M. R. (1992). Assessment of anxiety in social forstatisticalcomputing.Vienna.Retrievedfromhttp://www.r-
interactionandbeingobservedbyothers:Thesocialinteraction project.org/.
anxiety scale and the Social Phobia Scale. Behavior Therapy, Rodebaugh,T.L.,Woods,C.M.,&Heimberg,R.G.(2007).Thereverse
23(1),53–73.doi:10.1016/S0005-7894(05)80308-9. of social anxiety is not always the opposite: The reverse-scored
Li, S., Tan, J., Qian, M., & Liu, X. (2008). Continual training of itemsofthesocialinteractionanxietyscaledonotbelong.Behavior
attentional bias in social anxiety. Behaviour Research and Therapy,38(2),192–206.doi:10.1016/j.beth.2006.08.001.
Therapy,46(8),905–912.doi:10.1016/j.brat.2008.04.005. Rytwinski, N. K., Fresco, D. M., Heimberg, R. G., Coles, M. E.,
Liebowitz, M. R. (1987). Social phobia. Modern Problems of Liebowitz, M. R., & Cissell, S. (2009). Screening for social
Pharmacopsychiatry,22,141–173. anxiety disorder with the self-report version of the Liebowitz
Lovibond, S. H., & Lovibond, P. F. (1995). Manual for the Social Anxiety Scale. Depression and Anxiety, 26(1), 34–38.
DepressionAnxietyStressScales(2nded.).Sydney:Psychology doi:10.1002/da.20503.
Foundation. Sawyer, A. T., Whitfield-Gabrieli, S., Gabrieli, J. D. E., Amir, N.,
MacLeod, C. (1995). Training selective attention: A cognitive- Fang,A.,Richey,A.,etal.(2012).AttentionretraininginSAD:
experimental technique for reducing anxiety vulnerability? In Treatmentoutcomeandneurobiologicalcorrelates.InA.Asna-
Worldcongressofbehaviouralandcognitivetherapies(p.118). ani & A. T. Sawyer (Chairs), Modifying cognitive biases:
MacLeod, C., Mathews, A., & Tata, P. (1986). Attentional bias in Emergingdataonapplicationsandeffectsonclinicaldisorders.
emotional disorders. Journal of Abnormal Psychology, 95(1), Symposium conducted at the meeting of The Association of
15–20.doi:10.1037/0021-843X.95.1.15. BehavioralandCognitiveTherapies,NationalHarbor,MD.
MacLeod, C., Rutherford, E., Campbell, L. W., Ebsworthy, G., & Schmidt, N. B., Richey, J. A., Buckner, J. D., & Timpano, K. R.
Holker,L.(2002).Selectiveattentionandemotionalvulnerability: (2009).Attentiontrainingforgeneralizedsocialanxietydisorder.
Assessing the causal basis of their association through the Journal of Abnormal Psychology, 118(1), 5–14. doi:10.1037/
experimentalmanipulationofattentionalbias.JournalofAbnormal a0013643.
Psychology,111(1),107–123.doi:10.1037/0021-843X.111.1.107. Schmukle,S.C.(2005).Unreliabilityofthedotprobetask.European
MacLeod, C., Soong, L. Y., Rutherford, E. M., & Campbell, L. W. JournalofPersonality,19(7),595–605.doi:10.1002/per.554.
(2007). Internet-delivered assessment and manipulation of SPSS Inc. (2009). PASW Statistics for Windows, Version 18.0.
anxiety-linked attentional bias: Validation of a free-access Chicago: SPSS Inc. http://www-01.ibm.com/support/docview.
attentionalprobesoftwarepackage.BehaviorResearchMethods, wss?uid=swg21476197
39(3), 533–538. Retrieved from http://www.ncbi.nlm.nih.gov/ Staugaard,S.R.(2009).Reliabilityoftwoversionsofthedot-probe
pubmed/17958165. task using photographic faces. Psychology Science Quarterly,
Matsumoto,D.,&Ekman,P.(1988).JapaneseandCaucasianFacial 51(3),339–350.
Expressions of Emotion (JACFEE) and Neutral Faces (JAC- Ulrich,R.,&Giray,M.(1989).Timeresolutionofclocks:Effectson
NeuF).SanFrancisco,CA:InterculturalandEmotionResearch reaction time measurement-Good news for bad clocks. British
Laboratory, Department of Psychology, San Francisco State Journal of Mathematical and Statistical Psychology, 42(1),
University. 1–12.doi:10.1111/j.2044-8317.1989.tb01111.x.
Mattick, R., & Clarke, J. C. (1998). Development and validation of Waechter, S., Nelson, A. L., Wright, C., Hyatt, A., & Oakman, J.
measures of social phobia scrutiny fear and social interaction (2013). Measuring attentional bias to threat: Reliability of dot
anxiety. Behaviour Research and Therapy, 36(4), 455–470. probe and eye movement indices. Cognitive Therapy and
doi:10.1016/S0005-7967(97)10031-6. Research.doi:10.1007/s10608-013-9588-2.
McNally, R. J., Enock, P. M., Tsai, C., & Tousian, M. (2013). Wald,I.,Lubin,G.,Holoshitz,Y.,Muller,D.,Fruchter,E.,Pine,D.
Attentionbiasmodificationforreducingspeechanxiety.Behav- S., et al. (2011). Battlefield-like stress following simulated
iourResearchandTherapy,51(12),882–888.doi:10.1016/j.brat. combatandsuppressionofattentionbiastothreat.Psychological
2013.10.001. Medicine,41(4),699–707.doi:10.1017/S0033291710002308.
Meyer,T.J.,Miller,M.L.,Metzger,R.L.,&Borkovec,T.D.(1990). Watson, D., & Friend, R. (1969). Measurement of social-evaluative
DevelopmentandvalidationofthePennStateWorryQuestion- anxiety. Journal of Consulting and Clinical Psychology, 33(4),
naire.BehaviourResearchandTherapy,28(6),487–495.doi:10. 448–457.doi:10.1037/h0027806.
1016/0005-7967(90)90135-6. Wells,T.,&Beevers,C.G.(2010).Biasedattentionanddysphoria:
Neubauer,K.,vonAuer,M.,Murray,E.,Petermann,F.,Helbig-Lang, Manipulating selective attention reduces subsequent depressive
S., & Gerlach, A. L. (2013). Internet-delivered attention symptoms. Cognition and Emotion, 24(4), 719–728. doi:10.
modification training as a treatment for social phobia: A 1080/02699930802652388.
randomized controlled trial. Behaviour Research and Therapy, Zlomke,K.R.(2009).Psychometricpropertiesofinternetadministered
51(2),87–97.doi:10.1016/j.brat.2012.10.006. versionsofPennStateWorryQuestionnaire(PSWQ)andDepres-
Pinheiro,J.,Bates,D.,DebRoy,S.,&Sarkar,D.(2010).nlme:Linear sion, Anxiety, and Stress Scale (DASS). Computers in Human
and nonlinear mixed effects models. Vienna: R Foundation for Behavior,25(4),841–843.doi:10.1016/j.chb.2008.06.003.
123
